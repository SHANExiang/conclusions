
Golang 
go 代码编写到扩展名为.go 的文件中，通过 go build 命令对该 go 文件进行编译，
生成.exe 文件，之后执行.exe 文件即可看到运行的效果； 
通过 go run 命令可以直接运行.go 程序。 
 
行注释 //  
块注释 /* */ 
 
变量 
变量相当于内存中一个数据存储空间的表示。 
变量使用三种方式： 
1. 指定变量类型，声明后若不赋值，使用默认值；var i, j, k int；声明变量 
2. 根据值自行判断变量类型；var num1, s1 = 1.1, “string”  初始化变量 
3. 省略 var；name := “tom”; 等价于 var name string  name = “tom” 给变量赋值 
 
变量不能改变数据类型，变量在同一个作用域内(在一个函数或者代码块)内不能
重名； 
 
go 数据类型 
 
基本数据类型转成 string 
s = fmt.Sprintf(“%d”, num) 
值类型：基本数据类型 int 系列，float 系列，bool，string，数组和结构体 struct； 
引用类型：指针，slice 切片，map，管道 chan，interface 等 
 
package 名和其所在的目录名字一样； 
变量名、函数名、常量名采用驼峰法； 
如果变量名、函数名、常量名首字母大写，则可以被其他的包访问；如果小写，
则只能在本包内使用； 
 
 
多分支 
if 条件表达式 { 
} else if { 
} 
else { 
} 
 
switch 用法 
switch 表达式 { 
case 表达式 1，表达式 2，…： 
语句块 
default: 
    语句块 
} 
 
for 循环 
for 循环变量初始化；循环条件；循环变量迭代 { 
    循环语句 
} 
或 
j := 0 
for j < 10 { 
fmt.Printf(“%v”, j) 
j++ 
} 
for-range 用法 
    var s string = "dong is a genius!" 
    for index, val := range s { 
        fmt.Printf("%d===%c\n", index, val) 
    } 
 
init 函数 
每个源文件都可以包含一个 init 函数，该函数会在 main 函数执行前调用； 
如果 main.go 和 util.go 都含有变量定义，执行顺序是 util.go 中的变量定义init
函数main.go 中的变量定义init 函数main 函数 
 
 
 
 
 
匿名函数 
1. 在定义匿名函数时就直接调用； 
2. 将匿名函数赋给一个变量，再通过该变量来调用匿名函数； 
3. 全局匿名函数； 
 
 
 

 
3. 计算机网络 
简单一次完整的 HTTP 请求所经历的步骤？ 
1、DNS 解析，通过访问的域名找出其 IP 地址，具体过程包括浏览器搜索自身的
DNS 缓存、搜索操作系统的 DNS 缓存、读取本地的 Host 文件和向本地 DNS 服
务器进行查询等，如果本地域名服务器并未缓存该网址映射关系，那么将根据其
设置发起递归查询或者迭代查询； 
2、HTTP 请求，当输入一个请求时，建立一个 Socket 连接发起 TCP 的 3 次握手。 
如果是 HTTPS 请求，会略微有不同； 
3.1、客户端向服务器发送请求命令（一般是 GET 或 POST 请求）。客户端的网
络层不用关心应用层或者传输层的东西，主要做的是通过查找路由表确定如何 
到达服务器，期间可能经过多个路由器，就是通过查找路由表决定通过那个路径
到达服务器。客户端的链路层，包通过链路层发送到路由器，通过邻居协议查找
给定 IP 地址的 MAC 地址，然后发送 ARP 请求查找目的地址，如果得到回应后
就可以使用 ARP 的请求应答交换的 IP 数据包现在就可以传输了，然后发送 IP 
数据包到达服务器的地址； 
3.2、客户端发送请求头信息和数据。  
4.1、服务器发送应答头信息。 
4.2、服务器向客户端发送数据。  
5、服务器关闭 TCP 连接（4 次挥手）。这里是否关闭 TCP 连接，也根据 HTTP 
Keep-Alive 机制有关。 同时，客户端也可以主动发起关闭 TCP 连接。 
6、客户端根据返回的 HTML、CSS、JS 进行渲染。 
 
 
 
 
 
 
详细讲一下拥塞控制 
TCP 一共使用了四种算法来实现拥塞控制： 
慢开始 (slow-start)； 
拥塞避免 (congestion avoidance)； 
快速重传 (fast retransmit)； 
快速恢复 (fast recovery)。 
发送方维持一个叫做拥塞窗口 cwnd（congestion window）的状态变量。当
cwndssthresh 时，改用拥塞避免算法。 
慢开始：不要一开始就发送大量的数据，由小到大逐渐增加拥塞窗口的大小。 
拥塞避免：拥塞避免算法让拥塞窗口缓慢增长，即每经过一个往返时间 RTT 就
把发送方的拥塞窗口 cwnd 加 1 而不是加倍。这样拥塞窗口按线性规律缓慢增长。 
快重传：我们可以剔除一些不必要的拥塞报文，提高网络吞吐量。比如接收方在
收到一个失序的报文段后就立即发出重复确认，而不要等到自己发送数据时捎带
确认。快重传规定：发送方只要一连收到三个重复确认就应当立即重传对方尚未
收到的报文段，而不必继续等待设置的重传计时器时间到期。 
快恢复：主要是配合快重传。当发送方连续收到三个重复确认时，就执行“乘法
减小”算法，把 ssthresh 门限减半（为了预防网络发生拥塞），但接下来并不执行
慢开始算法，因为如果网络出现拥塞的话就不会收到好几个重复的确认，收到三
个重复确认说明网络状况还可以。 
 
 
TCP 中的流量控制和拥塞控制 
流量控制 
如果发送者发送数据过快，接收者来不及接收，那么就会出现分组丢失，为了避
免分组丢失，控制发送者的发送速度，使得接收者来得及接收，这就是流量控制。 
流量控制的目的是：防止分组丢失，是构成 TCP 可靠性的一方面。 
如何实现流量控制 
由滑动窗口协议（连续 ARQ 协议）实现，滑动窗口协议即保证了分组无差错，
有序接收，也实现了流量控制。主要的方式就是接收方返回的 ACK 会包含自己
的接受窗口大小，并利用大小来控制发送方的数据发送。 
拥塞控制 
拥塞控制是作用于网络的，它是防止过多的数据注入网络，避免出现网络负载过
大的情况，常见的方法就是慢开始、避免拥塞、快重传、快恢复； 
 
 


 
 
对称加密 
对称加密是指加密和解密都使用的同一个密钥， 
一方通过密钥将信息加密后，把密文传给另一个方，另一方通过这个相同的密钥
将密文解密，转换成可以理解的明文。他们之间的关系如下 
明文 -> 密钥 -> 密文 
这种方式存在的最大的问题就是密钥发送问题，即如何安全的将密钥发送给对方。 
 
非对称加密 
上面提到的是对称加密，其实还有一种是非对称加密，非对称加密是通过两个密
钥（公钥-私钥）来实现对数据的加密和解密的，公钥用于加密，私钥用于解密。 
 
过程如下： 
首先服务器会颁发一个公钥放在网络中，同时它自己还有一份私钥，然后客户端
可以直接获取到对应的公钥，然后将客户端的数据进行公钥的加密，加密后传输
的服务器中，服务器在进行私钥解密，得到最终的数据。 
 
由于非对称加密的方式不需要发送用来解密的私钥，所以可以保证安全性，但是
和对称加密比起来，它非常慢，所以我们还是要用对称加密来传送消息，但是对
称加密使用的密钥我们通过非对称加密的方式发送出去。这个结果就变成了： 
 
但是我们需要注意的是，此时交换的两个公钥不一定正确，因为可能会被中间人
截获，同时掉包 
例如：中间人虽然不知道小红的私钥是什么，但是在截获了小红的公钥 Key1 之
后，却可以偷天换日，自己另外生成一对公钥私钥，把自己的公钥 Key3 发送给
小灰。 
 
这一次通信再次被中间人截获，中间人先用自己的私钥解开了 Key3 的加密，获
得 Key2，然后再用当初小红发来的 Key1 重新加密，再发给小红 
 
 
证书机制 
这个时候我们需要做的就是从指定的机构出获取公钥，而不是任由其在网络传输 
 
作为服务器端的小红，首先先把自己的公钥给证书颁发机构，向证书颁发机构申
请证书 
 
证书颁发机构自己也有一堆公钥和私钥。机构利用自己的私钥来解密 Key1，通
过服务端网址等信息生成一个证书签名，证书签名同样经过机构的私钥加密。证
书制作完成后，机构把证书发送给服务端的小红。 
 
当小灰向小红请求通信的时候，小红不再直接返回自己的公钥，而是把自己申请
的证书返回给小灰。 
 
小灰收到证书以后，要做的第一件事就是验证证书的真伪，需要说明的是，各大
浏览器和操作系统已经维护了所有权威证书机构的名称和公钥，所以小灰只需要
知道是哪个机构颁发的证书，就可以从本地找到对应的机构公钥，解密出证书签
名。 
 
 
 
大流量 tcp 和 http 连接怎么排查 
tcpdump 
tcpdump 可以将网络中传送的数据包的头完全截取下来提供分析。它支持针对
网络层、协议、主机、网络或者端口的过滤。 
-n 禁止 IP 名称解析。  
-nn 禁止 IP 和端口名称解析。 
-i 指定捕获哪个网卡的网络数据包。  
-w 指定将包写入哪个文件，如果文件不存在则创建该文件；如果存在则覆盖其
内容。  
-f 指定过滤表达式，例如指定捕获哪个端口，哪个协议等。  
-r 指定从哪个文件读取网络数据包文件。  
-F 指定使用哪个文件的过滤表达式抓包。  
-D 列出所有可以使用 tcpdump 抓包的网卡。  
-c 指定捕获或者读取包的个数，-c 后面直接接数字即可。  
-l 抓包时保存到文件的同时查看包的内容。  
-t 不打印时间戳。 -tt 秒级时间戳。 -ttt 打印时间戳到微秒或者纳秒，取决于 –
time-stamp-precision option 选项。  
-s 指定每个包捕获的字节数。-s0 将不限制大小，如果想捕获完整的包可以这么
设置。 -S 打印绝对的 tcp 序列号，而不是相对的序列号。  
-v/-vv/-vvv 打印详细信息，v 的个数越多， 打印内容越详细。 
 
什么是 SYN 洪泛攻击？如何防范？ 
SYN 洪泛攻击属于 DOS 攻击的一种，它利用 TCP 协议缺陷，通过发送大量的
半连接请求，耗费 CPU 和内存资源。 
原理： 
• 
在三次握手过程中，服务器发送 [SYN/ACK] 包（第二个包）之后、收到客
户端的 [ACK] 包（第三个包）之前的 TCP 连接称为半连接（half-open connect），
此时服务器处于 SYN_RECV（等待客户端响应）状态。如果接收到客户端的 
[ACK]，则 TCP 连接成功，如果未接受到，则会不断重发请求直至成功。 
• 
SYN 攻击的攻击者在短时间内伪造大量不存在的 IP 地址，向服务器不断
地发送 [SYN] 包，服务器回复 [SYN/ACK] 包，并等待客户的确认。由于源地
址是不存在的，服务器需要不断的重发直至超时。 
• 
这些伪造的 [SYN] 包将长时间占用未连接队列，影响了正常的 SYN，导致
目标系统运行缓慢、网络堵塞甚至系统瘫痪。 
检测：当在服务器上看到大量的半连接状态时，特别是源 IP 地址是随机的，基
本上可以断定这是一次 SYN 攻击。 
防范： 
• 
通过防火墙、路由器等过滤网关防护。 
• 
通过加固 TCP/IP 协议栈防范，如增加最大半连接数，缩短超时时间。 
• 
SYN cookies 技术。SYN Cookies 是对 TCP 服务器端的三次握手做一些修
改，专门用来防范 SYN 洪泛攻击的一种手段。 
 
ISN 代表什么？意义何在？ 
ISN，发送方的字节数据编号的原点，让对方生成一个合法的接收窗口。 
ISN 是固定不变的吗？动态随机。 
 
什么是网络编程  
网络编程的本质是多台计算机之间的数据交换。数据传递本身没有多大的难度，
不就是把一个设备 中的数据发送给其他设备，然后接受另外一个设备反馈的数
据。现在的网络编程基本上都是基于请 求/响应方式的，也就是一个设备发送请
求数据给另外一个，然后接收另一个设备的反馈。在网络编程中，发起连接程序，
也就是发送第一次请求的程序，被称作客户端(Client)，等待其他程序连接 的程
序被称作服务器(Server)。客户端程序可以在需要的时候启动，而服务器为了能够
时刻相应连 接，则需要一直启动。 
网络编程中两个主要的问题 
1、一个是如何准确的定位网络上一台或多台主机，  
2、另一个就是找到主机后如何可靠高效的进行数据传输。  
在 TCP/IP 协议中 IP 层主要负责网络主机的定位，数据传输的路由，由 IP 地址
可以唯一地确定 Internet 上的一台主机。 
而 TCP 层则提供面向应用的可靠（TCP）的或非可靠（UDP）的数据传输机制，
这是网络编程的主 要对象，一般不需要关心 IP 层是如何处理数据的。 目前较
为流行的网络编程模型是客户机/服务器（C/S）结构。即通信双方一方作为服务
器等待客户 提出请求并予以响应。客户则在需要服务时向服务器提 出申请。服
务器一般作为守护进程始终运 行，监听网络端口，一旦有客户请求，就会启动
一个服务进程来响应该客户，同时自己继续监听服 务端口，使后来的客户也 能
及时得到服务。 
 
 
为什么网络要分层？ 
说到分层，我们先从我们平时使用框架开发一个后台程序来说，我们往往会按照
每一层做不 同的事情的原则将系统分为 三层（复杂的系统分层可能会更多）: 
Repository（数据库操作） 
Service（业务操作） 
Controller（数据交互） 
网络分层的原则：每一层独立于其它层完成自己的工作，而不需要相互依赖，上
下层之间通 过标准结构来互相通信，简单易用又具有拓展性。复杂的系统需要
分层，因为每一层都需要专注于一类事情。我们的网络分层的原因也是一 样，
每一层只专注于做一类事情。 
为什么计算机网络要分层呢？ ,我们再来较为系统的说一说： 
1. 各层之间相互独立：各层之间相互独立，各层之间不需要关心其他层是如何实现
的，只 需要知道自己如何调用下层提供好的功能就可以了（可以简单理解为接
口调用）。这个 和我们对开发时系统进行分层是一个道理。 
2. 提高了整体灵活性 ：每一层都可以使用最适合的技术来实现，你只需要保证你
提供的功能以及暴露的接口的规则没有改变就行了。这个和我们平时开发系统的
时候要求的高内 聚、低耦合的原则也是可以对应上的。 
3. 大问题化小 ：分层可以将复杂的网络间题分解为许多比较小的、界线比较清晰
简单的小问题来处理和解决。这样使得复杂的计算机网络系统变得易于设计，实
现和标准化。这 个和我们平时开发的时候，一般会将系统功能分解，然后将复
杂的问题分解为容易理解 的更小的问题是相对应的，这些较小的问题具有更好
的边界（目标和接口）定义。 
 
 
IP 地址分为几类，每类都代表什么，私网是哪些？  
大致上分为公共地址和私有地址两大类，公共地址可以在外网中随意访问，私有
地址只能在内网访 问只有通过代理服务器才可以和外网通信。  
公共地址： 1.0.0.1～126.255.255.254 128.0.0.1～191.255.255.254 192.0.0.1～
223.255.255.254 224.0.0.1～239.255.255.254 240.0.0.1～255.255.255.254  
私有地址： 10.0.0.0～10.255.255.255 172.16.0.0～172.31.255.255 192.168.0.0～
192.168.255.255 0.0.0.0 路由器转发使用  
127.x.x.x 保留  
255.255.255.255 局域网下的广播地址 
cidrs 
cidrs 地址计算 
当给定一个 IP 地址，比如 18.232.133.86/22，需要求一下这个 IP 所在网络的网络地址、
子网掩码、广播 i 地址、 
这个网络的第一台主机的 IP 地址： 
斜线后是 22 并不是 8 的整数倍，直接很难看出结果，所以需要通过一系列的计算。 
1.先用 8 的整数倍对 22 进行切割：22=16+6 ，所以这个 IP 地址的前 16 位保持不动即
18.232. 
2.发现问题出在了第三个 8 位上，这 8 位中前面 6 位被拿来做了网络号，后面 2 位被拿
去做了主机号， 
所以将这 8 位转化为二进制得到 10000101，拿出前 6 位为<100001>。这是得到了全部
的网络号为 18.232.<100001> 
3.将主机号全部置 0 便是网络地址，18.232.<100001><00>.<00000000>即网络地址为
18.232.132.0 
4.同时也得到了这个网络的第一台主机的 ip 地址，18.232.<100001><00>.<00000001>即
18.232.132.1 
5.将主机位全部置 1 便是广播地址，18.232.<100001><11>.<11111111>即 18.232.135.255 
6.子网掩码可以直接使用 22 计算即可，即前 22 位都为 1，其余为 0，即 255.255.252.0 
再举一例: 
10.42.115.24/20 
表示前面 20 位都是网路号，前 16 位固定，10.42 网段的，在这 115 用二进制表示位
01110011，再前 4 位固定， 
也就是说最小的主机 ip 地址位 10.42.112.0，后面 12 位全为 1 时，即最大主机号位
10.42.127.255。 
 
IPv6 的 128 位地址通常写成 8 组，每组为四个十六进制数的形式。 
 
 
 
============================================================= 
HTTP 报文详解？详细说一下请求报文，以及 HTTP 和 TCP 的区别 
HTTP 有两种报文：请求报文和响应报文 HTTP 请求报文主要包括请求行、请求
头部以及请求的数据（实体）三部分请求行（HTTP 请求报文的第一行）请求行
由方法字段、URL 字段和 HTTP 协议版本字段。其中，方法字段严格区分大小
写，当前 HTTP 协议中的方法都是大写，方法字段如下介绍如下： 
请求头部：位于请求行的下面, 是一个个的 key-value 值 
空行(CR+LF)：请求报文用空行表示 header 和请求数据的分隔 请求数据：GET
方法没有携带数据， POST 方法会携带一个 body 
HTTP 的响应报文包括：状态行，响应头部，相应的数据(响应体) 
状态行包括：HTTP 版本号，状态码和状态值组成。响应头类似请求头，是一系
列 key-value 值 
空白行：同上，响应报文也用空白行来分隔 header 和数据 响应体：响应的数据 
HTTP 请求报文和响应报文的格式？ 
请求报文格式： 
1. 请求行（请求方法+URI 协议+版本） 
2. 请求头部 
3. 空行 
4. 请求主体 
GET/sample.jspHTTP/1.1 请求行 
Accept:image/gif.image/jpeg, 请求头部 
Accept-Language:zh-cn 
Connection:Keep-Alive 
Host:localhost 
User-Agent:Mozila/4.0(compatible;MSIE5.01;Window NT5.0) 
Accept-Encoding:gzip,deflate 
 
username=jinqiao&password=1234 请求主体 
响应报文： 
1. 状态行（版本+状态码+原因短语） 
2. 响应首部 
3. 空行 
4. 响应主体 
HTTP/1.1 200 OK 
Server:Apache Tomcat/5.0.12 
Date:Mon,6Oct2003 13:23:42 GMT 
Content-Length:112 
 
<html> 
    <head> 
        <title>HTTP 响应示例<title> 
    </head> 
    <body> 
        Hello HTTP! 
    </body> 
</html> 
说说 HTTP 协议与 TCP/IP 协议的关系  
HTTP 的长连接和短连接本质上是 TCP 长连接和短连接。 HTTP 属于应用层协
议，在传输层使用 TCP 协议，在网络层使用 IP 协议。 IP 协议主要解决网络路
由和寻址问题， TCP 协议主要解决如何在 IP 层之上可靠地传递数据包，使得网
络上接收端收到发送端所发出的所有包，并且顺序与发送顺序一致。TCP 协议是
可靠的、面向连接的。 
如何理解 HTTP 协议是无状态的？  
HTTP 协议是无状态的，指的是协议对于事务处理没有记忆能力，服务器不知道
客户端是什么状态。 也就是说，打开一个服务器上的网页和上一次打开这个服
务器上的网页之间没有任何联系。HTTP 是 一个无状态的面向连接的协议，无
状态不代表 HTTP 不能保持 TCP 连接，更不能代表 HTTP 使用的是 UDP 协议
（无连接）。 
 
长连接和短连接的优缺点？  
长连接可以省去较多的 TCP 建立和关闭的操作，减少浪费，节约时间 。对于频
繁请求资源的客户来 说，较适用长连接。不过这里存在一个问题，存活功能的
探测周期太长，还有就是它只是探测 TCP 连接的存活，属于比较斯文的做法，
遇到恶意的连接时，保活功能就不够使了。在长连接的应用场 景下，client 端一
般不会主动关闭它们之间的连接，Client 与 server 之间的连接如果一直不关闭的 
话，会存在一个问题，随着客户端连接越来越多，server 早晚有扛不住的时候，
这时候 server 端需 要采取一些策略，如关闭一些长时间没有读写事件发生的连
接，这样可 以避免一些恶意连接导致 server 端服务受损；如果条件再允许就可
以以客户端机器为颗粒度，限制每个客户端的最大长连接 数，这样可以完全避
免某个蛋疼的客户端连累后端服务。 短连接对于服务器来说管理较为简单，存
在的连接都是有用的连接，不需要额外的控制手段。但如 果客户请求频繁，将
在 TCP 的建立和关闭操作上浪费时间和带宽。 
说说长连接短连接的操作过程  
短连接的操作步骤是：建立连接——数据传输——关闭连接...建立连接——数据
传输——关闭连 接长连接的操作步骤是：建立连接——数据传输...（保持连接）...
数据传输——关闭连接 
如何将长链接转换成短链接，并发送短信？  
短 URL 从生成到使用分为以下几步： 有一个服务,将要发送给你的长 URL 对
应到一个短 URL 上.例如 www.baidu.com -> www.t.cn/ 1。 把短 url 拼接到短
信等的内容上发送。 用户点击短 URL ,浏览器用 301 / 302 进行重定向,访问到
对应的长 URL。 展示对应的内容。  
长链接和短链接如何互相转换？  
思路是建立一个发号器。每次有一个新的长 URL 进来，我们就增加一。并且将
新的数值返回.第一 个来的 url 返回"www.x.cn/0",第二个返回"www.x.cn/1"。  
长链接和短链接的对应关系如何存储？  
如果数据量小且 QPS 低，直接使用数据库的自增主键就可以实现。 还可以将
最近/最热门的对应关 系存储在 K-V 数据库中,这样子可以节省空间的同时,加
快响应速度。 
# Accept:指浏览器或其他客户可以接爱的 MIME 文件格式。可以根据它判断并返回适当
的文件格式。 
# Accept-Charset：指出浏览器可以接受的字符编码。英文浏览器的默认值是 ISO-8859-
1. 
# Accept-Language：指出浏览器可以接受的语言种类，如 en 或 en-us，指英语。 
# Accept-Encoding：指出浏览器可以接受的编码方式。编码方式不同于文件格式，它是
为了压缩文件并加速文件传递速度。浏览器在接收到 Web 响应之后先解码，然后再检
查文件格式。 
# Cache-Control：设置关于请求被代理服务器存储的相关选项。一般用不到。 
# Connection：用来告诉服务器是否可以维持固定的 HTTP 连接。HTTP/1.1 使用 Keep-
Alive 为默认值，这样，当浏览器需要多个文件时(比如一个 HTML 文件和相关的图形文
件)，不需要每次都建立连接。 
# Content-Type ： 用 来 表 名 request 的 内 容 类 型 。 可 以 用 HttpServletRequest 的
getContentType()方法取得。 
# Cookie：浏览器用这个属性向服务器发送 Cookie。Cookie 是在浏览器中寄存的小型数
据体，它可以记载和服务器相关的用户信息，也可以用来实现会话功能。 
 
 
 
# 浏览器向服务器发送的请求格式如下： 
GET / HTTP/1.1 
Host: www.baidu.com 
Connection: keep-alive 
Cache-Control: max-age=0 
Upgrade-Insecure-Requests: 1 
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, 
like Gecko) Chrome/88.0.4324.190 Safari/537.36 
Accept: 
text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*
/*;q=0.8,application/signed-exchange;v=b3;q=0.9 
Sec-Fetch-Site: none 
Sec-Fetch-Mode: navigate 
Sec-Fetch-User: ?1 
Sec-Fetch-Dest: document 
Accept-Encoding: gzip, deflate, br 
Accept-Language: zh,zh-TW;q=0.9,en-US;q=0.8,en;q=0.7,zh-CN;q=0.6 
Cookie: 
__yjs_duid=1_c940e71be451d3762878fbddc4c2e2141614435162110; 
BAIDUID=6E788B30D916990EF40140461FD2CD6E:FG=1; 
BAIDUID_BFESS=6E788B30D916990E3A8E1C6C2313936A:FG=1; 
BIDUPSID=6E788B30D916990EF40140461FD2CD6E; 
PSTM=1614773571; 
BD_HOME=1; 
H_PS_PSSID=33512_33272_31253_33594_33570_33601_26350; 
BD_UPN=12314753; BA_HECTOR=al0k00250ha10kah971g3uvfq0r 
     
# User-Agent 为浏览器版本； 
     
# 服务器向浏览器返回格式：     
HTTP/1.1 200 OK 
Bdpagetype: 1 
Bdqid: 0xfd3c646400008152 
Cache-Control: private 
Connection: keep-alive 
Content-Encoding: gzip 
Content-Type: text/html;charset=utf-8 
Date: Wed, 03 Mar 2021 12:17:50 GMT 
Expires: Wed, 03 Mar 2021 12:17:50 GMT 
Server: BWS/1.1 
Set-Cookie: BDSVRTM=23; path=/ 
Set-Cookie: BD_HOME=1; path=/ 
Set-Cookie: 
H_PS_PSSID=33512_33272_31253_33594_33570_33601_26350; 
path=/; 
domain=.baidu.com 
Strict-Transport-Security: max-age=172800 
Traceid: 1614773870073621863418247570170857947474 
X-Ua-Compatible: IE=Edge,chrome=1 
Transfer-Encoding: chunked 
Http 和 Https 的区别 
超文本传输协议 HTTP 协议被用于在 Web 浏览器和网站服务器之间传递信息，
HTTP 协议以明文方式发送内容，不提供任何方式的数据加密 
安全套接字层超文本传输协议 HTTPS，为了数据传输的安全，HTTPS 在 HTTP
的基础上加入了 SSL（Secure Sockets Layer 安全套接层）协议，SSL 依靠证书
来验证服务器的身份，并为浏览器和服务器之间的通信加密。 
http 和 https 使用的是完全不同的连接方式，用的端口也不一样，前者是 80，后
者是 443。 
什么是 Cookie 和 Session ? 
什么是 Cookie 
HTTP Cookie（也叫 Web Cookie 或浏览器 Cookie）是服务器发送到用户浏览器
并保存在本地的一小块数据，它会在浏览器下次向同一服务器再发起请求时被携
带并发送到服务器上。通常，它用于告知服务端两个请求是否来自同一浏览器，
如保持用户的登录状态。Cookie 使基于无状态的 HTTP 协议记录稳定的状态信
息成为了可能。 
Cookie 主要用于以下三个方面： 
 
会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息） 
 
个性化设置（如用户自定义设置、主题等） 
 
浏览器行为跟踪（如跟踪分析用户行为等） 
什么是 Session 
Session 代表着服务器和客户端一次会话的过程。Session 对象存储特定用户会
话所需的属性及配置信息。这样，当用户在应用程序的 Web 页之间跳转时，存
储在 Session 对象中的变量将不会丢失，而是在整个用户会话中一直存在下去。
当客户端关闭会话，或者 Session 超时失效时会话结束。 
Cookie 和 Session 是如何配合的呢？ 
用户第一次请求服务器的时候，服务器根据用户提交的相关信息，创建对应的 
Session ，请求返回时将此 Session 的唯一标识信息 SessionID 返回给浏览器，
浏览器接收到服务器返回的 SessionID 信息后，会将此信息存入到 Cookie 中，
同时 Cookie 记录此 SessionID 属于哪个域名。 
当用户第二次访问服务器的时候，请求会自动判断此域名下是否存在 Cookie 信
息，如果存在自动将 Cookie 信息也发送给服务端，服务端会从 Cookie 中获取 
SessionID，再根据 SessionID 查找对应的 Session 信息，如果没有找到说明用户
没有登录或者登录失效，如果找到 Session 证明用户已经登录可执行后面操作。 
根据以上流程可知，SessionID 是连接 Cookie 和 Session 的一道桥梁，大部分
系统也是根据此原理来验证用户登录状态。 
如何考虑分布式 Session 问题？ 
在互联网公司为了可以支撑更大的流量，后端往往需要多台服务器共同来支撑前
端用户请求，那如果用户在 A 服务器登录了，第二次请求跑到服务 B 就会出
现登录失效问题。 
分布式 Session 一般会有以下几种解决方案： 
 
客户端存储：直接将信息存储在 cookie 中，cookie 是存储在客户端上的一小段数
据，客户端通过 http 协议和服务器进行 cookie 交互，通常用来存储一些不敏感
信息 
 
Nginx ip_hash 策略：服务端使用 Nginx 代理，每个请求按访问 IP 的 hash 分
配，这样来自同一 IP 固定访问一个后台服务器，避免了在服务器 A 创建 
Session，第二次分发到服务器 B 的现象。 
 
Session 复制：任何一个服务器上的 Session 发生改变（增删改），该节点会把
这个 Session 的所有内容序列化，然后广播给所有其它节点。 
 
共享 Session：服务端无状态话，将用户的 Session 等信息使用缓存中间件（如
Redis）来统一管理，保障分发到每一个服务器的响应结果都一致。 
建议采用共享 Session 的方案。 
cookie 和 session 的区别 
1，session 在服务器端，cookie 在客户端（浏览器） 
2、session 的运行依赖 session id，而 session id 是存在 cookie 中的，也就是说，
如果浏览器禁用了 cookie ，同时 session 也会失效，存储 Session 时，键与 Cookie
中的 sessionid 相同，值是开发人员设置的键值对信息，进行了 base64 编码，过
期时间由开发人员设置 
3、cookie 安全性比 session 差 
4、session 默认存在服务器上的文件里面（也可以是内存，数据库）； 
5、用户验证通常会用 session，维持一个会话核心就是客户端的唯一标识，即
session_id 
Session,Cookie 的理解 
为什么要使用会话管理 
众所周知，HTTP 协议是一个无状态的协议，也就是说每个请求都是一个独立的
请求，请求与请求之间并无关系。但在实际的应用场景，这种方式并不能满足我
们的需求。举个大家都喜欢用的例子，把商品加入购物车，单独考虑这个请求，
服务端并不知道这个商品是谁的，应该加入谁的购物车？因此这个请求的上下文
环境实际上应该包含用户的相关信息，在每次用户发出请求时把这一小部分额外
信息，也做为请求的一部分，这样服务端就可以根据上下文中的信息，针对具体
的用户进行操作。所以这几种技术的出现都是对 HTTP 协议的一个补充，使得我
们可以用 HTTP 协议+状态管理构建一个的面向用户的 WEB 应用。 
Session 和 Cookie 的区别 
个人认为 session 与 cookies 最核心区别在于额外信息由谁来维护。利用 cookies
来实现会话管理时，用户的相关信息或者其他我们想要保持在每个请求中的信息，
都是放在 cookies 中,而 cookies 是由客户端来保存，每当客户端发出新请求时，
就会稍带上 cookies,服务端会根据其中的信息进行操作。 当利用 session 来进行
会话管理时，客户端实际上只存了一个由服务端发送的 session_id,而由这个
session_id,可以在服务端还原出所需要的所有状态信息，从这里可以看出这部分
信息是由服务端来维护的。 
除此以外，session 与 cookies 都有一些自己的缺点： 
cookies 的安全性不好，攻击者可以通过获取本地 cookies 进行欺骗或者利用
cookies 进行 CSRF 攻击。使用 cookies 时,在多个域名下，会存在跨域问题。 session 
在一定的时间里，需要存放在服务端，因此当拥有大量用户时，也会大幅度降低
服务端的性能，当有多台机器时，如何共享 session 也会是一个问题.(redis 集群)
也就是说，用户第一个访问的时候是服务器 A，而第二个请求被转发给了服务器
B，那服务器 B 如何得知其状态。实际上，session 与 cookies 是有联系的，比如
我们可以把 session_id 存放在 cookies 中的。 
对 cookies 与 session 的了解？他们能单独用吗？ 
Session 采用的是在服务器端保持状态的方案，而 Cookie 采用的是在客户端保持
状态的方案。但是禁用 Cookie 就不能得到 Session。因为 Session 是用 Session ID
来确定当前对话所对应的服务器 Session，而 Session ID 是通过 Cookie 来传递的，
禁用 Cookie 相当于 SessionID,也就得不到 Session。 
讲一下对称加密算法和非对称加密算法？ 
对称加密：密钥只有一个，加密解密为同一个密码，且加解密速度快，典型的对
称 加密算法有 DES、AES 等； 
非对称密钥加密，加密和解密使用不同的密钥。通信发送方获得接收方的公开密
钥之后，就 可以使用公开密钥进行加密，接收方收到通信内容后使用私有密钥
解密。可以更安全地将公 开密钥传输给通信发送方；运算速度慢。典型的非对
称加密算法有 RSA、DSA 等 
HTTPS 采用混合的加密机制。所有传输的内容都经过加密，加密采用对称加密，
但对称加密的密钥用服务器方的证书进行了非对称加密。 
 
 
 
WSGI 
CGI 全称是“公共网关接口”(CommonGateway Interface)，HTTP 服务器与你的或
其它机器上的程序进行“交谈”的一种工具，其程序须运行在网络服务器上。 
WSGI(Web Server Gateway Interface)是一种 CGI，用于连接 WEB 服务器与应用
程序，WSGI 专指 Python 应用程序；WSGI 的其中一个目的就是让用户可以用统
一的语言(Python)编写前后端。 
 
 
 
 
谈一下你对 uWSGI 和 nginx 的理解 
1.uWSGI 是一个 Web 服务器，它实现了 WSGI 协议、uwsgi、http 等协议。Nginx
中 HttpUwsgiModule 的作用是与 uWSGI 服务器进行交换。WSGI 是一种 Web 服
务器网关接口。它是一个 Web 服务器（如 nginx，uWSGI 等服务器）与 web 应
用（如用 Flask 框架写的程序）通信的一种规范。 
要注意 WSGI/uwsgi/uWSGI 这三个概念的区分。 
WSGI 是一种通信协议。 
uwsgi 是一种线路协议而不是通信协议，在此常用于在 uWSGI 服务器与其他网
络服务器的数据通信。 
uWSGI 是实现了 uwsgi 和 WSGI 两种协议的 Web 服务器。 
nginx 是一个开源的高性能的 HTTP 服务器和反向代理： 
1.作为 web 服务器，它处理静态文件和索引文件效果非常高 
2.它的设计非常注重效率，最大支持 5 万个并发连接，但只占用很少的内存空间 
3.稳定性高，配置简洁。 
4.强大的反向代理和负载均衡功能，平衡集群中各个服务器的负载压力应用 
 
 
 
简述浏览器通过 WSGI 请求动态资源的过程? 
浏览器发送的请求被 Nginx 监听到，Nginx 根据请求的 URL 的 PATH 或者后缀
把请求静态资源的分发到静态资源的目录，别的请求根据配置好的转发到相应端
口。 实现了 WSGI 的程序会监听某个端口，监听到 Nginx 转发过来的请求接收
后(一般用 socket 的 recv 来接收 HTTP 的报文)以后把请求的报文封装成 environ
的字典对象，然后再提供一个 start_response 的方法。把这两个对象当成参数传入
某个方法比如 wsgi_app(environ, start_response) 或者实现了 __call__(self, environ, 
start_response)方法的某个实例。这个实例再调用 start_response 返回给实现了 WSGI
的中间件，再由中间件返回给 Nginx。 
 
 
简述 QQ 登陆过程 
qq 登录，在我们的项目中分为了三个接口， 
第一个接口是请求 qq 服务器返回一个 qq 登录的界面; 
第二个接口是通过扫码或账号登陆进行验证，qq 服务器返回给浏览器一个 code
和 state,利用这个 code 通过本地服务器去向 qq 服务器获取 access_token 覆返回
给本地服务器，凭借 access_token 再向 qq 服务器获取用户的 openid(openid 用户
的唯一标识) 
第三个接口是判断用户是否是第一次 qq 登录，如果不是的话直接登录返回的 jwt-
token 给用户，对没有绑定过本网站的用户，对 openid 进行加密生成 token 进行
绑定 
 
 
 
分别从前端、后端、数据库阐述 web 项目的性能优化 
前端优化： 
1、减少 http 请求、例如制作精灵图 
2、html 和 CSS 放在页面上部，javascript 放在页面下面，因为 js 加载比 HTML
和 Css 加载慢，所以要优先加载 html 和 css,以防页面显示不全，性能差，也影响
用户体验差 
后端优化： 
1、缓存存储读写次数高，变化少的数据，比如网站首页的信息、商品的信息等。
应用程序读取数据时，一般是先从缓存中读取，如果读取不到或数据已失效，再
访问磁盘数据库，并将数据再次写入缓存。 
2、异步方式，如果有耗时操作，可以采用异步，比如 celery 
3、代码优化，避免循环和判断次数太多，如果多个 if else 判断，优先判断最有
可能先发生的情况 
数据库优化： 
1、如有条件，数据可以存放于 redis，读取速度快 
2、建立索引、外键等 
什么是 rpc 
一个通俗的描述是：客户端在不知道调用细节的情况下，调用存在于远程计算机
上的某个对象，就像调用本地应用程序中的对象一样。 
 
比较正式的描述是：一种通过网络从远程计算机程序上请求服务，而不需要了解
底层网络技术的协议。 
远程过程调用 (RPC) 是一种协议，程序可使用这种协议向网络中的另一台计算
机上的程序请求服务 
1.RPC 采用客户机/服务器模式。请求程序就是一个客户机，而服务提供程序就是
一个服务器。 
2.首先，客户机调用进程发送一个有进程参数的调用信息到服务进程，然后等待
应答信息。 
2.在服务器端，进程保持睡眠状态直到调用信息到达为止。当一个调用信息到达，
服务器获得进程参数，计算结果，发送答复信息，然后等待下一个调用信息， 
3.最后，客户端调用进程接收答复信息，获得进程结果，然后调用执行继续进行。 
SOAP 
SOAP（原为 Simple Object Access Protocol 的首字母缩写，即简单对象访问协议）
是交换数据的一种协议规范，使用在计算机网络 Web 服务（web service）中，交
换带结构信息。SOAP 为了简化网页服务器（Web Server）从 XML 数据库中提
取数据时，节省去格式化页面时间，以及不同应用程序之间按照 HTTP 通信协议，
遵从 XML 格式执行资料互换，使其抽象于语言实现、平台和硬件。 
RESTful API 
REST 指 Representational State Transfer，可以翻译为“表现层状态转化” 
主要思想 
 
对网络 上的 所有资 源，都 有一 个 统一 资源标 识符  URI(Uniform Resource 
Identifier)； 
 
这些资源可以有多种表现形式，即 REST 中的“表现层”Representation，比如，文
本可以用 txt 格式表现，也可以用 HTML 格式、XML 格式、JSON 格式表现。
URI 只代表资源的实体，不代表它的形式； 
 
“无状态(Stateless)”思想：服务端不应该保存客户端状态，只需要处理当前的请求，
不需了解请求的历史，客户端每一次请求中包含处理该请求所需的一切信息； 
 
客户端使用 HTTP 协议中的 GET/POST/PUT/DELETE 方法对服务器的资源进行
操作，即 REST 中的”状态转化“ 
设计原则 
 
URL 设计 
o 最好只使用名词，而使用 GET/POST/PUT/DELETE 方法的不同表示不同的操作；
比如使用 POST /user 代替/user/create 
o GET：获取资源；POST：新建/更新资源；PUT：更新资源；DELETE：删除资源； 
o 对于只支持 GET/POST 的客户端，使用 X-HTTP-Method-Override 属性，覆盖 POST
方法； 
o 避 免 多 级
URL ， 比 如 使 用
GET /authors/12?categories=2
代 替
GET 
/authors/12/categories/2； 
o 避免在 URI 中带上版本号。不同的版本，可以理解成同一种资源的不同表现形
式，所以应该采用同一个 URI，版本号可以在 HTTP 请求头信息的 Accept 字段
中进行区分 
 
状态码：服务器应该返回尽可能精确的状态码，客户端只需查看状态码，就可以
判断出发生了什么情况。 
 
服务器回应：在响应中放上其它 API 的链接，方便用户寻找 
总结:服务提供的两大流派.传统意义以方法调用为导向通称 RPC。为了企业 SOA,
若干厂商联合推出 webservice,制定了 wsdl 接口定义,传输 soap.当互联网时代,臃
肿 SOA 被简化为 http+xml/json.但是简化出现各种混乱。以资源为导向,任何操作
无非是对资源的增删改查，于是统一的 REST 出现了。 
RestFul 和 RPC 的区别 
1、从本质区别上看，RPC 是基于 TCP 实现的，RestFul 是基于 HTTP 来实现的。 
2、从传输速度上来看，因为 HTTP 封装的数据量更多所以数据传输量更大，所
以 RPC 的传输速度是比 RestFul 更快的。 
3、因为 HTTP 协议是各个框架都普遍支持的。在 toC 情况下，因为不知道情况
来源的框架、数据形势是什么样的，所以在网关可以使用 RestFul 利用 http 来接
受。而在微服务内部的各模块之间因为各协议方案是公司内部自己定的，所以知
道各种数据方式，可以使用 TCP 传输以使各模块之间的数据传输更快。所以可
以网关和外界的数据传输使用 RestFul，微服务内部的各模块之间使用 RPC。 
4、RestFul 的 API 的设计上是面向资源的，对于同一资源的获取、传输、修改可
以使用 GET、POST、PUT 来对同一个 URL 进行区别，而 RPC 通常把动词直接
体现在 URL 上 
 
apache 和 nginx 的区别 
nginx 相对 apache 的优点： 
 
轻量级，同样起 web 服务，比 apache 占用更少的内存及资源 
 
抗并发，nginx 处理请求是异步非阻塞的，支持更多的并发连接，而 apache 则是
阻塞型的，在高并发下 nginx 能保持低资源低消耗高性能 
 
配置简洁 
 
高度模块化的设计，编写模块相对简单 
 
社区活跃 
apache 相对 nginx 的优点： 
 
rewrite ，比 nginx 的 rewrite 强大 
 
模块超多，基本想到的都可以找到 
 
少 bug ，nginx 的 bug 相对较多 
 
超稳定 
XSRF 和 XSS 
 
CSRF(Cross-site request forgery)跨站请求伪造 
 
XSS(Cross Site Scripting)跨站脚本攻击 
CSRF 重点在请求,XSS 重点在脚本 
Socket  
1、网络上的两个程序通过一个双向的通讯连接实现数据的交换，这个双向链路
的一端称为一个 Socket。Socket 通常用来实现客户方和服务方的连接。Socket 是
TCP/IP 协议的一个十分流行的编程界面，一个 Socket 由一个 IP 地址和一个端口
号唯一确定。  
2、但是，Socket 所支持的协议种类也不光 TCP/IP、UDP，因此两者之间是没有
必然联系的。在 Java 环境 下，Socket 编程主要是指基于 TCP/IP 协议的网络编
程。  
3、socket 连接就是所谓的长连接，客户端和服务器需要互相连接，理论上客户
端和服务器端一旦建立起连接将不会主动断掉的，但是有时候网络波动还是有可
能的 。 
4、Socket 偏向于底层。一般很少直接使用 Socket 来编程，框架底层使用 Socket
比较多 
  
 
案例 
自定义镜像 mycentosjava8 
要求 
Centos7 镜像具备 vim+ifconfig+jdk8 
JDK 的下载镜像地址 
官网 
  
 
 
  
FROM centos 
MAINTAINER zzyy<zzyybs@126.com> 
  
ENV MYPATH /usr/local 
WORKDIR $MYPATH 
  
###  18.1. <a name='vim'></a>vim 编辑器 
RUN yum -y install vim 
###  18.2. <a name='ifconfigIP'></a>ifconfig 命令查看网络 IP 
RUN yum -y install net-tools 
###  18.3. <a name='java8lib'></a>java8 及 lib 库 
RUN yum -y install glibc.i686 
RUN mkdir /usr/local/java 
####  18.3.1. <a name='jarjdk-8u171-linux-'></a>是 相 对 路 径 jar, 把 jdk-8u171-linux-
x64.tar.gz 添 加 到 容 器 中 , 安 装 包 必 须 要 和
Dockerfile 文件在同一位置 
ADD jdk-8u171-linux-x64.tar.gz /usr/local/java/ 
###  18.4. <a name='java'></a>java 环境变量 
ENV JAVA_HOME /usr/local/java/jdk1.8.0_171 
ENV JRE_HOME $JAVA_HOME/jre 
ENV 
CLASSPATH 
$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.j
ar:$JRE_HOME/lib:$CLASSPATH 
ENV PATH $JAVA_HOME/bin:$PATH 
  
EXPOSE 80 
  
CMD echo $MYPATH 
CMD echo "success--------------ok" 
CMD /bin/bash 
  
大写字母 D 
构建 
docker build -t 新镜像名字:TAG . 
docker build -t centosjava8:1.5 . 
  
 
 
 
注意，上面 TAG 后面有个空格，有个点 
运行 
docker run -it 新镜像名字:TAG 
 docker run -it centosjava8:1.5 /bin/bash 
  
 
再体会下 UnionFS（联合文件系统） 
UnionFS（联合文件系统）：Union 文件系统（UnionFS）是一
种分层、轻量级并且高性能的文件系统，它支持对文件系统
的修改作为一次提交来一层层的叠加，同时可以将不同目录
挂载到同一个虚拟文件系统下(unite several directories into a 
single virtual filesystem)。Union 文件系统是 Docker 镜像的
基础。镜像可以通过分层来进行继承，基于基础镜像（没有
父镜像），可以制作各种具体的应用镜像。 
  
特性：一次同时加载多个文件系统，但从外面看起来，只能
看到一个文件系统，联合加载会把各层文件系统叠加起来，
这样最终的文件系统会包含所有底层的文件和目录 
  
 
docker 是一个 client-server 结构的系统，docker 守护进程运行在主机上，然后通
过 socker 连接从客户端访问，守护进程从客户端接收命令并管理主机上的容器，
容器是个运行时环境。 
docker 命令 
# docker exec 执行多条命令 
docker exec -it -u root container_name bash -c "cd /home && mkdir dx" 
 
# 如果容器使用 host 网络驱动，意味着容器共享宿主机的网络栈，双方在网络名称空间
并没有隔离。 
docker run --network=host 
 
 
docker version 
----docker 版本信息 
docker info 
----docker 各种配置信息的描述 
docker images 
----列出本地主机上的所有镜像； 
docker images -qa 
----列出所有的镜像 id； 
docker search 镜像名字 
----在 docker hub 上查找某个镜像； 
docker search -s 30 tomcat----列出 docker hub 上点赞数超过 30 的镜像； 
docker pull 镜像名 
----从配置的仓库拉取镜像； 
docker rmi 镜像名/id 
----从本机中删除某个镜像； 
docker rmi -f 镜像名 
----强制删除； 
docker rmi -f $(docker images -qa)----删除多个镜像； 
docker run [option] 镜像 [command] [args] 
----新建并启动容器；-it----启动交互式容器并打开一个伪终 端；docker run -d 镜
像名----已后台进程运行容器； 
 
退出容器 
----1. exit----容器停止退出；2. ctrl+P+Q----容器不停止退出； 
进入正在运行的容器并以命令行交互----1. docker exec -it 容器 id；2. docker attach 
容 器 id； docker ps [options]----列出当前所有正在运行的容器； docker start 容
器名/id----启动容器；docker restart 容器/id----重启容器；docker stop 容器名/id； 
docker kill 容器名/id----强制停止容器；docker rm 容器名/id----删除已停止容器；
一次性删除多个容器--- -1. docker rm -f (docker ps -a -q)；2. docker ps -a -q |xargs 
docker rm； docker logs 容器----列出容器的运行日志；-f----跟随最新的日志打印；
-t----加入时间戳；--tial 数字----显 示最后多少条；docker events----打印出实时的
系统事件；docker history image----打印出指定镜像的历 史版本信息，即构建该
镜像的每一层镜像的命令记录； docker top 容器----查看容器中运行的进程； 
docker inspect 容器----查看容器的内部细节； docker cp 容器：容器内路径目的
主机路径----从容器内拷贝文件到主机； docker run -it -p 8888:8080 tomcat----指
的是以交互式方式运行 tomcat 并且将主机的端口 8888 映射到 docker 内部的
8080 端口的 tomcat，外部访问 tomcat 就通过 8888 端口访问； docker commit -
m="提交的描述信息" -a=“作者名” 容器 id 要创建的目标镜像名:标签名----提交
容器副本 使其成为一个新的镜像； docker run -it -v 主机目录:容器目录 镜像名
----指的是根据一个镜像运行你一个容器，-v 是达成主机目录和 容器目录实现数
据共享； ----数据卷的一种实现； 镜像原理： 镜像是一种轻量级、可执行的独
立软件包，用来打包软件运行环境和基于运行环境开发的软件，它包含运行某个
软件所需的所有内容，包括代码、运行时、库、环境变量和配置文件。 unionFS
（联合文件系统），对文件系统的修改作为一次提交来一层层叠加，同时将不同
文件目录挂载到同一虚拟文件系统下。 docker 镜像实际上是由一层层的文件系
统组成，这种层级的文件系统就是 unionFS；bootfs 和 rootfs---- bootfs 就是引导
加载 kernel，rootfs 在 bootfs 之上，就是各种目录和文件；镜像每一层都可以被
共享； 容器数据卷： 卷就是目录或文件，存在于一个或多个容器中，由 docker
挂载到容器，但不属于联合文件系统，因此能够绕过 Union File System 提供一
些用于持续存储或共享数据的特性： 卷的设计目的就是数据的持久化，完全独
立于容器的生存周期，因此 Docker 不会在容器删除时删除其挂载的数据 卷 特
点： 1：数据卷可在容器之间共享或重用数据 2：卷中的更改可以直接生效 3：
数据卷中的更改不会包含在镜像的更新中 4：数据卷的生命周期一直持续到没有
容器使用它为止 例如： 执行此命令 docker run -it -v /dx:/dx ubuntu 后，主机和
容器都会生成/dx 目录，并且 docker inspect 容器 id 之 后的结果显示，主机的目
录已经挂载到容器中，并且是可读写的： 
 
此时，两个文件夹可以共享资源； 如果命令变为 docker run -it -v /dx:/dx:ro ubuntu-
---表示容器中的文件/dx 是 readonly 文件，在容器中不能进行写操作，只能读；
但是在主机上在/dx 中写操作，容器中可以实时看到； 数据卷的另一种实现: 
1. /home 目录下创建 dockerfile 文件，指的是在 dockerfile 中使用 VOLUME 命令给
镜像添加一个或多个数据卷： 
 
\2. 使用 docker build 构造镜像 docker build -f /home/dockerfile -t dx/centos .----指
的是在当前路径下通过 dockerfile 文件构建一个 tag 为 dx/centos 的镜像，-f----
dockerfile 文件路径，-t----添加 tag； 
 
3. 运 行 容 器 ， 发 现 容 器 中 有 两 天 在 dockerfile 文 件 中 添 加 的 
数 据 卷 ,dataVolumeContainer01 和 dataVolumeContainer02： 
 
4. 而相应地挂载到容器中的主机的目录为，docker inspect 容器查看即得： 
 
数据卷容器： 命名的容器挂载数据卷，其它容器通过挂载这个(父容器)实现数据
共享，挂载数据卷的容器，称之为数据卷 容器容器间传递共享： 
1. 先启动一个父容器 container01: docker run -it --name container01 dx/centos docker
拉取 kolla 的 openstack 镜像 
2. 其它容器继承自 container01，使用命令：docker run -it --name container02 --
volumes-from container01 dx/centos 
3. 容器之间配置信息的传递，数据卷的声明周期一直持续到没有容器使用它为止，
也就是说，主要通过-- volumes-from 命令运行的容器，父容器的删除，其执行的
操作文件的读写一直存在，不会因为某个容器 的删除而消除。 
dockerfile 
dockerfile 就是构建镜像的构建文件，是由一系列命令和参数构成的脚本。 构建
三步骤：1. 编写 dockerfile 文件；2. docker build 构建镜像；3. docker run 运行； 
dockerfile 构建过程解析： 
docker 拉取 kolla 的 openstack 镜像 
阿里云镜像加速器 "registry-mirrors": ["https://kbagomoh.mirror.aliyuncs.com"] 
搭建 docker 应用栈 
目标：同一主机下搭建一个包含 6 个节点的 docker 应用栈，其中包含一个代理
节点、两个 web 应用节点、一个主数据库节点和两个从数据库节点； 
 
1. 获取应用栈需要的镜像； 
docker pull ubuntu/django/haproxy/redis/ 
2. 应用栈容器节点互联 
只需要完成容器互联来实现容器间的通信，采用 docker run 命令--link 选项建立
容器间的互联关系。 
docker run -it --name redis-slave1 --link redis-master:master redis /bin/bash 
---启动 redis-slave1 容器，同时将新启动的容器连接到名为 redis-master 的容器上；
启动后该容器中的/etc/hosts 文件记录了名为 master 的连接信息，即 redis-master
容器的 IP 地址。 
# cat /etc/hosts 
172.17.0.5 
应用栈各节点的连接信息如下： 
 
3. 应用栈容器节点启动 
 
docker 核心原理 
docker容器本质上是宿主机上的进程。docker通过namespace实现了资源隔离，
通过 cgroups 实现了资源限制，通过写时复制机制(copy-on-write)实现了高效的
文件操作。 
docker daemon 是 docker 架构中的主要用户接口。首先，它提供了 API server 用
于接收来自 docker client 的请求，其后根据不同的请求分发给 docker daemon 的
不同模块执行相应的工作，其中对容器运行时、volume、镜像以及网络方面的具
体实现已经放到 daemon 以外的模块或者项目中。 
docker daemon 
docker client 
docker client 是一个泛称，用来向 docker daemon 发起请求，执行相应的容器管理
操作。它既可以是命令行工具 docker，也可以是任何遵循了 docker API 的客户
端。 
镜像管理 
docker 通过 distribution、registry、layer、image、reference 等模块实现了 docker
镜像管理，将这些模块统称为镜像管理。 
execdriver、volumedriver、graphdriver 
docker daemon 负责将用户的请求转译成系统调用，进而创建和管理容器，而在
具体实现的过程中，为了将这些系统调用抽象成统一的接口方便调用者使用，
docker 把这些操作分为了容器执行驱动、volume 存储驱动、镜像存储驱动等。 
 
 
 
 
5. 操作系统 
查看 Linux 中被进程打开文件的信息 
不带任何参数执行 lsof 命令会输出当前所有活跃进程打开的所有文件 
lsof | more 来分页显示命令输出结果 
lsof -u tt 命令表示列出 tt 用户已经打开了的文件 
 
 
谈谈对 IO 多路复用机制的理解 
IO 指的是在操作系统中，数据在内核态和用户态之间的读写操作； 
多路大多数情况下指的是多个 TCP 连接(多个 socket 或者多个 channel)； 
复用指的是一个或多个线程资源； 
IO 多路复用指的是一个或多个线程资源处理多个 TCP 连接。无需创建和维护过
多的进程或线程。 
 
 
实现 IO 多路复用的模型 
select 
采用的是轮询加遍历的方式，也就是说，在客户端操作服务器时会创建三种文件
表符(简称 FD)，分别是写描述符、读描述符、异常描述符，而 select 会阻塞监视
这三种描述符，等到有数据可读、可写、出现异常或者超时时都会返回，返回后
通过遍历 FD 集合找到就绪的 FD，然后触发相应的 IO 操作。 
优点：几乎所有的平台都支持； 
缺点：随着 FD 数量增多而导致性能下降。所以每次调用 select 时将这个 FD 集
合从用户空间拷贝到内核空间进行遍历，由内核根据就绪状态修改该集合的内容，
而操作系统对单个进程打开的 FD 数量是有限制的，一般默认 1024 个； 
poll 
和 select 几乎没有区别，区别在于文件描述符的存储方式不同，poll 采用链表的
方式存储； 
优点：没有最大存储数量的限制； 
缺点：和 select 一样； 
epoll 
采用时间通知机制来触发相应的 IO 操作，没有 FD 的限制，从用户态拷贝到内
核态只需要一次，因为它主要通过调用系统底层的函数来实现注册、激活 FD，
这样大大提供了执行性能。主要通过调用以下三个系统函数： 
第一个是 epoll_create()函数，它在系统启动的时候会在 linux 内核里面申请一个
B+树结构的文件系统，然后再返回 epoll 对象，也就是一个 FD 对象； 
第二个是 epoll_ctl()函数，它会在没新建一个连接的时候会同步更新 epoll 对象中
FD，并且去绑定一个 callback 回调函数； 
第三个是 epoll_wait()函数，它会轮询所有的 callback 集合，并且去触发对应的 IO
操作； 
优点：轮询改成了回调，大大提供了 CPU 执行效率，也不会随 FD 数量的增加
而导致效率下降； 
缺点：只能在 linux 下工作； 
 
 
 
CPU 突然飙高，系统反应慢怎么排查 
CPU 是整个电脑的最核心的资源，对于一个应用程序来说，CPU 的最小执行单
元是线程，导致 CPU 飙升的原因有以下两个： 
1. CPU 的上下文切换过多； 
同一时刻下每个 CPU 核心只能运行一个线程，如果有多个线程要执行，CPU 只
能通过上下文切换的方式来切换不同的线程。上下文切换分两部分：保存运行线
程的执行状态和让处于等待中的线程执行，这两部分需要 CPU 执行内核相关的
指令实现状态保存。如果较多的上下文切换就会占用大量的 CPU 资源从而使得
CPU 无法去执行用户进程中的指令，而导致 CPU 的响应速度下降。文件 IO、网
络 IO、锁等待都会导致线程阻塞，从而去触发 CPU 的上下文切换。 
2. CPU 资源过度消耗； 
在我们的程序中创建了大量的线程或者是有线程一直占用 CPU 资源，无法被释
放，比如说死循环，当我们的 CPU 利用过高之后，就会导致应用程序中的线程
无法获取 CPU 的调度，从而影响 CPU 的执行效率； 
解决： 
可以通过 Top 命令找到 CPU 利用率过高的进程，通过 shift+H 找到进程中 CPU
消耗过高的线程。 
在查找过程中有两种情况： 
a. CPU 利用率过高的线程一直是同一个，说明程序中存在线程长期占用 CPU 没
有释放的情况，通过 jstack 获取线程的 dump 日志，定位到线程日志后，可以找
到对应的问题代码； 
b. CPU 利用率过高的线程 ID 一直变化，说明线程创建过多，就要去挑选几个线
程 ID，再通过 jstack 命令去排查，最后排查时可能发现程序正常，只是在 CPU
飙高的那一刻用户访问量大，从而导致系统资源不够。 
 
 
 
 
 
查看打开的线程 
ps -T -p <pid>   # 列出了由进程号为<pid>的进程创建的所有线程 
top -H -p <pid> # 输出某个特定进程<pid>并检查该进程内运行的线程状况 
htop 查看单个进程的线程 
内存泄漏怎么排查 
pdb 是专门用于 python 代码调试，模仿 gdb。使用 pdb 可以查看堆栈，打印变量等。 
使用 pdb 加载 python 程序 
.venv/bin/python -m pdb  orange.py 
> /Users/lanyang/workspace/orange/orange.py(3)<module>() 
-> import inspect 
(Pdb) 
启动程序 
(Pdb)c 
相关的命令有 
bt 打印堆栈 
q 退出 
pp 打印变量 
c(ont(inue)) 继续执行 
 
objgraph 
(Pdb) objgraph.show_growth(limit=10) 
function             22749    +22749 
dict                 15515    +15515 
tuple                12332    +12332 
weakref               6680     +6680 
list                  5517     +5517 
type                  3449     +3449 
getset_descriptor     3408     +3408 
cell                  2565     +2565 
set                   2496     +2496 
ModuleSpec            1588     +1588 
show_growth()打印两次调用之间增加的类型。如果这其中有自己定义的类型，很可能
就是问题所在。如果都是 python 内置类型，可能要花费更多功夫了。 
 
一般排查问题时，在程序开始执行时，调用 show_growth()，程序跑一段时间后，再次
调用 show_growth()，查看哪些对象增长最快。 
 
如果使用 pdb 在命令行下调试，ctrl+c 停止程序的时候，注意观察上下文，保证跟上次
import objgraph 时一样 
查看某个类型 
(Pdb) objgraph.by_type('list') 
 
pympler 
查看内存占用 
(Pdb) from pympler import tracker 
(Pdb) tr = tracker.SummaryTracker() 
(Pdb) tr.print_diff() 
                 types |   # objects |   total size 
======================= | =========== | ============ 
          <class 'list |       12769 |     1.18 MB 
           <class 'str |       12769 |   950.47 KB 
           <class 'int |       2513 |     68.71 KB 
          <class 'code |           1 |   144     B 
 function (store_info) |           1 |    136     B 
          <class 'cell |           2 |     96     B 
         <class 'tuple |           1 |     64     B 
        <class 'method |         -1 |   -64     B 
          <class 'dict |           0 |   -128     B 
(Pdb) tr.print_diff() 
        types |   # objects |   total size 
============== | =========== | ============ 
 <class 'list |           1 |     88     B 
  <class 'str |           1 |     70     B 
(Pdb) tr.print_diff() 
 types |   # objects |   total size 
======= | =========== | 
tracker 对象初始化的时候会创建一个 summary，每次调用 tracker.print_diff()的时候又
会创建一个 summary，当前的 summary 与上次的 summary 做比较，并打印两者之间的
不同。 
 
 
 
进程 
进程的异常控制流：陷阱、中断、异常和信号 
陷阱是有意造成的“异常”，是执行一条指令的结果。陷阱是同步的。陷阱的主要
作用是实现系统调用。比如，进程可以执行 syscall n 指令向内核请求服务。当进
程执行这条指令后，会中断当前的控制流，陷入到内核态，执行相应的系统调用。
内核的处理程序在执行结束后，会将结果返回给进程，同时退回到用户态。进程
此时继续执行下一条指令。 
中断由处理器外部的硬件产生，不是执行某条指令的结果，也无法预测发生时机。
由于中断独立于当前执行的程序，因此中断是异步事件。中断包括 I/O 设备发
出的 I/O 中断、各种定时器引起的时钟中断、调试程序中设置的断点等引起的
调试中断等。 
异常是一种错误情况，是执行当前指令的结果，可能被错误处理程序修正，也可
能直接终止应用程序。异常是同步的。这里特指因为执行当前指令而产生的错误
情况，比如除法异常、缺页异常等。有些书上为了区分，也将这类“异常”称为“故
障”。 
信号是一种更高层的软件形式的异常，同样会中断进程的控制流，可以由进程进
行处理。一个信号代表了一个消息。信号的作用是用来通知进程发生了某种系统
事件。 
进程与线程的切换流程 
进程切换分两步： 
1、切换页表以使用新的地址空间，一旦去切换上下文，处理器中所有已经缓存
的内存地址一瞬间都作废了。 
2、切换内核栈和硬件上下文。 
对于 linux 来说，线程和进程的最大区别就在于地址空间，对于线程切换，第 1
步是不需要做的，第 2 步是进程和线程切换都要做的。 
因为每个进程都有自己的虚拟地址空间，而线程是共享所在进程的虚拟地址空间
的，因此同一个进程中的线程进行线程切换时不涉及虚拟地址空间的转换。 
为什么虚拟地址空间切换会比较耗时？ 
进程都有自己的虚拟地址空间，把虚拟地址转换为物理地址需要查找页表，页表
查找是一个很慢的过程，因此通常使用 Cache 来缓存常用的地址映射，这样可以
加速页表查找，这个 Cache 就是 TLB（translation Lookaside Buffer，TLB 本质上
就是一个 Cache，是用来加速页表查找的）。 
由于每个进程都有自己的虚拟地址空间，那么显然每个进程都有自己的页表，那
么当进程切换后页表也要进行切换，页表切换后 TLB 就失效了，Cache 失效导
致命中率降低，那么虚拟地址转换为物理地址就会变慢，表现出来的就是程序运
行会变慢，而线程切换则不会导致 TLB 失效，因为线程无需切换地址空间，因
此我们通常说线程切换要比较进程切换块，原因就在这里。 
同一进程中的线程可以共享哪些数据？ 
 
进程代码段 
 
进程的公有数据（全局变量、静态变量...） 
 
进程打开的文件描述符 
 
进程的当前目录 
 
信号处理器/信号处理函数：对收到的信号的处理方式 
 
进程 ID 与进程组 ID 
单工/半双工/全双工 
单工----数据只能往一个方向，比如只能收或者只能发； 
半双工----可以收，也可以发，同一时刻只能收或者发； 
全双工----可以收，也可以发； 
 
进程间通信有哪些方式 
a) 管道/匿名管道(Pipes)：管道是半双工的，数据只能向一个方向流动；双方通
信时，需要建立起两个管道；一个进程向管道中写的内容被管道另一端的进程读
出。写入的内容每次都添加在管道缓冲区的末尾，并且每次都是从缓冲区的头部
读出数据；用于具有亲缘关系的父子进程间或者兄弟进程之间的通信。 
b) 有名管道(Names Pipes): 匿名管道由于没有名字，只能用于亲缘关系的进程间
通信。为了克服这个缺点，提出了有名管道。有名管道严格遵循先进先出(first in 
first out)。有名管道以磁盘文件的方式存在，可以实现本机任意两个进程通信。 
c)消息队列(Message Queuing)：消息队列是消息的链表，具有特定的格式，存放
在内存中并由消息队列标识符标识。管道和消息队列的通信数据都是先进先出的
原则。与管道（无名管道：只存在于内存中的文件；命名管道：存在于实际的磁
盘介质或者文件系统）不同的是消息队列存放在内核中，只有在内核重启(即，操
作系统重启)或者显示地删除一个消息队列时，该消息队列才会被真正的删除。
消息队列可以实现消息的随机查询，消息不一定要以先进先出的次序读取，也可
以按消息的类型读取，比 FIFO 更有优势。消息队列克服了信号承载信息量少，
管道只能承载无格式字节流以及缓冲区大小受限等缺点。 
d) 信号(Signal)：信号是一种比较复杂的通信方式，用于通知接收进程某个事件
已经发生；（对于异常情况下的工作模式，就需要用「信号」的方式来通知进程，
信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令）。
比如，Ctrl+C 产生 SIGINT 信号，表示终止该进程，Ctrl+Z 产生 SIGSTP，表
示停止该进程，但还未结束） 
e) 信号量(Semaphores)：信号量是一个计数器，用于多进程对共享数据的访问，
信号量的意图在于进程间同步。这种通信方式主要用于解决与同步相关的问题并
避免竞争条件。（信号量其实是一个整型的计数器，主要用于实现进程间的互斥
与同步，而不是用于缓存进程间通信的数据。） 
f) 共享内存(Shared memory)：使得多个进程可以访问同一块内存空间，不同进程
可以及时看到对方进程中对共享内存中数据的更新。这种方式需要依靠某种同步
操作，如互斥锁和信号量等。可以说这是最有用的进程间通信方式。（共享内存
的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中） 
h) 套接字(Sockets): 此方法主要用于在客户端和服务器之间通过网络进行通信。
套接字是支持 TCP/IP 的网络通信的基本操作单元，可以看做是不同主机之间的
进程进行双向通信的端点，简单的说就是通信的两方的一种约定，用套接字中的
相关函数来完成通信过程。 
int socket(int domain, int type, int protocal) 
优缺点： 
管道：速度慢，容量有限； 
Socket：任何进程间都能通讯，但速度慢； 
消息队列：容量受到系统限制，且要注意第一次读的时候，要考虑上一次没有读
完数据的问题； 
信号量：不能传递复杂消息，只能用来同步； 
共享内存区：能够很容易控制容量，速度快，但要保持同步，比如一个进程在写
的时候，另一个进程要注意读写的问题，相当于线程中的线程安全，当然，共享
内存区同样可以用作线程间通讯，不过没这个必要，线程间本来就已经共享了同
一进程内的一块内存。 
进程同步问题 
进程的同步是目的，而进程间通信是实现进程同步的手段 
管程 Monitor 
管程将共享变量以及对这些共享变量的操作封装起来，形成一个具有一定接口的
功能模块，这样只能通过管程提供的某个过程才能访问管程中的资源。进程只能
互斥地使用管程，使用完之后必须释放管程并唤醒入口等待队列中的进程。 
当一个进程试图进入管程时，在入口等待队列等待。若 P 进程唤醒了 Q 进程，
则 Q 进程先执行，P 在紧急等待队列中等待。（HOARE 管程） 
wait 操作：执行 wait 操作的进程进入条件变量链末尾，唤醒紧急等待队列或者
入口队列中的进程；signal 操作：唤醒条件变量链中的进程，自己进入紧急等待
队列，若条件变量链为空，则继续执行。（HOARE 管程） 
MESA 管程：将 HOARE 中的 signal 换成了 notify（或者 broadcast 通知所有满足
条件的），进行通知而不是立马交换管程的使用权，在合适的时候，条件队列首
位的进程可以进入，进入之前必须用 while 检查条件是否合适。优点：没有额外
的进程切 
生产者-消费者问题 
问题描述：使用一个缓冲区来存放数据，只有缓冲区没有满，生产者才可以写入
数据；只有缓冲区不为空，消费者才可以读出数据 
代码实现： 
// 伪代码描述  
// 定义信号量 full 记录缓冲区物品数量 empty 代表缓冲区空位数量 mutex 为互斥量 
semaphore full = 0, empty = n, mutex = 1; 
 
// 生产者进程 
void producer(){ 
 
do{ 
    
  P(empty); 
 
  P(mutex); 
 
     // 生产者进行生产 
    
 
    
  V(mutex); 
    
  V(full); 
  
} while(1); 
} 
 
void consumer(){ 
 
do{ 
 
  P(full); 
 
  P(mutex); 
 
     
// 消费者进行消费 
 
 
  V(mutex); 
 
  V(empty); 
  
} while(1); 
} 
进程间同步的方式有哪些？ 
1、临界区：通过对多线程的串行化来访问公共资源或一段代码，速度快，适合
控制数据访问。 
优点：保证在某一时刻只有一个线程能访问数据的简便办法。 
缺点：虽然临界区同步速度很快，但却只能用来同步本进程内的线程，而不可用
来同步多个进程中的线程。 
2、互斥量：为协调共同对一个共享资源的单独访问而设计的。互斥量跟临界区
很相似，比临界区复杂，互斥对象只有一个，只有拥有互斥对象的线程才具有访
问资源的权限。 
优点：使用互斥不仅仅能够在同一应用程序不同线程中实现资源的安全共享，而
且可以在不同应用程序的线程之间实现对资源的安全共享。 
缺点： 
 
互斥量是可以命名的，也就是说它可以跨越进程使用，所以创建互斥量需要的资
源更多，所以如果只为了在进程内部是用的话使用临界区会带来速度上的优势并
能够减少资源占用量。 
 
通过互斥量可以指定资源被独占的方式使用，但如果有下面一种情况通过互斥量
就无法处理，比如现在一位用户购买了一份三个并发访问许可的数据库系统，可
以根据用户购买的访问许可数量来决定有多少个线程/进程能同时进行数据库操
作，这时候如果利用互斥量就没有办法完成这个要求，信号量对象可以说是一种
资源计数器。 
3、信号量：为控制一个具有有限数量用户资源而设计。它允许多个线程在同一
时刻访问同一资源，但是需要限制在同一时刻访问此资源的最大线程数目。互斥
量是信号量的一种特殊情况，当信号量的最大资源数=1 就是互斥量了。 
优点：适用于对 Socket（套接字）程序中线程的同步。 
缺点: 
 
信号量机制必须有公共内存，不能用于分布式操作系统，这是它最大的弱点； 
 
信号量机制功能强大，但使用时对信号量的操作分散， 而且难以控制，读写和
维护都很困难，加重了程序员的编码负担； 
 
核心操作 P-V 分散在各用户程序的代码中，不易控制和管理，一旦错误，后果严
重，且不易发现和纠正。 
4、事件： 用来通知线程有一些事件已发生，从而启动后继任务的开始。 
优点：事件对象通过通知操作的方式来保持线程的同步，并且可以实现不同进程
中的线程同步操作。 
同步与互斥的概念？ 
 
同步：多个进程因为合作而使得进程的执行有一定的先后顺序。比如某个进程需
要另一个进程提供的消息，获得消息之前进入阻塞态； 
 
互斥：多个进程在同一时刻只有一个进程能进入临界区 
并发、并行、异步的区别？ 
并发：在一个时间段中同时有多个程序在运行，但其实任一时刻，只有一个程序
在 CPU 上运行，宏观上的并发是通过不断的切换实现的； 
多线程：并发运行的一段代码。是实现异步的手段 
并行（和串行相比）：在多 CPU 系统中，多个程序无论宏观还是微观上都是同
时执行的 
异步（和同步相比）：同步是顺序执行，异步是在等待某个资源的时候继续做自
己的事 
进程有哪几种状态？ 
进程一共有 5 种状态，分别是创建、就绪、运行（执行）、终止、阻塞。 
就绪状态：就是说进程已处于准备运行的状态，即进程获得了除 CPU 之外的一
切所需资源，一旦得到 CPU 即可运行。 
运行状态：就是进程正在 CPU 上运行。在单处理机环境下，每一时刻最多只有
一个进程处于运行状态。处于此状态的进程数小于等于 CPU 数 
阻塞状态：就是进程正在等待某一事件而暂停运行，比如等待某资源为可用或等
待 I/O 完成。即使 CPU 空闲，该进程也不能运行。 
运行态→阻塞态：往往是由于等待外设，等待主存等资源分配或等待人工干预而
引起的。 阻塞态→就绪态：则是等待的条件已满足，只需分配到处理器后就能
运行。 运行态→就绪态：不是由于自身原因，而是由外界原因使运行状态的进
程让出处理器，这时候就变成就绪态。例如时间片用完，或有更高优先级的进程
来抢占处理器等。 就绪态→运行态：系统按某种策略选中就绪队列中的一个进
程占用处理器，此时就变成了运行态。 
进程调度策略有哪些 
1. 批处理系统： 
先来先服务 first-come first-serverd（FCFS） 
按照请求的顺序进行调度。非抢占式，开销小，无饥饿问题，响应时间不确定（可
能很慢）； 
对短进程不利，对 IO 密集型进程不利。 
最短作业优先 shortest job first（SJF） 
按估计运行时间最短的顺序进行调度。非抢占式，吞吐量高，开销可能较大，可
能导致饥饿问题； 
对短进程提供好的响应时间，对长进程不利。 
最短剩余时间优先 shortest remaining time next（SRTN） 
按剩余运行时间的顺序进行调度。(最短作业优先的抢占式版本)。吞吐量高，开
销可能较大，提供好的响应时间； 
可能导致饥饿问题，对长进程不利。 
最高响应比优先 Highest Response Ratio Next（HRRN） 
响应比 = 1+ 等待时间/处理时间。同时考虑了等待时间的长短和估计需要的执
行时间长短，很好的平衡了长短进程。非抢占，吞吐量高，开销可能较大，提供
好的响应时间，无饥饿问题。 
2. 交互式系统 交互式系统有大量的用户交互操作，在该系统中调度算法的目标是
快速地进行响应。 
时间片轮转 Round Robin 
将所有就绪进程按 FCFS 的原则排成一个队列，用完时间片的进程排到队列最
后。抢占式（时间片用完时），开销小，无饥饿问题，为短进程提供好的响应时
间； 
若时间片小，进程切换频繁，吞吐量低；若时间片太长，实时性得不到保证。 
优先级调度算法 
为每个进程分配一个优先级，按优先级进行调度。为了防止低优先级的进程永远
等不到调度，可以随着时间的推移增加等待进程的优先级。 
多级反馈队列调度算法 Multilevel Feedback Queue 
设置多个就绪队列 1、2、3...，优先级递减，时间片递增。只有等到优先级更高
的队列为空时才会调度当前队列中的进程。如果进程用完了当前队列的时间片还
未执行完，则会被移到下一队列。 
抢占式（时间片用完时），开销可能较大，对 IO 型进程有利，可能会出现饥饿
问题。 
 
用户态和内核态 
为了限制不同程序的访问能力，防止一些程序访问其它程序的内存数据，CPU 划
分了用户态和内核态两个权限等级。 
用户态：用户态运行的程序只能受限地访问内存，只能直接读取用户程序的数据，
并且不允许访问外围设备，用户态下的 CPU 不允许独占，也就是说 CPU 能够被
其他程序获取。 
内核态：内核态运行的程序可以访问计算机的任何数据和资源，不受限制，包括
外围设备，比如网卡、硬盘等。处于内核态的 CPU 可以从一个程序切换到另外
一个程序，并且占用 CPU 不会发生抢占情况。。 
所有用户程序都运行在用户态，但有时需要进行一些内核态的操作，比如从硬盘
或者键盘读数据，这时就需要进行系统调用，使用陷阱指令，CPU 切换到内核
态，执行相应的服务，再切换为用户态并返回系统调用的结果。 
这些系统调用按功能大致可分为如下几类： 
1. 设备管理。完成设备的请求或释放，以及设备启动等功能。 
2. 文件管理。完成文件的读、写、创建及删除等功能。 
3. 进程控制。完成进程的创建、撤销、阻塞及唤醒等功能。 
4. 进程通信。完成进程之间的消息传递或信号传递等功能。 
5. 内存管理。完成内存的分配、回收以及获取作业占用内存区大小及地址等功
能。 
 
 
 
 
什么叫优先级反转？如何解决？ 
高优先级的进程等待被一个低优先级进程占用的资源时，就会出现优先级反转，
即优先级较低的进程比优先级较高的进程先执行。此处详细解释优先级反转带来
的问题：如果有一个中等优先级的进程将低优先级的进程抢占，那么此时低优先
级的进程无法正常进行并在后续释放被占用的资源，导致高优先级的任务一直被
挂起，直到中等优先级的进程完成后，低优先级的进程才可以继续并在后续释放
占用的资源，最后高优先级的进程才可以执行。导致的问题就是高优先级的进程
在中等优先级的进程调度之后。 
解决方法： 
 
优先级天花板(priority ceiling)：当任务申请某资源时，把该任务的优先级提升到
可访问这个资源的所有任务中的最高优先级，这个优先级称为该资源的优先级天
花板。简单易行。 
 
优先级继承(priority inheritance)：当任务 A 申请共享资源 S 时，如果 S 正在被任
务 C 使用，通过比较任务 C 与自身的优先级，如发现任务 C 的优先级小于自身
的优先级，则将任务 C 的优先级提升到自身的优先级，任务 C 释放资源 S 后，
再恢复任务 C 的原优先级。 
什么是僵尸进程？ 
一个子进程结束后，它的父进程并没有等待它（调用 wait 或者 waitpid），那么
这个子进程将成为一个僵尸进程。僵尸进程是一个已经死亡的进程，但是并没有
真正被销毁。它已经放弃了几乎所有内存空间，没有任何可执行代码，也不能被
调度，仅仅在进程表中保留一个位置，记载该进程的进程 ID、终止状态以及资
源利用信息(CPU 时间，内存使用量等等)供父进程收集，除此之外，僵尸进程不
再占有任何内存空间。这个僵尸进程可能会一直留在系统中直到系统重启。 
危害：占用进程号，而系统所能使用的进程号是有限的；占用内存。 
以下情况不会产生僵尸进程： 
 
该进程的父进程先结束了。每个进程结束的时候，系统都会扫描是否存在子进程，
如果有则用 Init 进程接管，成为该进程的父进程，并且会调用 wait 等待其结束。 
 
父进程调用 wait 或者 waitpid 等待子进程结束（需要每隔一段时间查询子进程是
否结束）。wait 系统调用会使父进程暂停执行，直到它的一个子进程结束为止。
waitpid 则可以加入 WNOHANG(wait-no-hang)选项，如果没有发现结束的子进程，
就会立即返回，不会将调用 waitpid 的进程阻塞。同时，waitpid 还可以选择是等
待任一子进程（同 wait），还是等待指定 pid 的子进程，还是等待同一进程组下
的任一子进程，还是等待组 ID 等于 pid 的任一子进程； 
 
子进程结束时，系统会产生 SIGCHLD(signal-child)信号，可以注册一个信号处理
函数，在该函数中调用 waitpid，等待所有结束的子进程（注意：一般都需要循环
调用 waitpid，因为在信号处理函数开始执行之前，可能已经有多个子进程结束
了，而信号处理函数只执行一次，所以要循环调用将所有结束的子进程回收）； 
 
也可以用 signal(SIGCLD, SIG_IGN)(signal-ignore)通知内核，表示忽略 SIGCHLD 信
号，那么子进程结束后，内核会进行回收。 
什么是孤儿进程？ 
一个父进程已经结束了，但是它的子进程还在运行，那么这些子进程将成为孤儿
进程。孤儿进程会被 Init（进程 ID 为 1）接管，当这些孤儿进程结束时由 Init 完
成状态收集工作。 
线程 
线程的分类？ 
从线程的运行空间来说，分为用户级线程（user-level thread, ULT）和内核级线程
（kernel-level, KLT） 
内核级线程：这类线程依赖于内核，又称为内核支持的线程或轻量级进程。无论
是在用户程序中的线程还是系统进程中的线程，它们的创建、撤销和切换都由内
核实现。比如英特尔 i5-8250U 是 4 核 8 线程，这里的线程就是内核级线程 
用户级线程：它仅存在于用户级中，这种线程是不依赖于操作系统核心的。应用
进程利用线程库来完成其创建和管理，速度比较快，操作系统内核无法感知用户
级线程的存在。 
线程同步有哪些方式？ 
为什么需要线程同步：线程有时候会和其他线程共享一些资源，比如内存、数据
库等。当多个线程同时读写同一份共享资源的时候，可能会发生冲突。因此需要
线程的同步，多个线程按顺序访问资源。 
 
互斥量 Mutex：互斥量是内核对象，只有拥有互斥对象的线程才有访问互斥资源
的权限。因为互斥对象只有一个，所以可以保证互斥资源不会被多个线程同时访
问；当前拥有互斥对象的线程处理完任务后必须将互斥对象交出，以便其他线程
访问该资源； 
 
信号量 Semaphore：信号量是内核对象，它允许同一时刻多个线程访问同一资源，
但是需要控制同一时刻访问此资源的最大线程数量。信号量对象保存了最大资源
计数和当前可用资源计数，每增加一个线程对共享资源的访问，当前可用资源计
数就减 1，只要当前可用资源计数大于 0，就可以发出信号量信号，如果为 0，则
将线程放入一个队列中等待。线程处理完共享资源后，应在离开的同时通过
ReleaseSemaphore 函数将当前可用资源数加 1。如果信号量的取值只能为 0 或 1，
那么信号量就成为了互斥量； 
 
事件 Event：允许一个线程在处理完一个任务后，主动唤醒另外一个线程执行任
务。事件分为手动重置事件和自动重置事件。手动重置事件被设置为激发状态后，
会唤醒所有等待的线程，而且一直保持为激发状态，直到程序重新把它设置为未
激发状态。自动重置事件被设置为激发状态后，会唤醒一个等待中的线程，然后
自动恢复为未激发状态。 
 
临界区 Critical Section：任意时刻只允许一个线程对临界资源进行访问。拥有临
界区对象的线程可以访问该临界资源，其它试图访问该资源的线程将被挂起，直
到临界区对象被释放。 
互斥量和临界区有什么区别？ 
互斥量是可以命名的，可以用于不同进程之间的同步；而临界区只能用于同一进
程中线程的同步。创建互斥量需要的资源更多，因此临界区的优势是速度快，节
省资源。 
什么是临界区，如何解决冲突？ 
每个进程中访问临界资源的那段程序称为临界区，一次仅允许一个进程使用的资
源称为临界资源。 
解决冲突的办法： 
 
如果有若干进程要求进入空闲的临界区，一次仅允许一个进程进入，如已有进程
进入自己的临界区，则其它所有试图进入临界区的进程必须等待； 
 
进入临界区的进程要在有限时间内退出。 
 
如果进程不能进入自己的临界区，则应让出 CPU，避免进程出现“忙等”现象。 
线程独占哪些资源？ 
 
线程 ID 
 
一组寄存器的值 
 
线程自身的栈（堆是共享的） 
 
错误返回码：线程可能会产生不同的错误返回码，一个线程的错误返回码不应该
被其它线程修改； 
 
信 号 掩 码 / 信 号 屏 蔽 字 (Signal mask) ： 表 示 是 否 屏 蔽 / 阻 塞 相 应 的 信 号
（SIGKILL,SIGSTOP 除外） 
协程 
协程多与线程进行比较？ 
1. 一个线程可以拥有多个协程，一个进程也可以单独拥有多个协程，这样 python 中
则能使用多核 CPU。 
2. 线程进程都是同步机制，而协程则是异步 
3. 协程能保留上一次调用时的状态，每次过程重入时，就相当于进入上一次调用的
状态 
IO 模型 
 
同步阻塞 IO（Blocking IO）：用户线程发起 IO 读/写操作之后，线程阻塞，直到
可以开始处理数据；对 CPU 资源的利用率不够； 
 
同步非阻塞 IO（Non-blocking IO）：发起 IO 请求之后可以立即返回，如果没有
就绪的数据，需要不断地发起 IO 请求直到数据就绪；不断重复请求消耗了大量
的 CPU 资源； 
 
IO 多路复用 
 
异步 IO（Asynchronous IO）：用户线程发出 IO 请求之后，继续执行，由内核进
行数据的读取并放在用户指定的缓冲区内，在 IO 完成之后通知用户线程直接使
用。 
 
什么是水平触发？什么是边缘触发？ 
水平触发（LT，Level Trigger）模式下，只要一个文件描述符就绪，就会触发通
知，如果用户程序没有一次性把数据读写完，下次还会通知； 
 
边缘触发（ET，Edge Trigger）模式下，当描述符从未就绪变为就绪时通知一次，
之后不会再通知，直到再次从未就绪变为就绪（缓冲区从不可读/写变为可读/写）。 
 
区别：边缘触发效率更高，减少了被重复触发的次数，函数不会返回大量用户程
序可能不需要的文件描述符。 
 
为什么边缘触发一定要用非阻塞（non-block）IO：避免由于一个描述符的阻塞读
/阻塞写操作让处理其它描述符的任务出现饥饿状态。 
 
文件描述符 
文件描述符（File Descriptor）是计算机科学中的一个术语，是用一个表述指向文
件的引用的抽象化概念。 
文件描述符在形式上是一个非负函数。实际上，它是一个索引，指向内核中每一
个进程所维护的该进程打开文件的记录表，当程序打开一个现有文件或者创建一
个新文件时，内核向进程返回一个文件描述符。在程序设计中，一些涉及底层的
程序编写往往会围绕着文件描述符展开。但是文件描述符这一概念只适用于
Unix 和 Linux 这样的操作系统。 
内核通过文件描述符来访问文件。文件描述符指向一个文件。 
什么是 IO 多路复用？怎么实现？ 
IO 多路复用（IO Multiplexing）是指单个进程/线程就可以同时处理多个 IO 请求。 
实现原理：用户将想要监视的文件描述符（File Descriptor）添加到 select/poll/epoll
函数中，由内核监视，函数阻塞。一旦有文件描述符就绪（读就绪或写就绪），
或者超时（设置 timeout），函数就会返回，然后该进程可以进行相应的读/写操
作。 
 
select/poll/epoll 三者的区别？ 
 
select ：将文件描述符放入一个集合中，调用 select 时，将这个集合从用户空间拷
贝到内核空间（缺点 1：每次都要复制，开销大），由内核根据就绪状态修改该
集合的内容。（缺点 2）集合大小有限制，32 位机默认是 1024（64 位：2048）；
采用水平触发机制。select 函数返回后，需要通过遍历这个集合，找到就绪的文
件描述符（缺点 3：轮询的方式效率较低），当文件描述符的数量增加时，效率
会线性下降； 
 
poll ：和 select 几乎没有区别，区别在于文件描述符的存储方式不同，poll 采用
链表的方式存储，没有最大存储数量的限制； 
 
epoll ：通过内核和用户空间共享内存，避免了不断复制的问题；支持的同时连接
数上限很高（1G 左右的内存支持 10W 左右的连接数）；文件描述符就绪时，采
用回调机制，避免了轮询（回调函数将就绪的描述符添加到一个链表中，执行
epoll_wait 时，返回这个链表）；支持水平触发和边缘触发，采用边缘触发机制
时，只有活跃的描述符才会触发回调函数。 
总结，区别主要在于： 
 
一个线程/进程所能打开的最大连接数 
 
文件描述符传递方式（是否复制） 
 
水平触发 or 边缘触发 
 
查询就绪的描述符时的效率（是否轮询） 
什么时候使用 select/poll，什么时候使用 epoll？ 
当连接数较多并且有很多的不活跃连接时，epoll 的效率比其它两者高很多；但
是当连接数较少并且都十分活跃的情况下，由于 epoll 需要很多回调，因此性能
可能低于其它两者。 
 
我们使用一张图来总结 select、poll、epoll 的区别 
 
select 
poll 
epoll 
操作方式 
遍历 
遍历 
回调 
底层实现 
数组 
链表 
哈希表 
IO 效率 
每 次 调 用 都
进 行 线 性 遍
历，时间复杂
度为 O(n) 
每次调用都进
行线性遍历，
时间复杂度为
O(n) 
事件通知方式，每当 fd 就
绪，系统注册的回调函数就
会被调用，将就绪 fd 放到
readyList 里面，时间复杂度
为 O(1) 
最 大 连 接
数 
1024 或 2048 
无上限 
无上限 
fd 拷贝 
每 次 调 用
select，都需
要把 fd 集合
每 次 调 用
poll，都需要
把 fd 集合从
调用 epoll_ctl 时，拷贝进内
核 并 保 存 ， 之 后 每 次
epoll_wait 不拷贝 
 
select 
poll 
epoll 
从 用 户 态 拷
贝到内核态 
用户态拷贝到
内核态 
select 和 poll 即使只有一个描述符就绪，也要遍历整个集合。如果集合中活跃的
描述符很少，遍历过程的开销就会变得很大，而如果集合中大部分的描述符都是
活跃的，遍历过程的开销又可以忽略。 
为什么要分用户态和内核态？ 
 
安全性：防止用户程序恶意或者不小心破坏系统/内存/硬件资源； 
 
封装性：用户程序不需要实现更加底层的代码； 
 
利于调度：如果多个用户程序都在等待键盘输入，这时就需要进行调度；统一交
给操作系统调度更加方便。 
 
如何从用户态切换到内核态？ 
所有的用户进程都是运行在用户态的，但是我们上面也说了，用户程序的访问能
力有限，一些比较重要的比如从硬盘读取数据，从键盘获取数据的操作则是内核
态才能做的事情，而这些数据却又对用户程序来说非常重要。所以就涉及到两种
模式下的转换，即用户态 -> 内核态 -> 用户态，而唯一能够做这些操作的只有 
系统调用，而能够执行系统调用的就只有 操作系统。 
一般用户态 -> 内核态的转换我们都称之为 trap 进内核，也被称之为 陷阱指令
(trap instruction)。 
他们的工作流程如下： 
 
首先用户程序会调用 glibc 库，glibc 是一个标准库，同时也是一套核心库，库
中定义了很多关键 API。 
 
glibc 库知道针对不同体系结构调用系统调用的正确方法，它会根据体系结构应
用程序的二进制接口设置用户进程传递的参数，来准备系统调用。 
 
然后，glibc 库调用软件中断指令(SWI) ，这个指令通过更新 CPSR 寄存器将模式
改为超级用户模式，然后跳转到地址 0x08 处。 
 
到目前为止，整个过程仍处于用户态下，在执行 SWI 指令后，允许进程执行内
核代码，MMU 现在允许内核虚拟内存访问 
 
从地址 0x08 开始，进程执行加载并跳转到中断处理程序，这个程序就是 ARM 
中的 vector_swi()。 
 
在 vector_swi() 处，从 SWI 指令中提取系统调用号 SCNO，然后使用 SCNO 
作为系统调用表 sys_call_table 的索引，调转到系统调用函数。 
 
执行系统调用完成后，将还原用户模式寄存器，然后再以用户模式执行。 
系统调用：比如读取命令行输入。本质上还是通过中断实现 
 
用户程序发生异常时：比如缺页异常 
 
外围设备的中断：外围设备完成用户请求的操作之后，会向 CPU 发出中断信号，
这时 CPU 会转去处理对应的中断处理程序 
 
内存管理 
操作系统的内存管理主要负责内存的分配与回收（malloc 函数：申请内存，free 
函数：释放内存），另外地址转换也就是将逻辑地址转换成相应的物理地址等功
能也是操作系统内存管理做的事情。 
 
操作系统的内存管理机制了解吗？内存管理有哪几
种方式? 
简单分为连续分配管理方式和非连续分配管理方式这两种。连续分配管理方式是
指为一个用户程序分配一个连续的内存空间，常见的如 块式管理 。同样地，非
连续分配管理方式允许一个程序使用的内存分布在离散或者说不相邻的内存中，
常见的如页式管理 和 段式管理。 
块式管理： 远古时代的计算机操作系统的内存管理方式。将内存分为几个固定
大小的块，每个块中只包含一个进程。如果程序运行需要内存的话，操作系统就
分配给它一块，如果程序运行只需要很小的空间的话，分配的这块内存很大一部
分几乎被浪费了。这些在每个块中未被利用的空间，我们称之为碎片。 
页式管理：把主存分为大小相等且固定的一页一页的形式，页较小，相比于块式
管理的划分粒度更小，提高了内存利用率，减少了碎片。页式管理通过页表对应
逻辑地址和物理地址。 
段式管理：页式管理虽然提高了内存利用率，但是页式管理其中的页并无任何实
际意义。 段式管理把主存分为一段段的，段是有实际意义的，每个段定义了一
组逻辑信息，例如,有主程序段 MAIN、子程序段 X、数据段 D 及栈段 S 等。 
段式管理通过段表对应逻辑地址和物理地址。简单来说：页是物理单位，段是逻
辑单位。分页可以有效提高内存利用率，分段可以更好满足用户需求。 
段页式管理机制 。段页式管理机制结合了段式管理和页式管理的优点。简单来
说段页式管理机制就是把主存先分成若干段，每个段又分成若干页，也就是说 段
页式管理机制 中段与段之间以及段的内部的都是离散的。 
 
硬盘分区分别是做什么 
/swap 分区是交换分区，是有一定磁盘空间（分区或文件），用于将部分内存中
的数据交换下来，以腾出内存空间用于其它需求。在一个系统中，物理内存快使
用完时，操作系统会使用交换分区。当系统内存紧张时，操作系统根据一定算法
规则，将一部分最近没有使用的内存页面保存到交换分区，从而为需要内存的程
序留出足够的内存空间，在 swap 中的内存页面被访问时，系统会将其重新载入
到物理内存中去运行。 
/var/lib/placements 创建共享存储，实现镜像共享。 
 
 
什么是分页？ 
把内存空间划分为大小相等且固定的块，作为主存的基本单位。因为程序数据存
储在不同的页面中，而页面又离散的分布在内存中，因此需要一个页表来记录映
射关系，以实现从页号到物理块号的映射。 
访问分页系统中内存数据需要两次的内存访问 (一次是从内存中访问页表，从中
找到指定的物理块号，加上页内偏移得到实际物理地址；第二次就是根据第一次
得到的物理地址访问内存取出数据)。 
 
什么是分段？ 
分页是为了提高内存利用率，而分段是为了满足程序员在编写代码的时候的一些
逻辑需求(比如数据共享，数据保护，动态链接等)。 
分段内存管理当中，地址是二维的，一维是段号，二维是段内地址；其中每个段
的长度是不一样的，而且每个段内部都是从 0 开始编址的。由于分段管理中，每
个段内部是连续内存分配，但是段和段之间是离散分配的，因此也存在一个逻辑
地址到物理地址的映射关系，相应的就是段表机制。 
 
分页和分段有什么区别？ 
 
页式存储：用户空间划分为大小相等的部分称为页（page），内存空间划分为同
样大小的区域称为页框，分配时以页为单位，按进程需要的页数分配，逻辑上相
邻的页物理上不一定相邻； 
 
段式存储：用户进程地址空间按照自身逻辑关系划分为若干个段（segment）（如
代码段，数据段，堆栈段），内存空间被动态划分为长度不同的区域，分配时以
段为单位，每段在内存中占据连续空间，各段可以不相邻； 
 
段页式存储：用户进程先按段划分，段内再按页划分，内存划分和分配按页。 
区别： 
 
目的不同：分页的目的是管理内存，用于虚拟内存以获得更大的地址空间；分段
的目的是满足用户的需要，使程序和数据可以被划分为逻辑上独立的地址空间； 
 
大小不同：段的大小不固定，由其所完成的功能决定；页的大小固定，由系统决
定； 
 
地址空间维度不同：分段是二维地址空间（段号+段内偏移），分页是一维地址
空间（每个进程一个页表/多级页表，通过一个逻辑地址就能找到对应的物理地
址）； 
 
分段便于信息的保护和共享；分页的共享收到限制； 
 
碎片：分段没有内碎片，但会产生外碎片；分页没有外碎片，但会产生内碎片（一
个页填不满） 
什么是交换空间？ 
操作系统把物理内存(physical RAM)分成一块一块的小内存，每一块内存被称为
页(page)。当内存资源不足时，Linux 把某些页的内容转移至硬盘上的一块空间
上，以释放内存空间。硬盘上的那块空间叫做交换空间(swap space),而这一过程
被称为交换(swapping)。物理内存和交换空间的总容量就是虚拟内存的可用容量。 
用途： 
 
物理内存不足时一些不常用的页可以被交换出去，腾给系统。 
 
程序启动时很多内存页被用来初始化，之后便不再需要，可以交换出去。 
物理地址、逻辑地址、有效地址、线性地址、虚拟地址的区别? 
物理地址就是内存中真正的地址，它就相当于是你家的门牌号，你家就肯定有这
个门牌号，具有唯一性。不管哪种地址，最终都会映射为物理地址。 
在实模式下，段基址 + 段内偏移经过地址加法器的处理，经过地址总线传输，
最终也会转换为物理地址。 
但是在保护模式下，段基址 + 段内偏移被称为线性地址，不过此时的段基址不能
称为真正的地址，而是会被称作为一个选择子的东西，选择子就是个索引，相当
于数组的下标，通过这个索引能够在 GDT 中找到相应的段描述符，段描述符记
录了段的起始、段的大小等信息，这样便得到了基地址。如果此时没有开启内存
分页功能，那么这个线性地址可以直接当做物理地址来使用，直接访问内存。如
果开启了分页功能，那么这个线性地址又多了一个名字，这个名字就是虚拟地址。 
不论在实模式还是保护模式下，段内偏移地址都叫做有效地址。有效抵制也是逻
辑地址。 
线性地址可以看作是虚拟地址，虚拟地址不是真正的物理地址，但是虚拟地址会
最终被映射为物理地址。下面是虚拟地址 -> 物理地址的映射。 
编程一般只有可能和逻辑地址打交道，比如在 C 语言中，指针里面存储的数值就
可以理解成为内存里的一个地址，这个地址也就是我们说的逻辑地址，逻辑地址
由操作系统决定。 
  
什么是虚拟内存？ 
每个程序都拥有自己的地址空间，这个地址空间被分成大小相等的页，这些页被
映射到物理内存；但不需要所有的页都在物理内存中，当程序引用到不在物理内
存中的页时，由操作系统将缺失的部分装入物理内存。这样，对于程序来说，逻
辑上似乎有很大的内存空间，只是实际上有一部分是存储在磁盘上，因此叫做虚
拟内存。 
虚拟内存的优点是让程序可以获得更多的可用内存。 
虚拟内存的实现方式、页表/多级页表、缺页中断、不同的页面淘汰算法： 
虚拟内存的实现方式有哪些? 
虚拟内存中，允许将一个作业分多次调入内存。釆用连续分配方式时，会使相当
一部分内存空间都处于暂时或永久的空闲状态，造成内存资源的严重浪费，而且
也无法从逻辑上扩大内存容量。因此，虚拟内存的实需要建立在离散分配的内存
管理方式的基础上。虚拟内存的实现有以下三种方式： 
 
请求分页存储管理。 
 
请求分段存储管理。 
 
请求段页式存储管理。 
如何进行地址空间到物理内存的映射？ 
内存管理单元（MMU）管理着逻辑地址和物理地址的转换，其中的页表（Page 
table）存储着页（逻辑地址）和页框（物理内存空间）的映射表，页表中还包含
包含有效位（是在内存还是磁盘）、访问位（是否被访问过）、修改位（内存中
是否被修改过）、保护位（只读还是可读写）。逻辑地址：页号+页内地址（偏
移）；每个进程一个页表，放在内存，页表起始地址在 PCB/寄存器中。 
有哪些页面置换算法？ 
在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页
调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁
盘中来腾出空间。页面置换算法的主要目标是使页面置换频率最低（也可以说缺
页率最低）。 
 
最佳页面置换算法 OPT（Optimal replacement algorithm）：置换以后不需要或者
最远的将来才需要的页面，是一种理论上的算法，是最优策略； 
 
先进先出 FIFO：置换在内存中驻留时间最长的页面。缺点：有可能将那些经常
被访问的页面也被换出，从而使缺页率升高； 
 
第二次机会算法 SCR：按 FIFO 选择某一页面，若其访问位为 1，给第二次机会，
并将访问位置 0； 
 
时钟算法 Clock：SCR 中需要将页面在链表中移动（第二次机会的时候要将这个
页面从链表头移到链表尾），时钟算法使用环形链表，再使用一个指针指向最老
的页面，避免了移动页面的开销； 
 
最近未使用算法 NRU（Not Recently Used）：检查访问位 R、修改位 M，优先置
换 R=M=0，其次是（R=0, M=1）； 
 
最近最少使用算法 LRU（Least Recently Used）：置换出未使用时间最长的一页；
实现方式：维护时间戳，或者维护一个所有页面的链表。当一个页面被访问时，
将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。 
 
最不经常使用算法 NFU：置换出访问次数最少的页面 
 
局部性原理 
 
时间上：最近被访问的页在不久的将来还会被访问； 
 
空间上：内存中被访问的页周围的页也很可能被访问。 
什么是颠簸现象 
颠簸本质上是指频繁的页调度行为。进程发生缺页中断时必须置换某一页。然而，
其他所有的页都在使用，它置换一个页，但又立刻再次需要这个页。因此会不断
产生缺页中断，导致整个系统的效率急剧下降，这种现象称为颠簸。内存颠簸的
解决策略包括： 
 
修改页面置换算法； 
 
降低同时运行的程序的数量； 
 
终止该进程或增加物理内存容量。 
什么是缓冲区溢出？C 语言使用运行时栈来存储过程信息。每个函数的信息存
储在一个栈帧中，包括寄存器、局部变量、参数、返回地址等。C 对于数组引用
不进行任何边界检查，因此**对越界的数组元素的写操作会破坏存储在栈中的状
态信息**，这种现象称为缓冲区溢出。缓冲区溢出会破坏程序运行，也可以被用
来进行攻击计算机，如使用一个指向攻击代码的指针覆盖返回地址。缓冲区溢出
的防范方式 
防范缓冲区溢出攻击的机制有三种：随机化、栈保护和限制可执行代码区域。 
 
随机化：包括栈随机化（程序开始时在栈上分配一段随机大小的空间）和地址空
间布局随机化（Address-Space Layout Randomization，ASLR，即每次运行时程序
的不同部分，包括代码段、数据段、栈、堆等都会被加载到内存空间的不同区域），
但只能增加攻击一个系统的难度，不能完全保证安全。 
 
栈保护：在每个函数的栈帧的局部变量和栈状态之间存储一个随机产生的特殊的
值，称为金丝雀值（canary）。在恢复寄存器状态和函数返回之前，程序检测这
个金丝雀值是否被改变了，如果是，那么程序异常终止。 
 
限制可执行代码区域：内存页的访问形式有三种：可读、可写、可执行，只有编
译器产生的那部分代码所处的内存才是可执行的，其他页限制为只允许读和写。 
 
磁盘调度 
过程：磁头（找到对应的盘面）；磁道（一个盘面上的同心圆环，寻道时间）；
扇区（旋转时间）。为减小寻道时间的调度算法： 
 
先来先服务 
 
最短寻道时间优先 
 
电梯算法：电梯总是保持一个方向运行，直到该方向没有请求为止，然后改变运
行方向。 
fork 函数的作用 
在 Linux 中 fork 函数是非常重要的函数，它的作用是从已经存在的进程中创建
一个子进程，而原进程称为父进程。 
调用 fork()，当控制转移到内核中的 fork 代码后，内核开始做： 
1. 分配新的内存块和内核数据结构给子进程。 
2. 将父进程部分数据结构内容拷贝至子进程。 
3. 将子进程添加到系统进程列表。 
4. fork 返回开始调度器，调度。 
特点： 
1)调用一次，返回两次并发执行 
2)相同但是独立的地址空间 
3)fork 的返回值：fock 函数调用一次却返回两次；向父进程返回子进程的 ID，
向子进程中返回 0， 
4)fork 的子进程返回为 0； 
5)父进程返回的是子进程的 pid。 
fork 调用失败的原因 
1)系统中有太多进程。 
2)实际用户的进程数超过限制。 
 
shell 
 
# 列出文件系统的磁盘使用状况 - df。df –h 
# free 命令,它是用来查看系统内存的命令 
free -h #查看内存使用情况,并且以合适的单位显示大小 
# 查看网络服务和端口 - netstat / ss。 
[root ~]# netstat -nap | grep nginx 
使用 ls -ll，会显示成字节大小，而 ls- lh 会以 KB、MB 等为单位
进行显示 
Linux 查看进程 
1. ps –aux 简单列表的形式显示出进程信息 
a：显示当前终端下的所有进程信息，包括其他用户的进程。 
u：使用以用户为主的格式输出进程信息。 
x：显示当前用户在所有终端下的进程。 
2. ps –elf 
-e：显示系统内的所有进程信息。 
-l：使用长（long）格式显示进程信息。 
-f：使用完整的（full）格式显示进程信息。  
3. top 
以全屏交互式的界面显示进程排名，及时跟踪包括 CPU、内存等系统资源占用情况，默认
情况下每三秒刷新一次，其作用基本类似于 Windows 系统中的任务管理器。 
4. pstree –aup 以树状图的方式展现进程之间的派生关系 
-a：显示每个程序的完整指令，包含路径，参数或是常驻服务的标示；  
-c：不使用精简标示法；  
-G：使用 VT100 终端机的列绘图字符；  
-h：列出树状图时，特别标明现在执行的程序；  
-H<程序识别码>：此参数的效果和指定”-h”参数类似，但特别标明指定的程序；  
-l：采用长列格式显示树状图；  
-n：用程序识别码排序。预设是以程序名称来排序；  
-p：显示程序识别码；  
-u：显示用户名称；  
 
4. uptime 
查看系统的负载情况。 
 
mount 
将 /dev/hda1 挂在 /mnt 之下 
 
ldd 
list dynamic dependencies，列出动态库依赖关系 
ldd 本身不是一个程序，而仅是一个 shell 脚本：ldd 可以列出一个程序
所需要得动态链接库（so） 
ldd 命令通常使用"-v"或"--verbose"选项来显示所依赖的动态连接库
的尽可能的详细信息。 
即可得到/bin/ls 命令的相关共享库文件列表： 
root@xxhui:/home/hui# ldd /bin/ls 
linux-vdso.so.1 (0x00007ffeeffc3000) 
libselinux.so.1 => /lib/x86_64-linux-gnu/libselinux.so.1 
(0x00007f8e631c7000) 
libacl.so.1 => /lib/x86_64-linux-gnu/libacl.so.1 
(0x00007f8e62fbe000) 
libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 
(0x00007f8e62c19000) 
libpcre.so.3 => /lib/x86_64-linux-gnu/libpcre.so.3 
(0x00007f8e629a9000) 
libdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 
(0x00007f8e627a5000) 
/lib64/ld-linux-x86-64.so.2 (0x00005599a18e8000) 
libattr.so.1 => /lib/x86_64-linux-gnu/libattr.so.1 
(0x00007f8e6259f000) 
libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 
(0x00007f8e62382000) 
注意： 在 ldd 命令打印的结果中，“=>”左边的表示该程序需要连
接的共享库之 so 名称，右边表示由 Linux 的共享库系统找到的对应
的共享库在文件系统中的具体位置。默认情况下， /etc/ld.so.conf 
文件中包含有默认的共享库搜索路径。 
ss 
ss 是 Socket Statistics 的缩写。ss 命令可以用来获取 socket 统计
信息 
-h, –help 帮助  
-V, –version 显示版本号  
-t, –tcp 显示 TCP 协议的 sockets  
-u, –udp 显示 UDP 协议的 sockets  
-x, –unix 显示 unix domain sockets，与 -f 选项相同  
-n, –numeric 不解析服务的名称，如 “22” 端口不会显示成 
“ssh”  
-l, –listening 只显示处于监听状态的端口  
-p, –processes 显示监听端口的进程(Ubuntu 上需要 sudo)  
-a, –all 对 TCP 协议来说，既包含监听的端口，也包含建立的连接  
-r, –resolve 把 IP 解释为域名，把端口号解释为协议名称 
 
chmod 
修改/test 下的 aaa.txt 的权限为文件所有者有全部权限，文件所有
者所在的组有读写权限，其他用户只有读的权限。 
chmod u=rwx,g=rw,o=r aaa.txt 或者 chmod 764 aaa.txt 
环境变量修改 
通过 export 命令可以修改指定的环境变量。不过，这种方式修改环境
变量仅仅对当前 shell 终端生效，关闭 shell 终端就会失效。修改完
成之后，立即生效。 
export CLASSPATH=./JAVA_HOME/lib;$JAVA_HOME/jre/lib 
通过 vim 命令修改环境变量配置文件。这种方式修改环境变量永久有
效。vim ~/.bash_profile 
如果修改的是系统级别环境变量则对所有用户生效，如果修改的是用
户级别环境变量则仅对当前用户生效。修改完成之后，需要 source 
命令让其生效或者关闭 shell 终端重新登录。source /etc/profile 
shell 单引号和双引号 
在单引号中所有的特殊符号，如$和反引号都没有特殊含义。在双引号
中，除了"$",""和反引号，其他的字符没有特殊含义。 
 
shell 数组 
array=(1 2 3 4 5); 
# 获取数组长度 
length=${#array[@]} 
# 或者 
length2=${#array[*]} 
#输出数组长度 
echo $length #输出：5 
echo $length2 #输出：5 
# 输出数组第三个元素 
echo ${array[2]} #输出：3 
unset array[1]# 删除下标为 1 的元素也就是删除第二个元素 
for i in ${array[@]};do echo $i ;done # 遍历数组，输出： 1 3 4 5 
unset array; # 删除数组中的所有元素 
for i in ${array[@]};do echo $i ;done # 遍历数组，数组元素为空，
没有任何输出内容 
 
 
 
 
VIM 使用 
 
# vim 
删除：在命令模式下可以用 dd 来删除整行；可以在 dd 前加数字来指定删除的行数；
可以用 d$ 来实现删除从光标处删到 
行尾的操作，也可以通过 d0 来实现从光标处删到行首的操作；如果想删除一个单词，
可以使用 dw ；如果要删除全文， 
可以在输入 :%d （其中 : 用来从命令模式进入末行模式）。 
撤销和恢复：在命令模式下输入 u 可以撤销之前的操作；通过 Ctrl+r 可以恢复被撤销
的操作。 
对内容进行排序：在命令模式下输入 %!sort 。 
查找操作需要输入 / 进入末行模式并提供正则表达式来匹配与之对应的内容，例如： 
/doc.*\. ，输入 n 来向前搜索，也 
可以输入 N 来向后搜索。 
在输入 : 进入末行模式后可以对 vim 进行设定。 
设置 Tab 键的空格数： set ts=4 
设置显示/不显示行号： set nu /  set nonu 
设置启用/关闭高亮语法： syntax on /  syntax off 
设置显示标尺（光标所在的行和列）：  set ruler 
设置启用/关闭搜索结果高亮： set hls /  set nohls 
# 比较多个文件。 
[root ~]# vim -d foo.txt bar.txt 
 
 
# vim 非编辑模式 
yy：复制光标当前行 
p：粘贴 
dd:删除光标当前行 
$:光标跳到当前行的行尾 
^:光标跳到当前行的行首 
:s/原字符串/新字符串/:替换光标当前行内容 
:%s/原字符串/新字符串/g:全文替换 #g 表示 global i 表示 ignore 忽略大小写 
/要查找的内容:从光标当前行向后查找内容 
/d #在文件中查找 d 字母 
?要查找的内容：从光标当前位置向前查找内容 
?d #查找文件中的 d 字母 
CTRL+F:向下翻 1 页 
CTRL+B:向上翻 1 页 
:set nu：显示文件的行号 
:set nonu: 去掉行号显示 
u:撤消 
**:set ff :显示文件的格式 #unix 表示在 unix 上的文件 dos 表示文件是 windows 上的文
件** 
:w ：表示保存文件 
:q :表示退出 vim 命令 
:wq:保存并退出 
:w!:强制保存 
:q!:强制退出但不保存 
:wq!:强制保存并退出 
i:表示进入编辑模式，并且光标在当前行 
o：表示进入编辑模式，并且光标出现的当前行的下一行(新行) 
 
 
 
10 个 Linux 常用命令 
ls  
pwd 
cd 
touch  
rm  
mkdir  
tree  
cp  
mv  
cat  
more  
grep  
echo 
获取登录信息 - w / who / last/ lastb。 
查看命令的说明和位置 - whatis / which / whereis。 
查看帮助文档 - man / info / help / apropos。 
查看系统和主机名 - uname / hostname。 
时间和日期 - date / cal。 
重启和关机 - reboot / shutdown。 
查看文件内容 - cat / tac / head / tail / more / less / rev / od。 
文件重命名 - rename。 
查找文件和查找内容 - find / grep。 
创建链接和查看链接 - ln / readlink。 
将标准输入转成命令行参数 - xargs。 
显示文件或目录 - basename / dirname。 
sort - 对内容排序 
uniq - 去掉相邻重复内容 
tr - 替换指定内容为新内容 
cut/paste - 剪切/黏贴内容 
split - 拆分文件 
file - 判断文件类型 
wc - 统计文件行数、单词数、字节数 
wc -l linux 常用命令.txt #-l 表示 line 行数 计算文件的行数 
wc -w linux 常用命令.txt #-w 表示 word 单词个数 计算文件的单词个数 
iconv - 编码转换 
输出重定向和错误重定向 - > / >> / 2>。 
 
# 多重定向 - tee。 
下面的命令除了在终端显示命令 ls 的结果之外，还会追加输出到 ls.txt 文件中 
ls | tee -a ls.txt 
 
# 别名 alias 
alias ll='ls -l' 
alias frm='rm -rf' 
 
# 创建和删除用户 - useradd / userdel 
# 创建和删除用户组 - groupadd / groupdel。 
useradd hellokitty 
userdel hellokitty 
说明：用户组主要是为了方便对一个组里面所有用户的管理。 
-d - 创建用户时为用户指定用户主目录 
-g - 创建用户时指定用户所属的用户组 
 
# 修改密码 - passwd。 
[root ~]# passwd hellokitty 
New password: 
Retype new password: 
passwd: all authentication tokens updated successfully. 
 
 
# 查看和修改密码有效期 - chage。 
设置 hellokitty 用户 100 天后必须修改密码，过期前 15 天通知该用户，过期后 15 天禁
用该用户。 
chage -M 100 -W 15 -I 15 hellokitty 
 
# 编辑 sudoers 文件 - visudo。 
# 显示用户与用户组的信息 - id。 
# 给其他用户发消息 -write / wall。 
# 查看/设置是否接收其他用户发送的消息 - mesg。 
# chown - 改变文件所有者。 
[root ~]# chown hellokitty readme.txt 
# 磁盘分区表操作 - fdisk。 
# 磁盘分区工具 - parted。 
# 格式化文件系统 - mkfs。 
# 文件系统检查 - fsck。 
# 转换或拷贝文件 - dd 
# 挂载/卸载 - mount / umount。 
# 创建/激活/关闭交换分区 - mkswap / swapon / swapoff。 
网络监听抓包 - tcpdump。 
文件同步工具 - rsync。 
说明：使用 rsync 可以实现文件的自动同步，这个对于文件服务器来说相当重要。 
 
# 用一条命令强制终止正在运行的 Redis 进程。 
ps -ef | grep redis | grep -v grep | awk '{print $2}' | xargs kill -9 
 
# echo 命令 
echo #输出命令，可以输入变量，字符串的值 
echo Hello World #打印 Hello World 
echo $PATH #打印环境变量 PATH 的值,其中$是取变量值的符号，用法：$变量名 或者 
${变量名} 
echo -n #打印内容但不换行 
echo -n Hello World 
 
# >和>>命令 
和>>:输出符号，将内容输出到文件中，>表示覆盖(会删除原文件内容) >>表示追加 
echo Hello World > 1.txt #将 Hello World 输出到当前目录下的 1.txt 文件 
#如果当前目录下没有 1.txt 文件会创建一个新文件， 
#如果当前目录下有 1.txt，则会删除原文件内容，写入 Hello World 
echo 1234 >> 1.txt #将 1234 追加到当前目录下的 1.txt 中，如果文件不存在会创建新文件 
通过>和>>都可以创建文件 
 
 
# zip 
zip 2.zip 2.txt #将 2.txt 压缩到 2.zip 中 
zip data.zip data #只会压缩文件夹,不会压缩文件夹下的内容 
zip da.zip da/* #压缩文件夹和文件夹内的文件(压缩文件夹和它的下一级文件) 
zip -r data.zip date #-r 表示递归地将文件夹及它的子目录文件全部压缩 
unzip 2.zip #将 2.zip 压缩包解压到当前目录下 
unzip -l 压缩文件名 #不解压文件,查看压缩包内的文件 
unzip -l da.zip #查看 da.zip 压缩文件中包含的文件 
unzip da.zip -d 目标目录 #将压缩文件解压到指定目录 
unzip da.zip -d tm/ #将压缩文件 da.zip 解压到 tm 目录下 
tar cvf 压缩文件名 要压缩的文件或目录 
tar cvf 2.tar 2.txt #将 2.txt 压缩为 2.tar 包 
tar cvf data.tar data #将 data 目录夸张到 data.tar 包中 
tar xvf 2.tar #将 2.tar 解压到当前目录 
tar xvf 2.tar -C a/ #将 2.tar 解压到 a 目录 
tar xvf data.tar #解压 data.tar 到当前目录 
tar zcvf 压缩文件名 要压缩的文件 
tar zcvf tm.tar.gz tm #将当前目录下的 tm 目录压缩为 tm.tar.gz 
tar zxvf 压缩文件名 
tar zxvf tm.tar.gz #将 tm.tar.gz 解压到当前目录 
gzip 命令,将文件压缩为.gz 包(可以用来压缩.tar 文件) 
gzip 要压缩的文件 
gzip 2.txt #将 2.txt 压缩为 2.txt.gz 
gzip data.tar #将 data.tar 压缩为 data.tar.gz 
 
 
/etc/profile #linux 上的系统环境变量配置文件 
source /etc/profile #将系统环境变量生效 
 
 
export 导入全局变量(环境变量) 
export 变量名=变量值 
export 变量名 
变量的赋值: 
变量名=变量值 
 
<<EOF 
<<EOF … EOF:将<<EOF 和 EOF 之间的多行内容传给前面的命令, 
其中 EOF 可以是任意字符串,但约定都使用 EOF 
 
 
# cut 
-f 参数,指定列 
-d 参数指定列和列之间的分隔符,默认的分隔符是\t(行向制表符) 
cut -f 1 1.txt #取 1.txt 文件中的第 1 列内容(列分隔符默认为\t) 
cut -f 2 1.txt #取 1.txt 文件中的第 2 列内容 
cut -f 1 -d ',' 3.txt #取 3.txt 文件中的第 1 列(列分隔符为,) 
cut -f 2 -d ',' 3.txt #取 3.txt 第 2 列 
 
# sudo 命令 
sudo 命令,它在非 root 用户下,去调用一些 root 用户的命令,或者修改一些文件 
sudo 命令是需要配置的,sudo 的配置文件是/etc/sudoers 
##  19. <a name='bowsudo'></a>bow 用户配置 sudo 权限 
[root@bow ~]# vim /etc/sudoers 
## 
##  20. <a name='Allowroottorunanycommandsanywhere'></a>Allow root to run any commands anywhere 
root ALL=(ALL) ALL 
##  21. <a name='bowsudo-1'></a>bow 用户设置 sudo 命令权限 
bow ALL=(ALL) ALL 
[root@bow ~]# su - bow 
上一次登录：四 3 月 26 07:30:53 CST 2020pts/0 上 
[bow@bow ~]$ sudo vim /etc/profile 
 
 
# ifconfig 
ifconfig 命令属于 net-tools 软件包,使用前需要安装 net-tools 
net-tools 的安装: 
yum -y install net-tools 
ifconfig 查看 ip 地址 
 
# netstat 
netstat 命令也属于 net-tools 软件包 
netstat -tulp | grep 1521 #查看 oracle 监听器程序是否正常启动 
 
# rpm 
rpm -ivh .rpm 文件的路径 #表示安装软件包 
rpm -qa #查看已安装的软件 
rpm -qa | grep mysql #查看已经安装的 mysql 软件包 
rpm -e --nodeps 安装包名 #卸载软件包 -e 表示卸载 --nodeps 表示不理会的依赖关系 
sed 
字符流编辑器--sed，sed 是操作、过滤和转换文本内容的工具。 
假设有一个名为 fruit.txt 的文件，内容如下所示。 
[root ~]# cat -n fruit.txt 
1 banana 
2 grape 
3 apple 
4 watermelon 
5 orange 
接下来，我们在第 2 行后面添加一个 pitaya。 
[root ~]# sed '2a pitaya' fruit.txt 
banana 
grape 
pitaya 
apple 
watermelon 
orange 
在第 2 行前面插入一个 waxberry。 
[root ~]# sed '2i waxberry' fruit.txt 
banana 
waxberry 
grape 
apple 
watermelon 
orange 
删除第 3 行。 
[root ~]# sed '3d' fruit.txt 
banana 
grape 
watermelon 
orange 
删除第 2 行到第 4 行。 
[root ~]# sed '2,4d' fruit.txt 
banana 
orange 
将文本中的字符 a 替换为@。 
[root ~]# sed 's#a#@#' fruit.txt 
b@nana 
gr@pe 
@pple 
w@termelon 
or@nge 
将文本中的字符 a 替换为@，使用全局模式。 
[root ~]# sed 's#a#@#g' fruit.txt 
b@n@n@ 
gr@pe 
@pple 
w@termelon 
or@nge 
 
sed 可以查找日志文件特定的一段 , 根据时间的一个范围查询，可以按照行号和时间范
围查询 
按照行号 
sed -n '5,10p' filename 这样你就可以只查看文件的第 5 行到第 10 行。 
按照时间段 
sed -n '/2014-12-17 16:17:20/,/2014-12-17 16:17:36/p' test.log 
awk 
模式匹配和处理语言 - awk。 awk 是一种编程语言，也是 Linux 系统中处理文本
最为强大的工具，它的作者之一和现在的维护者就是之前提到过的 Brian 
Kernighan（ken 和 dmr 最亲密的伙伴）。通过该命令可以从文本中提取出指定的
列、用正则表达式从文本中取出我们想要的内容、显示指定的行以及进行统计和
运算，总之它非常强大。 
假设有一个名为 fruit2.txt 的文件，内容如下所示。 
[root ~]# cat fruit2.txt 
1 banana 120 
2 grape 500 
3 apple 1230 
4 watermelon 80 
5 orange 400 
 
# 显示文件的第 3 行。 
[root ~]# awk 'NR==3' fruit2.txt 
3 apple 1230 
 
# 显示文件的第 2 列。 
[root ~]# awk '{print $2}' fruit2.txt 
banana 
grape 
apple 
watermelon 
orange 
 
# 显示文件的最后一列。 
[root ~]# awk '{print $NF}' fruit2.txt 
120 
500 
1230 
80 
400 
 
# 输出末尾数字大于等于 300 的行。 
[root ~]# awk '{if($3 >= 300) {print $0}}' fruit2.txt 
2 grape 500 
3 apple 1230 
5 orange 400 
 
 
 
 
 
find 和 grep 
grep 命令是一种强大的文本搜索工具，grep 搜索内容串可以是正则表达式，允许
对文本文件进行模式查找。如果找到匹配模式，grep 打印包含模式的所有行。 
find 通常用来再特定的目录下搜索符合条件的文件，也可以用来搜索特定用户属
主的文件。 
安装 Python 3.6 
[root ~]# yum install gcc 
[root ~]# wget https://www.python.org/ftp/python/3.6.5/Python-3.6.5.tgz 
[root ~]# gunzip Python-3.6.5.tgz 
[root ~]# tar -xvf Python-3.6.5.tar 
[root ~]# cd Python-3.6.5 
[root ~]# ./configure --prefix=/usr/local/python36 --enable-optimizations 
[root ~]# yum -y install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel 
readline-devel tk-devel gdbm-devel db4-devel libpcap-devel xz-devel 
[root ~]# make && make install 
... 
[root ~]# ln -s /usr/local/python36/bin/python3.6 /usr/bin/python3 
[root ~]# python3 --version 
Python 3.6.5 
[root ~]# python3 -m pip install -U pip 
[root ~]# pip3 --version 
说明：上面在安装好 Python 之后还需要注册 PATH 环境变量，将 Python 安装路
径下 bin 文件夹的绝对路径注册到 PATH 环境变量中。注册环境变量可以修改用
户主目录下的.bash_profile 或者/etc 目录下的 profile 文件，二者的区别在于前者
相当于是用户环境变量，而后者相当于是系统环境变量 
Linux 下的大多数服务都被设置为守护进程（驻留在系统后台运行，但不会因为
服务还在运行而导致 Linux 无法停止运行），所以我们安装的服务通常名字后面
都有一个字母 d ，它是英文单词 daemon 的缩写，例如：防火墙服务叫 firewalld，
我们之前安装的 MySQL 服务叫 mysqld，Apache 服务器叫 httpd 等。在安装好服
务之后，可以使用 systemctl 命令或 service 命令来完成对服务的启动、停止等
操作 
 
 
 
centos7 下编译安装 python3 
1.必须解决编译所需的基础开发环境 
yum install gcc patch libffi-devel python-devel zlib-devel bzip2-devel openssl-devel ncurses-
devel sqlite-devel readline-devel tk-devel gdbm-devel db4-devel libpcap-devel xz-devel -y 
2.下载 python3 的编代码包,解压缩 
wget https://www.python.org/ftp/python/3.7.4/Python-3.7.4.tar.xz 
xz -d Python-3.7.4.tar.xz 
tar -xf Python-3.7.4.tar 
3.进入解压缩生成的源码文件夹 
cd Python-3.7.4 
4.执行编译三部曲的命令 
第一曲：找到一个[配置的可执行文件，configure]，执行它，且指定软件安装位置 
./configure --prefix=/opt/python374/ 
第二曲：在上一步，会生成一个 makefile，编译安装，在 linux 下必须用 gcc 工具去编
译，使用的命令时 
make&&make 
第三曲：这一步是执行安装，会生成一个/opt/python374 文件夹，可用的解释器都在这里
了 
make install 
5.配置环境变量，便于快捷使用 python3 
1.先获取当前的 PATH 变量，然后把 python3 的 bin 目录加进去 
echo $PATH 
/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin:/root/bin 
2.永久修改 PATH 的值 
-直接修改/etc/profile ，系统全局的配置文件，每个用户在登陆系统的时候，都会加载这
个文件 
vim /etc/profile 
-写入新的 PATH 变量 
PATH="/opt/python367/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin:/root/bin 
" 
3.重新登陆，或者手动读取这个/etc/profile 
source /etc/profile # 让这个文件中的变量生效 
 
 
 
Linux 下安装 openJDK 
1. 卸载旧版本 
rpm -qa|grep gcj 
如果有 gcj 文件，yum remove 即可； 
2. 安装 OpenJDK，只是 1.8 以上 
注意：安装 java-1.8.0-openjdk 后只有 jre，必须继续安装 yum install java-1.8.0-openjdk-
devel 
安装完后的路径为：/usr/lib/jvm 
yum install java-1.8.0-openjdk 
yum install java-1.8.0-openjdk-devel 
3. 配置环境变量 
vi /etc/profile 
export JAVA_HOME=/usr/lib/jvm/java-1.8.0 
export JRE_HOME=$JAVA_HOME/jre 
export 
CLASS_PATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib 
export PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin 
 
 
 
虚拟环境 virtualenv 
virtualenv----虚拟环境，就是可以在一个主机上，自定义出多套的 python 环境，
多套环境中使用不同的 python 解析器，环境变量设置，第三方依赖包，执行不
同的测试命令，最重要的是各个环境之间互不影响，相互隔离； 
virtualenv 使用 
1. pip install virtualenv； 
2. cd 到存放虚拟环境的目录，执行 virtualenv ENV----在当前目录下创建名为 ENV
的虚拟环境（如果第三方包 virtualenv 安装在 python3 下面，此时创建的虚拟环
境就是基于 python3 的）; virtualenv -p /usr/local/bin/python2.7 ENV2 参数 -p 指
定 python 版本创建虚拟环境 virtualenv --system-site-packages ENV 参数 --
system-site-packages 指定创建虚拟环境时继承系统三方库 
3. source bin/activate 激活虚拟环境 pip list 查看当前虚拟环境下所安装的第三方
库 deactivate 退出虚拟环境 
4. 删除的话，直接删除虚拟环境所在目录即可。 
 
iptables 使用 
iptables –I INPUT –s 192.168.11.12 –p –tcp m tcp –j DROP 
iptables –D INPUT –s 192.168.11.12 –p –tcp m tcp –j DROP 
iptables –nL |grep 192.168.11.12 
 
 
linux 下的后台进程管理利器 supervisor 
每次文件修改后再 linux 执行 service supervisord restart 
用过 ping 命令么？简单介绍一下。TTL 是什么意思？ 
ping : 查看与某台机器的连接情况。TTL：生存时间。数据报被路由器丢弃之前
允许通过的网段数量。 
怎么判断一个主机是不是开放某个端口？ 
telnet IP 地址 端口 
telnet 127.0.0.1 3389 
 
6. git 
1. 配置 user.name 以及 user.email 
git 使用你的用户名将提交与身份相关联。 git config 命令可用来更改你的 git 配置，
包括你的用户名。 
 
----git config --global user.name dongxiang 
----git config --global user.email dong.xiangxiang@zte.com.cn 
git config --list                  # 列出 Git 可以在该处找到的所有的设置 
2. Git 终端的配置，生成公钥文件 
1. ssh-keygen -t rsa -C (这里是你的邮箱地址) # 之后一路回车即可； 
2. 执行完后，在指定路径生成公钥文件； 
linux 路径：~/.ssh 
windows 路径：c 盘>用户>自己的用户名>.ssh 
3. 将公钥 id_rsa.pub 文本内容拷贝到远端 ssh keys 中。 
3. git 修改上次提交 
修改后执行 git add .； 
然后 git commit --amend，把文件和上次提交合并（--amend 可以保持 change_Id 和上次
一样，如果被删掉的话，这条命令会生成新的 chang_id,此时如果想合并到上次的修改
中，必须复制上次的 Change_Id 作为本次的 Change_id）; 
最后 git push origin HEAD:refs/for/master 
 
git 本地只有在 add+commit 之后才能出现 master 分支； 
 
 
4. git 添加 github 远程仓库 
----- git remote add -m master origin git@github.com:SHANExiang/blog.git 
5. git 本地 master 分支与远程 master 分支关联 
当在本地新建一个已经存在代码的本地仓库时，想将这个仓库与远端的仓库关联，即 
----- git branch --set-upstream-to=origin/master master 
Branch 'master' set up to track remote branch 'master' from 'origin'. 
----- git push origin master 报错 
To github.com:SHANExiang/blog.git 
! [rejected] master -> master (non-fast-forward) 
error: failed to push some refs to 'git@github.com:SHANExiang/blog.git' 
----- git pull 
fatal: refusing to merge unrelated historie 
----- git pull --allow-unrelated-histories 
Merge made by the 'recursive' strategy. 
README.md | 1 + 
1 file changed, 1 insertion(+) 
create mode 100644 README.md 
可以发现将两者合并起来了； 
----- git push origin master 
 
 
 
6. git 版本回退 
本地修改但未 add/commit 
git checkout .      # 撤销对所有已修改但未提交的文件的修改，但不包括新增的文件 
git checkout [filename]     # 撤销对指定文件的修改，[filename]为文件名 
已 add/commit 但未 push 
git revert commitID # 其实，git revert 可以用来撤销任意一次的修改，不一定要是最近一
次 
或 git reset --hard commitID/git reset --hard HEAD^  
# HEAD 表示当前版本，几个^表示倒数第几个版本，倒数第 100 个版本可以用
HEAD~100）； 
# 参数--hard：强制将暂存区和工作区都同步到指定的版本 
git reset 和 git revert 的区别是：reset 是用来回滚的，将 HEAD 的指针指向了想要回滚的
版本，作为最新的版本，而后面的版本也都没有了；而 revert 只是用来撤销某一次更改，
对之后的更改并没有影响，然后再用 git push -f 提交到远程仓库。 
 
已 push 
首先查询这个文件的 log 
其次查找到这个文件的上次 commit id xxx，并对其进行 reset 操作 
再撤销对此文件的修改 
最后 amend 一下，再 push 上去 
$ git log <fileName> 
$ git reset <commit-id> <fileName> 
$ git checkout <fileName> 
$ git commit --amend 
$ git push origin <remoteBranch>  
7. 查看操作记录 
----- git reflog 
8. 工作区和暂存区 
git 管理的问题的修改，它只会提交暂存区的修改来创建版本； 
 
9. 撤销工作区的修改 
----- git checkout -- 文件名 
作了修改，但还没 git add，撤销到上一次提交：git checkout -f -- filename；git checkout -
f -- . 
10. 把暂存区的修改撤销掉，重新放回工作区 
----- git reset HEAD file 
作了修改，并且已经 git add，但还没 git commit： 
先将暂存区的修改撤销：git reset HEAD filename/git reset HEAD；此时修改只存在于工
作区，变为了 "unstaged changes"； 
再利用上面的 checkout 命令从工作区撤销修改 
11. 对比工作区和某个版本中文件的不同 
----- git diff HEAD -- file 
# +表示工作区中的内容，-表示版本中的内容； 
12. 对比两个版本间文件的不同 
----- git diff HEAD HEAD^ -- file 
# +表示 HEAD 版本文件内容，-表示 HEAD^版本文件的内容 
13. 删除一个文件 
----- git rm file 
14. 分支操作 
----- git branch # 查看当前分支 
----- git branch 分支名 # 创建分支 
----- git checkout -b dev # 创建分支 dev，并切换到它上面（也就是将 head 指向当前分
支） 
----- git checkout 分支名 # 切换分支 
----- git merge 分支名 # 合并某分支到当前分支 
----- git branch -d 分支名 # 删除分支 
----- git log --graph --pretty=oneline   # 看到分支的合并情况 
 
fast-forward    # 快速合并--分支管理策略 
1. checkout 一个分支 dev 上做了 commit，之后 checkout master 分支，对同一地方做了修
改，之后再 master 上执行 merge 操作，由于默认执行的是快速合并，这这个快速合并只
能试图把各自的修改合并起来，但是会有冲突，手动解决冲突后， 就是一次新的提交； 
2. 通常，合并分支时，如果可能，git 会用 fast-forward 模式，但是有些快速合并不能成
功而且合并时没有冲突，这个时候会合并之后并做一次新的提交； 
3. 禁用 fast-forward，----- git merge --no-ff -m "禁用 fast-forward 模式" dev  由于本次合
并要创建一个新的 commit,所以加上-m 参数； 
 
15. 工作现场保存 git stash 
----- git stash # 暂时保存工作现场 
----- git stash pop # 回到工作现场 
git stash drop 命令用于删除隐藏的项目。默认情况下，它将删除最后添加的存储项，如
果提供 
参数的话，它还可以删除特定项。 
下面举个例子。 
如果要从隐藏项目列表中删除特定的存储项目，可以使用以下命令： 
git stash list：它将显示隐藏项目列表，如： 
stash@{0}: WIP on master: 049d078 added the index file stash@{1}: WIP on master: c264051 
Revert “added file_size” stash@{2}: WIP on master: 21d80a5 added number to log 
如果要删除名为 stash@{0} 的项目，请使用命令 git stash drop stash@{0}。 
16. git 标签操作 
首先切换到需要打标签的分支上，然后使用 git tag v1.0 就可以在当前 commit 打上 v1.0
的标签 
git tag v1.0 commitID 对特定 commit 打标签 
打标签时加上 message：git tag -a <tagname> -m "message" 
git tag 查看所有标签 
git show [tagname] 查看标签详细信息 
git push origin <tagname>可以推送一个本地标签到远程仓库 
git push origin --tags 可以推送全部未推送过的本地标签 
git tag -d <tagname>可以删除一个本地标签 
git push origin :refs/tags/<tagname>可以删除一个远程标签（先从本地删除） 
17. git pull 和 git fetch 有什么区别？ 
git pull 命令从中央存储库中提取特定分支的新更改或提交，并更新本地存储库中的目
标分支。 
git fetch 也用于相同的目的，但它的工作方式略有不同。当你执行 git fetch 时，它会从
所需的分支中提取所有新提交，并将其存储在本地存储库中的新分支中。如果要在目标
分支中反映这些更改，必须在 git fetch 之后执行 git merge 。只有在对目标分支和获取
的分支进行合并后才会更新目标分支。为了方便起见，请记住以下等式： 
git pull = git fetch + git merge 
18. 如何找到特定提交中已更改的文件列表？ 
要获取特定提交中已更改的列表文件，请使用以下命令： 
git diff-tree -r {hash} 
给定提交哈希，这将列出在该提交中更改或添加的所有文件。 -r 标志使命令列出单个
文件，而不是仅将它们折叠到根目录名称中。 
你还可以包括下面提到的内容，虽然它是可选的，但有助于给面试官留下深刻印象。输
出还将包含一些额外信息，可以通过包含两个标志把它们轻松的屏蔽掉： 
git diff-tree –no-commit-id –name-only -r {hash} 
这里 -no-commit-id 将禁止提交哈希值出现在输出中，而 -name-only 只会打印文件名
而不是它们的路径。 
 
git merge 和 git rebase 之间有什么区别？ 
简单的说，git merge 和 git rebase 都是合并分支的命令。  
git merge branch 会把 branch 分支的差异 内容 pull 到本地，然后与本地分支的内容一并
形成一个 committer 对象提交到主分支上，合并后的分支与主分支一致；  
git rebase branch 会把 branch 分支优先合并到主分支，然后把本地分支的 commit 放到主
分支后面，合并后的分支就好像从合并后主分支又拉了一个分支一样，本地分支本身 不
会保留提交历史。 
 
 
 
 
8. Redis 
NoSQL---一类新出现的数据库（Not only Sql） 
# 不支持 SQL 语法； 
# 存储结构跟传统的关系型数据库中的那种关系表完全不同，nosql 中存储的数据都是
Key-Value 形式; 
# NoSQL 的世界没有一种通用的语言，每种 NoSQL 数据库都有自己的 api 和语法，以
及擅长的业务领域； 
# NoSQL 基本不支持事务； 事务---一组 sql 操作，要么都成功，要么都失败； 
种类： 
Mongodb 
Redis 
Hbase hadoop 
Cassandra hadoop   
 
Redis 基础 
特性： 
1. Redis 支持数据的持久化，可以将内存中的数据保存到磁盘中，重启的时候可以再次
加载进行使用； 
2. Redis 不仅支持简单的 key-value 类型的数据，同时还提供 list,set,zset,hash 等数据结构
的存储； 
3. Redis 支持数据的备份，即 master-slave 模式的数据备份； 
 
# redis 配置 
/etc/redis/redis.conf 
 
# 核心配置选项 
1. 绑定 ip;如果需要远程访问，可将此行注释掉，或绑定一个真实的 ip；bind 127.0.0.1 
2. 端口，默认为 6379 
3. 是否以守护进程运行； 
   如果以守护进程运行，则不会在命令行阻塞，类似于服务； 
   如果不以守护进程运行，则当前终端被阻塞； 
   daemonize yes 
4. 数据文件；dbfilename dump.rdb 
5. 数据文件存储路径；dir /var/lib/redis 
6. 日志文件；logfile /var/log/redis/redis-server.log 
7. 数据库，默认有 16 个；database 16; 
8. 主从复制，类似于双机备份；slaveof 
 
 
# 服务端 
服务端命令为 redis-server  
使用服务的方式管理 redis 服务： 
启动：service redis start  
停止：service redis stop 
重启：service redis restart  
redis-server /etc/redis/redis.conf 指定加载的配置文件； 
 
# 客户端 
客户端命令为 redis-cli 
连接 redis---redis-cli 
运行测试  ping-->回应 PONG 
数据库没有名称，默认有 16 个，通过 0-15 标识，连接 redis 默认选择第一个数据库； 
select n 
 
 
# Redis 中默认有多少个哈希槽? 
2^14 个 
Redis 集群没有使用一致性 hash, 而是引入了哈希槽的概念。 
请写一段 Python 连接 Redis 数据库的代码 
from redis import StrictRedis, ConnectionPool 
redis_url="redis://:xxxx@112.27.10.168:6379/15" 
pool = ConnectionPool.from_url(redis_url, decode_responses=True) 
r= StrictRedis(connection_pool=pool) 
 
redis 的数据结构（5 种） 
String hash set zset list 
string 
# 保存 
set key value  
 
 
    # 设置键值 
setex key seconds value      # 设置键值以及保存时间，以秒为单位； 
mset key1 value1 key2 value2 # 设置多个键值 
append key value             # 追加值 
 
# 获取 
get key                      # 根据键获取值，如果不存在此键返回 nil 
mget key1 key2...            # 根据多个键获取多个值； 
 
 
 
# 键命令 
keys pattern                 # 查找键，参数支持正则表达式 
keys *                       # 查看所有键 
keys 'a*'                    # 查看名称重包含 a 的键 
exists a1                    # 判断键 a1 是否存在 
type key                     # 查看键对应的 value 值的类型 
del key1 key2...             # 删除键及对应的值 
expire 'a1' 3                # 设置过期时间，设置键 a1 的过期时间为 3 秒 
ttl key                      # 查看有效时间 
 
hash 
hash 用于存储对象，对象的结构为属性、值 
值的类型为 string 
 
 
# 增加，修改 
hset key field value         # 设置键 key 的属性 field 为 value 
hset key field1 value1 field2 value2  # 设置多个属性 
 
 
# 获取 
hkey key                     # 获取指定键的所有属性 
hget key field               # 获取一个属性的值 
hmget key field1 field2...   # 获取多个属性的值 
hvals key                    # 获取所有属性的值 
 
# 删除 
删除整个 hash 键与值            # 使用 del 命令 
hdel key field1 field2       # 删除属性，属性对应的值会相应删除 
 
 
####  21.2. <a name='hash'></a>hash 的底层数据结构 
ziplist（压缩列表）和 hashtable 
list 
# 列表中的元素类型为 string 
# 按照插入顺序排序 
 
# 增加 
lpush key value1 value2...       # 在左侧插入数据 
rpush key value1 value2...       # 在右侧插入数据 
linsert key before 或 after 现有元素 新元素   # 在指定元素的前或后插入新元素 
 
# 获取 
lrange key start stop            # start 和 stop 为元素的下标索引，第一个元素索引为
0，索引可以为负数，表示从尾部开始计数； 
 
# 设置指定索引位置的元素值 
lset key index value  
 
# 删除 
lrem key count value              # 将列表中钱 count 次出现的值为 value 的元素移
除，count>0:从头到尾移除，count<0:从尾到头移除，count=0:移除所有； 
 
 
 
####  21.3. <a name='list'></a>list 的底层数据实现结构 
ziplist 或 linkedlist 
set 
# 无序集合 
# 元素为 string 类型 
# 元素具有唯一性，不重复 
# 集合没有修改操作 
 
# 增加 
sadd key member1 member2...      # 添加元素 
 
# 获取 
smembers key                     # 返回所有元素 
 
# 删除 
srem key member1                 # 删除指定元素 
 
 
 
zset 
sorted set，有序集合 
元素为 string 类型 
元素具有唯一性，不重复 
每个元素都会关联一个 double 类型的 score，表示权重，通过权重将元素从小到大排序 
说明：没有修改操作 
 
 
# 添加 
zadd key score1 member1 score2 member2...                  
 
# 获取 
zrange key start stop            # 返回指定范围内的元素,索引可以为负数，表示从尾
部开始计数；start，stop 为元素的下标索引,索引从左侧开始，第一个元素为 0 
zrangebyscore key min max        # 返回 score 值在 min 和 max 之间的成员 
zscore key member                # 返回成员 member 的 score 
 
# 删除 
zrem key member1 member2...      # 删除指定元素 
zremrangebyscore key min max     # 删除 score 值在 min 和 max 之间的成员 
 
 
####  21.4. <a name='zset'></a>zset 的底层数据实现结构 
zset 底层的存储结构包括 ziplist 或 skiplist，在同时满足以下两个条件的时候使用 ziplist，
其他时候使用 skiplist，两个条件如下： 
有序集合保存的元素数量小于 128 个 
有序集合保存的所有元素的长度小于 64 字节 
 
Redis 的数据类型有哪些？ 
有五种常用数据类型：String、Hash、Set、List、SortedSet。以及三种特殊的数据
类型：Bitmap、HyperLogLog、Geospatial ，其中 HyperLogLog、Bitmap 的底层
都是 String 数据类型，Geospatial 的底层是 Sorted Set 数据类型。 
五种常用的数据类型： 
1、String：String 是最常用的一种数据类型，普通的 key- value 存储都可以归为
此类。其中 Value 既可以是数字也可以是字符串。使用场景：常规 key-value 缓
存应用。常规计数: 微博数， 粉丝数。 
2、Hash：Hash 是一个键值(key => value)对集合。Redishash 是一个 string 类型
的 field 和 value 的映射表，hash 特别适合用于存储对象，并且可以像数据库
中 update 一个属性一样只修改某一项属性值。 
3、Set：Set 是一个无序的天然去重的集合，即 Key-Set。此外还提供了交集、并
集等一系列直接操作集合的方法，对于求共同好友、共同关注什么的功能实现特
别方便。 
4、List：List 是一个有序可重复的集合，其遵循 FIFO 的原则，底层是依赖双向
链表实现的，因此支持正向、反向双重查找。通过 List，我们可以很方面的获得
类似于最新回复这类的功能实现。 
5、SortedSet：类似于 java 中的 TreeSet，是 Set 的可排序版。此外还支持优先级
排序，维护了一个 score 的参数来实现。适用于排行榜和带权重的消息队列等场
景。 
三种特殊的数据类型： 
1、Bitmap：位图，Bitmap 想象成一个以位为单位数组，数组中的每个单元只能
存 0 或者 1，数组的下标在 Bitmap 中叫做偏移量。使用 Bitmap 实现统计功能，
更省空间。如果只需要统计数据的二值状态，例如商品有没有、用户在不在等，
就可以使用 Bitmap，因为它只用一个 bit 位就能表示 0 或 1。 
2 、 Hyperloglog 。 HyperLogLog 是 一 种 用 于 统 计 基 数 的 数 据 集 合 类 型 ，
HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大 
时，计算基数所需的空间总是固定 的、并且是很小的。每个 HyperLogLog 键只
需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基 数。场景：统计
网页的 UV（即 Unique Visitor，不重复访客，一个人访问某个网站多次，但是还
是只计算为一次）。 
要注意，HyperLogLog 的统计规则是基于概率完成的，所以它给出的统计结果是
有一定误差的，标准误算率是 0.81%。 
3、Geospatial ：主要用于存储地理位置信息，并对存储的信息进行操作，适用场
景如朋友的定位、附近的人、打车距离计算等。 
redis 中的跳跃表 
跳跃表是一种有序的数据结构，它通过在每个节点维持多个指向其他节点的指针，
从而达到快速访问节点的目的。 
 
跳跃表基于单链表加索引的方式实现 
 
跳跃表以空间换时间的方式提升了查找速度 
 
Redis 有序集合在节点元素较大或者元素数量较多时使用跳跃表实现 
 
Redis 的跳跃表实现由 zskiplist 和 zskiplistnode 两个结构组成,其中 zskiplist 用
于保存跳跃表信息(比如表头节点、表尾节点、长度),而 zskiplistnode 则用于表示
跳跃表节点 
 
Redis 每个跳跃表节点的层高都是 1 至 32 之间的随机数 
 
在同一个跳跃表中,多个节点可以包含相同的分值,但每个节点的成员对象必须是
唯一的，跳跃表中的节点按照分值大小进行排序,当分值相同时,节点按照成员对
象的大小进行排序。 
redis 缓存 
缓存穿透 
# 举例说明缓存穿透 
我现在有一个博客详情页，然后博客详情页中的内容假设是存储在 Redis 中的，然后通
过博客的 Uid 进行获取，正常的情况是：用户进入博客详情页，然后通过 uid 获取 redis
中缓存的文章详情，如果有内容就直接访问，如果不存在内容，那么需要访问数据库，
然后从数据库中查询我们的博客详情后，然后在存储到 redis 中，最后在把数据返回给
我们的页面。 
但是可能存在一些非法用户，他可能会模拟出很多不存在的 key，然后通过该 key 去请
求后台，首先 redis 的缓存没有命中，那么就去请求数据库，最后数据库没有查询出该
内容，这样很多个非法的请求直接打在数据库中，可能会导致数据库直接宕机，无法对
外提供服务。这就是我们所说的缓存穿透问题。 
 
# 简单的解决方法 
针对这个情况，我们有一种简单的解决方法就是，在数据库没有查询该条数据的时候，
我们让该 key 缓存一个 空数据，这样用户再次以该 key 请求后台的时候，会直接返回
null，避免了再次请求数据库。 
 
 
# 什么是布隆过滤器？ 
布隆过滤器的巨大作用 ，就是能够迅速判断一个元素是否存在一个集合中。因此次他
有如下几个使用场景： 
网站爬虫对 URL 的去重，避免爬取相同的 URL 
反垃圾邮件，从数十亿个垃圾邮件列表中判断某邮箱是否是垃圾邮件（同理，垃圾短信） 
缓存穿透，将所有可能的数据缓存放到布隆过滤器中，当黑客访问不存在的缓存时，迅
速返回避免缓存以及 DB 挂掉。 
 
 
布隆过滤器原理 
布隆过滤器其内部维护了一个全为 0 的 bit 数组，需要说明的是，布隆过滤器有
一个误判的概念，误判率越低，则数组越长，所占空间越大。误判率越高则数组
越小，所占的空间越小。 
假设，根据误判率，我们生成一个 10 位的 bit 数组，以及 2 个 hash 函数 f1 和 
f2，如下图所示：生成的数组的位数 和 hash 函数的数量，我们不用去关心如何
生成的，这是有数学论文进行验证。 
 
然后我们输入一个集合，集合中包含 N1 和 N2，我们通过计算 f1(N1) = 2，f2(N1) 
= 5，则将数组下标为 2 和下标为 5 的位置设置成 1，就得到了下图 
 
同理，我们再次进行计算 N2 的值， f1(N2) = 3，f2(N2) = 6。得到如下所示的图 
 
这个时候，假设我们有第三个数 N3 过来了，我们需要判断 N3 是否在集合 [N1,N2]
中，我们需要做的操作就是，使用 f1 和 f2 计算出数组中的地址 
 
若值恰巧都位于上图的红色位置，我们认为 N3 在集合 [N1,N2] 中 
 
若值有一个不位于上图的红色部分，我们认为 N3 不在集合[N1,N2] 中 
这就是布隆过滤器的计算原理。 
要是分布式缓存发生雪崩了怎么办，要怎么防止发生 
当缓存服务器重启或者大量缓存集中在某一个时间段失效，这样在失效的时候，
也会给后端系统(比如 DB)带来很大压力。通俗讲就是：缓存雪崩可能是因为数
据未加载到缓存中，或者缓存同一时间大面积的失效，从而导致所有请求都去查
数据库，导致数据库 CPU 和内存负载过高，甚至宕机。 
如何防止： 
缓存失效或，通过加锁或队列来控制读取数据库的访问的线程数量，比如对某个
key 值运行一个线程访问数据库，其他线程等待不同的 key，设置不同的过期时
间，让环创失效的时间点尽量均匀做二级缓存，a1 失效时候，访问 a2，a1 失效
的时间设置为短期，a2 为长期 
缓存调度算法 
有哪几种实现方法 
先进先出 FIFO 最近最少使用 LRU 最不经常使用算法 LFU，根据在一段时间里
页面被使用的次数选择出最少使用的页 最优替换（不能实现） LRU 的实现方
案 
用一个数组来存储数据，给每一个数据项标记一个访问时间戳，每次插入新数据
项的时候，先把数组中存在的数据项的时间戳自增，并将新数据项的时间戳置为
0 并插入到数组中。每次访问数组中的数据项的时候，将被访问的数据项的时间
戳置为 0。当数组空间已满时，将时间戳最大的数据项淘汰。 利用一个链表来实
现，每次新插入数据的时候将新数据插到链表的头部；每次缓存命中（即数据被
访问），则将数据移到链表头部；那么当链表满的时候，就将链表尾部的数据丢
弃。 利用链表和 hashmap。当需要插入新的数据项的时候，如果新数据项在链
表中存在（一般称为命中），则把该节点移到链表头部，如果不存在，则新建一
个节点，放到链表头部，若缓存满了，则把链表最后一个节点删除即可。在访问
数据的时候，如果数据项在链表中存在，则把该节点移到链表头部，否则返回-1。
这样一来在链表尾部的节点就是最近最久未访问的数据项。 
主从配置 
####  21.5. <a name='-1'></a>主从概念 
一个 master 可以有多个 slave，一个 slave 又可以拥有多个 slave，如此下去，形成强大
的多级服务器集群架构； 
master 用来写数据，slave 用来读数据，经统计：网站的读写比例为 10:1； 
通过主从配置可以实现读写分离； 
master 和 slave 都是一个 redis 实例（服务）； 
 
 
1. 配置主 
# 修改/etc/redis/redis.conf 文件； 
bind masterip    
# 重启 redis-server;   
service redis stop   
redis-server /etc/redis/redis.conf 
 
2. 配置从 
# 复制/etc/redis/redis.conf，重命名 slave.conf，之后修改  
bind slaveip 
slaveof masterip masterport 
port slaveport 
# 启动 redis 服务 
redis-server /etc/redis/slave.conf 
 
3. 查看主从关系 
redis-cli -h masterip -p masterport info Replication    #主服务的主从关系 
redis-cli -h masterip -p masterport info Replication    #从服务的主从关系 
 
 
 
 
搭建集群 
# 集群是一组相互独立的、通过高速网络互联的计算机，它们构成了一个组，并以单一
系统的模式加以管理。一个客户与集群相互作用时，集群就像是一个独立的服务器。集
群配置是用于提高可用性和可缩放性。 
 
 
# redis 集群 
1. 软件层面； 
只有一台电脑，在这台电脑上启动多个 redis 服务； 
2. 硬件层面； 
存在多台实体的电脑，每台电脑都启动一个 redis 或者多个 redis 服务； 
 
分布式锁 
共享资源+并发请求的时候才会需要加锁。 
锁----是一种参照（也可以是目录/对象）,具有排他性； 
自旋----while True； 
抢锁失败，进入阻塞队列； 
分布式锁是控制分布式系统之间的同步访问共享资源的一种方式。 
分布式锁的实现有三种方式 
 
数据库乐观锁 
 
基于 Redis 的分布式锁 
 
基于 Zookeeper 的分布式锁 
分布式锁满足的条件 
为了确保分布式锁可用，我们至少要保证锁的实现同时满足以下几个条件 
 
互斥性：在任意时刻只有一个客户端能持有锁； 
 
不会死锁：即使有一个客户端在持有锁的期间发生崩溃而没有主动解锁，也能保
证后续其它客户端能加锁； 
 
容错性：只要大部分的 Redis 节点正常运行，客户端就可以加锁和解锁； 
 
解铃还须系铃人：加锁和解锁必须是同一个客户端，客户端自己不能把别人加的
锁给解除； 
 
锁超时：支持超时释放锁，防止死锁 高效，高可用：加锁和解锁需要高效，同
时也需要保证高可用防止分布式锁失效，可以增加降级； 
 
支持阻塞和非阻塞：可以实现超时获取失败，tryLock(long timeOut) 支持公平锁
和非公平锁。 
加锁代码 
public class RedisTool { 
 
    private static final String LOCK_SUCCESS = "OK"; 
    private static final String SET_IF_NOT_EXIST = "NX"; 
    private static final String SET_WITH_EXPIRE_TIME = "PX"; 
 
    /** 
     * 尝试获取分布式锁 
     * @param jedis Redis 客户端 
     * @param lockKey 锁 
     * @param requestId 请求标识 
     * @param expireTime 超期时间 
     * @return 是否获取成功 
     */ 
    public static boolean tryGetDistributedLock(Jedis jedis, String lockKey, String requestId, 
int expireTime) { 
         
        String 
result 
= 
jedis.set(lockKey, 
requestId, 
SET_IF_NOT_EXIST, 
SET_WITH_EXPIRE_TIME, expireTime); 
 
        if (LOCK_SUCCESS.equals(result)) { 
            return true; 
        } 
        return false; 
    } 
} 
可以看到，我们加锁就一行代码：jedis.set(String key, String value, String nxxx, String expx, 
int time)，这个 set()方法一共有五个形参 
 
第一个为 key，我们使用 key 来当锁，因为 key 是唯一的。 
第二个为 value，我们传的是 requestId，很多童鞋可能不明白，有 key 作为锁不就够了
吗，为什么还要用到 value？原因就是我们在上面讲到可靠性时，分布式锁要满足第四
个条件解铃还须系铃人，通过给 value 赋值为 requestId，我们就知道这把锁是哪个请求
加的了，在解锁的时候就可以有依据。requestId 可以使用 UUID.randomUUID().toString()
方法生成。 
第三个为 nxxx，这个参数我们填的是 NX，意思是 SET IF NOT EXIST，即当 key 不存
在时，我们进行 set 操作；若 key 已经存在，则不做任何操作； 
第四个为 expx，这个参数我们传的是 PX，意思是我们要给这个 key 加一个过期的设置，
具体时间由第五个参数决定。 
第五个为 time，与第四个参数相呼应，代表 key 的过期时间。 
总的来说，执行上面的 set()方法就只会导致两种结果：1. 当前没有锁（key 不存在），
那么就进行加锁操作，并对锁设置个有效期，同时 value 表示加锁的客户端。2. 已有锁
存在，不做任何操作 
 
加锁代码满足我们可靠性里描述的三个条件。首先，set()加入了 NX 参数，可以保证如
果已有 key 存在，则函数不会调用成功，也就是只有一个客户端能持有锁，满足互斥性。
其次，由于我们对锁设置了过期时间，即使锁的持有者后续发生崩溃而没有解锁，锁也
会因为到了过期时间而自动解锁（即 key 被删除），不会发生死锁。最后，因为我们将
value 赋值为 requestId，代表加锁的客户端请求标识，那么在客户端在解锁的时候就可
以进行校验是否是同一个客户端。由于我们只考虑 Redis 单机部署的场景，所以容错性
我们暂不考虑。 
面试题 
1. Redis 是什么？简述它的优缺点？ 
Redis 本质上是一个 Key-Value 类型的内存数据库，很像 Memcached，整个数据
库加载在内存当中操作，定期通过异步操作把数据库中的数据 flush 到硬盘上进
行保存。 
因为是纯内存操作，Redis 的性能非常出色，每秒可以处理超过 10 万次读写操
作，是已知性能最快的 Key-Value 数据库。 
优点： 
读写性能极高， Redis 能读的速度是 110000 次/s，写的速度是 81000 次/s。 支
持数据持久化，支持 AOF 和 RDB 两种持久化方式。 支持事务， Redis 的所有
操作都是原子性的，意思就是要么成功执行要么失败完全不执行。单个操作是原
子性的。多个操作也支持事务，即原子性，通过 MULTI 和 EXEC 指令包起来。 
数据结构丰富，除了支持 string 类型的 value 外，还支持 hash、set、zset、list 等
数据结构。 支持主从复制，主机会自动将数据同步到从机，可以进行读写分离。 
丰富的特性 – Redis 还支持 publish/subscribe， 通知， key 过期等特性。 缺点： 
数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此 Redis
适合的场景主要局限在较小数据量的高性能操作和运算上。 主机宕机，宕机前
有部分数据未能及时同步到从机，切换 IP 后还会引入数据不一致的问题，降低
了系统的可用性。 
2. Redis 为什么这么快？ 
内存存储：Redis 是使用内存(in-memeroy)存储，没有磁盘 IO 上的开销。数据存
在内存中，类似于 HashMap，HashMap 的优势就是查找和操作的时间复杂度都
是 O(1)。 
单线程实现（ Redis 6.0 以前）：Redis 使用单个线程处理请求，避免了多个线程
之间线程切换和锁资源争用的开销。注意：单线程是指的是在核心网络模型中，
网络请求模块使用一个线程来处理，即一个线程处理所有网络请求。 
非阻塞 IO：Redis 使用多路复用 IO 技术，将 epoll 作为 I/O 多路复用技术的实现，
再加上 Redis 自身的事件处理模型将 epoll 中的连接、读写、关闭都转换为事件，
不在网络 I/O 上浪费过多的时间。 
优化的数据结构：Redis 有诸多可以直接应用的优化数据结构的实现，应用层可
以直接使用原生的数据结构提升性能。 
使用底层模型不同：Redis 直接自己构建了 VM (虚拟内存)机制 ，因为一般的系
统调用系统函数的话，会浪费一定的时间去移动和请求。 
Redis 的 VM(虚拟内存)机制就是暂时把不经常访问的数据(冷数据)从内存交换到
磁盘中，从而腾出宝贵的内存空间用于其它需要访问的数据(热数据)。通过 VM
功能可以实现冷热数据分离，使热数据仍在内存中、冷数据保存到磁盘。这样就
可以避免因为内存不足而造成访问速度下降的问题。 
Redis 提高数据库容量的办法有两种：一种是可以将数据分割到多个 RedisServer
上；另一种是使用虚拟内存把那些不经常访问的数据交换到磁盘上。需要特别注
意的是 Redis 并没有使用 OS 提供的 Swap，而是自己实现。 
3. Redis 相比 Memcached 有哪些优势？ 
数据类型：Memcached 所有的值均是简单的字符串，Redis 支持更为丰富的数据
类型，支持 string(字符串)，list(列表)，Set(集合)、Sorted Set(有序集合)、Hash(哈
希)等。 
持久化：Redis 支持数据落地持久化存储，可以将内存中的数据保持在磁盘中，
重启的时候可以再次加载进行使用。 memcache 不支持数据持久存储 。 
集群模式：Redis 提供主从同步机制，以及 Cluster 集群部署能力，能够提供高可
用服务。Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片
写入数据 
性能对比：Redis 的速度比 Memcached 快很多。 
网络 IO 模型：Redis 使用单线程的多路 IO 复用模型，Memcached 使用多线程
的非阻塞 IO 模式。 
Redis 支持服务器端的数据操作：Redis 相比 Memcached 来说，拥有更多的数据
结构和并支持更丰富的数据操作，通常在 Memcached 里，你需要将数据拿到客
户端来进行类似的修改再 set 回去。 
这大大增加了网络 IO 的次数和数据体积。在 Redis 中，这些复杂的操作通常和
一般的 GET/SET 一样高效。所以，如果需要缓存能够支持更复杂的结构和操作，
那么 Redis 会是不错的选择。 
4. 为什么要用 Redis 做缓存？ 
从高并发上来说： 
直接操作缓存能够承受的请求是远远大于直接访问数据库的，所以我们可以考虑
把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这
里而不用经过数据库。 从高性能上来说： 
用户第一次访问数据库中的某些数据。 因为是从硬盘上读取的所以这个过程会
比较慢。将该用户访问的数据存在缓存中，下一次再访问这些数据的时候就可以
直接从缓存中获取了。操作缓存就是直接操作内存，所以速度相当快。如果数据
库中的对应数据改变的之后，同步改变缓存中相应的数据。 
5. 为什么要用 Redis 而不用 map/guava 做缓存? 
缓存分为本地缓存和分布式缓存。以 java 为例，使用自带的 map 或者 guava 实
现的是本地缓存，最主要的特点是轻量以及快速，生命周期随着 jvm 的销毁而结
束，并且在多实例的情况下，每个实例都需要各自保存一份缓存，缓存不具有一
致性。 
使用 Redis 或 memcached 之类的称为分布式缓存，在多实例的情况下，各实例共
用一份缓存数据，缓存具有一致性。缺点是需要保持 Redis 或 memcached 服务的
高可用，整个程序架构上较为复杂。 
对比: 
Redis 可以用几十 G 内存来做缓存，Map 不行，一般 JVM 也就分几个 G 数
据就够大了； Redis 的缓存可以持久化，Map 是内存对象，程序一重启数据就
没了； Redis 可以实现分布式的缓存，Map 只能存在创建它的程序里； Redis 
可以处理每秒百万级的并发，是专业的缓存服务，Map 只是一个普通的对象； 
Redis 缓存有过期机制，Map 本身无此功能；Redis 有丰富的 API，Map 就简单
太多了； Redis 可单独部署，多个项目之间可以空想，本地内存无法共享； Redis
有专门的管理工具可以查看缓存数据。 
6. Redis 的常用场景有哪些? 
1、缓存 
缓存现在几乎是所有中大型网站都在用的必杀技，合理的利用缓存不仅能够提升
网站访问速度，还能大大降低数据库的压力。Redis 提供了键过期功能，也提供
了灵活的键淘汰策略，所以，现在 Redis 用在缓存的场合非常多。 
2、排行榜 
很多网站都有排行榜应用的，如京东的月度销量榜单、商品按时间的上新排行榜
等。Redis 提供的有序集合数据类构能实现各种复杂的排行榜应用。 
3、计数器 
什么是计数器，如电商网站商品的浏览量、视频网站视频的播放数等。为了保证
数据实时效，每次浏览都得给+1，并发量高时如果每次都请求数据库操作无疑是
种挑战和压力。Redis 提供的 incr 命令来实现计数器功能，内存操作，性能非常
好，非常适用于这些计数场景。 
4、分布式会话 
集群模式下，在应用不多的情况下一般使用容器自带的 session 复制功能就能满
足，当应用增多相对复杂的系统中，一般都会搭建以 Redis 等内存数据库为中心
的 session 服务，session 不再由容器管理，而是由 session 服务及内存数据库管
理。 
5、分布式锁 
在很多互联网公司中都使用了分布式技术，分布式技术带来的技术挑战是对同一
个资源的并发访问，如全局 ID、减库存、秒杀等场景，并发量不大的场景可以使
用数据库的悲观锁、乐观锁来实现，但在并发量高的场合中，利用数据库锁来控
制资源的并发访问是不太理想的，大大影响了数据库的性能。可以利用 Redis 的
setnx 功能来编写分布式的锁，如果设置返回 1 说明获取锁成功，否则获取锁失
败，实际应用中要考虑的细节要更多。 
6、 社交网络 
点赞、踩、关注/被关注、共同好友等是社交网站的基本功能，社交网站的访问量
通常来说比较大，而且传统的关系数据库类型不适合存储这种类型的数据，Redis
提供的哈希、集合等数据结构能很方便的的实现这些功能。如在微博中的共同好
友，通过 Redis 的 set 能够很方便得出。 
7、最新列表 
Redis 列表结构，LPUSH 可以在列表头部插入一个内容 ID 作为关键字，LTRIM
可用来限制列表的数量，这样列表永远为 N 个 ID，无需查询最新的列表，直接
根据 ID 去到对应的内容页即可。 
8、消息系统 
消息队列是大型网站必用中间件，如 ActiveMQ、RabbitMQ、Kafka 等流行的消
息队列中间件，主要用于业务解耦、流量削峰及异步处理实时性低的业务。Redis
提供了发布/订阅及阻塞队列功能，能实现一个简单的消息队列系统。另外，这个
不能和专业的消息中间件相比。 
7. Redis 持久化机制？ 
为了能够重用 Redis 数据，或者防止系统故障，我们需要将 Redis 中的数据写入
到磁盘空间中，即持久化。 
Redis提供了两种不同的持久化方法可以将数据存储在磁盘中，一种叫快照RDB，
另一种叫只追加文件 AOF。 
RDB 
在指定的时间间隔内将内存中的数据集快照写入磁盘(Snapshot)，它恢复时是将
快照文件直接读到内存里。 
优势：适合大规模的数据恢复；对数据完整性和一致性要求不高 
劣势：在一定间隔时间做一次备份，所以如果 Redis 意外 down 掉的话，就会丢
失最后一次快照后的所有修改。 
AOF 
以日志的形式来记录每个写操作，将 Redis 执行过的所有写指令记录下来(读操
作不记录)，只许追加文件但不可以改写文件，Redis 启动之初会读取该文件重新
构建数据，换言之，Redis 重启的话就根据日志文件的内容将写指令从前到后执
行一次以完成数据的恢复工作。 
AOF 采用文件追加方式，文件会越来越大，为避免出现此种情况，新增了重写机
制，当 AOF 文件的大小超过所设定的阈值时， Redis 就会启动 AOF 文件的内容
压缩，只保留可以恢复数据的最小指令集.。 
优势 
每修改同步：appendfsync always 同步持久化，每次发生数据变更会被立即记录
到磁盘，性能较差但数据完整性比较好 每秒同步：appendfsync everysec 异步操
作，每秒记录，如果一秒内宕机，有数据丢失 不同步：appendfsync no 从不同步 
劣势 
相同数据集的数据而言 aof 文件要远大于 rdb 文件，恢复速度慢于 rdb aof 运行效
率要慢于 rdb，每秒同步策略效率较好，不同步效率和 rdb 相同 
9. 如何选择合适的持久化方式 如果是数据不那么敏感，且可以从其他地方重新生
成补回的，那么可以关闭持久化。 如果是数据比较重要，不想再从其他地方获
取，且可以承受数分钟的数据丢失，比如缓存等，那么可以只使用 RDB。 如果
是用做内存数据库，要使用 Redis 的持久化，建议是 RDB 和 AOF 都开启，或者
定期执行 bgsave 做快照备份，RDB 方式更适合做数据的备份，AOF 可以保证数
据的不丢失。 补充：Redis4.0 对于持久化机制的优化 
Redis4.0 相对与 3.X 版本其中一个比较大的变化是 4.0 添加了新的混合持久化方
式。 
简单的说：新的 AOF 文件前半段是 RDB 格式的全量数据后半段是 AOF 格式的
增量数据，如下图： 
优势：混合持久化结合了 RDB 持久化 和 AOF 持久化的优点， 由于绝大部分
都是 RDB 格式，加载速度快，同时结合 AOF，增量的数据以 AOF 方式保存了，
数据更少的丢失。 
劣势：兼容性差，一旦开启了混合持久化，在 4.0 之前版本都不识别该 aof 文件，
同时由于前部分是 RDB 格式，阅读性较差。 
10. Redis 持久化数据和缓存怎么做扩容？ 如果 Redis 被当做缓存使用，使用一致性
哈希实现动态扩容缩容。 
如果 Redis 被当做一个持久化存储使用，必须使用固定的 keys-to-nodes 映射关
系，节点的数量一旦确定不能变化。否则的话(即 Redis 节点需要动态变化的情
况），必须使用可以在运行时进行数据再平衡的一套系统，而当前只有 Redis 集
群可以做到这样。 
过期键的删除策略、淘汰策略 
11. Redis 过期键的删除策略 Redis 的过期删除策略就是：惰性删除和定期删除两种
策略配合使用。 
惰性删除：惰性删除不会去主动删除数据，而是在访问数据的时候，再检查当前
键值是否过期，如果过期则执行删除并返回 null 给客户端，如果没有过期则返
回正常信息给客户端。它的优点是简单，不需要对过期的数据做额外的处理，只
有在每次访问的时候才会检查键值是否过期，缺点是删除过期键不及时，造成了
一定的空间浪费。 
定期删除：Redis 会周期性的随机测试一批设置了过期时间的 key 并进行处理。
测试到的已过期的 key 将被删除。 
附：删除 key 常见的三种处理方式。 
1、定时删除 
在设置某个 key 的过期时间同时，我们创建一个定时器，让定时器在该过期时间
到来时，立即执行对其进行删除的操作。 
优点：定时删除对内存是最友好的，能够保存内存的 key 一旦过期就能立即从内
存中删除。 
缺点：对 CPU 最不友好，在过期键比较多的时候，删除过期键会占用一部分 CPU 
时间，对服务器的响应时间和吞吐量造成影响。 
2、惰性删除 
设置该 key 过期时间后，我们不去管它，当需要该 key 时，我们在检查其是否过
期，如果过期，我们就删掉它，反之返回该 key。 
优点：对 CPU 友好，我们只会在使用该键时才会进行过期检查，对于很多用不
到的 key 不用浪费时间进行过期检查。 
缺点：对内存不友好，如果一个键已经过期，但是一直没有使用，那么该键就会
一直存在内存中，如果数据库中有很多这种使用不到的过期键，这些键便永远不
会被删除，内存永远不会释放。从而造成内存泄漏。 
3、定期删除 
每隔一段时间，我们就对一些 key 进行检查，删除里面过期的 key。 
优点：可以通过限制删除操作执行的时长和频率来减少删除操作对 CPU 的影响。
另外定期删除，也能有效释放过期键占用的内存。 
缺点：难以确定删除操作执行的时长和频率。如果执行的太频繁，定期删除策略
变得和定时删除策略一样，对 CPU 不友好。如果执行的太少，那又和惰性删除
一样了，过期键占用的内存不会及时得到释放。另外最重要的是，在获取某个键
时，如果某个键的过期时间已经到了，但是还没执行定期删除，那么就会返回这
个键的值，这是业务不能忍受的错误。 
12. Redis key 的过期时间和永久有效分别怎么设置？ 通过 expire 或 pexpire 命令，
客户端可以以秒或毫秒的精度为数据库中的某个键设置生存时间。 
与 expire 和 pexpire 命令类似，客户端可以通过 expireat 和 pexpireat 命令，以秒
或毫秒精度给数据库中的某个键设置过期时间，可以理解为：让某个键在某个时
间点过期。 
13. Redis 内存淘汰策略 Redis 是不断的删除一些过期数据，但是很多没有设置过期
时间的数据也会越来越多，那么 Redis 内存不够用的时候是怎么处理的呢？答案
就是淘汰策略。此类的 
当 Redis 的内存超过最大允许的内存之后，Redis 会触发内存淘汰策略，删除一
些不常用的数据，以保证 Redis 服务器的正常运行。 
Redisv4.0 前提供 6 种数据淘汰策略： 
volatile-lru：利用 LRU 算法移除设置过过期时间的 key (LRU:最近使用 Least 
Recently Used ) allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除
最近最少使用的 key（这个是最常用的） volatile-ttl：从已设置过期时间的数据
集（server.db[i].expires）中挑选将要过期的数据淘汰 volatile-random：从已设置
过期时间的数据集（server.db[i].expires）中任意选择数据淘汰 allkeys-random：
从数据集（server.db[i].dict）中任意选择数据淘汰 no-eviction：禁止驱逐数据，也
就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用
吧！ Redisv4.0 后增加以下两种： 
volatile-lfu：从已设置过期时间的数据集(server.db[i].expires)中挑选最不经常使用
的数据淘汰(LFU(Least Frequently Used)算法，也就是最频繁被访问的数据将来最
有可能被访问到) allkeys-lfu：当内存不足以容纳新写入数据时，在键空间中，移
除最不经常使用的 key。 内存淘汰策略可以通过配置文件来修改，Redis.conf 对
应的配置项是 maxmemory-policy 修改对应的值就行，默认是 noeviction。 
缓存异常 缓存异常有四种类型，分别是缓存和数据库的数据不一致、缓存雪崩、
缓存击穿和缓存穿透。 
14. 如何保证缓存与数据库双写时的数据一致性？ 背景：使用到缓存，无论是本地
内存做缓存还是使用 Redis 做缓存，那么就会存在数据同步的问题，因为配置信
息缓存在内存中，而内存时无法感知到数据在数据库的修改。这样就会造成数据
库中的数据与缓存中数据不一致的问题。 
共有四种方案： 
先更新数据库，后更新缓存 先更新缓存，后更新数据库 先删除缓存，后更新数
据库 先更新数据库，后删除缓存 第一种和第二种方案，没有人使用的，因为第
一种方案存在问题是：并发更新数据库场景下，会将脏数据刷到缓存。 
第二种方案存在的问题是：如果先更新缓存成功，但是数据库更新失败，则肯定
会造成数据不一致。 
目前主要用第三和第四种方案。 
15. 先删除缓存，后更新数据库 该方案也会出问题，此时来了两个请求，请求 A（更
新操作） 和请求 B（查询操作） 
请求 A 进行写操作，删除缓存 请求 B 查询发现缓存不存在 请求 B 去数据库查
询得到旧值 请求 B 将旧值写入缓存 请求 A 将新值写入数据库 上述情况就会
导致不一致的情形出现。而且，如果不采用给缓存设置过期时间策略，该数据永
远都是脏数据。 
答案一：延时双删 最简单的解决办法延时双删 
使用伪代码如下： 
public void write(String key,Object data){   
Redis.delKey(key); 
 
db.updateData(data);  
Thread.sleep(1000);  Redis.delKey(key);  } 转 化 为
中文描述就是 （1）先淘汰缓存 （2）再写数据库（这两步和原来一样） （3）
休眠 1 秒，再次淘汰缓存，这么做，可以将 1 秒内所造成的缓存脏数据，再次删
除。确保读请求结束，写请求可以删除读请求造成的缓存脏数据。自行评估自己
的项目的读数据业务逻辑的耗时，写数据的休眠时间则在读数据业务逻辑的耗时
基础上，加几百 ms 即可。 
如果使用的是 Mysql 的读写分离的架构的话，那么其实主从同步之间也会有时
间差。 
此时来了两个请求，请求 A（更新操作） 和请求 B（查询操作） 
请求 A 更新操作，删除了 Redis 请求主库进行更新操作，主库与从库进行同步
数据的操作 请 B 查询操作，发现 Redis 中没有数据 去从库中拿去数据 此时
同步数据还未完成，拿到的数据是旧数据 此时的解决办法就是如果是对 Redis 
进行填充数据的查询数据库操作，那么就强制将其指向主库进行查询。 
答案二： 更新与读取操作进行异步串行化 采用更新与读取操作进行异步串行化 
异步串行化 
我在系统内部维护 n 个内存队列，更新数据的时候，根据数据的唯一标识，将该
操作路由之后，发送到其中一个 jvm 内部的内存队列中（对同一数据的请求发送
到同一个队列）。读取数据的时候，如果发现数据不在缓存中，并且此时队列里
有更新库存的操作，那么将重新读取数据+更新缓存的操作，根据唯一标识路由
之后，也将发送到同一个 jvm 内部的内存队列中。然后每个队列对应一个工作线
程，每个工作线程串行地拿到对应的操作，然后一条一条的执行。 
这样的话，一个数据变更的操作，先执行删除缓存，然后再去更新数据库，但是
还没完成更新的时候，如果此时一个读请求过来，读到了空的缓存，那么可以先
将缓存更新的请求发送到队列中，此时会在队列中积压，排在刚才更新库的操作
之后，然后同步等待缓存更新完成，再读库。 
读操作去重 
多个读库更新缓存的请求串在同一个队列中是没意义的，因此可以做过滤，如果
发现队列中已经有了该数据的更新缓存的请求了，那么就不用再放进去了，直接
等待前面的更新操作请求完成即可，待那个队列对应的工作线程完成了上一个操
作（数据库的修改）之后，才会去执行下一个操作（读库更新缓存），此时会从
数据库中读取最新的值，然后写入缓存中。 
如果请求还在等待时间范围内，不断轮询发现可以取到值了，那么就直接返回；
如果请求等待的时间超过一定时长，那么这一次直接从数据库中读取当前的旧值。
（返回旧值不是又导致缓存和数据库不一致了么？那至少可以减少这个情况发
生，因为等待超时也不是每次都是，几率很小吧。这里我想的是，如果超时了就
直接读旧值，这时候仅仅是读库后返回而不放缓存） 
16. 先更新数据库，后删除缓存 这一种情况也会出现问题，比如更新数据库成功了，
但是在删除缓存的阶段出错了没有删除成功，那么此时再读取缓存的时候每次都
是错误的数据了。 
此时解决方案就是利用消息队列进行删除的补偿。具体的业务逻辑用语言描述如
下： 
请求 A 先对数据库进行更新操作 在对 Redis 进行删除操作的时候发现报错，
删除失败 此时将 Redis 的 key 作为消息体发送到消息队列中 系统接收到消息
队列发送的消息后再次对 Redis 进行删除操作 但是这个方案会有一个缺点就
是会对业务代码造成大量的侵入，深深的耦合在一起，所以这时会有一个优化的
方案，我们知道对 Mysql 数据库更新操作后再 binlog 日志中我们都能够找到
相应的操作，那么我们可以订阅 Mysql 数据库的 binlog 日志对缓存进行操作。 
17. 什么是缓存击穿? 缓存击穿跟缓存雪崩有点类似，缓存雪崩是大规模的 key 失效，
而缓存击穿是某个热点的 key 失效，大并发集中对其进行请求，就会造成大量请
求读缓存没读到数据，从而导致高并发访问数据库，引起数据库压力剧增。这种
现象就叫做缓存击穿。 
从两个方面解决，第一是否可以考虑热点 key 不设置过期时间，第二是否可以考
虑降低打在数据库上的请求数量。 
解决方案： 
在缓存失效后，通过互斥锁或者队列来控制读数据写缓存的线程数量，比如某个
key 只允许一个线程查询数据和写缓存，其他线程等待。这种方式会阻塞其他的
线程，此时系统的吞吐量会下降 
热点数据缓存永远不过期。永不过期实际包含两层意思： 
物理不过期，针对热点 key 不设置过期时间 逻辑过期，把过期时间存在 key 对
应的 value 里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建 
18. 什么是缓存穿透? 缓存穿透是指用户请求的数据在缓存中不存在即没有命中，同
时在数据库中也不存在，导致用户每次请求该数据都要去数据库中查询一遍。如
果有恶意攻击者不断请求系统中不存在的数据，会导致短时间大量请求落在数据
库上，造成数据库压力过大，甚至导致数据库承受不住而宕机崩溃。 
缓存穿透的关键在于在 Redis 中查不到 key 值，它和缓存击穿的根本区别在于传
进来的 key 在 Redis 中是不存在的。假如有黑客传进大量的不存在的 key，那么
大量的请求打在数据库上是很致命的问题，所以在日常开发中要对参数做好校验，
一些非法的参数，不可能存在的 key 就直接返回错误提示。 
解决方法： 
将无效的 key 存放进 Redis 中： 当出现 Redis 查不到数据，数据库也查不到数据
的情况，我们就把这个 key 保存到 Redis 中，设置 value="null"，并设置其过期时
间极短，后面再出现查询这个 key 的请求的时候，直接返回 null，就不需要再查
询数据库了。但这种处理方式是有问题的，假如传进来的这个不存在的 Key 值每
次都是随机的，那存进 Redis 也没有意义。 
使用布隆过滤器： 如果布隆过滤器判定某个 key 不存在布隆过滤器中，那么就
一定不存在，如果判定某个 key 存在，那么很大可能是存在(存在一定的误判率)。
于是我们可以在缓存之前再加一个布隆过滤器，将数据库中的所有 key 都存储在
布隆过滤器中，在查询 Redis 前先去布隆过滤器查询 key 是否存在，如果不存
在就直接返回，不让其访问数据库，从而避免了对底层存储系统的查询压力。 
如何选择：针对一些恶意攻击，攻击带过来的大量 key 是随机，那么我们采用第
一种方案就会缓存大量不存在 key 的数据。那么这种方案就不合适了，我们可以
先对使用布隆过滤器方案进行过滤掉这些 key。所以，针对这种 key 异常多、请
求重复率比较低的数据，优先使用第二种方案直接过滤掉。而对于空数据的 key
有限的，重复率比较高的，则可优先采用第一种方式进行缓存。 
19. 什么是缓存雪崩? 如果缓在某一个时刻出现大规模的 key 失效，那么就会导致大
量的请求打在了数据库上面，导致数据库压力巨大，如果在高并发的情况下，可
能瞬间就会导致数据库宕机。这时候如果运维马上又重启数据库，马上又会有新
的流量把数据库打死。这就是缓存雪崩。 
造成缓存雪崩的关键在于同一时间的大规模的 key 失效，主要有两种可能：第一
种是 Redis 宕机，第二种可能就是采用了相同的过期时间。 
解决方案： 
1、事前： 
均匀过期：设置不同的过期时间，让缓存失效的时间尽量均匀，避免相同的过期
时间导致缓存雪崩，造成大量数据库的访问。如把每个 Key 的失效时间都加个随
机值，setRedis（Key，value，time + Math.random() * 10000）；，保证数据不会
在同一时间大面积失效。 
分级缓存：第一级缓存失效的基础上，访问二级缓存，每一级缓存的失效时间都
不同。 
热点数据缓存永远不过期。永不过期实际包含两层意思： 
物理不过期，针对热点 key 不设置过期时间 逻辑过期，把过期时间存在 key 对
应的 value 里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建 保
证 Redis 缓存的高可用，防止 Redis 宕机导致缓存雪崩的问题。可以使用 主从+ 
哨兵，Redis 集群来避免 Redis 全盘崩溃的情况。 
2、事中： 
互斥锁：在缓存失效后，通过互斥锁或者队列来控制读数据写缓存的线程数量，
比如某个 key 只允许一个线程查询数据和写缓存，其他线程等待。这种方式会阻
塞其他的线程，此时系统的吞吐量会下降 
使用熔断机制，限流降级。当流量达到一定的阈值，直接返回“系统拥挤”之类的
提示，防止过多的请求打在数据库上将数据库击垮，至少能保证一部分用户是可
以正常使用，其他用户多刷新几次也能得到结果。 
3、事后： 
开启 Redis 持久化机制，尽快恢复缓存数据，一旦重启，就能从磁盘上自动加载
数据恢复内存中的数据。 
20. 什么是缓存预热? 缓存预热是指系统上线后，提前将相关的缓存数据加载到缓存
系统。避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题，用户
直接查询事先被预热的缓存数据。 
如果不进行预热，那么 Redis 初始状态数据为空，系统上线初期，对于高并发的
流量，都会访问到数据库中， 对数据库造成流量的压力。 
缓存预热解决方案： 
数据量不大的时候，工程启动的时候进行加载缓存动作； 
数据量大的时候，设置一个定时任务脚本，进行缓存的刷新； 
数据量太大的时候，优先保证热点数据进行提前加载到缓存。 
21. 什么是缓存降级？ 缓存降级是指缓存失效或缓存服务器挂掉的情况下，不去访
问数据库，直接返回默认数据或访问服务的内存数据。降级一般是有损的操作，
所以尽量减少降级对于业务的影响程度。 
在进行降级之前要对系统进行梳理，看看系统是不是可以丢卒保帅；从而梳理出
哪些必须誓死保护，哪些可降级；比如可以参考日志级别设置预案： 
一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级； 
警告：有些服务在一段时间内成功率有波动（如在 95~100%之间），可以自动降
级或人工降级，并发送告警； 
错误：比如可用率低于 90%，或者数据库连接池被打爆了，或者访问量突然猛增
到系统能承受的最大阀值，此时可以根据情况自动降级或者人工降级； 
严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级。 
线程模型 
22. Redis 为何选择单线程？ 在 Redis 6.0 以前，Redis 的核心网络模型选择用单线程
来实现。先来看下官方的回答： 
It's not very frequent that CPU becomes your bottleneck with Redis， as usually Redisis 
either memory or network bound. For instance， using pipelining Redisrunning on an 
average Linux system can deliver even 1 million requests per second， so if your 
application mainly uses O(N) or O(log(N)) commands， it is hardly going to use too 
much CPU. 
核心意思就是，对于一个 DB 来说，CPU 通常不会是瓶颈，因为大多数请求不
会是 CPU 密集型的，而是 I/O 密集型。具体到 Redis 的话，如果不考虑 
RDB/AOF 等持久化方案，Redis 是完全的纯内存操作，执行速度是非常快的，
因此这部分操作通常不会是性能瓶颈，Redis 真正的性能瓶颈在于网络 I/O，也
就是客户端和服务端之间的网络传输延迟，因此 Redis 选择了单线程的 I/O 多
路复用来实现它的核心网络模型。 
实际上更加具体的选择单线程的原因如下： 
避免过多的上下文切换开销：如果是单线程则可以规避进程内频繁的线程切换开
销，因为程序始终运行在进程中单个线程内，没有多线程切换的场景。 避免同
步机制的开销：如果 Redis 选择多线程模型，又因为 Redis 是一个数据库，那么
势必涉及到底层数据同步的问题，则必然会引入某些同步机制，比如锁，而我们
知道 Redis 不仅仅提供了简单的 key-value 数据结构，还有 list、set 和 hash 等
等其他丰富的数据结构，而不同的数据结构对同步访问的加锁粒度又不尽相同，
可能会导致在操作数据过程中带来很多加锁解锁的开销，增加程序复杂度的同时
还会降低性能。 简单可维护：如果 Redis 使用多线程模式，那么所有的底层数
据结构都必须实现成线程安全的，这无疑又使得 Redis 的实现变得更加复杂。 
总而言之，Redis 选择单线程可以说是多方博弈之后的一种权衡：在保证足够的
性能表现之下，使用单线程保持代码的简单和可维护性。 
23. Redis 真的是单线程？ 讨论 这个问题前，先看下 Redis 的版本中两个重要的节
点： 
Redisv4.0（引入多线程处理异步任务） Redis 6.0（在网络模型中实现多线程 I/O ） 
所以，网络上说的 Redis 是单线程，通常是指在 Redis 6.0 之前，其核心网络模型
使用的是单线程。 
且 Redis6.0 引入多线程 I/O，只是用来处理网络数据的读写和协议的解析，而执
行命令依旧是单线程。 
Redis 在 v4.0 版本的时候就已经引入了的多线程来做一些异步操作，此举主要
针对的是那些非常耗时的命令，通过将这些命令的执行进行异步化，避免阻塞单
线程的事件循环。 
在 Redisv4.0 之后增加了一些的非阻塞命令如 UNLINK、FLUSHALL ASYNC、
FLUSHDB ASYNC。 
24. Redis 6.0 为何引入多线程？ 很简单，就是 Redis 的网络 I/O 瓶颈已经越来越明
显了。 
随着互联网的飞速发展，互联网业务系统所要处理的线上流量越来越大，Redis
的单线程模式会导致系统消耗很多 CPU 时间在网络 I/O 上从而降低吞吐量，
要提升 Redis 的性能有两个方向： 
优化网络 I/O 模块 提高机器内存读写的速度 后者依赖于硬件的发展，暂时无
解。所以只能从前者下手，网络 I/O 的优化又可以分为两个方向： 
零拷贝技术或者 DPDK 技术 利用多核优势 零拷贝技术有其局限性，无法完全
适配 Redis 这一类复杂的网络 I/O 场景，更多网络 I/O 对 CPU 时间的消耗和 
Linux 零拷贝技术。而 DPDK 技术通过旁路网卡 I/O 绕过内核协议栈的方式又
太过于复杂以及需要内核甚至是硬件的支持。 
总结起来，Redis 支持多线程主要就是两个原因： 
可以充分利用服务器 CPU 资源，目前主线程只能利用一个核 
多线程任务可以分摊 Redis 同步 IO 读写负荷 
25. Redis 6.0 采用多线程后，性能的提升效果如何？ Redis 作者 antirez 在 
RedisConf 2019 分享时曾提到：Redis 6 引入的多线程 IO 特性对性能提升至少
是一倍以上。 
国内也有大牛曾使用 unstable 版本在阿里云 esc 进行过测试，GET/SET 命令
在 4 线程 IO 时性能相比单线程是几乎是翻倍了。 
26. 介绍下 Redis 的线程模型 Redis 的线程模型包括 Redis 6.0 之前和 Redis 6.0。 
下面介绍的是 Redis 6.0 之前。 
Redis 是基于 reactor 模式开发了网络事件处理器，这个处理器叫做文件事件处
理器（file event handler）。由于这个文件事件处理器是单线程的，所以 Redis 才
叫做单线程的模型。采用 IO 多路复用机制同时监听多个 Socket，根据 socket 
上的事件来选择对应的事件处理器来处理这个事件。 
IO 多路复用是 IO 模型的一种，有时也称为异步阻塞 IO，是基于经典的 Reactor 
设计模式设计的。多路指的是多个 Socket 连接，复用指的是复用一个线程。多
路复用主要有三种技术：Select，Poll，Epoll。 
Epoll 是最新的也是目前最好的多路复用技术。 
模型如下图： 
文件事件处理器的结构包含了四个部分： 
多个 Socket。Socket 会产生 AE_READABLE 和 AE_WRITABLE 事件： 当 
socket 变得可读时或者有新的可以应答的 socket 出现时，socket 就会产生一个 
AE_READABLE 事 件  当  socket 变 得 可 写 时 ， socket 就 会 产 生 一 个 
AE_WRITABLE 事件。 IO 多路复用程序 文件事件分派器 事件处理器。事件
处理器包括：连接应答处理器、命令请求处理器、命令回复处理器，每个处理器
对应不同的 socket 事件： 如果是客户端要连接 Redis，那么会为 socket 关联
连接应答处理器 如果是客户端要写数据到 Redis（读、写请求命令），那么会为 
socket 关联命令请求处理器 如果是客户端要从 Redis 读数据，那么会为 socket 
关联命令回复处理器 多个 socket 会产生不同的事件，不同的事件对应着不同的
操作，IO 多路复用程序监听着这些 Socket，当这些 Socket 产生了事件，IO 多
路复用程序会将这些事件放到一个队列中，通过这个队列，以有序、同步、每次
一个事件的方式向文件时间分派器中传送。当事件处理器处理完一个事件后，IO 
多路复用程序才会继续向文件分派器传送下一个事件。 
下图是客户端与 Redis 通信的一次完整的流程： 
Redis 启动初始化的时候，Redis 会将连接应答处理器与 AE_READABLE 事件
关联起来。 如果一个客户端跟 Redis 发起连接，此时 Redis 会产生一个 
AE_READABLE 事件，由于开始之初 AE_READABLE 是与连接应答处理器关
联，所以由连接应答处理器来处理该事件，这时连接应答处理器会与客户端建立
连接，创建客户端响应的 socket，同时将这个 socket 的 AE_READABLE 事件
与命令请求处理器关联起来。 如果这个时间客户端向 Redis 发送一个命令（set 
k1 v1），这时 socket 会产生一个 AE_READABLE 事件，IO 多路复用程序会
将该事件压入队列中，此时事件分派器从队列中取得该事件，由于该 socket 的 
AE_READABLE 事件已经和命令请求处理器关联了，因此事件分派器会将该事
件交给命令请求处理器处理，命令请求处理器读取事件中的命令并完成。操作完
成后，Redis 会将该 socket 的 AE_WRITABLE 事件与命令回复处理器关联。 
如 果 客 户 端 已 经 准 备 好 接 受 数 据 后 ， Redis 中 的 该  socket 会 产 生 一 个 
AE_WRITABLE 事件，同样会压入队列然后被事件派发器取出交给相对应的命
令回复处理器，由该命令回复处理器将准备好的响应数据写入 socket 中，供客
户端读取。 命令回复处理器写完后，就会删除该 socket 的 AE_WRITABLE 事
件与命令回复处理器的关联关系。 
27. Redis 6.0 多线程的实现机制？ 流程简述如下： 
主线程负责接收建立连接请求，获取 Socket 放入全局等待读处理队列。 主线程
处理完读事件之后，通过 RR（Round Robin）将这些连接分配给这些 IO 线程。 
主线程阻塞等待 IO 线程读取 Socket 完毕。 主线程通过单线程的方式执行请
求命令，请求数据读取并解析完成，但并不执行。 主线程阻塞等待 IO 线程将
数据回写 Socket 完毕。 
该设计有如下特点： 
IO 线程要么同时在读 Socket，要么同时在写，不会同时读或写。 IO 线程只负
责读写 Socket 解析命令，不负责命令处理。 
28. Redis 6.0 开启多线程后，是否会存在线程并发安全问题？ 从实现机制可以看出，
Redis 的多线程部分只是用来处理网络数据的读写和协议解析，执行命令仍然是
单线程顺序执行。 
所以我们不需要去考虑控制 Key、Lua、事务，LPUSH/LPOP 等等的并发及线程
安全问题。 
29. Redis 6.0 与 Memcached 多线程模型的对比 相同点：都采用了 Master 线程 -
Worker 线程的模型。 
不同点：Memcached 执行主逻辑也是在 Worker 线程里，模型更加简单，实现
了真正的线程隔离，符合我们对线程隔离的常规理解。 
而 Redis 把处理逻辑交还给 Master 线程，虽然一定程度上增加了模型复杂度，
但也解决了线程并发安全等问题。 
事务 
30. Redis 事务的概念 Redis 的事务并不是我们传统意义上理解的事务，我们都知道 
单个 Redis 命令的执行是原子性的，但 Redis 没有在事务上增加任何维持原子
性的机制，所以 Redis 事务的执行并不是原子性的。 
事务可以理解为一个打包的批量执行脚本，但批量指令并非原子化的操作，中间
某条指令的失败不会导致前面已做指令的回滚，也不会造成后续的指令不做。 
总结： 
1. Redis 事务中如果有某一条命令执行失败，之前的命令不会回滚，其后的命令仍
然会被继续执行。鉴于这个原因，所以说 Redis 的事务严格意义上来说是不具备
原子性的。 
2. Redis 事务中所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会
被其他客户端发送来的命令请求所打断。 
3. 在事务开启之前，如果客户端与服务器之间出现通讯故障并导致网络断开，其后
所有待执行的语句都将不会被服务器执行。然而如果网络中断事件是发生在客户
端执行 EXEC 命令之后，那么该事务中的所有命令都会被服务器执行。 
当使用 Append-Only 模式时，Redis 会通过调用系统函数 write 将该事务内的所
有写操作在本次调用中全部写入磁盘。然而如果在写入的过程中出现系统崩溃，
如电源故障导致的宕机，那么此时也许只有部分数据被写入到磁盘，而另外一部
分数据却已经丢失。Redis 服务器会在重新启动时执行一系列必要的一致性检测，
一旦发现类似问题，就会立即退出并给出相应的错误提示。此时，我们就要充分
利用 Redis 工具包中提供的 Redis-check-aof 工具，该工具可以帮助我们定位到数
据不一致的错误，并将已经写入的部分数据进行回滚。修复之后我们就可以再次
重新启动 Redis 服务器了。 
31. Redis 事务的三个阶段 multi 开启事务 大量指令入队 exec 执行事务块内命令，
截止此处一个事务已经结束。 discard 取消事务 watch 监视一个或多个 key，如
果事务执行前 key 被改动，事务将打断。unwatch 取消监视。 事务执行过程中，
如果服务端收到有 EXEC、DISCARD、WATCH、MULTI 之外的请求，将会把请
求放入队列中排队. 
32. Redis事务相关命令 Redis事务功能是通过MULTI、EXEC、DISCARD 和WATCH 
四个原语实现的 
WATCH 命令是一个乐观锁，可以为 Redis 事务提供 check-and-set （CAS）行
为。 可以监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事
务就不会执行，监控一直持续到 EXEC 命令。 MULTI 命令用于开启一个事务，
它总是返回 OK。 MULTI 执行之后，客户端可以继续向服务器发送任意多条命
令，这些命令不会立即被执行，而是被放到一个队列中，当 EXEC 命令被调用
时，所有队列中的命令才会被执行。 EXEC：执行所有事务块内的命令。返回事
务块内所有命令的返回值，按命令执行的先后顺序排列。 当操作被打断时，返
回空值 nil 。 通过调用 DISCARD，客户端可以清空事务队列，并放弃执行事务， 
并且客户端会从事务状态中退出。 UNWATCH 命令可以取消 watch 对所有 key
的监控。 
33. Redis 事务支持隔离性吗? Redis 是单进程程序，并且它保证在执行事务时，不会
对事务进行中断，事务可以运行直到执行完所有事务队列中的命令为止。因此，
Redis 的事务是总是带有隔离性的。 
34. Redis 为什么不支持事务回滚？ Redis 命令只会因为错误的语法而失败，或是命
令用在了错误类型的键上面，这些问题不能在入队时发现，这也就是说，从实用
性的角度来说，失败的命令是由编程错误造成的，而这些错误应该在开发的过程
中被发现，而不应该出现在生产环境中. 因为不需要对回滚进行支持，所以 Redis 
的内部可以保持简单且快速。 
35. Redis 事务其他实现 基于 Lua 脚本，Redis 可以保证脚本内的命令一次性、按顺
序地执行， 其同时也不提供事务运行错误的回滚，执行过程中如果部分命令运
行错误，剩下的命令还是会继续运行完。 基于中间标记变量，通过另外的标记
变量来标识事务是否执行完成，读取数据时先读取该标记变量判断是否事务执行
完成。但这样会需要额外写代码实现，比较繁琐。 主从、哨兵、集群 
36. Redis 常见使用方式有哪些？ Redis 的几种常见使用方式包括： 
Redis 单副本； Redis 多副本（主从）； Redis Sentinel（哨兵）； Redis Cluster； 
Redis 自研。 使用场景： 
如果数据量很少，主要是承载高并发高性能的场景，比如缓存一般就几个 G 的
话，单机足够了。 
主从模式：master 节点挂掉后，需要手动指定新的 master，可用性不高，基本不
用。 
哨兵模式：master 节点挂掉后，哨兵进程会主动选举新的 master，可用性高，但
是每个节点存储的数据是一样的，浪费内存空间。数据量不是很多，集群规模不
是很大，需要自动容错容灾的时候使用。 
Redis cluster 主要是针对海量数据+高并发+高可用的场景，如果是海量数据，如
果你的数据量很大，那么建议就用 Redis cluster，所有 master 的容量总和就是
Redis cluster 可缓存的数据容量。 
37. 介绍下 Redis 单副本 Redis 单副本，采用单个 Redis 节点部署架构，没有备用节
点实时同步数据，不提供数据持久化和备份策略，适用于数据可靠性要求不高的
纯缓存业务场景。 
优点： 
架构简单，部署方便； 高性价比：缓存使用时无需备用节点（单实例可用性可
以用 supervisor 或 crontab 保证），当然为了满足业务的高可用性，也可以牺牲一
个备用节点，但同时刻只有一个实例对外提供服务； 高性能。 缺点： 
不保证数据的可靠性； 在缓存使用，进程重启后，数据丢失，即使有备用的节
点解决高可用性，但是仍然不能解决缓存预热问题，因此不适用于数据可靠性要
求高的业务； 高性能受限于单核 CPU 的处理能力（Redis 是单线程机制），CPU
为主要瓶颈，所以适合操作命令简单，排序、计算较少的场景。也可以考虑用
Memcached 替代。 
38. 介绍下 Redis 多副本（主从） Redis 多副本，采用主从（replication）部署结构，
相较于单副本而言最大的特点就是主从实例间数据实时同步，并且提供数据持久
化和备份策略。主从实例部署在不同的物理服务器上，根据公司的基础环境配置，
可以实现同时对外提供服务和读写分离策略。 
优点： 
高可靠性：一方面，采用双机主备架构，能够在主库出现故障时自动进行主备切
换，从库提升为主库提供服务，保证服务平稳运行；另一方面，开启数据持久化
功能和配置合理的备份策略，能有效的解决数据误操作和数据异常丢失的问题； 
读写分离策略：从节点可以扩展主库节点的读能力，有效应对大并发量的读操作。 
缺点： 
故障恢复复杂，如果没有 RedisHA 系统（需要开发），当主库节点出现故障时，
需要手动将一个从节点晋升为主节点，同时需要通知业务方变更配置，并且需要
让其它从库节点去复制新主库节点，整个过程需要人为干预，比较繁琐； 
主库的写能力受到单机的限制，可以考虑分片； 
主库的存储能力受到单机的限制，可以考虑 Pika； 
原生复制的弊端在早期的版本中也会比较突出，如：Redis 复制中断后，Slave 会
发起 psync，此时如果同步不成功，则会进行全量同步，主库执行全量备份的同
时可能会造成毫秒或秒级的卡顿；又由于 COW 机制，导致极端情况下的主库内
存溢出，程序异常退出或宕机；主库节点生成备份文件导致服务器磁盘 IO 和 CPU
（压缩）资源消耗；发送数 GB 大小的备份文件导致服务器出口带宽暴增，阻塞
请求，建议升级到最新版本。 
39. 介绍下 Redis Sentinel（哨兵） 主从模式下，当主服务器宕机后，需要手动把一
台从服务器切换为主服务器，这就需要人工干预，费事费力，还会造成一段时间
内服务不可用。这种方式并不推荐，实际生产中，我们优先考虑哨兵模式。这种
模式下，master 宕机，哨兵会自动选举 master 并将其他的 slave 指向新的 
master。 
Redis Sentinel 是社区版本推出的原生高可用解决方案，其部署架构主要包括两部
分：Redis Sentinel 集群和 Redis 数据集群。 
其中 Redis Sentinel 集群是由若干 Sentinel 节点组成的分布式集群，可以实现故
障发现、故障自动转移、配置中心和客户端通知。Redis Sentinel 的节点数量要满
足 2n+1（n>=1）的奇数个。 
优点： 
Redis Sentinel 集群部署简单； 能够解决 Redis 主从模式下的高可用切换问题； 
很方便实现 Redis 数据节点的线形扩展，轻松突破 Redis 自身单线程瓶颈，可极
大满足 Redis 大容量或高性能的业务需求； 可以实现一套 Sentinel 监控一组 Redis
数据节点或多组数据节点。 缺点： 
部署相对 Redis 主从模式要复杂一些，原理理解更繁琐； 资源浪费，Redis 数据
节点中 slave 节点作为备份节点不提供服务； Redis Sentinel 主要是针对 Redis 数
据节点中的主节点的高可用切换，对 Redis 的数据节点做失败判定分为主观下线
和客观下线两种，对于 Redis 的从节点有对节点做主观下线操作，并不执行故障
转移。 不能解决读写分离问题，实现起来相对复杂。 
40. 介绍下 Redis Cluster Redis 的哨兵模式基本已经可以实现高可用，读写分离 ，但
是在这种模式下每台 Redis 服务器都存储相同的数据，很浪费内存，所以在 
Redis3.0 上加入了 Cluster 集群模式，实现了 Redis 的分布式存储，对数据进行
分片，也就是说每台 Redis 节点上存储不同的内容。 
Redis Cluster 是社区版推出的 Redis 分布式集群解决方案，主要解决 Redis 分布
式方面的需求，比如，当遇到单机内存，并发和流量等瓶颈的时候，Redis Cluster
能起到很好的负载均衡的目的。 
Redis Cluster 集群节点最小配置 6 个节点以上（3 主 3 从），其中主节点提供读
写操作，从节点作为备用节点，不提供请求，只作为故障转移使用。 
Redis Cluster 采用虚拟槽分区，所有的键根据哈希函数映射到 0～16383 个整数
槽内，每个节点负责维护一部分槽以及槽所印映射的键值数据。 
优点： 
无中心架构； 数据按照 slot 存储分布在多个节点，节点间数据共享，可动态调
整数据分布； 可扩展性：可线性扩展到 1000 多个节点，节点可动态添加或删除； 
高可用性：部分节点不可用时，集群仍可用。通过增加 Slave 做 standby 数据副
本，能够实现故障自动 failover，节点之间通过 gossip 协议交换状态信息，用投
票机制完成 Slave 到 Master 的角色提升； 降低运维成本，提高系统的扩展性和
可用性。 缺点： 
Client 实现复杂，驱动要求实现 Smart Client，缓存 slots mapping 信息并及时更
新，提高了开发难度，客户端的不成熟影响业务的稳定性。目前仅 JedisCluster 相
对成熟，异常处理部分还不完善，比如常见的“max redirect exception”。 节点会
因为某些原因发生阻塞（阻塞时间大于 clutser-node-timeout），被判断下线，这
种 failover 是没有必要的。 数据通过异步复制，不保证数据的强一致性。 多个
业务使用同一套集群时，无法根据统计区分冷热数据，资源隔离性较差，容易出
现相互影响的情况。 Slave 在集群中充当“冷备”，不能缓解读压力，当然可以通
过 SDK 的合理设计来提高 Slave 资源的利用率。 Key 批量操作限制，如使用
mset、mget 目前只支持具有相同 slot 值的 Key 执行批量操作。对于映射为不同
slot 值的 Key 由于 Keys 不支持跨 slot 查询，所以执行 mset、mget、sunion 等操
作支持不友好。 Key 事务操作支持有限，只支持多 key 在同一节点上的事务操
作，当多个 Key 分布于不同的节点上时无法使用事务功能。 Key 作为数据分区
的最小粒度，不能将一个很大的键值对象如 hash、list 等映射到不同的节点。 不
支持多数据库空间，单机下的 Redis 可以支持到 16 个数据库，集群模式下只能
使用 1 个数据库空间，即 db 0。 复制结构只支持一层，从节点只能复制主节点，
不支持嵌套树状复制结构。 避免产生 hot-key，导致主库节点成为系统的短板。 
避免产生 big-key，导致网卡撑爆、慢查询等。 重试时间应该大于 cluster-node-
time 时间。 Redis Cluster 不建议使用 pipeline 和 multi-keys 操作，减少 max redirect
产生的场景。 
41. 介绍下 Redis 自研 Redis 自研的高可用解决方案，主要体现在配置中心、故障探
测和 failover 的处理机制上，通常需要根据企业业务的实际线上环境来定制化。 
优点： 
高可靠性、高可用性； 自主可控性高； 贴切业务实际需求，可缩性好，兼容性
好。 缺点： 
实现复杂，开发成本高； 需要建立配套的周边设施，如监控，域名服务，存储
元数据信息的数据库等； 维护成本高。 
42. Redis 高可用方案具体怎么实施？ 使用官方推荐的哨兵(sentinel)机制就能实现，
当主节点出现故障时，由 Sentinel 自动完成故障发现和转移，并通知应用方，实
现高可用性。它有四个主要功能： 
集群监控，负责监控 Redis master 和 slave 进程是否正常工作。 消息通知，如果
某个 Redis 实例有故障，那么哨兵负责发送消息作为报警通知给管理员。 故障
转移，如果 master node 挂掉了，会自动转移到 slave node 上。 配置中心，如果
故障转移发生了，通知 client 客户端新的 master 地址。 
43. 了解主从复制的原理吗？ 1、主从架构的核心原理 
当启动一个 slave node 的时候，它会发送一个 PSYNC 命令给 master node 
如果这是 slave node 重新连接 master node，那么 master node 仅仅会复制给 slave
部分缺少的数据; 否则如果是 slave node 第一次连接 master node，那么会触发一
次 full resynchronization 
开始 full resynchronization 的时候，master 会启动一个后台线程，开始生成一份
RDB 快照文件，同时还会将从客户端收到的所有写命令缓存在内存中。RDB 文
件生成完毕之后，master 会将这个 RDB 发送给 slave，slave 会先写入本地磁盘，
然后再从本地磁盘加载到内存中。然后 master 会将内存中缓存的写命令发送给
slave，slave 也会同步这些数据。 
slave node 如果跟 master node 有网络故障，断开了连接，会自动重连。master 如
果发现有多个 slave node 都来重新连接，仅仅会启动一个 rdb save 操作，用一份
数据服务所有 slave node。 
2、主从复制的断点续传 
从 Redis 2.8 开始，就支持主从复制的断点续传，如果主从复制过程中，网络连
接断掉了，那么可以接着上次复制的地方，继续复制下去，而不是从头开始复制
一份 
master node 会在内存中常见一个 backlog，master 和 slave 都会保存一个 replica 
offset 还有一个 master id，offset 就是保存在 backlog 中的。如果 master 和 slave
网络连接断掉了，slave 会让 master 从上次的 replica offset 开始继续复制 
但是如果没有找到对应的 offset，那么就会执行一次 resynchronization 
3、无磁盘化复制 
master 在内存中直接创建 rdb，然后发送给 slave，不会在自己本地落地磁盘了 
repl-diskless-sync repl-diskless-sync-delay，等待一定时长再开始复制，因为要等更
多 slave 重新连接过来 
4、过期 key 处理 
slave 不会过期 key，只会等待 master 过期 key。如果 master 过期了一个 key，或
者通过 LRU 淘汰了一个 key，那么会模拟一条 del 命令发送给 slave。 
44. 由于主从延迟导致读取到过期数据怎么处理？ 通过 scan 命令扫库：当 Redis 中
的 key 被 scan 的时候，相当于访问了该 key，同样也会做过期检测，充分发挥
Redis 惰性删除的策略。这个方法能大大降低了脏数据读取的概率，但缺点也比
较明显，会造成一定的数据库压力，否则影响线上业务的效率。 Redis 加入了一
个新特性来解决主从不一致导致读取到过期数据问题，增加了 key 是否过期以及
对主从库的判断，如果 key 已过期，当前访问的 master 则返回 null；当前访问的
是从库，且执行的是只读命令也返回 null。 
45. 主从复制的过程中如果因为网络原因停止复制了会怎么样？ 如果出现网络故障
断开连接了，会自动重连的，从 Redis 2.8 开始，就支持主从复制的断点续传，可
以接着上次复制的地方，继续复制下去，而不是从头开始复制一份。 
master 如果发现有多个 slave node 都来重新连接，仅仅会启动一个 rdb save 操作，
用一份数据服务所有 slave node。 
master node 会在内存中创建一个 backlog，master 和 slave 都会保存一个 replica 
offset，还有一个 master id，offset 就是保存在 backlog 中的。如果 master 和 slave
网络连接断掉了，slave 会让 master 从上次的 replica offset 开始继续复制。 
但是如果没有找到对应的 offset，那么就会执行一次 resynchronization 全量复制。 
46. Redis 主从架构数据会丢失吗，为什么？ 有两种数据丢失的情况： 
异步复制导致的数据丢失：因为 master -> slave 的复制是异步的，所以可能有部
分数据还没复制到 slave，master 就宕机了，此时这些部分数据就丢失了。 脑裂
导致的数据丢失：某个 master 所在机器突然脱离了正常的网络，跟其他 slave 机
器不能连接，但是实际上 master 还运行着，此时哨兵可能就会认为 master 宕机
了，然后开启选举，将其他 slave 切换成了 master。这个时候，集群里就会有两
个 master，也就是所谓的脑裂。此时虽然某个 slave 被切换成了 master，但是可
能 client 还没来得及切换到新的 master，还继续写向旧 master 的数据可能也丢失
了。因此旧 master 再次恢复的时候，会被作为一个 slave 挂到新的 master 上去，
自己的数据会清空，重新从新的 master 复制数据。 
47. 如何解决主从架构数据丢失的问题？ 数据丢失的问题是不可避免的，但是我们
可以尽量减少。 
在 Redis 的配置文件里设置参数 
min-slaves-to-write 1 min-slaves-max-lag 10 min-slaves-to-write 默认情况下是 0，
min-slaves-max-lag 默认情况下是 10。 
上面的配置的意思是要求至少有 1 个 slave，数据复制和同步的延迟不能超过 10
秒。如果说一旦所有的 slave，数据复制和同步的延迟都超过了 10 秒钟，那么这
个时候，master 就不会再接收任何请求了。 
减小 min-slaves-max-lag 参数的值，这样就可以避免在发生故障时大量的数据丢
失，一旦发现延迟超过了该值就不会往 master 中写入数据。 
那么对于 client，我们可以采取降级措施，将数据暂时写入本地缓存和磁盘中，
在一段时间后重新写入 master 来保证数据不丢失；也可以将数据写入 kafka 消息
队列，隔一段时间去消费 kafka 中的数据。 
48. Redis 哨兵是怎么工作的？ 每个 Sentinel 以每秒钟一次的频率向它所知的 Master，
Slave 以及其他 Sentinel 实例发送一个 PING 命令。 
如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-
after-milliseconds 选项所指定的值， 则这个实例会被当前 Sentinel 标记为主观
下线。 
如果一个 Master 被标记为主观下线，则正在监视这个 Master 的所有 Sentinel 要
以每秒一次的频率确认 Master 的确进入了主观下线状态。 
当有足够数量的 Sentinel（大于等于配置文件指定的值）在指定的时间范围内确
认 Master 的确进入了主观下线状态， 则 Master 会被标记为客观下线 。 
当 Master 被 Sentinel 标记为客观下线时，Sentinel 向下线的 Master 的所有 
Slave 发送 INFO 命令的频率会从 10 秒一次改为每秒一次 （在一般情况下， 
每个 Sentinel 会以每 10 秒一次的频率向它已知的所有 Master，Slave 发送 
INFO 命令 ）。 
若没有足够数量的 Sentinel 同意 Master 已经下线， Master 的客观下线状态就
会变成主观下线。若 Master 重新向 Sentinel 的 PING 命令返回有效回复， 
Master 的主观下线状态就会被移除。 
sentinel 节点会与其他 sentinel 节点进行“沟通”，投票选举一个 sentinel 节点进行
故障处理，在从节点中选取一个主节点，其他从节点挂载到新的主节点上自动复
制新主节点的数据。 
49. 故障转移时会从剩下的 slave 选举一个新的 master，被选举为 master 的标准是什
么？ 如果一个 master 被认为 odown 了，而且 majority 哨兵都允许了主备切换，
那么某个哨兵就会执行主备切换操作，此时首先要选举一个 slave 来，会考虑 slave
的一些信息。 
跟 master 断开连接的时长。 如果一个 slave 跟 master 断开连接已经超过了 down-
after-milliseconds 的 10 倍，外加 master 宕机的时长，那么 slave 就被认为不适合
选举为 master. 
( down-after-milliseconds * 10) + milliseconds_since_master_is_in_SDOWN_state 
slave 优先级。 按照 slave 优先级进行排序，slave priority 越低，优先级就越高 
复制 offset。 如果 slave priority 相同，那么看 replica offset，哪个 slave 复制了越
多的数据，offset 越靠后，优先级就越高 
run id 如果上面两个条件都相同，那么选择一个 run id 比较小的那个 slave。 
50. 同步配置的时候其他哨兵根据什么更新自己的配置呢？ 执行切换的那个哨兵，
会从要切换到的新 master（salve->master）那里得到一个 configuration epoch，这
就是一个 version 号，每次切换的 version 号都必须是唯一的。 
如果第一个选举出的哨兵切换失败了，那么其他哨兵，会等待 failover-timeout 时
间，然后接替继续执行切换，此时会重新获取一个新的 configuration epoch 作为
新的 version 号。 
这个 version 号就很重要了，因为各种消息都是通过一个 channel 去发布和监听
的，所以一个哨兵完成一次新的切换之后，新的 master 配置是跟着新的 version
号的，其他的哨兵都是根据版本号的大小来更新自己的 master 配置的。 
51. 为什么 Redis 哨兵集群只有 2 个节点无法正常工作？ 哨兵集群必须部署 2 个以
上节点。 
如果两个哨兵实例，即两个 Redis 实例，一主一从的模式。 
则 Redis 的配置 quorum=1，表示一个哨兵认为 master 宕机即可认为 master 已宕
机。 
但是如果是机器 1 宕机了，那哨兵 1 和 master 都宕机了，虽然哨兵 2 知道 master
宕机了，但是这个时候，需要 majority，也就是大多数哨兵都是运行的，2 个哨
兵的 majority 就是 2（2 的 majority=2，3 的 majority=2，5 的 majority=3，4 的
majority=2），2 个哨兵都运行着，就可以允许执行故障转移。 
但此时哨兵 1 没了就只有 1 个哨兵了了，此时就没有 majority 来允许执行故障转
移，所以故障转移不会执行。 
52. Redis cluster 中是如何实现数据分布的？这种方式有什么优点？ Redis cluster 有
固定的 16384 个 hash slot（哈希槽），对每个 key 计算 CRC16 值，然后对 16384
取模，可以获取 key 对应的 hash slot。 
Redis cluster 中每个 master 都会持有部分 slot（槽），比如有 3 个 master，那么
可能每个 master 持有 5000 多个 hash slot。 
hash slot 让 node 的增加和移除很简单，增加一个 master，就将其他 master 的 hash 
slot 移动部分过去，减少一个 master，就将它的 hash slot 移动到其他 master 上
去。每次增加或减少 master 节点都是对 16384 取模，而不是根据 master 数量，
这样原本在老的 master 上的数据不会因 master 的新增或减少而找不到。并且增
加或减少 master 时 Redis cluster 移动 hash slot 的成本是非常低的。 
53. Redis cluster 节点间通信是什么机制？ Redis cluster 节点间采取 gossip 协议进行
通信，所有节点都持有一份元数据，不同的节点如果出现了元数据的变更之后 U
不断地 i 将元数据发送给其他节点让其他节点进行数据变更。 
节点互相之间不断通信，保持整个集群所有节点的数据是完整的。 主要交换故
障信息、节点的增加和移除、hash slot 信息等。 
这种机制的好处在于，元数据的更新比较分散，不是集中在一个地方，更新请求
会陆陆续续，打到所有节点上去更新，有一定的延时，降低了压力; 
缺点，元数据更新有延时，可能导致集群的一些操作会有一些滞后。 
分布式问题 
54. 什么是分布式锁？为什么用分布式锁？ 锁在程序中的作用就是同步工具，保证
共享资源在同一时刻只能被一个线程访问，Java 中的锁我们都很熟悉了，像
synchronized 、Lock 都是我们经常使用的，但是 Java 的锁只能保证单机的时候
有效，分布式集群环境就无能为力了，这个时候我们就需要用到分布式锁。 
分布式锁，顾名思义，就是分布式项目开发中用到的锁，可以用来控制分布式系
统之间同步访问共享资源。 
思路是：在整个系统提供一个全局、唯一的获取锁的“东西”，然后每个系统在需
要加锁时，都去问这个“东西”拿到一把锁，这样不同的系统拿到的就可以认为是
同一把锁。至于这个“东西”，可以是 Redis、Zookeeper，也可以是数据库。 
一般来说，分布式锁需要满足的特性有这么几点： 
1、互斥性：在任何时刻，对于同一条数据，只有一台应用可以获取到分布式锁； 
2、高可用性：在分布式场景下，一小部分服务器宕机不影响正常使用，这种情
况就需要将提供分布式锁的服务以集群的方式部署； 
3、防止锁超时：如果客户端没有主动释放锁，服务器会在一段时间之后自动释
放锁，防止客户端宕机或者网络不可达时产生死锁； 
4、独占性：加锁解锁必须由同一台服务器进行，也就是锁的持有者才可以释放
锁，不能出现你加的锁，别人给你解锁了。 
55. 常见的分布式锁有哪些解决方案？ 实现分布式锁目前有三种流行方案，即基于
关系型数据库、Redis、ZooKeeper 的方案 
1、基于关系型数据库，如 MySQL 基于关系型数据库实现分布式锁，是依赖数
据库的唯一性来实现资源锁定，比如主键和唯一索引等。 
缺点： 
这把锁强依赖数据库的可用性，数据库是一个单点，一旦数据库挂掉，会导致业
务系统不可用。 这把锁没有失效时间，一旦解锁操作失败，就会导致锁记录一
直在数据库中，其他线程无法再获得到锁。 这把锁只能是非阻塞的，因为数据
的 insert 操作，一旦插入失败就会直接报错。没有获得锁的线程并不会进入排队
队列，要想再次获得锁就要再次触发获得锁操作。 这把锁是非重入的，同一个
线程在没有释放锁之前无法再次获得该锁。因为数据中数据已经存在了。 2、基
于 Redis 实现 
优点： 
Redis 锁实现简单，理解逻辑简单，性能好，可以支撑高并发的获取、释放锁操
作。 
缺点： 
Redis 容易单点故障，集群部署，并不是强一致性的，锁的不够健壮； key 的过
期时间设置多少不明确，只能根据实际情况调整； 需要自己不断去尝试获取锁，
比较消耗性能。 3、基于 zookeeper 
优点： 
zookeeper 天生设计定位就是分布式协调，强一致性，锁很健壮。如果获取不到
锁，只需要添加一个监听器就可以了，不用一直轮询，性能消耗较小。 
缺点： 
在高请求高并发下，系统疯狂的加锁释放锁，最后 zk 承受不住这么大的压力可
能会存在宕机的风险。 
56. Redis 实现分布式锁 分布式锁的三个核心要素 1、加锁 
使用 setnx 来加锁。key 是锁的唯一标识，按业务来决定命名，value 这里设置为
test。 
setx key test 当一个线程执行 setnx 返回 1，说明 key 原本不存在，该线程成功得
到了锁；当一个线程执行 setnx 返回 0，说明 key 已经存在，该线程抢锁失败； 
2、解锁 
有加锁就得有解锁。当得到的锁的线程执行完任务，需要释放锁，以便其他线程
可以进入。释放锁的最简单方式就是执行 del 指令。 
del key 释放锁之后，其他线程就可以继续执行 setnx 命令来获得锁。 
3、锁超时 
锁超时知道的是：如果一个得到锁的线程在执行任务的过程中挂掉，来不及显式
地释放锁，这块资源将会永远被锁住，别的线程北向进来。 
所以，setnx 的 key 必须设置一个超时时间，以保证即使没有被显式释放，这把
锁也要在一段时间后自动释放。setnx 不支持超时参数，所以需要额外指令， 
expire key 30 上述分布式锁存在的问题 通过上述 setnx 、del 和 expire 实现的分
布式锁还是存在着一些问题。 
1、SETNX 和 EXPIRE 非原子性 
假设一个场景中，某一个线程刚执行 setnx，成功得到了锁。此时 setnx 刚执行成
功，还未来得及执行 expire 命令，节点就挂掉了。此时这把锁就没有设置过期时
间，别的线程就再也无法获得该锁。 
解决措施: 
由于 setnx 指令本身是不支持传入超时时间的，而在 Redis2.6.12 版本上为 set 指
令增加了可选参数, 用法如下： 
SET key value EX seconds [NX|XX] EX second: 设置键的过期时间为 second 秒； 
PX millisecond：设置键的过期时间为 millisecond 毫秒； NX：只在键不存在时，
才对键进行设置操作； XX：只在键已经存在时，才对键进行设置操作； SET 操
作完成时，返回 OK，否则返回 nil。 2、锁误解除 
如果线程 A 成功获取到了锁，并且设置了过期时间 30 秒，但线程 A 执行时
间超过了 30 秒，锁过期自动释放，此时线程 B 获取到了锁；随后 A 执行完
成，线程 A 使用 DEL 命令来释放锁，但此时线程 B 加的锁还没有执行完成，
线程 A 实际释放的线程 B 加的锁。 
解决办法： 
在 del 释放锁之前加一个判断，验证当前的锁是不是自己加的锁。 
具体在加锁的时候把当前线程的 id 当做 value，可生成一个 UUID 标识当前线
程，在删除之前验证 key 对应的 value 是不是自己线程的 id。 
还可以使用 lua 脚本做验证标识和解锁操作。 
3、超时解锁导致并发 
如果线程 A 成功获取锁并设置过期时间 30 秒，但线程 A 执行时间超过了 30 
秒，锁过期自动释放，此时线程 B 获取到了锁，线程 A 和线程 B 并发执行。 
A、B 两个线程发生并发显然是不被允许的，一般有两种方式解决该问题： 
将过期时间设置足够长，确保代码逻辑在锁释放之前能够执行完成。 为获取锁
的线程增加守护线程，为将要过期但未释放的锁增加有效时间。 4、不可重入 
当线程在持有锁的情况下再次请求加锁，如果一个锁支持一个线程多次加锁，那
么这个锁就是可重入的。如果一个不可重入锁被再次加锁，由于该锁已经被持有，
再次加锁会失败。Redis 可通过对锁进行重入计数，加锁时加 1，解锁时减 1，
当计数归 0 时释放锁。 
5、无法等待锁释放 
上述命令执行都是立即返回的，如果客户端可以等待锁释放就无法使用。 
可以通过客户端轮询的方式解决该问题，当未获取到锁时，等待一段时间重新获
取锁，直到成功获取锁或等待超时。这种方式比较消耗服务器资源，当并发量比
较大时，会影响服务器的效率。 另一种方式是使用 Redis 的发布订阅功能，当
获取锁失败时，订阅锁释放消息，获取锁成功后释放时，发送锁释放消息。 具
体实现参考：https://xiaomi-info.github.io/2019/12/17/Redis-distributed-lock/ 
57. 了解RedLock吗？ Redlock是一种算法，Redlock也就是 Redis Distributed Lock，
可用实现多节点 Redis 的分布式锁。 
RedLock 官方推荐，Redisson 完成了对 Redlock 算法封装。 
此种方式具有以下特性： 
互斥访问：即永远只有一个 client 能拿到锁 避免死锁：最终 client 都可能拿到
锁，不会出现死锁的情况，即使锁定资源的服务崩溃或者分区，仍然能释放锁。 
容错性：只要大部分 Redis 节点存活（一半以上），就可以正常提供服务 
58. RedLock 的原理 假设有 5 个完全独立的 Redis 主服务器 
获取当前时间戳 
client 尝试按照顺序使用相同的 key,value 获取所有 Redis 服务的锁，在获取锁的
过程中的获取时间比锁过期时间短很多，这是为了不要过长时间等待已经关闭的
Redis 服务。并且试着获取下一个 Redis 实例。 
比如：TTL 为 5s,设置获取锁最多用 1s，所以如果一秒内无法获取锁，就放弃获
取这个锁，从而尝试获取下个锁 
client 通过获取所有能获取的锁后的时间减去第一步的时间，这个时间差要小于
TTL 时间并且至少有 3 个 Redis 实例成功获取锁，才算真正的获取锁成功 
如果成功获取锁，则锁的真正有效时间是 TTL 减去第三步的时间差 的时间；比
如：TTL 是 5s,获取所有锁用了 2s,则真正锁有效时间为 3s(其实应该再减去时钟
漂移); 
如果客户端由于某些原因获取锁失败，便会开始解锁所有 Redis 实例；因为可能
已经获取了小于 3 个锁，必须释放，否则影响其他 client 获取锁 
算法示意图如下： 
其他 
59. Redis 如何做内存优化？ 控制 key 的数量。当使用 Redis 存储大量数据时，通常
会存在大量键，过多的键同样会消耗大量内存。Redis 本质是一个数据结构服务
器，它为我们提供多种数据结构，如 hash，list，set，zset 等结构。使用 Redis 时
不要进入一个误区，大量使用 get/set 这样的 API，把 Redis 当成 Memcached 使
用。对于存储相同的数据内容利用 Redis 的数据结构降低外层键的数量，也可以
节省大量内存。 
缩减键值对象，降低 Redis 内存使用最直接的方式就是缩减键（key）和值（value）
的长度。 
key 长度：如在设计键时，在完整描述业务情况下，键值越短越好。 value 长度：
值对象缩减比较复杂，常见需求是把业务对象序列化成二进制数组放入 Redis。
首先应该在业务上精简业务对象，去掉不必要的属性避免存储无效数据。其次在
序列化工具选择上，应该选择更高效的序列化工具来降低字节数组大小。 编码
优化。Redis 对外提供了 string,list,hash,set,zet 等类型，但是 Redis 内部针对不同
类型存在编码的概念，所谓编码就是具体使用哪种底层数据结构来实现。编码不
同 将 直 接 影 响 数 据 的 内 存 占 用 和 读 写 效 率 。 可 参 考 文 章 ：
https://cloud.tencent.com/developer/article/1162213 
60. 如果现在有个读超高并发的系统，用 Redis 来抗住大部分读请求，你会怎么设计？ 
如果是读高并发的话，先看读并发的数量级是多少，因为 Redis 单机的读 QPS 在
万级，每秒几万没问题，使用一主多从+哨兵集群的缓存架构来承载每秒 10W+
的读并发，主从复制，读写分离。 
使用哨兵集群主要是提高缓存架构的可用性，解决单点故障问题。主库负责写，
多个从库负责读，支持水平扩容，根据读请求的 QPS 来决定加多少个 Redis 从实
例。如果读并发继续增加的话，只需要增加 Redis 从实例就行了。 
如果需要缓存 1T+的数据，选择 Redis cluster 模式，每个主节点存一部分数据，
假设一个 master 存 32G，那只需要 n*32G>=1T，n 个这样的 master 节点就可以
支持 1T+的海量数据的存储了。 
Redis 单主的瓶颈不在于读写的并发，而在于内存容量，即使是一主多从也是不
能解决该问题，因为一主多从架构下，多个 slave 的数据和 master 的完全一样。
假如 master 是 10G 那 slave 也只能存 10G 数据。所以数据量受单主的影响。 而
这个时候又需要缓存海量数据，那就必须得有多主了，并且多个主保存的数据还
不能一样。Redis 官方给出的 Redis cluster 模式完美的解决了这个问题。 
9. MQ 
为什么使用 MQ？ 
使用 MQ 的场景很多，主要有三个：解耦、异步、削峰。 
 
解耦：假设现在，日志不光要插入到数据库里，还要在硬盘中增加文件类型的日
志，同时，一些关键日志还要通过邮件的方式发送给指定的人。那么，如果按照
原来的逻辑，A 可能就需要在原来的代码上做扩展，除了 B 服务，还要加上日志
文件的存储和日志邮件的发送。但是，如果你使用了 MQ，那么，A 服务是不需
要做更改的，它还是将消息放到 MQ 中即可，其它的服务，无论是原来的 B 服
务还是新增的日志文件存储服务或日志邮件发送服务，都直接从 MQ 中获取消
息并处理即可。这就是解耦，它的好处是提高系统灵活性，扩展性。 
 
异步：可以将一些非核心流程，如日志，短信，邮件等，通过 MQ 的方式异步去
处理。这样做的好处是缩短主流程的响应时间，提升用户体验。互联网类企业对
用户的直接操作，一般要求每个请求在 200ms 以内完成。对于一个系统调用多
个系统，不使用 MQ 的情况下，它执行完返回的耗时是调用完所有系统所需时
间的总和；使用 MQ 进行优化后，执行的耗时则是执行主系统的耗时加上发送
数据到消息队列的耗时，大幅度提升系统性能和用户体验。 
 
削峰：MQ 的本质就是业务的排队。所以，面对突然到来的高并发，MQ 也可以
不用慌忙，先排好队，不要着急，一个一个来。削峰的好处就是避免高并发压垮
系统的关键组件，如某个核心服务或数据库等。MySQL 每秒最高并发请求在 
2000 左右，用户访问量高峰期的时候涌入的大量请求，会将 MySQL 打死，然
后系统就挂掉，但过了高峰期，请求量可能远低于 2000，这种情况去增加服务
器就不值得，如果使用 MQ 的情况，将用户的请求全部放到 MQ 中，让系统去
消费用户的请求，不要超过系统所能承受的最大请求数量，保证系统不会再高峰
期挂掉，高峰期过后系统还是按照最大请求数量处理完请求。 
下面附场景解释： 
解耦 
场景：A 系统发送数据到 BCD 三个系统，通过接口调用发送。如果 E 系统也
要这个数据呢？那如果 C 系统现在不需要了呢？A 系统负责人几乎崩溃...... 
在这个场景中，A 系统跟其它各种乱七八糟的系统严重耦合，A 系统产生一条
比较关键的数据，很多系统都需要 A 系统将这个数据发送过来。A 系统要时时
刻刻考虑 BCDE 四个系统如果挂了该咋办？要不要重发，要不要把消息存起来？
头发都白了啊！ 
如果使用 MQ，A 系统产生一条数据，发送到 MQ 里面去，哪个系统需要数据
自己去 MQ 里面消费。如果新系统需要数据，直接从 MQ 里消费即可；如果某
个系统不需要这条数据了，就取消对 MQ 消息的消费即可。这样下来，A 系统
压根儿不需要去考虑要给谁发送数据，不需要维护这个代码，也不需要考虑人家
是否调用成功、失败超时等情况。 
总结：通过一个 MQ，Pub/Sub 发布订阅消息这么一个模型，A 系统就跟其它系
统彻底解耦了。 
异步 
场景：A 系统接收一个请求，需要在自己本地写库，还需要在 BCD 三个系统写
库，自己本地写库要 3ms，BCD 三个系统分别写库要 300ms、450ms、200ms。
最终请求总延时是 3 + 300 + 450 + 200 = 953ms，接近 1s，用户感觉搞个什么东
西，慢死了慢死了。用户通过浏览器发起请求，等待个 1s，这几乎是不可接受
的。 
一般互联网类的企业，对于用户直接的操作，一般要求是每个请求都必须在 200 
ms 以内完成，对用户几乎是无感知的。 
如果使用 MQ，那么 A 系统连续发送 3 条消息到 MQ 队列中，假如耗时 5ms，
A 系统从接受一个请求到返回响应给用户，总时长是 3 + 5 = 8ms，对于用户而
言，其实感觉上就是点个按钮，8ms 以后就直接返回了。 
削峰 
场景：每天 0:00 到 12:00，A 系统风平浪静，每秒并发请求数量就 50 个。结
果每次一到 12:00 ~ 13:00 ，每秒并发请求数量突然会暴增到 5k+ 条。但是系统
是直接基于 MySQL 的，大量的请求涌入 MySQL，每秒钟对 MySQL 执行约 
5k 条 SQL。 
使用 MQ，每秒 5k 个请求写入 MQ，A 系统每秒钟最多处理 2k 个请求，因
为 MySQL 每秒钟最多处理 2k 个。A 系统从 MQ 中慢慢拉取请求，每秒钟就
拉取 2k 个请求，不要超过自己每秒能处理的最大请求数量就 ok，这样下来，
哪怕是高峰期的时候，A 系统也绝对不会挂掉。而 MQ 每秒钟 5k 个请求进来，
就 2k 个请求出去，结果就导致在中午高峰期（1 个小时），可能有几十万甚至
几百万的请求积压在 MQ 中。 
这个短暂的高峰期积压是 ok 的，因为高峰期过了之后，每秒钟就 50 个请求进 
MQ，但是 A 系统依然会按照每秒 2k 个请求的速度在处理。所以说，只要高峰
期一过，A 系统就会快速将积压的消息给解决掉。 
消息队列的缺点 
1、 系统可用性降低 
系统引入的外部依赖越多，越容易挂掉。MQ 挂掉，所关联的系统 都会无法提
供服务。 
2、 系统复杂度提高 
加入了消息队列，要多考虑很多方面的问题，比如：一致性问题、如何保证消息
不被重复消费、如何保证消息可靠性传输等。因此，需要考虑的东西更多，复杂
性增大。 
3、 一致性问题 
A 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，
要是 BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了，
这就数据不一致了。 
Kafka、ActiveMQ、RabbitMQ、RocketMQ 有什么优缺点？ 
特性 
ActiveMQ 
RabbitMQ 
RocketMQ 
Kafka 
开发语
言 
java 
erlang 
java 
scala 
单机吞
吐量 
万
级
，
比 
RocketMQ
、
Kafka 低一个数
量级 
同 ActiveMQ 
10 万级，支撑高吞吐 
10 万级，高吞
数据类的系统
据计算、日志
topic 
数量对
吞吐量
的影响 
 
 
topic 可以达到几百/几千
的级别，吞吐量会有较小
幅 度 的 下 降 ， 这 是 
RocketMQ 的一大优势，在
同等机器下，可以支撑大
量的 topic 
topic 从几十到
吞吐量会大幅
机 器 下 ， K
topic 数量不要
支撑大规模的
加更多的机器
时效性 
ms 级 
微 秒 级 ， 这 是 
RabbitMQ 的 一
大特点，延迟最
低 
ms 级 
延迟在 ms 级
可用性 
高，基于主从架
构实现高可用 
同 ActiveMQ 
非常高，分布式架构 
非常高，分布
个副本，少数
丢失数据，不
特性 
ActiveMQ 
RabbitMQ 
RocketMQ 
Kafka 
消息可
靠性 
有较低的概率丢
失数据 
基本不丢 
经过参数优化配置，可以
做到 0 丢失 
同 RocketMQ
功能支
持 
MQ 领域的功能
极其完备 
基 于  erlang 开
发，并发能力很
强，性能极好，延
时很低 
MQ 功能较为完善，还是
分布式的，扩展性好 
功能较为简单
的 MQ 功能
的实时计算以
大规模使用 
社区活
跃度 
低 
很高 
一般 
很高 
 
中小型公司，技术实力较为一般，技术挑战不是特别高，用 RabbitMQ 是不错的
选择； 
 
大型公司，基础架构研发实力较强，用 RocketMQ 是很好的选择。 
 
大数据领域的实时计算、日志采集等场景，用 是业内标准的，几乎是全世界这
个领域的事实性规范。 
RabbitMQ 
RabbitMQ 是什么？ 
RabbitMQ 是实现了高级消息队列协议（AMQP）的开源消息代理软件（亦称面
向消息的中间件）。RabbitMQ 服务器是用 Erlang 语言编写的，而群集和故障转
移是构建在开放电信平台框架上的。所有主要的编程语言均有与代理接口通讯的
客户端库。 
RabbitMQ 特点? 
可靠性: RabbitMQ 使用一些机制来保证可靠性， 如持久化、传输确认及发布确
认等。 
灵活的路由 : 在消息进入队列之前，通过交换器来路由消息。对于典型的路由
功能， RabbitMQ 己经提供了一些内置的交换器来实现。针对更复杂的路由功
能，可以将多个 交换器绑定在一起， 也可以通过插件机制来实现自己的交换器。 
扩展性: 多个 RabbitMQ 节点可以组成一个集群，也可以根据实际业务情况动态
地扩展集群中节点。 
高可用性: 队列可以在集群中的机器上设置镜像，使得在部分节点出现问题的情
况下队 列仍然可用。 
多种协议: RabbitMQ 除了原生支持 AMQP 协议，还支持 STOMP， MQTT 等多
种消息 中间件协议。 
多语言客户端: RabbitMQ 几乎支持所有常用语言，比如 Java、 Python、 Ruby、 
PHP、C#、JavaScript 等。 
管理界面 : RabbitMQ 提供了一个易用的用户界面，使得用户可以监控和管理消
息、集 群中的节点等。 
令插件机制: RabbitMQ 提供了许多插件 ， 以实现从多方面进行扩展，当然也
可以编写自 己的插件。 
AMQP 是什么? 
RabbitMQ 就 是  AMQP 协 议 的  Erlang 的 实 现 ( 当 然  RabbitMQ 还 支 持 
STOMP2、 MQTT3 等协议 ) AMQP 的模型架构 和 RabbitMQ 的模型架构是一
样的，生产者将消息发送给交换器，交换器和队列绑定 。 
RabbitMQ 中的交换器、交换器类型、队列、绑定、路由键等都是遵循的 AMQP 
协议中相 应的概念。目前 RabbitMQ 最新版本默认支持的是 AMQP 0-9-1。 
AMQP 的 3 层协议？ 
Module Layer:协议最高层，主要定义了一些客户端调用的命令，客户端可以用这
些命令实现自己的业务逻辑。 
Session Layer:中间层，主要负责客户端命令发送给服务器，再将服务端应答返回
客户端，提供可靠性同步机制和错误处理。 
TransportLayer:最底层，主要传输二进制数据流，提供帧的处理、信道服用、错
误检测和数据表示等。 
说说 Broker 服务节点、Queue 队列、Exchange 交换器？ 
 
Broker 可以看做 RabbitMQ 的服务节点。一般请下一个 Broker 可以看做一个
RabbitMQ 服务器。 
 
Queue:RabbitMQ 的内部对象，用于存储消息。多个消费者可以订阅同一队列，
这时队列中的消息会被平摊（轮询）给多个消费者进行处理。 
 
Exchange:生产者将消息发送到交换器，由交换器将消息路由到一个或者多个队
列中。当路由不到时，或返回给生产者或直接丢弃。 
如何保证消息的可靠性？ 
分三点： 
 
生产者到 RabbitMQ：事务机制和 Confirm 机制，注意：事务机制和 Confirm 机
制是互斥的，两者不能共存，会导致 RabbitMQ 报错。 
 
RabbitMQ 自身：持久化、集群、普通模式、镜像模式。 
 
RabbitMQ 到消费者：basicAck 机制、死信队列、消息补偿机制。 
生产者消息运转的流程？ 
1. Producer 先连接到 Broker,建立连接 Connection,开启一个信道(Channel)。 
2. Producer 声明一个交换器并设置好相关属性。 
3. Producer 声明一个队列并设置好相关属性。 
4. Producer 通过路由键将交换器和队列绑定起来。 
5. Producer 发送消息到 Broker,其中包含路由键、交换器等信息。 
6. 相应的交换器根据接收到的路由键查找匹配的队列。 
7. 如果找到，将消息存入对应的队列，如果没有找到，会根据生产者的配置丢弃或
者退回给生产者。 
8. 关闭信道。 
9. 管理连接。 
import pika 
 
###  21.1. <a name='rabbitMQ'></a>rabbitMQ 
connection=pika.BlockingConnection(pika.ConnectionParameters('localhost')) 
channel=connection.channel()       #生成管道，在管道里跑不同的队列 
 
###  21.2. <a name='queue'></a>queue 
channel.queue_declare(queue='hello1') 
##  22. <a name='RabbitMQamessagecanneverbesentdirectlytothequeueitalwaysneedstogothrough'></a>RabbitMQ a message can never be sent directly to the queue,it always needs to go through 
an exchange. 
 
#向队列里发数据 
channel.basic_publish(exchange='',      #先把数据发给 exchange 交换器,exchage
再发给相应队列 
                      routing_key='hello1', #向"hello'队列发数据 
                      body='HelloWorld!!')  #发的消息 
 
print("[x]Sent'HelloWorld!'") 
connection.close() 
消费者接收消息过程？ 
1. Producer 先连接到 Broker,建立连接 Connection,开启一个信道(Channel)。 
2. 向 Broker 请求消费响应的队列中消息，可能会设置响应的回调函数。 
3. 等待 Broker 回应并投递相应队列中的消息，接收消息。 
4. 消费者确认收到的消息,ack。 
5. RabbitMq 从队列中删除已经确定的消息。 
6. 关闭信道。 
7. 关闭连接。 
import pika 
 
connection=pika.BlockingConnection(pika.ConnectionParameters('localhost')) 
channel=connection.channel() 
# You may ask why we declare the queue again ‒ we have already declared it in our previous 
code. 
# We could avoid that if we were sure that the queue already exists. For example if send.py 
program 
# was run before. But we're not yet sure which program to run first. In such cases it's a good 
# practice to repeat declaring the queue in both programs. 
channel.queue_declare(queue='hello1')#声明队列，保证程序不出错 
 
def callback(ch,method,properties,body): 
    print("-->ch",ch) 
    print("-->method",method) 
    print("-->properties",properties) 
    print("[x] Received %r" % body)         #一条消息被一个消费者接收后，该消息
就从队列删除 
 
channel.basic_consume(callback,              #回调函数，一接收到消息就调用回调函
数 
                      queue='hello1', 
                      no_ack=False)    #消费完毕后向服务端发送一个确认，默认
为 False 
 
print('[*] Waiting for messages.To exit press CTRL+C') 
channel.start_consuming() 
生产者如何将消息可靠投递到 RabbitMQ？ 
1. Client 发送消息给 MQ 
2. MQ 将消息持久化后，发送 Ack 消息给 Client，此处有可能因为网络问题导致 Ack
消息无法发送到 Client，那么 Client 在等待超时后，会重传消息； 
3. Client 收到 Ack 消息后，认为消息已经投递成功。 
RabbitMQ 如何将消息可靠投递到消费者？ 
1. MQ 将消息 push 给 Client（或 Client 来 pull 消息） 
2. Client 得到消息并做完业务逻辑 
3. Client 发送 Ack 消息给 MQ，通知 MQ 删除该消息，此处有可能因为网络问题导
致 Ack 失败，那么 Client 会重复消息，这里就引出消费幂等的问题； 
4. MQ 将已消费的消息删除。 
如何保证 RabbitMQ 消息队列的高可用? 
RabbitMQ 有三种模式：单机模式，普通集群模式，镜像集群模式。 
单机模式：就是 demo 级别的，一般就是你本地启动了玩玩儿的，没人生产用单
机模式 
普通集群模式：意思就是在多台机器上启动多个 RabbitMQ 实例，每个机器启动
一个。 
镜像集群模式：这种模式，才是所谓的 RabbitMQ 的高可用模式，跟普通集群模
式不一样的是，你创建的 queue，无论元数据(元数据指 RabbitMQ 的配置数据)还
是 queue 里的消息都会存在于多个实例上，然后每次你写消息到 queue 的时候，
都会自动把消息到多个实例的 queue 里进行消息同步。 
AMQP 模型的几大组件？  
交换器 (Exchange)：消息代理服务器中用于把消息路由到队列的组件。  
队列 (Queue)：用来存储消息的数据结构，位于硬盘或内存中。  
绑定 (Binding)：一套规则，告知交换器消息应该将消息投递给哪个队列。  
生产者 Producer?  
消息生产者，就是投递消息的一方。 消息一般包含两个部分：消息体（payload)
和标签(Label)。  
消费者 Consumer?  
消费消息，也就是接收消息的一方。 消费者连接到 RabbitMQ 服务器，并订阅
到队列上。消费消息时只消费消息体，丢弃标签。  
Broker 服务节点？ 
Broker 可以看做 RabbitMQ 的服务节点。一般请下一个 Broker 可以看做一个
RabbitMQ 服务器。  
Queue 队列？ 
Queue:RabbitMQ 的内部对象，用于存储消息。多个消费者可以订阅同一队列，
这时队列中的消息会被 平摊（轮询）给多个消费者进行处理。  
Exchange 交换器？  
Exchange:生产者将消息发送到交换器，有交换器将消息路由到一个或者多个队
列中。当路由不到时， 或返回给生产者或直接丢弃。  
RoutingKey 路由键？  
生产者将消息发送给交换器的时候，会指定一个 RoutingKey,用来指定这个消息
的路由规则，这个 RoutingKey 需要与交换器类型和绑定键(BindingKey)联合使
用才能最终生效。  
Binding 绑定？  
通过绑定将交换器和队列关联起来，一般会指定一个 BindingKey,这样 RabbitMq
就知道如何正确路由消 息到队列了。  
交换器 4 种类型？  
主要有以下 4 种。  
fanout: 把所有发送到该交换器的消息路由到所有与该交换器绑定的队列中。  
direct:把消息路由到 BindingKey 和 RoutingKey 完全匹配的队列中。  
topic: 匹 配 规 则 ：  RoutingKey 为 一 个  点 号 '.': 分 隔 的 字 符 串 。 比 如 : 
java.xiaoka.show BindingKey 和 RoutingKey 一样也是点号“.“分隔的字符串。 
BindingKey 可使用 * 和 # 用于做模糊匹配，*匹配一个单词，#匹配多个或者 0
个  
headers:不依赖路由键匹配规则路由消息。是根据发送消息内容中的 headers 属性
进行匹配。性能差， 基本用不到。  
如何保证消息不被重复消费?  
消息被重复消费，就是消费方多次接受到了同一条消息。根本原因就是，第一次
消费完之后，消费方给 MQ 确认已消费的反馈，MQ 没有成功接受。比如网络
原因、MQ 重启等。 所以 MQ 是无法保证消息不被重复消费的，只能业务系统
层面考虑。 不被重复消费的问题，就被转化为消息消费的幂等性的问题。幂等
性就是指一次和多次请求的结果一 致，多次请求不会产生副作用。 保证消息消
费的幂等性可以考虑下面的方式： 给消息生成全局 id，消费成功过的消息可以
直接丢弃 消息中保存业务数据的主键字段，结合业务系统需求场景进行处理，
避免多次插入、是否可以根据 主键多次更新而并不影响结果等  
如何保证消息不丢失？  
生产者丢失消息：如网络传输中丢失消息、MQ 发生异常未成功接收消息等情况。
解决办法：主流的 MQ 都有确认或事务机制，可以保证生产者将消息送达到 
MQ。如 RabbitMQ 就有事务模式和 confirm 模式。 MQ 丢失消息：MQ 成功
接收消息内部处理出错、宕机等情况。解决办法：开启 MQ 的持久化配置。 消
费者丢失消息：采用消息自动确认模式，消费者取到消息未处理挂掉了。解决办
法：改为手动确认模 式，消费者成功消费消息再确认。  
如何保证消息的顺序性？  
生产者保证消息入队的顺序。 MQ 本身是一种先进先出的数据接口，将同一类
消息，发到同一个 queue 中，保证出队是有序的。 避免多消费者并发消费同一
个 queue 中的消息。  
消息大量积压怎么解决？  
消息的积压来自于两方面：要么发送快了，要么消费变慢了。 单位时间发送的
消息增多，比如赶上大促或者抢购，短时间内不太可能优化消费端的代码来提升
消费性 能，唯一的办法是通过扩容消费端的实例数来提升总体的消费能力。严
重影响 QM 甚至整个系统时，可 以考虑临时启用多个消费者，并发接受消息，
持久化之后再单独处理，或者直接丢弃消息，回头让生产 者重新生产。 如果短
时间内没有服务器资源扩容，没办法的办法是将系统降级，通过关闭某些不重要
的业务，减少发 送的数据量，最低限度让系统还能正常运转，服务重要业务。 
监控发现，产生和消费消息的速度没什么变化，出现消息积压的情况，检查是有
消费失败反复消费的情 况。 监控发现，消费消息的速度变慢，检查消费实例，
日志中是否有大量消费错误、消费线程是否死锁、是 否卡在某些资源上。  
如何保证 MQ 的高可用?  
ActiveMQ： Master-Slave 部署方式主从热备，方式包括通过共享存储目录来实
现(shared filesystem MasterSlave)、通过共享数据库来实现(shared database Master-
Slave)、5.9 版本后新特性使用 ZooKeeper 协 调选择 master(Replicated LevelDB 
Store)。 Broker-Cluster 部署方式进行负载均衡。 RabbitMQ： 单机模式与普通
集群模式无法满足高可用，镜像集群模式指定多个节点复制 queue 中的消息做
到高可 用，但消息之间的同步网络性能开销较大。  
RocketMQ： 有多 master 多 slave 异步复制模式和多 master 多 slave 同步双
写模式支持集群部署模式。 Producer 随机选择 NameServer 集群中的其中一个
节点建立长连接，定期从 NameServer 获取 Topic 路由信息，并向提供 Topic 
服务的 Broker Master 建立长连接，且定时向 Master 发送心跳，只能将消 息发
送到 Broker master。 Consumer 同时与提供 Topic 服务的 Master、Slave 建立
长连接，从 Master、Slave 订阅消息都可以， 订阅规则由 Broker 配置决定。  
Kafka： 由多个 broker 组成，每个 broker 是一个节点；topic 可以划分为多个 
partition，每个 partition 可以 存在于不同的 broker 上，每个 partition 存放一部
分数据，这样每个 topic 的数据就分散存放在多个机 器上的。 replica 副本机制
保证每个 partition 的数据同步到其他节点，形成多 replica 副本；所有 replica 
副本会 选举一个 leader 与 Producer、Consumer 交互，其他 replica 就是 follower；
写入消息 leader 会把数 据同步到所有 follower，从 leader 读取消息。 每个 
partition 的所有 replica 分布在不同的机器上。某个 broker 宕机，它上面的 
partition 在其他节点 有副本，如果有 partition 的leader，会进行重新选举 leader。  
生产者消息运转？  
1、Producer 先连接到 Broker,建立连接 Connection,开启一个信道(Channel)。 2、
Producer 声明一个交换器并设置好相关属性。 3、Producer 声明一个队列并设置
好相关属性。 4、Producer 通过路由键将交换器和队列绑定起来。 5、Producer
发送消息到 Broker,其中包含路由键、交换器等信息。 6、相应的交换器根据接收
到的路由键查找匹配的队列。 7、如果找到，将消息存入对应的队列，如果没有
找到，会根据生产者的配置丢弃或者退回给生产者。 8、关闭信道。 9、管理连
接。  
消费者接收消息过程？  
1、Producer 先连接到 Broker,建立连接 Connection,开启一个信道(Channel)。 2、
向 Broker 请求消费响应的队列中消息，可能会设置响应的回调函数。 3、等待
Broker 回应并投递相应队列中的消息，接收消息。 4、消费者确认收到的消息,ack。 
5、RabbitMq 从队列中删除已经确定的消息。 6、关闭信道。 7、关闭连接。  
交换器无法根据自身类型和路由键找到符合条件队列时，有哪些 处理？ 
mandatory ：true 返回消息给生产者。 mandatory: false 直接丢弃。  
死信队列？  
DLX，全称为 Dead-Letter-Exchange，死信交换器，死信邮箱。当消息在一个队
列中变成死信 (dead message) 之后，它能被重新被发送到另一个交换器中，这个
交换器就是 DLX，绑定 DLX 的队列就称之 为死信队列。  
导致的死信的几种原因？  
消息被拒（Basic.Reject /Basic.Nack) 且 requeue = false。 消息 TTL 过期。 队列
满了，无法再添加。 
延迟队列？  
存储对应的延迟消息，指当消息被发送以后，并不想让消费者立刻拿到消息，而
是等待特定时间后，消 费者才能拿到这个消息进行消费。  
优先级队列？  
优先级高的队列会先被消费。 可以通过 x-max-priority 参数来实现。 当消费速
度大于生产速度且 Broker 没有堆积的情况下，优先级显得没有意义。  
事务机制？  
RabbitMQ 客户端中与事务机制相关的方法有三个: 1、channel.txSelect 用于将当
前的信道设置成事务模式。 2、channel . txCommit 用于提交事务 。 3、channel . 
txRollback 用于事务回滚,如果在事务提交执行之前由于 RabbitMQ 异常崩溃或
者其他原因 抛出异常,通过 txRollback 来回滚。  
发送确认机制？  
生产者把信道设置为 confirm 确认模式,设置后，所有再改信道发布的消息都会被
指定一个唯一的 ID，一 旦消息被投递到所有匹配的队列之后，RabbitMQ 就会
发送一个确认（Basic.Ack)给生产者（包含消息的 唯一 ID)，这样生产者就知道
消息到达对应的目的地了。  
消费者获取消息的方式？  
推  
拉 
消费者某些原因无法处理当前接受的消息如何来拒绝？  
channel .basicNack channel .basicReject  
消息传输保证层级？  
At most once:最多一次。消息可能会丢失，单不会重复传输。 At least once：最
少一次。消息觉不会丢失，但可能会重复传输。 Exactly once: 恰好一次，每条
消息肯定仅传输一次。  
vhost?  
每一个 RabbitMQ 服务器都能创建虚拟的消息服务器，也叫虚拟主机(virtual host)，
简称 vhost。 默认为“/”。 
集群中的节点类型？  
内存节点：ram,将变更写入内存。 磁盘节点：disc,磁盘写入操作。 RabbitMQ 要
求最少有一个磁盘节点。 队列结构？  
通常由以下两部分组成？ rabbit_amqqueue_process :负责协议相关的消息处理，
即接收生产者发布的消息、向消费者交付 消息、处理消息的确认(包括生产端的 
confirm 和消费端的 ack) 等。 backing_queue:是消息存储的具体形式和引擎，并
向 rabbit amqqueue process 提供相关的接口 以供调用。  
RabbitMQ 中消息可能有的几种状态? alpha: 消息内容(包括消息体、属性和 
headers) 和消息索引都存储在内存中 。 beta: 消息内容保存在磁盘中，消息索
引保存在内存中。 gamma: 消息内容保存在磁盘中，消息索引在磁盘和内存中都
有 。 delta: 消息内容和索引都在磁盘中 。 
 
 
 
10. Nginx 
简述一下什么是 Nginx，它有什么优势和功能？  
Nginx 是一个 web 服务器和方向代理服务器，用于 HTTP、HTTPS、SMTP、POP3
和 IMAP 协议。因它的稳定性、丰富的功能集、示例配置文件和低系统资源的消
耗而闻名。  
Nginx---Ngine X，是一款免费的、自由的、开源的、高性能 HTTP 服务器和反向
代理服务器； 也是一个 IMAP、POP3、SMTP 代理服务器；Nginx 以其高性能、
稳定性、丰富的功能、简单的 配置和低资源消耗而闻名。 也就是说 Nginx 本身
就可以托管网站（类似于 Tomcat 一样），进行 Http 服务处理，也可以作为反向
代理服务器 、负载均衡器和 HTTP 缓存。 Nginx 解决了服务器的 C10K（就是
在一秒之内连接客户端的数目为 10k 即 1 万）问题。它的设计不像传统的服务器
那样使用线程处理请求，而是一个更加高级的机制—事件驱动机制，是一 种异
步事件驱动结构。  
优点：  
（1）更快 这表现在两个方面：一方面，在正常情况下，单次请求会得到更快的
响应；另一方面， 在高峰期（如有数以万计的并发请求），Nginx 可以比其他
Web 服务器更快地响应请求。  
（2）高扩展性，跨平台 Nginx 的设计极具扩展性，它完全是由多个不同功能、
不同层次、不同类型 且耦合度极低的模块组成。因此，当对某一个模块修复 Bug
或进行升级时，可以专注于模块自身， 无须在意其他。而且在 HTTP 模块中，
还设计了 HTTP 过滤器模块：一个正常的 HTTP 模块在处理完请 求后，会有一
串 HTTP 过滤器模块对请求的结果进行再处理。这样，当我们开发一个新的 HTTP
模块 时，不但可以使用诸如 HTTP 核心模块、events 模块、log 模块等不同层次
或者不同类型的模块，还 可以原封不动地复用大量已有的 HTTP 过滤器模块。
这种低耦合度的优秀设计，造就了 Nginx 庞大的 第三方模块，当然，公开的第
三方模块也如官方发布的模块一样容易使用。 Nginx 的模块都是嵌入 到二进制
文件中执行的，无论官方发布的模块还是第三方模块都是如此。这使得第三方模
块一样具 备极其优秀的性能，充分利用 Nginx 的高并发特性，因此，许多高流
量的网站都倾向于开发符合自 己业务特性的定制模块。  
（3）高可靠性：用于反向代理，宕机的概率微乎其微 高可靠性是我们选择 Nginx
的最基本条件，因 为 Nginx 的可靠性是大家有目共睹的，很多家高流量网站都
在核心服务器上大规模使用 Nginx。 Nginx 的高可靠性来自于其核心框架代码的
优秀设计、模块设计的简单性；另外，官方提供的常用 模块都非常稳定，每个
worker 进程相对独立，master 进程在 1 个 worker 进程出错时可以快速“拉 起”新
的 worker 子进程提供服务。  
（4）低内存消耗 一般情况下，10000 个非活跃的 HTTP Keep-Alive 连接在 Nginx
中仅消耗 2.5MB 的内存，这是 Nginx 支持高并发连接的基础。  
（5）单机支持 10 万以上的并发连接 这是一个非常重要的特性！随着互联网的
迅猛发展和互联网用 户数量的成倍增长，各大公司、网站都需要应付海量并发
请求，一个能够在峰值期顶住 10 万以上并 发请求的 Server，无疑会得到大家的
青睐。理论上，Nginx 支持的并发连接上限取决于内存，10 万 远未封顶。当然，
能够及时地处理更多的并发请求，是与业务特点紧密相关的。  
（6）热部署 master 管理进程与 worker 工作进程的分离设计，使得 Nginx 能够
提供热部署功能，即 可以在 7×24 小时不间断服务的前提下，升级 Nginx 的可执
行文件。当然，它也支持不停止服务就更 新配置项、更换日志文件等功能。  
（7）最自由的 BSD 许可协议 这是 Nginx 可以快速发展的强大动力。BSD 许可
协议不只是允许用户免 费使用 Nginx，它还允许用户在自己的项目中直接使用
或修改 Nginx 源码，然后发布。这吸引了无数 开发者继续为 Nginx 贡献自己的
智慧。 以上 7 个特点当然不是 Nginx 的全部，拥有无数个官方功能模 块、第三
方功能模块使得 Nginx 能够满足绝大部分应用场景，这些功能模块间可以叠加以
实现更加 强大、复杂的功能，有些模块还支持 Nginx 与 Perl、Lua 等脚本语言集
成工作，大大提高了开发效 率。这些特点促使用户在寻找一个 Web 服务器时更
多考虑 Nginx。 选择 Nginx 的核心理由还是它能 在支持高并发请求的同时保持
高效的服务。 
Nginx 是如何处理一个 HTTP 请求的呢？  
Nginx 是一个高性能的 Web 服务器，能够同时处理大量的并发请求。它结合多
进程机制和异步机制 ，异步机制使用的是异步非阻塞方式 ，接下来就给大家介
绍一下 Nginx 的多线程机制和异步非阻塞机制 。  
1、多进程机制 服务器每当收到一个客户端时，就有服务器主进程（ master 
process ）生成一个子进程（ worker process ）出来和客户端建立连接进行交互，
直到连接断开，该子进程就结束了。 使用进程的好处是各个进程之间相互独立，
不需要加锁，减少了使用锁对性能造成影响，同时降低编程的复杂度，降低开发
成本。其次，采用独立的进程，可以让进程互相之间不会影响 ，如果一个进程
发生异常退出时，其它进程正常工作， master 进程则很快启动新的 worker 进
程，确保服务 不会中断，从而将风险降到最低。 缺点是操作系统生成一个子进
程需要进行 内存复制等操作，在资源和时间上会产生一定的开销。当 有大量请
求时，会导致系统性能下降 。  
2、异步非阻塞机制 每个工作进程 使用 异步非阻塞方式 ，可以处理 多个客户
端请求 。 当某个 工作进程 接收到客户端的请求以后，调用 IO 进行处理，如
果不能立即得到结果，就去 处理 其他请求 （即为 非阻塞 ）；而 客户端 在
此期间也 无需等待响应 ，可以去处理其他事情（即为 异 步 ）。 当 IO 返回
时，就会通知此 工作进程 ；该进程得到通知，暂时 挂起 当前处理的事务去 响
应客户端 请求 。  
列举一些 Nginx 的特性  
1. Nginx 服务器的特性包括： 2. 反向代理/L7 负载均衡器 3. 嵌入式 Perl 解释器 
4. 动态二进制升级 5. 可用于重新编写 URL，具有非常好的 PCRE 支持  
请列举 Nginx 和 Apache 之间的不同点  
 
在 Nginx 中，如何使用未定义的服务器名称来阻止处理请求？  
只需将请求删除的服务器就可以定义为：  
Server{  
 
 
listen 80;  
 
 
server_name "";  
 
 
return 444;  
}  
这里，服务器名被保留为一个空字符串，它将在没有“主机”头字段的情况下匹配
请求，而一个特殊 的 Nginx 的非标准代码 444 被返回，从而终止连接。 一般推
荐 worker 进程数与 CPU 内核数一致，这样一来不存在大量的子进程生成和管
理任务，避免 了进程之间竞争 CPU 资源和进程切换的开销。而且 Nginx 为了
更好的利用 多核特性 ，提供了 CPU 亲缘性的绑定选项，我们可以将某一个进
程绑定在某一个核上，这样就不会因为进程的切换带来 Cache 的失效。 对于每
个请求，有且只有一个工作进程 对其处理。首先，每个 worker 进程都是从 
master 进程 fork 过来。在 master 进程里面，先建立好需要 listen 的 socket
（listenfd） 之后，然后再 fork 出 多个 worker 进程。 所有 worker 进程的 
listenfd 会在新连接到来时变得可读 ，为保证只有一个进程处理该连接，所有 
worker 进程在注册 listenfd 读事件前抢占 accept_mutex ，抢到互斥锁的那个进
程注册 listenfd 读 事件 ，在读事件里调用 accept 接受该连接。 当一个 worker 
进程在 accept 这个连接之后，就开始读取请求、解析请求、处理请求，产生数
据 后，再返回给客户端 ，最后才断开连接。这样一个完整的请求就是这样的了。
我们可以看到，一个 请求，完全由 worker 进程来处理，而且只在一个 worker 
进程中处理。 在 Nginx 服务器的运行过程中， 主进程和工作进程 需要进程交
互。交互依赖于 Socket 实现的管道 来实现。  
请解释 Nginx 服务器上的 Master 和 Worker 进程分别是什么?  
主程序 Master process 启动后，通过一个 for 循环来 接收 和 处理外部信号 ； 
主进程通过 fork() 函数产生 worker 子进程 ，每个子进程执行一个 for 循环来
实现 Nginx 服务器 对事件的接收和处理 。  
请解释代理中的正向代理和反向代理  
首先，代理服务器一般指局域网内部的机器通过代理服务器发送请求到互联网上
的服务器，代理服 务器一般作用在客户端。例如：GoAgent 翻墙软件。我们的
客户端在进行翻墙操作的时候，我们使 用的正是正向代理，通过正向代理的方
式，在我们的客户端运行一个软件，将我们的 HTTP 请求转发 到其他不同的服
务器端，实现请求的分发。 反向代理服务器作用在服务器端，它在服务器端接
收客户端的请求，然后将请求分发给具体的服务 器进行处理，然后再将服务器
的相应结果反馈给客户端。Nginx 就是一个反向代理服务器软件。 从上图可以
看出：客户端必须设置正向代理服务器，当然前提是要知道正向代理服务器的 IP
地址， 还有代理程序的端口。 反向代理正好与正向代理相反，对于客户端而言
代理服务器就像是原始服务 器，并且客户端不需要进行任何特别的设置。客户
端向反向代理的命名空间（name-space）中的 内容发送普通请求，接着反向代理
将判断向何处（原始服务器）转交请求，并将获得的内容返回给 客户端。  
解释 Nginx 用途  
Nginx 服务器的最佳用法是在网络上部署动态 HTTP 内容，使用 SCGI、WSGI 应
用程序服务器、用于 脚本的 FastCGI 处理程序。它还可以作为负载均衡器。 
11. 分布式 
集群和分布式区别 
集群：同一业务部署在多台服务器上，提供可用性和并发度； 
分布式：不同的业务模块部署在不同的服务器上或者同一业务模块拆分多个字业
务，部署在不同的服务器上； 
分布式幂等性如何设计 
在高并发场景的架构里，幂等性是必须得保证的。比如说支付功能，用户发起支
付，如果后台没有做幂等校验，刚好用户手抖多点了几下，于是后台就可能多次
收到同一个订单请求，不做幂等很容易就让用户重复支付了，这样用户是肯定不
能忍的。 
解决方案： 
1，查询和删除不在幂等讨论范围，查询肯定没有幂等的说，删除：第一次删除
成功后，后面来删除直接返回 0，也是返回成功。  
2，建唯一索引：唯一索引或唯一组合索引来防止新增数据存在脏数据 （当表存
在唯一索引，并发时新增异常时，再查询一次就可以了，数据应该已经存在了，
返回结果即可）。  
3，token 机制：由于重复点击或者网络重发，或者 nginx 重发等情况会导致数据
被重复提交。前端在数据提交前要向后端服务的申请 token，token 放到 Redis 
或 JVM 内存，token 有效时间。提交后后台校验 token，同时删除 token，生成
新的 token 返回。redis 要用删除操作来判断 token，删除成功代表 token 校验通
过，如果用 select+delete 来校验 token，存在并发问题，不建议使用。 
4，悲观锁 悲观锁使用时一般伴随事务一起使用，数据锁定时间可能会很长，根
据实际情况选用（另外还要考虑 id 是否为主键，如果 id 不是主键或者不是 
InnoDB 存储引擎，那么就会出现锁全表）。  
select id ,name from table_# where id='##' for update; 
5，乐观锁，给数据库表增加一个 version 字段，可以通过这个字段来判断是否已
经被修改了  
update table_xxx set name=#name#,version=version+1 where version=#version# 
6，分布式锁，比如 Redis 、 Zookeeper 的分布式锁。单号为 key，然后给 Key
设置有效期（防止支付失败后，锁一直不释放），来一个请求使用订单号生成一
把锁，业务代码执行完成后再释放锁。  
7，保底方案，先查询是否存在此单，不存在进行支付，存在就直接返回支付结
果。 
 
负载均衡的理解 
集群化部署的架构，也就是把一个软件应用同事部署在多个服务器上。 
负载均衡机制的核心目的是让客户端的请求合理均匀的分发到多台目标服务器，
由于请求被多个节点分发，使得服务端的性能得到有效提升。 
1. 基于 DNS 实现负载均衡； 
客户端用户请求 www.xxx.com，DNS 服务器进行域名的解析，返回域名对应的
IP 地址，然后请求实际的 IP 地址； 
DNS 服务器上去针对某个域名做多个 IP 映射，可以随机分配个 IP 地址进行访
问，这样就可以实现目标服务器集群的请求分发；DNS 服务器也可以根据不同
的地域分配就近机房的 IP，比如一个来自长沙的客户端请求，可能会得到一个湖
南范围内最近的机房的 IP，在这个模式下可以实现就近原则的一个请求分发，这
样可以缩短通信距离，从而提升网站的访问速率。 
2. 基于硬件的负载均衡 
可以理解为一个网络设备，类似于物理交换机，性能比较好，每秒可以处理百万
级的请求；支持多种负载均衡的算法，可以非常灵活的去配置不同的负载均衡策
略；具备防火墙等安全功能； 
3. 基于软件的负载均衡 
通过一些开源软件或者商业软件来完成负载均衡的功能。常用的有 Nginx、LVS、
Haproxy； 
负载均衡是作用在网络通信上来实现请求的分发；由于网络架构分成 7 层模型，
根据这一特性，负载均衡根据作用范围分为二层负载、三层负载、四层负载、七
层负载； 
二层负载：根据 MAC 地址来实现请求的分发，一般采用虚拟 MAC 的方式实现；
当服务器收到请求后，可以通过动态分配后的服务器的 MAC 地址来进行响应。 
三层负载：基于 IP 层负载，一般通过虚拟 IP 来实现；外部的请求去访问虚拟 IP
时，服务器收到请求，根据后端的实际 IP 地址进行转发； 
四层负载：将用户请求转发给后端，通过修改请求报文中的目标地址和源地址进
行转发。 
七层负载：基于应用层的负载。服务器端可以根据 http 协议中的请求的报文信息
来决定将请求分发到哪个服务器；比如 cookie，消息体以及 Requestheader 等等； 
 
说说你对分布式事务的了解  
分布式事务是企业集成中的一个技术难点，也是每一个分布式系统架构中都会涉
及到的一个东西， 特别是在微服务架构中，几乎可以说是无法避免。  
首先要搞清楚：ACID、CAP、BASE 理论。  
ACID 指数据库事务正确执行的四个基本要素：  
1. 原子性（Atomicity）  
2. 一致性（Consistency）  
3. 隔离性（Isolation）  
4. 持久性（Durability）  
CAP 
CAP 原则又称 CAP 定理，指的是在一个分布式系统中，一致性（Consistency）、
可用性 （Availability）、分区容忍性（Partition tolerance）。CAP 原则指的是，
这三个要素最多只能同时实现两点，不可能三者兼顾。 一致性：在分布式系统
中的所有数据备份，在同一时刻是否同样的值。 可用性：在集群中一部分节点
故障后，集群整体是否还能响应客户端的读写请求。 分区容忍性：以实际效果
而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数 据一致性，
就意味着发生了分区的情况，必须就当前操作在 C 和 A 之间做出选择。 
BASE 理论  
BASE 理论是对 CAP 中的一致性和可用性进行一个权衡的结果，理论的核心思
想就是：我们无法做到 强一致，但每个应用都可以根据自身的业务特点，采用
适当的方式来使系统达到最终一致性。 Basically Available（基本可用） Soft state
（软状态） Eventually consistent（最终一致性） 
你知道哪些分布式事务解决方案？ 
我目前知道的有五种：  
1. 两阶段提交(2PC)  
2. 三阶段提交(3PC)  
3. 补偿事务(TCC=Try-Confirm-Cancel)  
4. 本地消息队列表(MQ)  
5. Sagas 事务模型(最终一致性) 说完上面五种，面试官一般都会继续问下面这几个
问题（可能就问一两个，也可能全部问）。 
什么是二阶段提交？  
两阶段提交 2PC 是分布式事务中最强大的事务类型之一，两段提交就是分两个
阶段提交： 第一阶段询问各个事务数据源是否准备好。 第二阶段才真正将数据
提交给事务数据源。 为了保证该事务可以满足 ACID，就要引入一个协调者
（Cooradinator）。其他的节点被称为参与者 （Participant）。协调者负责调度参
与者的行为，并最终决定这些参与者是否要把事务进行提交。 处理流程如下： 
 
阶段一 a) 协调者向所有参与者发送事务内容，询问是否可以提交事务，并等待
答复。 b) 各参与者执行事务操作，将 undo 和 redo 信息记入事务日志中（但
不提交事务）。 c) 如参与者执行成功，给协调者反馈 yes，否则反馈 no。  
阶段二 如果协调者收到了参与者的失败消息或者超时，直接给每个参与者发送
回滚(rollback)消息；否则， 发送提交(commit)消息。两种情况处理如下： 情况
1：当所有参与者均反馈 yes，提交事务 a) 协调者向所有参与者发出正式提交事
务的请求（即 commit 请求）。 b) 参与者执行 commit 请求，并释放整个事务
期间占用的资源。 c) 各参与者向协调者反馈 ack(应答)完成的消息。 d) 协调者
收到所有参与者反馈的 ack 消息后，即完成事务提交。 情况 2：当有一个参与
者反馈 no，回滚事务 a) 协调者向所有参与者发出回滚请求（即 rollback 请求）。 
b) 参与者使用阶段 1 中的 undo 信息执行回滚操作，并释放整个事务期间占用
的资源。 c) 各参与者向协调者反馈 ack 完成的消息。 d) 协调者收到所有参与
者反馈的 ack 消息后，即完成事务。  
问题 1) 性能问题：所有参与者在事务提交阶段处于同步阻塞状态，占用系统资
源，容易导致性能瓶颈。 2) 可靠性问题：如果协调者存在单点故障问题，或出
现故障，提供者将一直处于锁定状态。 3) 数据一致性问题：在阶段 2 中，如果
出现协调者和参与者都挂了的情况，有可能导致数据不一 致。 优点：尽量保证
了数据的强一致，适合对数据强一致要求很高的关键领域。（其实也不能 100%
保证 强一致）。 缺点：实现复杂，牺牲了可用性，对性能影响较大，不适合高
并发高性能场景。 
什么是补偿事务？  
TCC （Try Confirm Cancel）是服务化的二阶段编程模型，采用的补偿机制： TCC 
其实就是采用的补偿机制，其核心思想是：针对每个操作，都要注册一个与其对
应的确认和补 偿（撤销）操作。 它分为三个步骤： Try 阶段主要是对业务系
统做检测及资源预留。 Confirm 阶段主要是对业务系统做确认提交，Try 阶段执
行成功并开始执行 Confirm 阶段时，默 认 Confirm 阶段是不会出错的。即：只
要 Try 成功，Confirm 一定成功。 Cancel 阶段主要是在业务执行错误，需要回
滚的状态下执行的业务取消，预留资源释放。 举个例子，假入你要向 老田 转
账，思路大概是： 我们有一个本地方法，里面依次调用步骤： 1、 首先在 Try 
阶段，要先调用远程接口把 你 和 老田 的钱给冻结起来。 2、在 Confirm 阶
段，执行远 程调用的转账的操作，转账成功进行解冻。 3、如果第 2 步执行成
功，那么转账成功，如果第二步执 行失败，则调用远程冻结接口对应的解冻方
法 (Cancel)。 优点： 性能提升：具体业务来实现控制资源锁的粒度变小，不会
锁定整个资源。 数据最终一致性：基于 Confirm 和 Cancel 的幂等性，保证事
务最终完成确认或者取消，保证数据 的一致性。 可靠性：解决了 XA 协议的
协调者单点故障问题，由主业务方发起并控制整个业务活动，业务活动 管理器
也变成多点，引入集群。 缺点：TCC 的 Try、Confirm 和 Cancel 操作功能要
按具体业务来实现，业务耦合度较高，提高了开发成本。 
 
 
分布式缓存 
缓存理解：第一次请求时将一些耗时操作的结果暂存，以后遇到相同的请求，直
接返回暂存的数据，缓存不存在时，调用回调函数获取源数据； 
缓存中最简单的莫过于存储在内存中的键值对缓存了。说到键值对，很容易想到
的是字典(dict)类型，Go 语言中称之为 map。那直接创建一个 map，每次有新数
据就往 map 中插入不就好了，这不就是键值对缓存么？这样做有什么问题呢？ 
1）内存不够了怎么办？ 
那就随机删掉几条数据好了。随机删掉好呢？还是按照时间顺序好呢？或者是有
没有其他更好的淘汰策略呢？不同数据的访问频率是不一样的，优先删除访问频
率低的数据是不是更好呢？数据的访问频率可能随着时间变化，那优先删除最近
最少访问的数据可能是一个更好的选择。我们需要实现一个合理的淘汰策略。 
2）并发写入冲突了怎么办？ 
对缓存的访问，一般不可能是串行的。map 是没有并发保护的，应对并发的场景，
修改操作(包括新增，更新和删除)需要加锁。 
3）单机性能不够怎么办？ 
单台计算机的资源是有限的，计算、存储等都是有限的。随着业务量和访问量的
增加，单台机器很容易遇到瓶颈。如果利用多台计算机的资源，并行处理提高性
能就要缓存应用能够支持分布式，这称为水平扩展(scale horizontally)。与水平扩
展相对应的是垂直扩展(scale vertically)，即通过增加单个节点的计算、存储、带
宽等，来提高系统的性能，硬件的成本和性能并非呈线性关系，大部分情况下，
分布式系统是一个更优的选择。 
 
缓存淘汰算法 
1.1 FIFO(First In First Out) 
先进先出，也就是淘汰缓存中最老(最早添加)的记录。FIFO 认为，最早添加的记
录，其不再被使用的可能性比刚添加的可能性大。这种算法的实现也非常简单，
创建一个队列，新增记录添加到队尾，每次内存不够时，淘汰队首。但是很多场
景下，部分记录虽然是最早添加但也最常被访问，而不得不因为呆的时间太长而
被淘汰。这类数据会被频繁地添加进缓存，又被淘汰出去，导致缓存命中率降低。 
1.2 LFU(Least Frequently Used) 
最少使用，也就是淘汰缓存中访问频率最低的记录。LFU 认为，如果数据过去被
访问多次，那么将来被访问的频率也更高。LFU 的实现需要维护一个按照访问次
数排序的队列，每次访问，访问次数加 1，队列重新排序，淘汰时选择访问次数
最少的即可。LFU 算法的命中率是比较高的，但缺点也非常明显，维护每个记录
的访问次数，对内存的消耗是很高的；另外，如果数据的访问模式发生变化，LFU
需要较长的时间去适应，也就是说 LFU 算法受历史数据的影响比较大。例如某
个数据历史上访问次数奇高，但在某个时间点之后几乎不再被访问，但因为历史
访问次数过高，而迟迟不能被淘汰。 
1.3 LRU(Least Recently Used) 
最近最少使用，相对于仅考虑时间因素的 FIFO 和仅考虑访问频率 LFU，LRU 算
法可以认为是相对平衡的一种淘汰算法。LRU 认为，如果数据最近被访问过，
那么将来被访问的概率也会更高。LRU 算法的实现非常简单，维护一个队列，如
果某条记录被访问了，则移动到队尾，那么队首则是最近最少访问的数据，淘汰
该条记录即可。 
LRU 算法最核心的 2 个数据结构 
字典(map)，存储键和值的映射关系。这样根据某个键(key)查找对应的值(value)
的复杂是 O(1)，在字典中插入一条记录的复杂度也是 O(1)。 
双向链表(double linked list)实现的队列。将所有的值放到双向链表中，这样，当
访问到某个值时，将其移动到队尾的复杂度是 O(1)，在队尾新增一条记录以及删
除一条记录的复杂度均为 O(1)。 
 
一致性哈希 
对于分布式缓存来说，当一个节点接收到请求，如果该节点并没有存储缓存值，
那么它面临的难题是，从谁那获取数据？自己，还是节点 1, 2, 3, 4… 。假设包
括自己在内一共有 10 个节点，当一个节点接收到请求时，随机选择一个节点，
由该节点从数据源获取数据。 
假设第一次随机选取了节点 1 ，节点 1 从数据源获取到数据的同时缓存该数据；
那第二次，只有 1/10 的可能性再次选择节点 1, 有 9/10 的概率选择了其他节
点，如果选择了其他节点，就意味着需要再一次从数据源获取数据，一般来说，
这个操作是很耗时的。这样做，一是缓存效率低，二是各个节点上存储着相同的
数据，浪费了大量的存储空间。 
那有什么办法，对于给定的 key，每一次都选择同一个节点呢？使用 hash 算法
也能够做到这一点。那把 key 的每一个字符的 ASCII 码加起来，再除以 10 取
余数可以吗？当然可以，这可以认为是自定义的 hash 算法。 
节点数量变化了怎么办？ 
简单求取 Hash 值解决了缓存性能的问题，但是没有考虑节点数量变化的场
景。假设，移除了其中一台节点，只剩下 9 个，那么之前 hash(key) % 10 变
成了 hash(key) % 9，也就意味着几乎缓存值对应的节点都发生了改变。即几
乎所有的缓存值都失效了。节点在接收到对应的请求时，均需要重新去数据源
获取数据，容易引起 缓存雪崩。 
缓存雪崩：缓存在同一时刻全部失效，造成瞬时 DB 请求量大、压力骤增，引起雪崩。常因
为缓存服务器宕机，或缓存设置了相同的过期时间引起。 
算法原理 
一致性哈希算法将 key 映射到 2^32 的空间中，将这个数字首尾相连，形成
一个环。 
 
计算节点/机器(通常使用节点的名称、编号和 IP 地址)的哈希值，放置在环
上。 
 
计算 key 的哈希值，放置在环上，顺时针寻找到的第一个节点，就是应选取的
节点/机器。 
 
环上有 peer2，peer4，peer6 三个节点，key11，key2，key27 均映射到 peer2，
key23 映射到 peer4。此时，如果新增节点/机器 peer8，假设它新增位置如图所
示，那么只有 key27 从 peer2 调整到 peer8，其余的映射均没有发生改变。 
也就是说，一致性哈希算法，在新增/删除节点时，只需要重新定位该节点附近的
一小部分数据，而不需要重新定位所有的节点，这就解决了上述的问题。 
数据倾斜问题 
如果服务器的节点过少，容易引起 key 的倾斜。例如上面例子中的 peer2，
peer4，peer6 分布在环的上半部分，下半部分是空的。那么映射到环下半部
分的 key 都会被分配给 peer2，key 过度向 peer2 倾斜，缓存节点间负载
不均。 
为了解决这个问题，引入了虚拟节点的概念，一个真实节点对应多个虚拟节
点。 
假设 1 个真实节点对应 3 个虚拟节点，那么 peer1 对应的虚拟节点是 
peer1-1、 peer1-2、 peer1-3（通常以添加编号的方式实现），其余节点也
以相同的方式操作。 
 
第一步，计算虚拟节点的 Hash 值，放置在环上。 
 
第二步，计算 key 的 Hash 值，在环上顺时针寻找到应选取的虚拟节点，例如是 
peer2-1，那么就对应真实节点 peer2。 
虚拟节点扩充了节点的数量，解决了节点较少的情况下数据容易倾斜的问题。
而且代价非常小，只需要增加一个字典(map)维护真实节点与虚拟节点的映射
关系即可。 
缓存雪崩、缓存击穿与缓存穿透 
缓存雪崩：缓存在同一时刻全部失效，造成瞬时 DB 请求量大、压力骤增，引起
雪崩。缓存雪崩通常因为缓存服务器宕机、缓存的 key 设置了相同的过期时间
等引起。 
缓存击穿：一个存在的 key，在缓存过期的一刻，同时有大量的请求，这些请求
都会击穿到 DB ，造成瞬时 DB 请求量大、压力骤增。 
缓存穿透：查询一个不存在的数据，因为不存在则不会写到缓存中，所以每次都
会去请求 DB，如果瞬间流量过大，穿透到 DB，导致宕机。 
 
 
 
protobuf 
protobuf 即 Protocol Buffers，Google 开发的一种数据描述语言，是一种轻便高
效的结构化数据存储格式，与语言、平台无关，可扩展可序列化。protobuf 以二
进制方式存储，占用空间小。 
protobuf 广泛地应用于远程过程调用(RPC) 的二进制传输，使用 protobuf 的目
的非常简单，为了获得更高的性能。传输前使用 protobuf 编码，接收方再进行
解码，可以显著地降低二进制传输的大小。另外一方面，protobuf 可非常适合传
输结构化数据，便于通信字段的扩展。 
使用 protobuf 一般分为以下 2 步： 
1. 按照 protobuf 的语法，在 .proto 文件中定义数据结构，并使用 protoc 生成 
Go 代码（.proto 文件是跨平台的，还可以生成 C、Java 等其他源码文件）。 
2. 在项目代码中引用生成的 Go 代码。 
 
 
10. Django 
Django 的请求生命周期 
1、当用户在浏览器中输入 url 时浏览器会生成请求头和请求体发送给服务端请
求头和请求体中会包含浏览器的动作（action）这个动作通常为 get 或者 post 提
现在 url 之中； 
2、url 经过 Django 中的 wsgi，就是 socket 服务端，用于接收用户请求并将请求
进行初次封装，然后将请求交给 web 框架； 
3、再经过 django 的中间件，中间件处理请求，帮助我们对请求进行校验或在请
求对象中添加其他相关数据，例如：csrf、request.session； 
4、最后 url 到路由的映射表一条一条进行匹配一旦其中的某一条匹配成功就执
行视图函数，后面的路由就不在继续匹配了； 
5、视图函数中进行业务逻辑的处理，可能涉及到：orm、view 视图将数据渲染到
template 模板，视图函数执行完毕之后，会把客户端想要的数据返回给 dispatch
方法，由 dispatch 方法把数据返回给客户端； 
6、中间件处理响应； 
7、wsgi，将响应的内容发送给浏览器； 
8、客户端浏览器接受到返回的数据，经过渲染后显示给用户. 
 
Flask 和 Django 路由映射的区别？ 
在 django 中，路由是浏览器访问服务器时，先访问的项目中的 url，再由项目中
的 url 找到应用中 url，这些 url 是放在一个列表里，遵从从前往后匹配的规则。
在 flask 中，路由是通过装饰器给每个视图函数提供的，而且根据请求方式的不
同可以一个 url 用于不同的作用。 
 
 
 
 
 
django rest framework 规范 
1url 后尽量用名词，因为 rest frame 是面向资源的编程，因此 url 命名时能体现出
资源 2method 的不同，实现增删改查的操作 3 版本号，因为有版本的更替，为
了体现出版本的过度，因此在发请求的时候，要体现出版本号 4 返回值，与以往
只返回 json 不同,rest api 规范要加上状态码。 5 域名，由于前后端分离，因此要
处理跨域问题，解决方法:jsonp,cors 6 过滤，通过 url 传参的形式传递搜索条件
（列如：指定返回的记录数量，指定分页等） 
 
 
 
简述 Django 的 orm 
ORM，全拼 Object-Relation Mapping，意为对象-关系映射 
实现了数据模型与数据库的解耦，通过简单的配置就可以轻松更换数据库，而不
需要修改代码只需要面向对象编程,orm 操作本质上会根据对接的数据库引擎，
翻译成对应的 sql 语句,所有使用 Django 开发的项目无需关心程序底层使用的是
MySQL、Oracle、sqlite....，如果数据库迁移，只需要更换 Django 的数据库引擎
即可。 
 
 
 
 
django 中当一个用户登录 A 应用服务器（进入登录状态），然
后下次请求被 nginx 代理到 B 应用服务器会出现什么影响？ 
如果用户在 A 应用服务器登陆的 session 数据没有共享到 B 应用服务器，纳米之
前的登录状态就没有了。 
 
 
 
跨域请求问题 django 怎么解决的（原理） 
启用中间件 post 请求 验证码 表单中添加{%csrf_token%}标签 
 
 
 
请解释或描述一下 Django 的架构 
对于 Django 框架遵循 MVC 设计，并且有一个专有名词：MVT M 全拼为 Model，
与 MVC 中的 M 功能相同，负责数据处理，内嵌了 ORM 框架 V 全拼为 View，
与 MVC 中的 C 功能相同，接收 HttpRequest，业务处理，返回 HttpResponse T 全
拼为 Template，与 MVC 中的 V 功能相同，负责封装构造要返回的 html，内嵌了
模板引擎 
 
 
 
django 对数据查询结果排序怎么做，降序怎么做，查询大于某个
字段怎么做 
排序使用 order_by() 降序需要在排序字段名前加- 查询字段大于某个值：使用
filter(字段名_gt=值) 
 
 
 
说一下 Django，MIDDLEWARES 中间件的作用？ 
中间件是介于 request 与 response 处理之间的一道处理过程，相对比较轻量级，
并且在全局上改变 django 的输入与输出。 
 
 
 
你对 Django 的认识？ 
Django 是走大而全的方向，它最出名的是其全自动化的管理后台：只需要使用起
ORM，做简单的对象定义，它就能自动生成数据库结构、以及全功能的管理后
台。 Django 内置的 ORM 跟框架内的其他模块耦合程度高。 
应用程序必须使用 Django 内置的 ORM，否则就不能享受到框架内提供的种种基
于其 ORM 的便利；理论上可以切换掉其 ORM 模块，但这就相当于要把装修完
毕的房子拆除重新装修，倒不如一开始就去毛胚房做全新的装修。 
Django 的卖点是超高的开发效率，其性能扩展有限；采用 Django 的项目，在流
量达到一定规模后，都需要对其进行重构，才能满足性能的要求。 
Django 适用的是中小型的网站，或者是作为大型网站快速实现产品雏形的工具。 
Django 模板的设计哲学是彻底的将代码、样式分离； Django 从根本上杜绝在模
板中进行编码、处理数据的可能。 
 
 
Django 重定向你是如何实现的？用的什么状态码？ 
使用 HttpResponseRedirect redirect 和 reverse 状态码：302,301 
 
 
   
 
 
 
ngnix 的正向代理与反向代理 
正向代理 是一个位于客户端和原始服务器(origin server)之间的服务器，为了从
原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然
后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端必须要进行
一些特别的设置才能使用正向代理。 反向代理正好相反，对于客户端而言它就
像是原始服务器，并且客户端不需要进行任何特别的设置。客户端向反向代理的
命名空间中的内容发送普通请求，接着反向代理将判断向何处(原始服务器)转交
请求，并将获得的内容返回给客户端，就像这些内容原本就是它自己的一样。 
 
 
 
Django 本身提供了 runserver，为什么不能用来部署？ 
runserver 方法是调试 Django 时经常用到的运行方式，它使用 Django 自带的 
WSGI Server 运行，主要在测试和开发中使用，并且 runserver 开启的方式也是
单进程 。 uWSGI 是一个 Web 服务器，它实现了 WSGI 协议、uwsgi、http 等
协议。注意 uwsgi 是一种通信协议，而 uWSGI 是实现 uwsgi 协议和 WSGI 协
议的 Web 服务器。uWSGI 具有超快的性能、低内存占用和多 app 管理等优点，
并且搭配着 Nginx 就是一个生产环境了，能够将用户访问请求与应用 app 隔离
开，实现真正的部署。相比来讲，支持的并发量更高，方便管理多进程，发挥多
核的优势，提升性能。 
 
 
 
 
 
11. flask 
1. 第一个 flask 程序 
from flask import Flask 
# 创建 flask 应用对象，flask 以这个模块所在的总目录为总目录，默认这个目录中的 static
为静态目录，templates 为模板目录 
app = Flask(__name__) 
 
@app.route("/") 
def index(): 
    """定义的视图函数""" 
    return "hello flask!" 
 
 
if __name__ == '__main__': 
    app.run() 
2. 配置参数 
# 配置参数使用方式 
1. 使用配置文件 
app.config.from_pyfile('config.cfg') 
 
2. 使用对象配置参数 
class Config(object): 
    DEBUG = True 
    par = 'python' 
app.config.from_obj(Config) 
 
# 读取配置参数 
1. 直接从全局参数 app 的 config 字典中取值 
app.config.get('par') 
2. 从 current_app 中取值(from flask import current_app) 
current_app.config.get('par') 
3. 启动 flask 程序 
app.run()   # 默认 host 为 127.0.0.1    端口号为 5000 
app.run(host="192.168.10.10", port=5001)   # 自定义监控 ip 和端口 
app.run(host="0.0.0。0", port=5001)   # 默认 127.0.0.1 和主机 ip 都可以访问 
app.run(host="0.0.0。0", port=5001， debug=True)   # 打开 debug 
4. 视图函数的路由规则 
app.url_map     # 可以查看整个 flask 中的路由信息 
# methods 参数限定访问方式，默认是 get/options/head 
@app.route('hello', methods=['POST']) 
def hello(): 
    print('hello') 
 
# 使用 url_for 函数，通过视图函数的名字找到视图对应的 url 路径 
@app.route('/login') 
def login(): 
    url = url_for('hello') 
return redirect(url) 
 
 
 
 
 
 
 
route 装饰器，其实就是将 rule 字符串跟视图函数进行了绑定，通过 add_url_rule()实现
了绑定； 
源代码： 
def route(): 
def decorator(f: t.Callable) -> t.Callable: 
        endpoint = options.pop("endpoint", None) 
        self.add_url_rule(rule, endpoint, f, **options) 
        return f 
    return decorator 
 
 
 
5. 请求参数 
上传文件 
abort(400) 
abort 函数可以立即终止视图函数的执行，并可以返回给前端指定的信息； 
6. 设置响应信息 
# 1. 使用元组，返回自定义的响应信息 
响应体、状态码、响应头 
@app.route('/index') 
def index(): 
    return 'index page', '400', [('city': 'shenzhen', 'age': 20)] 
 
# 2. 使用 make_response 构造响应信息 
resp = make_response('index page') 
resp.status = '400' 
resp.headers['age'] = 20 
7. cookie 
# 设置 cookie，默认有效期是临时 cookie，浏览器关闭就失效 
resp = make_response('success') 
resp.set_cookie('age', 20, max-age=3600)   # max-age 设置有效期的参数，单位为 s 
 
# 获取 cookie 
request.cookies.get('age') 
 
# 删除 cookie 
resp = make_response('success') 
resp.delete_cookie('age')    # 不是让浏览器及时删除此 cookie，而是设置有效期过期 
 
 
  
8. session 
# 一般而言：cookie 中保存 session_id，session_id 以及 session 数据维护在数据库中； 
flask 并不是将 session 保存到数据库，而是保存到 cookie 中，通过 SECRET_KEY 将
session 内容混淆；也就是说 cookie 中保存的是混乱后的 session 数据； 
 
app.config['SECRET_KEY'] = 'sdgdfgfgs454' 
 
@app.route('/login') 
def login(): 
    # 设置 session 数据 
    session['name'] = 'python' 
    session['age'] = '20' 
 
@app.route('/index') 
def index(): 
    # 获取 session 数据 
    name = session.get('name') 
    return 'hello %s' % name 
 
 
session 存储 
1. session 保存到程序内容中；也就是 python 模块中的全局变量中；session 跨机器时会
导致问题；也就是当负载均衡到某台机器时，session 修改了此程序的全局变量，但是下
次请求获取 session 时，可能会返回到前端数据还是未修改前的； 
2. session 保存到数据库中（mysql/redis）； 
 
当浏览器禁用 cookie 时，session_id 在页面中传导；类似这种 index?session_id=1 
     
9. flask-sqlalchemy 
flask 数据库设置 
app = create_app() 
1. 配置数据库连接路径 
mysql+pymysql://user:password@host:port/database 
app.config['SQLALCHEMY_DATABASE_URL'] 
= 
'mysql://root:mysql@127.0.0.1:3306/test3' 
class Config(object): 
    SQLALCHEMY_DATABASE_URL = 'mysql://root:mysql@127.0.0.1:3306/test3' 
    SQLALCHEMY_TRACK_MODIFICATIONS = True   # 设置 sqlalchemy 自动跟踪
数据库 
2. 创建包 ext 
在__init__.py 文件中添加 
app.config.from_object(Config) 
db = SQLAlchemy(app)   # 创建数据库 sqlalchemy 工具对象，必须跟 app 关联 
3. 配置 migrate 
migrate = Migrate(app=app, db=db) 
manager = Manager(app=app) 
manager.add_command(‘db’, MigrateCommand) 
 
4. 创建模型类 
其实就是一个类，继承 db.Model 
5. 使用命令 
在 app.py 中导入模型类 
在终端使用命令 python app.py db init，产生文件夹 migrations 
执行命令 python app.py migrate，自动生成 revision 文件； 
执行命令 python app.py upgrade，就是执行 revision 中的 upgrade 函数； 
 
 
 
数据库查询 
and_  # 并且 
or_  # 或者 
not_ # 取反 
User.query.all()  # 所有 
User.query.get(pk) # 一个 
 
User.query.filter(User.username.in_([‘’, ‘’, ‘’])) 
User.query.filter(User.username == ‘zhangsan’).all() 
User.query.filter(or_(User.username.like(‘z%’), User.username.contains(‘i’)))).all() 
User.query.filter(User.username.contains(‘zs’)).order_by(-User.rdatetime).all() 
User.query.order_by(User.id).all() 
User.query.limit(2).all()  # 取前两条记录 
User.query.offset(2).limit(2).all() # 偏移 2 条取两条，也就是取第 3 条和第 4 条记录 
 
 
app 是实例化的 Flask APP 对象，通过 app.route() 来装饰视图函数。 
Flask-基础 Web 框架 
flask_restful- Flask 的扩展，增加了对快速构建 REST API 的支持 
flask_restful 文件中导入 Api、Resource 两个类，使用上面的 app 对象，构
建一个 api 对象， 
from flask_restful import Api,Resource 
 
app = Flask(__name__) 
 
###  22.1. <a name='ApiRESTfulApi'></a>实例化一个 Api 对象，用来创建、管理 RESTful Api 
api = Api(app) 
###  22.2. <a name='Resource'></a>创建一个 Resource 类的子类，用于定义资源路由 
class UserView(Resource): 
   """ 
  通过继承 Resource 来实现调用 GET/POST 等动作方法 
  """ 
   def get(self): 
       """ 
      GET 请求 
      :return: 
      """ 
 
 
   def post(self): 
       """ 
      POST 请求 
      :return: 
      """ 
       # 参数数据 
       json_data = request.get_json() 
###  22.3. <a name='Api'></a>最后，使用 Api 的实例对象，将上面定义的资源，利用路径，完全暴露出去 
 
 
 
 
 
10. flask 使用蓝图 
app.py 中 
app=Flak(__name__)  创建一个应用 
admin.py 引用 app route 直接报错 
这是由于 flask 使用传统的模块化行不通 
flask 内置模块化处理的类 Blueprint 
使用蓝图三个步骤 
a.创建蓝图对象 Blueprint(‘admin’, __name__) 
b.在这个蓝图对象上进行操作，注册路由，指定静态文件夹，注册模板过滤器等： 
c.在应用对象注册这个蓝图对象。 
 
11. sqlalchemy 使用 
connect 是 mysql 和用户、密码、host、端口、数据库名组合的字符串； 
engine = create_engine(connect) 
session_class = sessionmaker(bind=engine) 
session = session_class() 
models 里面定义类继承 declarative_base 对象，类中有表 id 和表中的字段 
增 session.add(table_name(**kwarg)) 
更新 
session.query(table_name).filter_by(id=id).update(param) 
删 
obj = session.query(table_name).filter_by(id=id) 
session.delete(obj) 
 
 
12. openstack 
网络虚拟化主要为计算存储虚拟化提供流量支撑的，通常包括接口虚拟化：虚拟
机的虚拟端口，转发虚拟化：虚拟交换机，网络虚拟化：vlan 或者 vxlan，网络
功能虚拟化：虚拟路由器，虚拟防火墙，虚拟 vpn，虚拟 lb 等。 
 
云计算 
按使用量付费的模式，提供按需便捷的网络访问，进入可配置的计算资源池。 
私有云----私有环境中，比如企业机房中建立的，运营商建立好租给某些企业的； 
公有云----放到互联网上，付费用户都可以使用。 
 
 
openstack 对数据中心的计算、存储和网络资源进行统一管理。 
openstack 创建虚机的流程 
创建虚机的请求流如下: 
1. 首先 Dashboard 或者 CLI 获取用户的登录信息，调用 keystone 的 REST API 去
做用户身份验证，keystone 对用户登录信息进行校验，然后产生 token 并发回，
用于后续的 REST 调用请求； 
2. Dashboard 或者 CLI 将创建虚机的 REST 请求中的‘launch instance’或‘nova-
boot’部分进行转换，然后调用 nova-api 的 REST 接口; 
3. nova-api 接到请求，向 keystone 发送 auth-token 校验和权限认证请求。Keystone 
校验 token，并将 auth headers 发回，它包括了 roles 和 permissions。nova-api 和 
nova-database 进行交互。nova-database 为新实例创建一个数据库条目。 
4. nova-api 向 nova-scheduler 发送 rpc.call 请求，期望它能通过附带的 host ID 
获取到数据库条目。nova-scheduler 从 queue 中获取到请求。 
5. nova-scheduler 和 nova-database 交互，获取集群中计算节点的信息和状态。
nova-scheduler 通过过滤（filtering）和称重（weighting）找到一个合适的计算节
点（host）。nova-scheduler 向找到的那个 host 上的 nova-compute 发送 rpc.cast 
请求去启动虚机。 
6. 目标 host 上的 nova-compute 从 queue 中获取到请求。nova-compute 向 
nova-conductor 发送 rpc.call 请求去获取待创建虚机的信息比如 host ID 和 
flavor 等。nova-conductor 从 queue 中获取到请求。nova-conductor 和 nova-
database 交互，nova-database 向 nova-conductor 返回虚机的信息。 
7. nova-conductor 向 nova-compute 发送 rpc.call，附带所请求的信息。nova-
compute 从 queue 中获取返回的数据。  
8. nova-compute 调用 glance-api 的 REST API，传入 auth-token，去根据镜像 ID 
获取镜像 URI，从镜像存储中下载（原文为 upload）镜像。glance-api 向 keystone 
校验 auth-token。nova-compute 获取 image 的元数据。 
9. nova-compute 调用 Neutron API ，传入 auth-token，去分配和配置网络，比如
虚机的 IP 地址。neutron-server 通过 keystone 校验 auth-token。nova-compute 获
得网络信息。 
10. nova-compute 调用 Cinder API，传入 auth-token，去将 volume 挂接到实例。
cinder-api 通过 keystone 校验 auth-token。nova-compute 获得块存储信息。 
nova-compute 为 hypervisor driver 产生数据，并调用 Hypersior 执行请求（通过 
libvirt 或者 api）。 
 
OpenStack 创建虚拟机的流程通常如下： 
1. 配置网络和存储：在 OpenStack 控制节点上，管理员需要配置网络和存储，以
便虚拟机可以使用这些资源。这些资源包括网络拓扑、IP 地址、存储池等。 
2. 创建虚拟机镜像：管理员需要创建虚拟机镜像，包括操作系统、软件和预装应
用程序等，这是创建虚拟机的基础。 
3. 创建云主机实例：用户可以通过 OpenStack 管理界面或 API 创建虚拟机。用
户需要选择虚拟机镜像、云主机实例类型、网络配置和安全组等。 
4. 启动云主机实例：一旦创建了云主机实例，OpenStack 就会将虚拟机镜像复制
到计算节点，并在计算节点上创建虚拟机实例。虚拟机实例启动后，OpenStack
会将 IP 地址、MAC 地址和其他网络配置信息等发送到虚拟机。 
5. 配置云主机实例：一旦虚拟机启动，用户可以登录虚拟机并配置操作系统和应
用程序。 
6. 关闭和删除云主机实例：当用户不再需要虚拟机实例时，可以将其关闭并从
OpenStack 中删除。 
需要注意的是，OpenStack 创建虚拟机的流程可能会因为不同的 OpenStack 版本
和配置而有所不同。上述流程仅作为参考。 
 
port 创建成功后的 dhcp 相关操作 
创建 VM 时，nova-compute 与 neutron 的 plugin 交互，在 neutron 的数据库中创
建 VM 所需的 port 信息。neutron 数据库中的 port 信息创建完成后，通知 neutron-
dhcp-agent 去将数据库中的 port 中的 ip 和 mac 信息加载到 dnsmasq 所需的配置
文件中(包括 host 和 addn_hosts 文件)。 
在 VM 启动时，广播 dhcp discover 请求，当 dnsmasq 进程的监听接口 ns-xxx 监
听到这种请求时，dnsmasq 进程将根据配置文件(host 和 leases 文件)中的内容去
判定是否有未分配的 ip 和 mac 为请求者进行提供。  
最终 VM 便真实的获取到与保存在数据库中的 ip 和 mac 信息。neutron-dhcp-agent
只是将所创建 VM 的 ip 和 mac 信息从数据库中获取到自己的配置文件中，然后
等到 VM 启动时，为它提供。因此 neutron-dhcp-agent 相当于在 VM 和数据库之
间起了个中间桥梁的作用。  
当 ports 表发生变化时，neutron-server 将通过 HTTP 请求的方式发送 event 事件
给 nova。 
 
每个网络 dhcp agent 会创建一个 dhcp 命名空间，并在其中创建虚拟网卡，每创
建一个子网就会创建一个 dhcp port，将这个 port 配置到这个虚拟网卡上。命名
空间内的 dnsmasq 进程监听 53 端口，当 network 创建一个 IP 会向 dhcp 的 host
文件中添加一条记录，当 port 绑定虚机时，就能通过 dhcp client 自动获取 IP。 
 
 
 
 
ovs 场景下东西南北向流量 
南北向流量：虚拟机连通外网； ovs 架构下，虚拟机网卡 tap 连接 Linux-bridge
网桥(qbr)，Linux- bridge 通过 qvb 和 qvo 连接集成网桥 br-int，每个 vxlan 网络下
会有对应的 dhcp 端口连接到 br-int 上，qvo 和 vxlan 网络是一对一关系，虚拟
router 有端口 qr 连接到 br-int 上，这样流量经过 br-int 到 router，之后到 br-ex 上
的端口 qg，br-ex 连接到宿主机网卡和互联网通信。router 的内部接口就是 br-int
上的 qr 口，外部网关就是 br-ex 上的 qg 口。  
 
东西向流量：虚拟机与虚拟机时间连通； br-int 下连接一样，这时候 br-int 通过
patch-tun 和 patch-int 连接 br-tun，br-tun 连接到宿主机租户网卡，br-tun 上 vxlan
口和对端 vxlan 口经过隧道连通，之后通过 br-tun 和 br-int 连接到对端虚拟机。 
br-tun 使用 Openflow 规则来处理 Van ID 和 Tunnel Id 的转换； 
 
qrouter 命名空间中有两个接口，qg 连接 br-ex，qr 连接 br-int； 
1．同一个 host 上同一个子网内虚机之间的通信过程 
br-int 是个虚拟的二层交换机，所以同一个 host 上的同一个子网内的虚机之间的
通信只是经过 br-int 桥，不需要经过 br-tun 桥； 
2. 不同主机上同一个子网内的虚机之间的通信过程 
1. 从一个 compute 节点的虚机 1 出发的 packet，经过 Linux bridge 到达 br-int，被打上 
VLAN ID Tag； 
2. 到达 br-tun，将 VLAN ID 转化为 Tunnel ID，从 Tunnel 发出，到达另一个 compute 节
点； 
3. 在另一个 compute 节点上经过相反的过程，到达右边的虚机 
3. 虚机访问外网 
1. Packet 离开虚机，经过 Linux bridge， 到达 br-int，打上 VLAN ID Tag； 
2. 达到 br-tun，将 VLAN ID 转化为 Tunnel ID； 
3. 从物理网卡进入 vxlan 通道； 
4. 从 vxlan 通道达到网络节点的网卡； 
5. 达到跟物理网卡相连的 br-tun，将 Tunnel ID 转化为 VLAN ID； 
6. 达到 br-int，再达到 router，router 的 NAT 表将 fixed IP 地址转化为 floatiing 
IP 地址，再被 route 到 br-ex； 
7. 从 br-ex 相连的物理网卡上出去到外网； 
外网 IP 访问虚机是个相反的过程。 
 
4. 虚机发送 DHCP 请求 
1. 虚机的 packet -> br-int -> br-tun -> GRE Tunnel -> eth2 ------>eth2->br-tun->br-
int->qDHCP 
2. qDHCP 返回其 fixed IP 地址，原路返回 
 
5. 不同 tenant 内虚机之间的通信 
Neutron Tenant 网络是为 tenant 中的虚机之间的通信。如果需要不同 tenant 内的
虚机之间通信，需要在两个 subnet 之间增加 Neutron 路由。 
 
 
Vmware 提供了三种网络工作模式 
bridged 桥接模式 
手工为虚机配置 IP 地址掩码并且和宿主机同一网段，使用桥接模式的虚机和宿
主机的关系就像连接到同一 hub 上的两台电脑。 
host- only 主机模式 
在此模式下，虚机的 IP 配置由 vmnet1 虚拟网络的 DHCP 服务器动态分配，但是
虚机和网内其他机器相隔离，虚机和宿主机可以通信。 
NAT 网络地址转化模式 
在虚拟系统中不用通过任何手动配置就直接访问互联网，只需要宿主机能访问互
联网即可。IP 由 vmnet8 虚拟网络的 DHCP 服务器提供，不能手动修改。 
 
vlan 
virtual local area network 
每个 vlan 对应一个广播域，不同 vlan 间的设备不能互通，只能通过路由器等三
层设备而互通。vlan tag 由交换机端口在数据帧进入交换机时添加，数据帧出交
换机时交换机会剥离其 tag。 
vlan id 取值范围是 1-4094 
 
 
vxlan 
virtual extensible local area network  
采用 L2 over L4(Mac in UDP)的报文封装模式，将二层报文用三层协议进行封装
可以实现二层网络在三层网络扩展，同时满足数据中心大二层虚拟迁移和多租户
的需求。 
1.同网段主机通信，报文查询 Mac 地址进行通信。但是虚拟机规模增加，网卡
Mac 地址增加，二层设备 Mac 地址表项 hold 不住。 
2.vlan 数量只有 4000 个左右，无法满足更多虚拟云计算服务租户隔离。 
3.虚机迁移 IP 和 Mac 参数不变，导致虚机只能限制在一个二层域中； 
 
vtep     
vxlan tunnel endpoints  vxlan 隧道端点 
VTEP 会将 VM 发出的原始报文封装成一个新的 UDP 报文，并使用物理网络的
IP 和 MAC 地址作为外层头，对网络中的其他设备只表现为封装后的参数。也就
是说，网络中的其他设备看不到 VM 发送的原始报文。 
如果服务器作为 VTEP，那从服务器发送到接入设备的报文便是经过封装后的报
文，这样，接入设备就不需要学习 VM 的 MAC 地址了，它只需要根据外层封装
的报文头负责基本的三层转发就可以了。因此，虚拟机规模就不会受网络设备表
项规格的限制了。 
如果网络设备作为 VTEP，它还是需要学习 VM 的 MAC 地址。但是，从对报文
进行封装的角度来说，网络设备的性能还是要比服务器强很多。 
 
vni 
vxlan network identifier   vxlan 网络标识 
一个 vni 代表一个租户，属于不同 vni 的虚拟机时间不能进行二层通信。 
VTEP 在对报文进行 VXLAN 封装时，给 VNI 分配了 24 比特的空间，这就意味
着 VXLAN 网络理论上支持多达 1600 万（即：224-1）的租户隔离。 
 
vxlan 隧道 
是用来传输经过 vxlan 封装的报文，它是建立在 vtep 之间的一条虚拟通道。 
在 IP 网络中，“明”里传输的是跨越三层网络的 UDP 报文，“暗”里却已经悄悄将
源 VM 的原始报文送达目的 VM。就好像在三层的网络之上，构建出了一个虚拟
的二层网络，而且只要 IP 网络路由可达，这个虚拟的二层网络想做多大就做多
大。 
 
VXLAN 部署方法 
VXLAN 网络设备主要有三种角色，分别是 VTEP(VXLAN Tunnel End Point)、
VXLAN 网关、VXLAN IP 网关，对于应用系统来说，只与这三种设备相关，而
与底层传统三层 IP 网络无关。 
 
VTEP、VXLAN 网关、VXLAN IP 网关、形态可以是虚拟交换机，也可以是物理
交换机。根据 VTEP、VXLAN 网关、VXLAN IP 网关是虚拟交换机还是物理交
换机，VXLAN 网络的部署方法主要分三种。 
(1) 第一种是 VTEP、VXLAN 网关、VXLAN IP 网关均通过安装在服务器上的软
件实现。 
(2) 第二种是 VTEP、VXLAN 网关、VXLAN IP 网关均由物理交换机承担，物理
服务器支持 SR-IOV 功能，使虚拟机通过 SR-IOV 技术直接与物理交换机相连，
虚拟机的流量在接入交换机上进行 VXLAN 报文的封装和解封装。 
(3)第三种是 VTEP 由安装在服务器上的软件实现，VXLAN 网关、VXLAN IP 网
关由物理交换机承担。 
对于第一种部署方法，由于所有 VXLAN 报文的封装解封装都通过软件实现，会
占用部分服务器资源，特别是 VXLAN IP 网关，当访问量大时，将会成为系统瓶
颈。对于第二种部署方法，由于需要通过一些特殊的要求或技术实现虚拟机与
VTEP 的对接，组网不够灵活。第三种部署方法通过安装在服务器上的软件实现
虚拟机的 VTEP，通过物理交换机实现物理服务器的 VTEP，通过专业的硬件交
换机实现 VXLAN IP 网关，从而可承载超大规模的流量转发，避免成为系统瓶
颈，第三种部署方法结合了第一种和第二种方法的优势，相对而言是目前最优的
部署方法。 
VxLAN 网络中，虚机之间的三种互访形式： 
相同 VXLAN 内 VM 之间互访： 
单播报文在 VTEP 处查找目的 MAC 地址，确定对应的 VTEP 主机 IP 地址 
根据目的和源 VTEP 主机 IP 地址封装 VXLAN 报文头后发送给 IP 核心网 
IP 核心内部根据路由转发该 UDP 报文给目的 VTEP 
目的 VTEP 解封装 VXLAN 报文头后按照目的 MAC 转发报文给目的 VM 
 
不同 VXLAN 内 VM 之间需要互访经过 VXLAN IP GW 完成， 
在 VXLAN IP GW 上匹配 VXLAN Maping 表项进行转发，报文封装模式同同一
VXLAN 内 VM 一致 
 
VXLAN VM 与 VLAN VM 之间互访，通过 VXLAN GW 来完成， 
VXLAN 报文先通过 VXLAN 内部转发模式对报文进行封装，目的 IP 为 VXLAN 
GW， 
在 VXLAN GW 把 VXLAN 报文解封装后，匹配二层转发表项进行转发，VLAN
到 VXLAN 的访问流程正好相反 
 
 
 
云计算 
云计算是一种资源的服务模式，该模式可以实现随时随地、便捷按需地从可配置
计算资源共享池中获取所需的资源（如网络、服务器、存储、应用及服务），资
源可以快速供应并释放，大大减少了资源管理工作开销。 
 
 
虚拟化 
硬件虚拟化主要通过一个叫 Hypervisor 的程序实现，根据 Hypervisor 的实现方式
和所处的位置，虚拟化分为 I 型虚拟化和 II 型虚拟化； 
 
 
TAP/TUN 是 linux 内核实现的一对虚拟网络设备，TAP 工作在二层，TUN 工作
在三层，linux 内核通过 TAP/TUN 设备向绑定该设备的用户空间程序发送数据。 
openstack 开发基础 
setup.cfg 
setup.py 就是调用 setuptools.setup()，setup()函数有大量的参数需要设置，包括项目的名
称，作者，版本等。setup.cfg 文件的出现就是将 setup()函数解脱出来，它使用 pbr 工具
去读取和过滤 setup.cfg 中的数据，并将其解析后的结果作为自己的参数。 
entry points 
entry points 可以简单理解为它通过 setuptools 注册的外部可以直接调用的接口。 
KVM 
Kernel-based Virtual Machine 
KVM 是一个虚拟机管理程序，它是基于虚拟化扩展的 x86 硬件，现己集成到 
linux 内核中，由标准的 linux 调度程序进行调度。它可以具备内存管理、 存储、
设备驱动及可伸缩性等特点。KVM 有一个内核模块 kvm.ko，用于管理虚拟 CPU
和内存。KVM 本身只关注虚拟机调度和内存管理这两个方面，IO 的虚拟化，比
如存储和网络设备交给 Linux 内核和 QUMU 实现。 
除了 KVM 虚拟化外，目前的虚拟化产品还有 Xen VMWare VirtualBox Hyper-V 
等。  
KVM 的管理工具 Libvirt 
Libvirt 是一套对平台虚拟化技术进行管理的管理工具和 Linux API 作为连接底
层多种虚拟机管理器（Hypervisor）与上层应用的中间适配层，它可以支持 KVM 
Xen QEMU VirtualBox 等多种虚拟机管理器。 
Libvirt 包含 3 个东西，后台 daemon 程序 libvirtd、API 库和命令行工具 virsh； 
libvirtd 是服务程序，接受和处理 API 请求； 
API 库使得其他人可以开发基于 Libvirt 的高级工具，比如 virt-manager，这个是
图形化的 KVM 管理工具，可以用来启动虚拟，对虚机进行各种管理操作； 
virsh 是常用的 KVM 命令行工具； 
 
 
RPC 
openstack 各组件之间的主要是通过 rest api 接口进行通信，而同一组件内部都基
于 AMQP 通信模型的 RPC 通信； 
AMQP 
生产者（Publisher）首先将消息（Message）发送到 Exchange 中， Exchange 可
以对接多个消息队列，根据不同的 Routing， 最终可以把消息分别发送到相应的
消息队列中。不同的消费者最终从各自对应的消息队列中获取消息进行消费。 
 
AMQP 中每种 Exchange 类型都实现 某种路由算法 在这些类型的 Exchange 中，
以下类型 Exchange 在 OpenStack 中比较常见： 
( 1) Direct Exchange 。这是一种默认的 Exchange ，它是基于路由键（ Routing 
Key)来路由消息的一种方式在这种类型 Exchange 中，只有消息中的 Routing 
Key 属性与消费者 routing_key 属性一致时，此消息才会被此消费者获取并处理。 
( 2) Fan-out Exchange 。这是类似于广播的消息分发方式，所有的消费者都可以
接收来自这种类型的 Exchange 消息并处理。  
( 3 ) Topic Exchange 。这 类型 Exchange 允许 Routing Key 表达式的形式进行
定义。在 这类 Routing Key 中允许使用 个特殊符号 “．” “＊”和“＃"，“*”表示
匹配任意字符，“＃”表示匹 配零个或多个字符。例如，“**.stock. ＃＂可以匹配
“usd.stock ”和“eur.stock.db ”这样的 Routing Key， 但是不能匹配“ stock. nasdaq 
这样的 Routing Key; 
 
openstack 通用设计思路 
1.每个 openstack 组件包含若干个服务，其中必有一个 API 服务负责接收客户请
求；对外提供统一接口，隐藏实现细节；运行多个 API 服务实例实现 API 的高
可用； 
2.对一个某个操作，如果有多个实体都能够完成任务，通常有个 scheduler 负责从
这些实体中挑选出一个最合适的来执行操作；调度服务只管分配任务，真正执行
任务的是 worker 工作服务； 
3.基于 Driver 的框架； 
4.messaging 服务； 
程序之间的调用通常分为两种：同步调用和异步调用； 
rpc.call----如 nova 中 api 直接调用 scheduler 的接口就是同步调用。api 发送给
scheduler 请求后，一直等待，直至 scheduler 调用 computer 完成任务，将结果返
回 api，api 才进行后面的任务。rpc.call 就是请求响应类型，一个请求发送出去以
后，需要等待响应，调用需要制定目标的服务节点； 
rpc.cast----api 通过 messaging 调用 scheduler 就是异步调用。API 发出请求后不需
要等待，直接返回，继续做后面的工作，scheduler 从 messaging 接收到请求后执
行调用操作，完成后将结果也通过 messaging 发送给 API。rpc.cast 就是请求响应
类型，一个请求发出去后，不需要等待响应。 
 
 
 
 
 
 
 
neutron 
neutron 核心组件提供了云平台中软件定义网络的功能，它负责管理虚拟网络组
件，包括networks，subnets，switchs和routers，同时提供网络服务，如loadbalancer，
Firewall 和 VPN。 
core api：对外提供管理 network/subnet/port 的 restful api； 
extension api：对外提供管理 lbaas，fwaas，router 等的 restful api； 
common service：认证和校验 api 请求； 
neutron core：neutron-server 的核心处理程序，通过调用相应的 plugin 处理请求； 
core plugin api：定义了 core plugin 的抽象功能集合，neutron core 通过该 api 调用
相应的 core plugin； 
extension plugin api：定义了 service plugin 的抽象功能集合，neutron core 通过该
api 调用相应的 service plugin； 
core plugin：实现 core plugin api，在数据库中实现 network/subnet/port 的状态，
负责调用相应的 agent 在 network provider 上执行相关操作，比如创建网络； 
service plugin：实现 extension plugin api，在数据库中实现 sg/router/lb 等资源的状
态，并负责调用相应的agent在network provider上执行相关操作，比如创建router； 
 
neutron- server 服务启动 
创建一个 socket 监听本机的 9696 端口，neutron.conf 中有 host 和 bind_port 参数。 
之后创建 WSGI server 进程用于处理 neutron client 发来的请求。 
neutron/api/v2 
v2 目录下包含了核心资源的实现代码。每个 neutron API 资源都会被封装成一个
Wsgi application。neutron API 服务进程 neutron- server 接收到用户的 http 请求后
会通过 Router 模块将其路由到相应的资源的 controller 中去执行。 
plugin 初始化时调 neutron.api.extensions 的 append_api_extensions_path 方法，传
入 extension 的路径。 
extension 中 get_resources 方法，根据 plugin，plural_mappings，resource_map，
action_map ， path_prefix
进 行
create_resources ， create_resounces
中 迭 代
resource_map 创建 controller，将 controller 传给 Resource Extension 初始化放到
create_resources 的返回值列表中。 
 
bind_port 
bind_port接口定义在class MechanismDriver，目录为neutron_lib/plugins/ml2/api.py。 
所谓 bind_port 就是将 Network 中的 segment 与 port 之间的关系，存入数据库表
ml2_port_binding_levels 中， 
 
 
Ethernet/以太网 
工作在数据链路层，Ethernet 中的主机使用数据帧通信，MAC(Media Access 
Control）地址是每台主机的唯一标识，MAC 地址由设备厂商硬编码在有线网卡
NIC 中。 
  
VLAN/虚拟局域网 
连接在同一交换机上的主机，如果它们具有不同的 VLAN ID，那么它们之间的
数据是相互隔离的。配置了指定的 VLAN ID 的交换机端口叫做 ACCESS 口。交
换机端口支持配置为允许多个 VLAN ID 的数据帧通过，这样的端口叫做 TRUNK
口。 
Subnet/子网 
 
ARP 
Address Resolution Protocol 
 
DHCP 
Dynamic Host Configuration Protocol 
 
 
DHCP agent 还会在 DHPC namespace 中启动一个 dnsmasq 进程，由它提供 dhcp 
server 服务； 
L2 
链路层，一个可靠的点对点的数据对接，常见：网卡，二层交换机，网桥等； 
port 
port 是虚拟交换机上一个端口，port 上定义 mac 和 ip 地址，instance 的虚拟网卡
VIF(virtual interface)绑定到 port 上时，port 会将 mac 和分配给 VIF。 
nova 中的 instance 是通过虚拟交换机连接到虚拟二层网络的。 
L3 
网络层，在网络的各个节点之间进行地址分配、路由和分发报文，常见：路由器，
多层交换机，防火墙等； 
 
静态路由 
 
 
 
NAT 
Network Address Translation 
NAT 是一个在 IP 数据包传输的过程，动态修改其头部的源 IP 地址或者目的 IP
地址的程序。Linux 中实现 NAT 的工具是 iptables。 
SNAT，通常利用 SNAT 来使具有私网 IP 的主机访问 Internat 网络。当具有私网
IP 的主机访问公网服务时，SNAT 将数据包中的源地址从该私网 IP 修改成一个
公网 IP，这样公网服务就知道回包发给谁了。 
DNAT，NAT 路由器修改 IP 数据包中的目的 IP 地址。 
One-to-One NAT，NAT 路由器维护一张私有 IP 地址到公共 IP 地址的一对一映
射表。Openstack 使用 One-to-One NAT 来实现 Floating IP 功能。 
Router 的 NAT 功能通过 iptables 实现： 
 
传统 Router 
 
 
虚拟路由器（virtual router） 
一个 VR 只属于创建它的租户，只用于该租户的子网之间和子网与外网的路由；
同一网络内的若干子网可以挂在一个 VR 上； 
同一租户的不同网络的没有 IP 地址重叠的子网可以挂在一个 VR 上； 
不同租户之间的内网之间是不能使用 VR 的； 
同一租户的不同网络内的有 IP 地址重叠的两个子网不能使用同一个 VR（添加
子网到 VR 时会报错）； 
在网络节点上，一个 VR 运行在一个 Network namespace 内，该 namespace 的
名称包含该 VR 的 UUID； 
 
 
 
常用的网络设备 
(Switch/Router/Firewall/Load Balancer) 
 
Lbaas 
 负载均衡（Load Balancing）是将来访的网络流量在运行相同应用的多个服务器
之间进行分发的一种核心网络服务。 
负载均衡器一般可以分为两类：第 4 层负载均衡器和第 7 层负载均衡器。 
第 4 层负载平衡器：基于网络和传输层协议（IP，TCP，FTP，UDP 等）来均衡
负载。 
 
第 7 层的负载均衡器：基于应用层协议比如 HTTP, SMTP, SNMP, FTP, Telnet 等
均衡负载。比如对 HTTP 来说，第七层的负载均衡器能根据应用的特定数据比
如 HTTP 头，cookies 或者应用消息中的数据来做进一步的请求分发。 
两种类型的负载均衡器都能接收请求，然后根据特定的算法将请求分发到特定的
服务器。一些行业标准的算法是： 
轮询 (Round robin)：轮流分发到各个（活动）服务器 
加权轮循 (Weighted round robin)：每个服务器有一定的加权（weight），轮询时
考虑加权。 
最少连接 (Least connections)：转发到有最少连接数的服务器 
最少响应时间 (Least response time)：转发到响应时间最短的服务器 
 
 
 
 
 
 
  
L2 Population 
L2 Population 是用来提高 VXLAN 网络 Scalability 的。 
通常我们说某个系统的 Scalability 好，其意思是： 
当系统的规模变大时，仍然能够高效地工作。 
L2 Population 到底解决了怎样的 Scalability 问题？ 
有一个包含 5 个节点的 VXLAN 网络，每个节点上运行了若干 VM。 
现在假设 Host 1 上的 VM A 想与 Host 4 上的 VM G 通信，VM A 要做的第一步
是获知 VM G 的 MAC 地址。 
于是 VM A 需要在整个 VXLAN 网络中广播 APR 报文：“VM G 的 MAC 地址是
多少？” 
如果 VXLAN 网络的节点很多，广播的成本会很大，这样 Scalability 就成问题了。 
幸好 L2 Population 出现了。 
L2 Population 的作用是在 VTEP 上提供 Porxy ARP 功能，使得 VTEP 能够预先
获知 VXLAN 网络中如下信息： 
1. VM IP – MAC 对应关系 
2. VM – VTEP 的对应关系 
当 VM A 需要与 VM G 通信时： 
1. Host 1 上的 VTEP 直接响应 VM A 的 APR 请求，告之 VM G 的 MAC 地
址。 
2. 因为 Host 1 上的 VTEP 知道 VM G 位于 Host 4，会将封装好的 VXLAN 
数据包直接发送给 Host 4 的 VTEP。 
这样就解决了 MAC 地址学习和 APR 广播的问题，从而保证了 VXLAN 的 
Scalability。 
那么下一个关键问题是： 
VTEP 是如何提前获知 IP – MAC – VTEP 相关信息的呢？ 
答案是： 
1. Neutron 知道每一个 port 的状态和信息；port 保存了 IP，MAC 相关数据。 
2. instance 启动时，其 port 状态变化过程为：down -> build -> active。 
3. 每当 port 状态发生变化时，Neutron 都会通过 RPC 消息通知各节点上的 
Neutron agent，使得 VTEP 能够更新 VM 和 port 的相关信息 
4. VTEP 可以根据这些信息判断出其他 Host 上都有哪些 VM，以及它们的 
MAC 地址，这样就能直接与之通信，从而避免了不必要的隧道连接和广播。 
 
neutron 使用示例 
# 创建网络 
openstack network create net1 
# 在 net1 中创建子网 subnet1 
openstack subnet create subnet1 --subnet-range 10.0.0.0/24 --network net1 
# 在 net1 中创建一个端口 port1 
openstack port create port1 --network net1 
# 启动虚机时指定网卡所在的网络 
openstack server create --image IMAGE --flavor FLAVOR --nic net-id=NET_ID vm1 
# 添加安全组 
openstack security group rule create --protocol icmp default 
# 创建外部网络和子网 
openstack network create public_net --external 
openstack subnet create --network public_net --subnet-range 172.16.1.0/24 public_subnet 
# 创建 router 
openstack router create router1 
# 将 router 连接到子网 
openstack router add subnet router1 subnet1 
# 将 router 添加到外部网络 
openstack router set --external-gateway public_net router1 
# router 添加静态路由 
openstack router set --route destination=172.16.2.0/24,gateway=172.16.2.1 router1 
# 查看 router 上的 port 
openstack port list -router router1 
# 创建 floatingip 
openstack floating ip create public_net 
# 将 floatingip 和 port 关联 
openstack floating ip add port floatingip_id --port-id internal_vm_port_id 
 
 
 
 
 
keystone 

 
glance 
Image 是一个模板，里面包含了基本的操作系统和其他软件； 
 
 
 
 
 
 
 
image 的元数据 通过 glance-registry 存放在 db 中； image 的 chunk 数据 通
过 glance-store 存放在各种 backend store 中，并从中获取。 
 
 
 
openstack metadata 
开启的服务/安装的包/添加 ssh 密钥/配置 hostname 等 
nova-api-metadata 服务提供 restful API 接口，用于虚拟机访问此 API 获取 metadata
信息。 
大致流程：请求发送给 neuteon-ns-metadata-proxy，请求中添加 router-id 和
netwoek-id，然后转发给 neutron-metadata-agent，获取 port 信息，最后转发给 nova-
api-metadata 获取虚拟机的 metadata。 
 
 
 
SDN 
背景 
手工配置和维护各种硬件设备，网络业务变复杂，多租户场景不能通过手工来保
证。 
SDN 是新型网络架构，设计理念是将网络的控制平面和数据转发平面进行分离，
从而通过集中的控制器中的软件平台去实现可编程化底层硬件，实现对网络资源
灵活的按需调度。 
通过集中的 SDN 控制器实现网络资源的统一管理整合以及虚拟化后，采用规范
化的北向接口为上层应用提供按需的网络资源和服务，实现网络功能开放。 
控制层，主要负责数据平面资源的编排，维护网络拓扑，状态信息等； 
基础设施层，负责基于流表的数据处理、转发和状态收集； 
 
SDN 层次化绑定 
VxLAN 的处理主要包括 VxLAN 数据的封装和解封装，这些都是由 VTEP
（VxLAN Tunnel EndPoint）完成的。如果硬件交换机来处理 VxLAN，那么就相
当于 VTEP 要在交换机上，VxLAN 报文的封装解封装都在交换机上完成。这样
的交换机一般是直接与服务器相连接的交换机（ToR，Top of Rack 交换机）。因
为 VxLAN 现在放到了硬件交换机处理，对于服务器或者位于服务器上的虚拟机
来说，是感知不到 VxLAN 的存在。大多数的硬件 SDN（或者说 underlay SDN）
都是采用这种方式处理 VxLAN。 
 
VxLAN 的一个最大好处在于，能够提供更多的租户隔离。多租户隔离依靠的是
VxLAN Header 里面的 24bit VNI（Virtual Networking Identity），不同的租户有不
同的 VNI。但是现在 VxLAN 的封装解封装都是在硬件交换机完成，租户拥有的
服务器或者虚拟机又感知不到 VxLAN，硬件交换机怎么知道哪些网络数据属于
哪个租户，进而给网络数据分配 VNI，完成 VxLAN 封装呢？ 
第一种方式是根据交换机端口来区分。例如，交换机端口 A 的网络流量，认为是
租户 A 的流量，封装成 VNI 为 A 的 VxLAN 数据。同理，端口 B 的流量认为是
租户 B 的流量，封装成 VNI B 的 VxLAN 数据。如下图所示： 
 
这种方式要求交换机的一个端口只能连接一个租户，也就是说，交换机端口连接
的服务器上只能部署一个租户的虚拟机。无论对于管理员还是用户来说，这都不
是一个友好的限制。 
反过来说，一个服务器如果同时有多个租户的虚拟机，那么交换机的一个端口就
会同时存在多个租户的网络数据，也就没有办法再通过交换机端口区分租户，分
配 VNI，进而封装 VxLAN 数据。服务器部署多个租户虚拟机，如下图所示： 
 
这种情况下该怎么让位于交换机上的 VTEP 识别多租户，进而封装 VxLAN 呢？
这就需要另外一种标记多租户网络数据的方式。传统网络里面，是通过 VLAN 识
别多租户的网络，这里还可以通过 VLAN 来做同样的事。首先在服务器内部对
不同租户的虚拟机打上不同的 VLAN Tag，同时将服务器连接到交换机的 Trunk
口，这样服务器可以把多个 VLAN Tag 的网络数据送到交换机。交换机根据
VLAN Tag 识别不同的租户，进而封装成相应的 VxLAN 数据。硬件交换机内的
VTEP 构成如下所示： 
 
硬件交换机上的 VTEP 从 Downlink，也就是与服务器连接的 Trunk 口，收到带 
VLAN Tag 的网络数据，之后查找“VLAN To VxLAN ID MAP”，找到对应的
VxLAN ID，进而封装成 VxLAN 数据。VTEP L2 Table 是 VxLAN 控制层要填的
表，与本文要描述的内容没有关联。 
这样，硬件交换机能够完成多个租户的 VxLAN 封装，而租户虚拟机也不需要知
道 VxLAN 的存在。但是同时，问题也来了。首先，服务器该给不同的租户打什
么样的VLAN Tag？其次，交换机里面的 VLAN To VxLAN ID MAP 由谁来填写？
对于 OpenStack，是通过层次化端口绑定这个功能来解决这两个问题。  
层次化端口绑定 
既然在 OpenStack 内实现这么一个功能，那就需要符合 OpenStack 的软件架构。
层次化端口绑定是在 OpenStack Neutron ML2 模块中实现的。Neutron ML2 我曾
在[2]中有过介绍。ML2 由多类 Driver 组成，其中一类是 Mechanism Driver。每
一个 Mechanism Driver 都管理一种二层网络设备。在层次化端口绑定的场景下，
需要两个 Mechanism Driver，其中一个管理硬件交换机，另一个管理 OpenVSwitch
（当然也可以是其他的虚拟交换机，我曾经在 VMware DVS 上也实现过相同的
功能），具体连接图如下所示： 
 
 
原理讲清楚了，具体的连接关系也讲清楚了，接下来的流程就顺利成章了。我们
最后来过一下层次化端口绑定的流程。 
用户创建了一个虚拟机，并且将虚拟机创建在 VxLAN A 网络中。Neutron 需要
创建一个 VxLAN A 的网络接口，请求被发送到了 ML2。Neutron ML2 先调用到
物理交换机对应的 Mechanism driver 进行端口绑定（port binding），将 VxLAN 
A 与网络接口进行绑定。因为底层还有 VLAN，物理交换机的 Mechanism Driver
会再申请一个 VLAN B，并告知 Neutron ML2，当前网络接口还需要绑定到对应
的 VLAN 上。之后物理交换机的 Mechanism Driver 会通过相应的 API，告知物
理交换机 VLAN B 和 VxLAN A 的对应关系，这样物理交换机就有了 VLAN To 
VxLAN ID MAP。ML2 因为知道了网络接口还需要绑定到对应的 VLAN 上，再
调用 OpenVSwitch 的 Mechanism Driver，将 VLAN B 与网络接口进行绑定。 
之后，OVS 的 Mechanism Driver 会通过相应的 API，告知位于计算节点的
OpenVSwitch，对于这个网络接口的网络数据，打上 VLAN B 的 Tag。 
到此为止层次化端口绑定完成了。在这里，对于同一个网络接口，实际上绑定了
两次，一次是在虚拟交换机上的 VLAN 绑定，另一次是在硬件交换机上的
VxLAN 绑定。所以，对于“Hierarchical Port Binding”到层次化端口绑定这个翻译，
我个人觉得还是比较符合“信雅达”的标准的。 
绑定完成之后，网络数据送到 OpenVSwitch，OVS 会打上 VLAN B 的 Tag，带
VLAN B Tag 的网络数据送到物理交换机。物理交换机根据自己的 VLAN To 
VxLAN ID MAP，将 VLAN Tag 去掉，再封装成相应的 VxLAN 数据。经过这样
的处理，VxLAN 的封装解封装被 offload 到了物理交换机。  
那为什么 OpenStack Neutron 里面没有相应的全部代码？因为层次化端口绑定的
逻辑，有一半是在 Neutron ML2 里面，有另一半是在物理交换机对应的 Mechanism 
driver 里面。物理交换机属于各个厂商，相应的 Mechanism Driver 由各个厂商维
护，而 OpenStack Neutron 不包含各个厂商的代码。 
 
 
OVS 
虚机交换机，为虚拟机提供二层交换功能，支持 openflow 协议，支持控制器对
ovs 远程管理控制; 
openvswich 作为网络驱动之后创建 vxlan 网络会生成三个网桥： 
br-int   连接 dnsmasq，流表逻辑处理； 
br-ex   连接网卡，发送外网，在网络节点 
br-tun  隧道端点，vxlan 和 gre 进行通信 
可以进出流量的端口，往往绑定若干 Mac 地址和 IP 地址，以进行寻址。一般为
虚拟交换机上的虚拟接口，通过端口访问网络。port 可以看作虚拟交换机上的一
个端口。port 上定义了 Mac 地址和 IP 地址，当 instance 的虚拟网卡 VIF 绑定到
port 时，port 会将 Mac 地址和 IP 地址分配给 VIF。 
 
 
控制节点一般需要一个网络端口用于通信/管理各个节点； 
网络节点包含三个网络端口， 
eth0 用于与控制节点进行通信； 
eth1 用于与除了控制节点之外的计算节点/存储节点之间的通信； 
eth2 用于外部的虚拟机与相应网络之间的通信； 
 
计算节点包含至少两个网络端口， 
eth0 与控制节点进行通信，受控制节点统一调配； 
eth1 与网络节点存储节点进行通信； 
 
存储节点包含至少两个网络端口， 
eth0 与控制节点进行通信，接受控制节点任务，受控制节点统一调配； 
eth1 与计算节点/网络节点进行通信，完成控制节点下发的各类任务。 
 
 
 
rpm 安装 openstack 
1.安装 python3-openstackclient 
2.安装 mariadb/mariadb-server/python3-PyMysql 
3.安装 socat/erlang，rpm 安装 rabbitmq- server 包 
4.安装 memcached/python3-memcached 
5.安装 etcd 
6.keystone 身份认证部署，数据库相关 
7.glance 镜像服务 
8.placement 放置服务 
9.nova 计算服务 
10.neutron 网络服务 
11.horizon  安装 openstack-dashboard 
12.安装块存储 cinder 
 
 
 
 
 
 
 
kolla-ansible 安装 openstack 
 
ansible 
是一种 agentless，基于 ssh，可实现批量配置、命令执行和控制，基于 python 实
现的自动化运维工具。 
yaml 三板斧 
缩进： 每个缩进由两个空格组成 
冒号： 以冒号结尾的除外，其它所有冒号后面所有必须有空格 
短横线：表示列表项，使用一个短横杠加一个空格，多个项使用同样的缩进级别
作为同一个列表； 
ansible-playbook 
1.关闭 selinux，关闭防火墙，更改 hosts 并免密登陆 
2.安装 docker-ce 
3.安装 ansible，先 pip2.4.0 后 yum 
4.安装 kolla-ansible 
5.生成密码文件，修改 global.xml 文件以及 multinode 文件 
6.拉取镜像 
7.预检查 
8.部署 
9.验证部署 
10.安装 openstack client 
 
 
 
 
13. Kubernetes 
K8s 是一个管理跨主机容器化应用系统，实现了包括应用部署、高可用管理和弹
性伸缩在内的一系列基础功能并封装成为一套完整、简单易用的 RESTful API 对
外提供服务。 
k8s 整体架构 
 
k8s 由两种节点组成，master 节点和工作节点；前者是管理节点，后者是容器运
行的节点； 
master 主要有三个重要的组件，分别是 APIServer、scheduler 和 controller manager； 
 
 
 
 
pod 
k8s 中，能够被创建、调度和管理的最小单元是 pod，而非单个容器，一个 pod 是
由若干个 docker 容器构成的容器组，pod 里的容器共享 network namespace，并
通过 volume 机制共享一部分存储。 
pod 是 IP 等网络资源的分配的基本单元，这个 IP 及其对应的 network namespace
是由 pod 里面的容器共享的； 
pod 内的容器也共享 volume。当一个 volume 被挂载在同属一个 pod 的多个 docker
容器的文件系统上时，该 volume 可以被这些容器共享； 
每个 pod 都有一个属性 labels----一组键值对，形如： 
"labels": { 
    "key1": "value1", 
    "key2": "value2" 
} 
replication controller 
备份控制器；用于保证在同一时刻 pod 能够维持特定的数目。用户可以将备份控
制器理解为整个容器集群全部节点的进程的监督者。 
它决定了一个 pod 有多少同时运行的副本，并保证这些副本的期望状态与当前状
态一致；如果创建了一个 pod，并且在希望该 pod 是持续运行的应用时[即仅适用
于重启策略为 always 的 pod]，一般都推荐同时给 pod 创建一个 replication 
controller，让这个 controller 一直守护 pod，直到 pod 被删除。 
service 
pod 在 k8s 中 IP 地址不是固定的，因此需要一个代理来确保需要使用 pod 的应
用不需要知晓 pod 的真实 IP 地址；当 replication controller 创建了多个 pod 副本
时，需要一个代理来为这些 pod 做负载均衡。 
service 主要由一个 IP 地址和一个 label selector 组成。 
service 提供的是 pod 的入口访问以及访问策略。 
Label 是一组键值对，用来标识创建的对象的属性。选择器用来过滤带有特定标
签的对象。 
k8s 命令 
# 列举所有匹配标签{"name": "nginx"}的 pod 
kubectl get pods -l name=nginx 
kubectl get pod   # 查看创建的 pod 信息 
kubectl get pod_name container   # 查看 pod 中容器输出的 log 信息 
kubectl get replicationController -o wide   # 查看 replication controller 的基本信息 
kubectl get service   # 查看创建的 service 
kubectl get services   # 查看创建的 services 
 
# 创建 pod，其中 obj.json 可以定义 pod、replication controller、service 等 k8s 对象的 json
格式资源配置文件 
kunectl create -f obj.json     
 
 
# 删除 pod 
kubectl delete pod pod_name    
 
14. jenkins 
持续集成----频繁将代码集成到主干； 持续交付----频繁将软件的新版本交付该
质量团队或者用户，以供审批； 持续部署----代码评审或者测试通过后，将其自
动部署到生产环境； 
 
 
 
 
 
 
 
 
智力题 
字节一面 
1. 有 64 匹马和 8 条跑道，每次只允许最多 8 匹马同时比赛（假定每匹
马每次比赛速度相同），但是没有秒表不能计时，问最少要比多少次，才
能选出最快的 4 匹马？ 
https://zhuanlan.zhihu.com/p/398143738 
 
 
 
英文自我介绍 
Good morning, Interviewers. It is really my honor to have this opportunity for an 
interview, I hope I can make a good performance today. Now I will introduce myself 
briefly. My name is dongxiangxiang. I received a master’s degree from the University 
of Electronic Science and Technology of China in the year of two thousand and 
nineteen. I passed CET6. During my postgraduate study in the major of eletronic 
science and technology, I published two SCI papers.  
I have three years work experience in ZTE Nanjing Research Institute, engaged in 
network protocol development. I was in charge of the development of extended network 
resources based on openstack and the northbound interface orchestration of the SDN 
controller. I'm a hardworking, responsible person. During my spare time, I like playing 
table tennis and running, I think we should work actively and keep exercising at the 
same time. I'm quite interested in this job, I sincerely hope to get the chance to work 
for your company, so that I can promote myself and make my contributions to the 
company. Thanks. 
 
From the SDN controller's point of view 
 
 
 
项目经历 
 
 
Director  
Director 和 Tecs 安装完毕，迪普防火墙接入成功，通过 Director 配置 ipsec-site-
connection 实例，可以通过 Tecs 正常配置正确落地生效到迪普防火墙上。 
配置包括增删改查以及查列表，还有订购，取消订购，修改订购。 
 
director web 门户—director 订单管理—CloudNetwork 微服务—neutron-server—
driver—迪普防火墙。 
   
vpn driver 开发 
配置 service_provider VPN driver 
在创建 VPN service 时进行 VPN service_id 和 provider 的关系存库   provider 根
据 flavor 来确定，不然是默认值 
 
创建 ipsec 时，根据 ipsec 中的 VPN service_id 取得 provider，再根据 provider 获
得 driver 对象，来进行 driver 的增删改 
 
初始化 driver 时获得 rest 对象、迪普设备账号密码 IP、引流参数配置对象 
创建时创 SA policy—protect net—ipsec connection 
neutron vpn-ikepolicy-create ikepolicy1 
neutron vpn-ipsecpolicy-create ipsecpolicy1 
neutron vpn-service-create --name myvpnA routerA netA 
neutron ipsec-site-connection-create --name vpnconnectionA --vpnservice-id myvpnA 
--ikepolicy-id ikepolicy1 --ipsecpolicy-id ipsecpolicy1 --peer-address 172.24.4.233 --
peer-id 172.24.4.233 --peer-cidr 10.2.0.0/24 --psk secret 
 
 
Director 云安全服务开发 
web 应用防火墙 
漏洞扫描 
数据库安全审计 
日志审计 
堡垒机 
功能：创建 更新 删除 订单支付 订单修改 资源列表 续费 安全服务详情页 
实际服务创建请求都是从订单下来的。 
订单支付后，在服务页面，可以看到安全服务的状态是 building，过一段时间状
态变成 active。 
为安全服务虚机 port 绑定安全组和浮动 IP 整个流程：调用山石云池创建接口，
创建安全服务虚机，云池接口返回创建状态，以及安全服务虚机 id 等信息，将
安全服务虚机相关字段写入数据库包括虚机状态。flask 框架中微服务起进程定
时读取数据库中虚机实例列表，过滤列表中虚机状态不为 error/deleted/active 的
虚机，使用山石云池 get 接口实时查询上一个步骤中取出的正在创建的虚机状态，
如果创建时间在 30 分钟完成，则取出符合条件的虚机 port_id 进行浮动 IP 和安
全组绑定。 
 
单点登录： 
云池接口获取 token，拿着 token 获取跳转到安全服务虚机页面 url，根据用户名
密码单点登录至安全服务页面详情页。 
 
 
 
A10 plugin 创建 lbaas 冲突问题 
resource_lock 表 
user_id 和 lock 和 last_lock_time 
 
handler_lb 初始化时，user_id 赋值 1，初始化 lock 即 init_lock，init_lock 中根据
user_id=1 取库，如果库里没有值，按 user_id=1，lock=false，last_lock_time=now
时间  存库。如果库里有值时将 lock 值置成 false，last_lock_time 更新成 now 时
间。 
 
aquire_lock 时，根据 user_id 获取 db 如果 lock=True 当前时间的上下超时时间比
如 10s 内，不允许获取 lock。 
否则获取锁，将 lock=true，将 last_lock_time=now 时间更新库。 
执行完毕后，在 context.session.begin()上下文中释放锁，lock=false。 
 
with A10context(self, context, lb) as c 
__enter__方法中获取 client 也就是下发设备的 rest API，之后 active partition，hook
钩子进行下发设备前的操作 before_vip_create 返回参数进行 after_vip_create。 
  
创建的 lb 中有参数子网，根据子网通过 ml2 plugin 获取 network_id，如果从数据
库中有此 network_id 关联的数据，则说明是在同一网络下创建 lb，一个网络一个
vlan_id，一个 vrrp，同网络子网已经存在，创建 ve 口以及 floatingip， 
同网络，有 v4 子网，并且要创建的 lb 的子网也是 v4，取之前的 v4 的 ve 口 port_id
以及 vrrp 的 floatingip 下发； 
同网络，有 v6 子网，并且要创建的 lb 的子网也是 v6，取之前的 v6 的 ve 口 port_id
以及 vrrp 的 floatingip 下发； 
现在问题是两个 lb 同一子网几乎同时创建，在 lb 创建流程中，会根据 network_id
查库，然而在两个 lb 都查找为空，所以创建了两个 vlan_id，导致接下来下发设
备时创建了两个 ve 口 ip 地址，设备不支持报错。 
LOCK_TIMEOUT = 10 
 
 
class ResourceLock(model.BASEV2): 
    __tablename__ = 'zte_resource_lock' 
    user_id = sa.Column(sa.Interger, primary_key=True, nullable=False) 
    lock = sa.Column(sa.Boolean(), nullable=False) 
    last_lock_time = sa.Column(sa.DateTime, nullable=True) 
 
 
class DeviceLockDb(object): 
    def init_lock_db(self, context, user_id): 
        db = context.session.query(ResourceLock) 
        db = db.filter(ResourceLock.user_id == user_id).first() 
        if not db: 
            with context.session.begin(subtransactions=True): 
                args = { 
                    'user_id': user_id, 
                    'lock': False, 
                    'last_lock_time': timeutils.utcnow() 
                } 
                db = ResourceLock(**args) 
                context.session.add(db) 
        else: 
            db.lock = False 
            db.last_lock_time = timeutils.utcnow() 
            with context.session.begin(subtransactions=True): 
                db.update(db) 
 
    def acquire_lock(self, context, user_id): 
        db = context.session.query(ResourceLock) 
        db = db.filter(ResourceLock.user_id == 
user_id).with_for_update().first() 
        if db.lock: 
            if not timeutils.is_newer_than(db.last_lock_time, LOCK_TIMEOUT) 
and \ 
                not timeutils.is_older_than(db.last_lock_time, LOCK_TIMEOUT) 
                return False 
        db.lock = True 
        db.last_lock_time = timeutils.utcnow() 
        with context.session.begin(subtransactions=True): 
            db.update(db) 
             
    def release_lock(self, context, user_id): 
        db = context.session.query(ResourceLock) 
        db = db.filter(ResourceLock.user_id == user_id).first() 
        db.lock = False 
        with context.session.begin(subtransactions=True): 
            db.update(db) 
 
 
class DeviceLock(DeviceLockDb): 
    def init_db(self, context, user_id): 
        self.init_lock_db(context, user_id) 
        LOG.info('init resource lock...') 
     
    def acquire(self, context, user_id): 
        ret = self.acquire_lock(context, user_id) 
        if ret: 
            LOG.info('get resource lock successfullly, user_id: %s', 
user_id) 
            return True 
        else: 
            LOG.info('can not get resource lock, user_id: %s', user_id) 
            return False 
         
    def release(self, context, user_id): 
        self.release_lock(context, user_id) 
        LOG.info('release resource lock, user_id: %s', user_id) 
 
 
插件部署 
bin 包生成 
首先分别用 python2 和 python3 setup.py bdist_rpm 生成 rpm 包 
之后通过 makeself.sh 脚本创建安装文件*.bin； 
 
 
ml2 
l3 
qos 
taas 
trunk 
vpc 
fwaas 
bgp 
 
 
 
项目产品很稳定，以及商用 6 年了了，暂时的需求只是修修补补，对于个人而言
就是增删几行代码的工作，提升机会不多，所以外边看看机会，想找能学到东西
的岗位。 
公司加班文化比较严重，1 2 4 6 加班，而且没有加班费，经常性被叫白嫖厂，考
核时同样完成任务，会将加班时长作为考核项。 
 
