<!-- vscode-markdown-toc -->
* 1. [2. Golang ........................................................................................................................................................... 414](#Golang...........................................................................................................................................................414)
* 2. [python概述](#python)
* 3. [python2 与 python3 区别](#python2python3)
* 4. [py2 项目如何迁移成 py3](#py2py3)
* 5. [python 解释代码原理，函数怎么解析的](#python-1)
* 6. [GIL](#GIL)
* 7. [装饰器](#)
	* 7.1. [1. 不带参数的装饰器](#-1)
	* 7.2. [2. 带参数的装饰器](#-1)
* 8. [可迭代对象、生成器、迭代器的区别](#-1)
* 9. [copy 和 deepcopy 区别](#copydeepcopy)
* 10. [进程、线程、协程](#-1)
* 11. [python 中 IO 密集型为什么用多线程](#pythonIO)
* 12. [简述__new__和__init__区别](#__new____init__)
* 13. [python 内存管理机制](#python-1)
	* 13.1. [python 内存池](#python-1)
	* 13.2. [垃圾回收](#-1)
	* 13.3. [分代回收](#-1)
* 14. [python 中单例模式实现方式](#python-1)
* 15. [python 编码](#python-1)
* 16. [python 新式类和经典类的区别](#python-1)
	* 16.1. [ 合并两个字典](#-1)
* 17. [用 Python 匹配 HTML tag 的时候，<.> 和 <.?> 有什么区别](#PythonHTMLtag..)
		* 17.1. [json.dump 显示中文](#json.dump)
* 18. [快速排序](#-1)
		* 18.1. [不用+号，两个数相加](#-1)
	* 18.1. [vim 编辑器](#vim)
	* 18.2. [ifconfig 命令查看网络 IP](#ifconfigIP)
	* 18.3. [java8 及 lib 库](#java8lib)
		* 18.3.1. [是 相 对 路 径 jar, 把 jdk-8u171-linux-](#jarjdk-8u171-linux-)
	* 18.4. [java 环境变量](#java)
* 19. [bow 用户配置 sudo 权限](#bowsudo)
* 20. [Allow root to run any commands anywhere](#Allowroottorunanycommandsanywhere)
* 21. [bow 用户设置 sudo 命令权限](#bowsudo-1)
		* 21.1. [消除重复行](#-1)
		* 21.2. [hash 的底层数据结构](#hash)
		* 21.3. [list 的底层数据实现结构](#list)
		* 21.4. [zset 的底层数据实现结构](#zset)
		* 21.5. [主从概念](#-1)
	* 21.1. [rabbitMQ](#rabbitMQ)
	* 21.2. [queue](#queue)
* 22. [RabbitMQ a message can never be sent directly to the queue,it always needs to go through](#RabbitMQamessagecanneverbesentdirectlytothequeueitalwaysneedstogothrough)
	* 22.1. [实例化一个 Api 对象，用来创建、管理 RESTful Api](#ApiRESTfulApi)
	* 22.2. [创建一个 Resource 类的子类，用于定义资源路由](#Resource)
	* 22.3. [最后，使用 Api 的实例对象，将上面定义的资源，利用路径，完全暴露出去](#Api)
* 23. [1. 合并两个无序链表](#-1)

<!-- vscode-markdown-toc-config
	numbering=true
	autoSave=true
	/vscode-markdown-toc-config -->
<!-- /vscode-markdown-toc -->


# 1. python ............................................................................................................................................................... 11 
python2 与 python3 区别 ....................................................................................................................... 13 
python 解释代码原理，函数怎么解析的 ........................................................................................ 13 
GIL ............................................................................................................................................................... 14 
装饰器 ......................................................................................................................................................... 16 
可迭代对象、生成器、迭代器的区别 ............................................................................................. 20 
copy 和 deepcopy 区别......................................................................................................................... 21 
进程、线程、协程 .................................................................................................................................. 22 
python 中 IO 密集型为什么用多线程 .............................................................................................. 24 
简述__new__和__init__区别 .................................................................................................................. 25 
python 内存管理机制 ............................................................................................................................ 26 
python 内存池 ................................................................................................................................. 26 
垃圾回收 ........................................................................................................................................... 28 
python 中单例模式实现方式 .............................................................................................................. 31 
python 方法与函数 ................................................................................................................................. 42 
例举几个规范 Python 代码风格的工具 ........................................................................................ 46 
python 内置数据类型 ............................................................................................................................ 47 
list 列表 .............................................................................................................................................. 48 
tuple 元组 ......................................................................................................................................... 53 
str 字符串 .......................................................................................................................................... 53 
dic 字典.............................................................................................................................................. 58 
bytes 字节 ......................................................................................................................................... 66 
函数 .............................................................................................................................................................. 70 
lambda 匿名函数 .................................................................................................................................... 76 
python 函数参数传递方式 ................................................................................................................... 94 
静态方法/类方法/实例方法 ................................................................................................................. 94 
生成器详解 .............................................................................................................................................. 100 
什么是闭包？ ......................................................................................................................................... 106 
__setattr__ __getattr__ __delattr__ .................................................................................................... 117 
__getattribute__ ...................................................................................................................................... 121 
__get__ __set__ __delete__ .................................................................................................................. 123 
__getitem__ __setitem__ __delitem__ .............................................................................................. 129 
python 上下文管理器的两种方式？ .............................................................................................. 134 
Python 中的反射了解么? .................................................................................................................. 182 
元类 ............................................................................................................................................................ 194 
定义接口和抽象基类 .................................................................................................................. 198 
python2 和 python3 定义元类的方式................................................................................... 198 
正则表达式 .............................................................................................................................................. 199 
贪婪模式和惰性模式 .................................................................................................................. 202 
re 模块实现正则的功能简单举例 ........................................................................................... 204 
re.match 与 re.search 的区别 ................................................................................................... 205 
正则表达式中的特殊字符 ......................................................................................................... 206 
多线程同步方式 ..................................................................................................................................... 211 
asyncio ...................................................................................................................................................... 229 
死锁 ............................................................................................................................................................ 241 
什么是僵尸进程和孤儿进程？怎么避免僵尸进程？ok ........................................................... 244 
简述乐观锁和悲观锁 ........................................................................................................................... 246 
python 模块............................................................................................................................................. 247 
__init__.py 用法 ....................................................................................................................................... 251 
with 方法打开处理文件做了什么?.................................................................................................. 294 
位运算 ...................................................................................................................................................... 358 
设计模式 .................................................................................................................................................. 404 
说说工厂模式 ......................................................................................................................................... 407 
策略模式 .................................................................................................................................................. 408 
##  1. <a name='Golang...........................................................................................................................................................414'></a>2. Golang ........................................................................................................................................................... 414 
匿名函数 .................................................................................................................................................. 418 
go web ...................................................................................................................................................... 418 
gin ............................................................................................................................................................... 418 
路由分组 ......................................................................................................................................... 419 
gin 中路由 ...................................................................................................................................... 420 
go 包 ................................................................................................................................................. 424 
swagger 使用 ................................................................................................................................. 424 
gorm 加上 logger......................................................................................................................... 425 
gorm 里面如何批量插入某个字段 ........................................................................................ 425 
gorm 里面更新有几种方式？ .................................................................................................. 427 
GIN 怎么做参数校验？ ............................................................................................................. 429 
你项目有优雅的启停吗？ ......................................................................................................... 429 
RPC ............................................................................................................................................................. 430 
RPC 工作原理 ................................................................................................................................ 431 
gRPC 是什么？ ........................................................................................................................... 433 
grpc 为啥好，基本原理是什么，和 http 比呢 ................................................................ 433 
面试题 ....................................................................................................................................................... 434 
= 和 := 的区别？ok ................................................................................................................ 434 
❤ 如何高效地拼接字符串 ok ............................................................................................... 434 
什么是 rune 类型 ok................................................................................................................. 436 
如何判断 map 中是否包含某个 key ？ok .................................................................... 437 
Go 支持默认参数或可选参数吗？ok ................................................................................... 437 
defer 的执行顺序 ........................................................................................................................ 438 
如何交换 2 个变量的值？ok ................................................................................................. 440 
Go 语言 tag 的用处？ ............................................................................................................ 440 
如何获取一个结构体的所有 tag？ ....................................................................................... 440 
结构体打印时，%v 和 %+v 的区别 ok ........................................................................ 441 
Go 语言中如何表示枚举值(enums)？ .............................................................................. 442 
空 struct{} 的用途 ok ............................................................................................................ 442 
go 里面的 int 和 int32 是同一个概念吗？ok ................................................................... 443 
init() 函数是什么时候执行的？ok ....................................................................................... 444 
❤new 和 make 的区别？ ........................................................................................................ 445 
请你讲一下 Go 面向对象是如何实现的？ ok ................................................................. 445 
uint 型变量值分别为 1，2，它们相减的结果是多少？ .............................................. 446 
下面这句代码是什么作用，为什么要定义一个空值？ ................................................. 446 
微服务了解吗？ ........................................................................................................................... 447 
服务发现是怎么做的？ ............................................................................................................. 448 
ETCD 用过吗？ok ...................................................................................................................... 449 
中间件用过吗？ ........................................................................................................................... 449 
持久化怎么做的？ ....................................................................................................................... 449 
map 的底层实现 .......................................................................................................................... 450 
go GC 的原理知道吗？ ............................................................................................................ 451 
go 里用过哪些设计模式 ? ...................................................................................................... 451 
go 的调试/分析工具用过哪些。 ............................................................................................ 462 
进程被 kill，如何保证所有 goroutine 顺利退出 ............................................................ 462 
说说 context 包的作用？你用过哪些，原理知道吗？ ................................................. 463 
Go 中发生熔断怎么做的 ........................................................................................................... 466 
服务降级怎么搞 ........................................................................................................................... 467 
1 亿条数据动态增长，取 top10，怎么实现 ..................................................................... 467 
总结 ............................................................................................................................................................ 468 
fallthrough ............................................................................................................................................... 468 
nil ................................................................................................................................................................ 469 
iota ............................................................................................................................................................. 469 
Go 中 Label 使用 ................................................................................................................................... 470 
切片 ............................................................................................................................................................ 471 
切片拷贝三种方式 ....................................................................................................................... 473 
扩容策略 ......................................................................................................................................... 474 
如何判断 2 个字符串切片（slice) 是相等的？ ............................................................ 475 
map ............................................................................................................................................................ 475 
map 基本用法 ............................................................................................................................... 475 
go 里面的 map 是并发安全的吗？如何并发安全 ............................................................ 477 
解决 hash 碰撞的方法 ................................................................................................................ 478 
channel 通道 ........................................................................................................................................... 479 
channel 死锁的场景 ok ......................................................................................................... 479 
对已经关闭的 chan 进行读写会怎么样？ ......................................................................... 481 
channel 底层实现？是否线程安全。 .................................................................................. 481 
当 select 监控多个 chan 同时到达就绪态时，如何先执行某个任务？ ................ 482 
select 的实现原理？ .................................................................................................................. 483 
无缓冲的 channel 和有缓冲的 channel 的区别？ ................................................... 484 
Go 语言中可以使用 channel 和 mutex 实现阻塞队列 .................................................... 484 
异常处理 .................................................................................................................................................. 488 
Go 有异常类型吗？ok .............................................................................................................. 488 
Goroutine ................................................................................................................................................. 489 
什么是协程（Goroutine）与线程区别 .............................................................................. 489 
go 通道和锁的使用场景？ ....................................................................................................... 490 
select ................................................................................................................................................ 491 
goroutine 什么情况会发生内存泄漏？如何避免。 ....................................................... 491 
如果若干个 goroutine，有一个 panic 会怎么做？ ...................................................... 492 
recover 的执行时机 ok ............................................................................................................. 492 
为什么有协程泄露(Goroutine Leak)？ ............................................................................. 493 
Go 可以限制运行时操作系统线程的数量吗？ 常见的 goroutine 操作函数有哪些？
 ............................................................................................................................................................ 494 
如何控制协程数目 ok ............................................................................................................... 494 
defer 可以捕获 goroutine 的子 goroutine 吗？ ........................................................... 495 
go 竞态条件了解吗？ ................................................................................................................ 496 
（Goroutine）有三个函数，分别打印"cat", "fish","dog"要求每一个函数都用一
个 goroutine，按照顺序打印 100 次。 ............................................................................. 497 
两个协程交替打印 10 个字母和数字 ................................................................................... 498 
启动 2 个 groutine 2 秒后取消， 第一个协程 1 秒执行完，第二个协程 3 秒执行
完。 .................................................................................................................................................. 500 
GMP 模型 ................................................................................................................................................. 502 
❤go 如何进行调度的。GMP 中状态流转。 .................................................................... 502 
Go 什么时候发生阻塞？阻塞时，调度器会怎么做。 ................................................... 504 
❤Go 中 GMP 有哪些状态？ .................................................................................................. 504 
GMP 能不能去掉 P 层？会怎么样？ ................................................................................... 506 
如果有一个 G 一直占用资源怎么办？什么是 work stealing 算法？ ..................... 506 
指针 ............................................................................................................................................................ 507 
指针的作用 ok ............................................................................................................................. 507 
函数返回局部变量的指针是否安全？ .................................................................................. 508 
非接口的任意类型 T() 都能够调用 *T 的方法吗？反过来呢？ ............................ 508 
反射 ............................................................................................................................................................ 508 
实现使用字符串函数名，调用函数。 .................................................................................. 508 
go 的 reflect 底层实现 ............................................................................................................ 509 
接口 ............................................................................................................................................................ 510 
2 个 interface 可以比较吗？ok ............................................................................................. 510 
go 的 interface 怎么实现的？ ............................................................................................... 511 
2 个 nil 可能不相等吗？ ok.................................................................................................... 513 
sync ............................................................................................................................................................ 513 
说说 atomic 底层怎么实现的. .............................................................................................. 513 
❤mutex 有几种模式？ ............................................................................................................. 513 
GC 和内存管理 ....................................................................................................................................... 514 
你是否主动关闭过 http 连接，为啥要这样做？ok .......................................................... 514 
Go GC 有几个阶段 ..................................................................................................................... 515 
❤golang 的内存管理的原理清楚吗？简述 go 内存管理机制。 .............................. 516 
05 ❤简述 Go 语言 GC(垃圾回收)的工作原理 ok ......................................................... 517 
02 ❤如何知道一个对象是分配在栈上还是堆上？ ......................................................... 519 
go 工具包 ................................................................................................................................................. 519 
3. 计算机网络 ................................................................................................................................................. 520 
简单一次完整的 HTTP 请求所经历的步骤？ ............................................................................. 520 
DNS 解析的过程 .................................................................................................................................... 521 
TCP ............................................................................................................................................................ 522 
TCP 和 UDP 区别 ................................................................................................................................. 523 
TCP 协议如何保证可靠性 .................................................................................................................. 524 
详细讲一下 TCP 的滑动窗口 ............................................................................................................. 525 
详细讲一下拥塞控制 ........................................................................................................................... 525 
TCP 中的流量控制和拥塞控制 ......................................................................................................... 526 
三次握手和四次挥手 ........................................................................................................................... 527 
TCP 协议为什么需要三次握手 ......................................................................................................... 530 
四次挥手释放连接时，等待 2MSL 的意义 .................................................................................. 530 
HTTPS 原理详解 .................................................................................................................................. 531 
对称加密 ......................................................................................................................................... 534 
非对称加密 ..................................................................................................................................... 535 
ARP ............................................................................................................................................................ 540 
大流量 tcp 和 http 连接怎么排查 .................................................................................................... 541 
OSI 的七层模型都有哪些 .................................................................................................................. 542 
TCP/IP 4 层模型 .................................................................................................................................... 543 
为什么要 Time_Wait ............................................................................................................................. 543 
要是没有三次握手会怎么样.............................................................................................................. 543 
要是没有四次挥手会怎么样.............................................................................................................. 544 
为什么要四次挥手？ ........................................................................................................................... 544 
为什么需要三次握手，而不是两次？ ........................................................................................... 544 
为什么要三次握手，而不是四次？ ................................................................................................ 546 
三次握手建立连接时，发送方再次发送确认的必要性？ ...................................................... 546 
三次握手连接阶段，最后一次 ACK 包丢失，会发生什么？ ................................................ 547 
为什么连接的时候是三次握手，关闭的时候却是四次握手？ ............................................. 547 
CLOSE-WAIT 状态问题 ...................................................................................................................... 548 
TIME-WAIT 状态问题 ......................................................................................................................... 548 
如果已经建立了连接，但是客户端出现故障了怎么办？ ...................................................... 548 
TIME-WAIT 状态过多会产生什么后果？怎样处理？ ............................................................. 549 
TIME_WAIT 是服务器端的状态?还是客户端的状态? .............................................................. 550 
第 2 次握手传回了 ACK，为什么还要传回 SYN？ .................................................................... 550 
http ............................................................................................................................................................. 556 
HTTP 和 HTTPS 有什么区别？ ...................................................................................................... 557 
http 请求中 get post 区别 .................................................................................................................. 560 
幂等 Idempotence ............................................................................................................................... 563 
如何解决幂等性问题 ........................................................................................................................... 564 
解释一下 HTTP 长连接和短连接 ..................................................................................................... 569 
WSGI .......................................................................................................................................................... 579 
谈一下你对 uWSGI 和 nginx 的理解 ............................................................................................... 580 
什么是 rpc ................................................................................................................................................ 583 
RESTful API .............................................................................................................................................. 584 
RestFul 和 RPC 的区别 ......................................................................................................................... 585 
4. docker ............................................................................................................................................................. 588 
云原生 ....................................................................................................................................................... 588 
centos 安装 docker ............................................................................................................................... 589 
docker 容器与主机时间保持同步.................................................................................................... 589 
docker 隔离原理 .................................................................................................................................... 589 
网络模式 .................................................................................................................................................. 590 
bridge ............................................................................................................................................... 591 
host ................................................................................................................................................... 592 
none .................................................................................................................................................. 593 
container ......................................................................................................................................... 593 
Docker-compose 容器编排 ............................................................................................................... 594 
DockerFile 解析 ...................................................................................................................................... 597 
docker 核心原理 .................................................................................................................................... 614 
5. 操作系统 ...................................................................................................................................................... 615 
查看 Linux 中被进程打开文件的信息 ............................................................................................ 615 
谈谈对 IO 多路复用机制的理解 ...................................................................................................... 615 
实现 IO 多路复用的模型 .................................................................................................................... 616 
CPU 突然飙高，系统反应慢怎么排查 ......................................................................................... 617 
查看打开的线程 ..................................................................................................................................... 618 
内存泄漏怎么排查 ................................................................................................................................ 618 
进程与线程的切换流程 ....................................................................................................................... 621 
进程间通信有哪些方式 ....................................................................................................................... 623 
进程间同步的方式有哪些？.............................................................................................................. 627 
进程有哪几种状态？ ........................................................................................................................... 630 
进程调度策略有哪些 ........................................................................................................................... 630 
用户态和内核态 ..................................................................................................................................... 632 
如何从用户态切换到内核态？ ......................................................................................................... 643 
内存管理 .................................................................................................................................................. 644 
操作系统的内存管理机制了解吗？内存管理有哪几种方式? ................................................ 645 
shell ............................................................................................................................................................ 654 
Linux 查看进程 .............................................................................................................................. 655 
ldd ..................................................................................................................................................... 656 
ss ........................................................................................................................................................ 658 
VIM 使用 ......................................................................................................................................... 661 
虚拟环境 virtualenv .............................................................................................................................. 683 
iptables 使用 ........................................................................................................................................... 683 
6. git ..................................................................................................................................................................... 684 
17. git pull 和 git fetch 有什么区别？ ........................................................................................ 692 
7. mysql .............................................................................................................................................................. 693 
3 类数据读取问题 ................................................................................................................................. 693 
幻读是怎么解决的 ................................................................................................................................ 694 
2 类数据更新问题 ................................................................................................................................. 696 
事务隔离级别 ......................................................................................................................................... 696 
三范式 ....................................................................................................................................................... 698 
在哪些地方适合创建索引？.............................................................................................................. 699 
当前读和快照读 ..................................................................................................................................... 700 
MVCC ........................................................................................................................................................ 701 
为什么需要 MVCC ....................................................................................................................... 701 
MVCC 能解决什么问题 .............................................................................................................. 702 
MVCC 实现原理............................................................................................................................ 702 
为什么 MySQL 索引结构采用 B+树 ................................................................................................ 704 
执行 SQL 响应比较慢，你有哪些排查思路？ .......................................................................... 706 
MySQL 执行查询的过程 .................................................................................................................... 709 
索引 ........................................................................................................................................................... 715 
索引的分类 .............................................................................................................................................. 716 
为什么使用 MySQL 的最左匹配原则 ............................................................................................. 718 
聚簇索引和非聚簇索引 ....................................................................................................................... 719 
mysql 什么情况下不会使用索引 ..................................................................................................... 721 
索引下推 .................................................................................................................................................. 722 
事务特性 .................................................................................................................................................. 725 
数据库主键使用自增主键还是 UUID ............................................................................................. 728 
使用 B 树和 B+树的比较 .................................................................................................................... 730 
使用哈希索引、有序数组、二叉搜索树、平衡二叉树、红黑树、B+树索引的比较 ... 732 
哈希表 ............................................................................................................................................. 732 
有序数组 ......................................................................................................................................... 733 
二叉搜索树 .................................................................................................................................... 734 
平衡二叉树(AVL) ......................................................................................................................... 735 
红黑树 ............................................................................................................................................. 737 
B+树 ................................................................................................................................................. 737 
数据库为什么要用 B+树结构 ........................................................................................................... 739 
为什么红黑树不适合做索引？ ......................................................................................................... 740 
回表 ............................................................................................................................................................ 741 
索引覆盖 .................................................................................................................................................. 742 
不符合范式会出现哪些异常.............................................................................................................. 743 
事务 ........................................................................................................................................................... 743 
事务的启动方式 ..................................................................................................................................... 744 
事务的实现原理 ..................................................................................................................................... 745 
MySQL 事务日志介绍下 ..................................................................................................................... 745 
触发器 ....................................................................................................................................................... 748 
什么是存储过程？有哪些优缺点？ ................................................................................................ 749 
MySQL 建表的约束条件有哪些？ ................................................................................................... 751 
触发器与存储过程区别 ....................................................................................................................... 752 
MyISAM 与 InnoDB 区别 ................................................................................................................. 753 
mysql 引擎 ............................................................................................................................................... 757 
列出常见 MYSQL 数据存储引擎 ...................................................................................................... 757 
SQL 语句的优化 ..................................................................................................................................... 758 
大表怎么优化 ......................................................................................................................................... 768 
简述 mysql 和 redis 区别 .................................................................................................................... 772 
mysql 语句 ............................................................................................................................................... 772 
select 语句 ...................................................................................................................................... 777 
连接查询(join) ............................................................................................................................... 782 
举例 .................................................................................................................................................. 784 
为什么 SELECT COUNT(*) FROM table 在 InnoDB 比 MyISAM 慢 ................................. 801 
explain ....................................................................................................................................................... 802 
drop,delete 与 truncate 的区别 ........................................................................................................ 815 
MySQL 中的 varchar 和 char 有什么区别？ ........................................................................... 818 
基于 Redis 和 Mysql 的架构，如何保证数据一致性 ................................................................ 819 
视图 ............................................................................................................................................................ 859 
binlog(归档日志) ................................................................................................................................... 861 
8. Redis ............................................................................................................................................................... 867 
zset ............................................................................................................................................................. 876 
Redis 的数据类型有哪些？ ................................................................................................................ 877 
9. MQ .................................................................................................................................................................. 939 
为什么使用 MQ？ ................................................................................................................................. 939 
RabbitMQ ................................................................................................................................................. 945 
11. 分布式 ........................................................................................................................................................ 966 
分布式幂等性如何设计 ....................................................................................................................... 967 
负载均衡的理解 ..................................................................................................................................... 968 
分布式缓存 .............................................................................................................................................. 974 
一致性哈希 .............................................................................................................................................. 976 
节点数量变化了怎么办？ ......................................................................................................... 977 
算法原理 ......................................................................................................................................... 977 
数据倾斜问题 ................................................................................................................................ 978 
缓存雪崩、缓存击穿与缓存穿透 ........................................................................................... 979 
protobuf .......................................................................................................................................... 980 
10. Django ......................................................................................................................................................... 980 
Django 的请求生命周期 ..................................................................................................................... 980 
Flask 和 Django 路由映射的区别？ ............................................................................................. 981 
11. flask .............................................................................................................................................................. 986 
1. 第一个 flask 程序 ............................................................................................................................. 986 
2. 配置参数 ............................................................................................................................................. 987 
3. 启动 flask 程序 .................................................................................................................................. 988 
4. 视图函数的路由规则 ...................................................................................................................... 988 
5. 请求参数 ............................................................................................................................................. 989 
6. 设置响应信息 ................................................................................................................................... 990 
7. cookie ................................................................................................................................................... 990 
8. session .................................................................................................................................................. 991 
9. flask-sqlalchemy ............................................................................................................................... 992 
10. flask 使用蓝图 ................................................................................................................................. 996 
11. sqlalchemy 使用 ............................................................................................................................. 996 
12. openstack ..................................................................................................................................................... 997 
openstack 创建虚机的流程 ................................................................................................................. 997 
port 创建成功后的 dhcp 相关操作 ........................................................................................... 1000 
ovs 场景下东西南北向流量 ........................................................................................................... 1001 
Vmware 提供了三种网络工作模式 .............................................................................................. 1003 
vlan .......................................................................................................................................................... 1004 
vxlan ........................................................................................................................................................ 1004 
KVM ........................................................................................................................................................ 1011 
openstack 通用设计思路 ................................................................................................................. 1013 
neutron .................................................................................................................................................. 1014 
L3 .................................................................................................................................................... 1019 
Lbaas ............................................................................................................................................. 1023 
nova ........................................................................................................................................................ 1028 
keystone ................................................................................................................................................ 1030 
glance ..................................................................................................................................................... 1032 
openstack metadata .......................................................................................................................... 1034 
SDN ......................................................................................................................................................... 1035 
OVS ......................................................................................................................................................... 1042 
rpm 安装 openstack .......................................................................................................................... 1044 
kolla-ansible 安装 openstack ......................................................................................................... 1045 
15. 算法 .......................................................................................................................................................... 1051 
1. 合并两个无序链表 ....................................................................................................................... 1051 
2. 一次遍历获取列表第二大值 ok ............................................................................................. 1052 
3. 快排 .................................................................................................................................................. 1052 
4. 归并排序 ......................................................................................................................................... 1053 
5. 最大子列表和 ok ......................................................................................................................... 1055 
6. 数组中重复的数字 ok ................................................................................................................ 1055 
7. 最小的 k 个数 ok ......................................................................................................................... 1056 
8. 两个栈实现一个队列 ok ........................................................................................................... 1056 
9. 单链表相交的入口节点 ok ....................................................................................................... 1057 
10. 三数之和 97 ................................................................................................................................ 1058 
11. 搜索二维矩阵 ok ....................................................................................................................... 1059 
12. 从前序与中序遍历序列构造二叉树 ok ............................................................................. 1060 
13. 旋转图像 ....................................................................................................................................... 1061 
14. 反转链表 ok ................................................................................................................................ 1061 
15. K 个一组反转链表 ...................................................................................................................... 1062 
16. 相交链表 ok ................................................................................................................................ 1063 
17. 反转链表 II ................................................................................................................................... 1064 
18. 合并 K 个升序链表 ..................................................................................................................... 1066 
19. 堆排序 ............................................................................................................................................ 1067 
20. 双向链表 ....................................................................................................................................... 1069 
21. LRU 缓存机制 ............................................................................................................................... 1076 
22. 缺失的第一个正数 ..................................................................................................................... 1079 
23. 只出现一次的数字 ok .............................................................................................................. 1080 
24. 全排列 ............................................................................................................................................ 1080 
25. 无重复字符的最长子串 100 .................................................................................................. 1082 
26. 数组中的第 K 个最大元素 99 ................................................................................................ 1083 
27. 二叉树的锯齿形层序遍历 98 ok .......................................................................................... 1085 
28. 买卖股票的最佳时机 ok ......................................................................................................... 1086 
29. 二叉树的最近公共祖先 ............................................................................................................ 1087 
30. 字符串相加 ................................................................................................................................... 1089 
31. 接雨水 ............................................................................................................................................ 1090 
32. 二叉树的右视图 ok .................................................................................................................. 1095 
33. 合并两个有序数组 ..................................................................................................................... 1096 
34. 搜索旋转排序数组 ..................................................................................................................... 1097 
35. 螺旋矩阵 ....................................................................................................................................... 1098 
36. 二叉树的层序遍历 ok .............................................................................................................. 1099 
37. 有效的括号 ok............................................................................................................................ 1100 
38. 数组中的逆序对 ......................................................................................................................... 1100 
39. 岛屿数量 ....................................................................................................................................... 1101 
40. 合并区间 ....................................................................................................................................... 1102 
41. 递增的三元子序列 ..................................................................................................................... 1103 
42. 最长递增子序列 ......................................................................................................................... 1103 
43. x 的平方根 .................................................................................................................................... 1104 
44. 二叉树中的最大路径和 ............................................................................................................ 1104 
45. 最长回文子串 .............................................................................................................................. 1105 
46. 二叉树中序遍历 ......................................................................................................................... 1106 
47. 最小栈 ............................................................................................................................................ 1107 
48. 重排链表 ....................................................................................................................................... 1108 
49. 对称的二叉树 .............................................................................................................................. 1109 
50. 路径总和 II ................................................................................................................................... 1110 
51. 二叉树的完全性检验 ................................................................................................................ 1111 
52. 爬楼梯 ............................................................................................................................................ 1111 
53. 链表中倒数第 k 个节点 ok ..................................................................................................... 1112 
54. 验证二叉搜索树 ......................................................................................................................... 1112 
55. 组合总和 ....................................................................................................................................... 1113 
56. 奇偶链表 ....................................................................................................................................... 1114 
57. 回文链表 ....................................................................................................................................... 1115 
58. 平衡二叉树 ................................................................................................................................... 1116 
59. 二叉树的直径 .............................................................................................................................. 1117 
60. 最长重复子数组 ......................................................................................................................... 1118 
61. 反转字符串中的单词 ................................................................................................................ 1119 
62. 最小路径和 ................................................................................................................................... 1120 
63. 不同路径 ok ................................................................................................................................ 1120 
64. 删除排序链表中的重复元素 ok ........................................................................................... 1121 
65. 寻找峰值 ok ................................................................................................................................ 1121 
66. 长度最小的子数组 ok .............................................................................................................. 1122 
67. 零钱兑换 II ................................................................................................................................... 1123 
68. 最小覆盖子串 .............................................................................................................................. 1124 
69. 最长有效括号 .............................................................................................................................. 1125 
70. 交替打印奇偶数 ok .................................................................................................................. 1126 
71. 滑动窗口最大值 ......................................................................................................................... 1127 
72. 复原 IP 地址 ................................................................................................................................. 1128 
73. 调整数组顺序使奇数位于偶数前面 ..................................................................................... 1130 
74. 最长公共前缀 .............................................................................................................................. 1130 
智力题 .................................................................................................................................................... 1131 
英文自我介绍 ...................................................................................................................................... 1132 
项目经历 ............................................................................................................................................... 1132 
 
 
 
 
 
 
2. Golang 
go 代码编写到扩展名为.go 的文件中，通过 go build 命令对该 go 文件进行编译，
生成.exe 文件，之后执行.exe 文件即可看到运行的效果； 
通过 go run 命令可以直接运行.go 程序。 
 
行注释 //  
块注释 /* */ 
 
变量 
变量相当于内存中一个数据存储空间的表示。 
变量使用三种方式： 
1. 指定变量类型，声明后若不赋值，使用默认值；var i, j, k int；声明变量 
2. 根据值自行判断变量类型；var num1, s1 = 1.1, “string”  初始化变量 
3. 省略 var；name := “tom”; 等价于 var name string  name = “tom” 给变量赋值 
 
变量不能改变数据类型，变量在同一个作用域内(在一个函数或者代码块)内不能
重名； 
 
go 数据类型 
 
基本数据类型转成 string 
s = fmt.Sprintf(“%d”, num) 
值类型：基本数据类型 int 系列，float 系列，bool，string，数组和结构体 struct； 
引用类型：指针，slice 切片，map，管道 chan，interface 等 
 
package 名和其所在的目录名字一样； 
变量名、函数名、常量名采用驼峰法； 
如果变量名、函数名、常量名首字母大写，则可以被其他的包访问；如果小写，
则只能在本包内使用； 
 
 
多分支 
if 条件表达式 { 
} else if { 
} 
else { 
} 
 
switch 用法 
switch 表达式 { 
case 表达式 1，表达式 2，…： 
语句块 
default: 
    语句块 
} 
 
for 循环 
for 循环变量初始化；循环条件；循环变量迭代 { 
    循环语句 
} 
或 
j := 0 
for j < 10 { 
fmt.Printf(“%v”, j) 
j++ 
} 
for-range 用法 
    var s string = "dong is a genius!" 
    for index, val := range s { 
        fmt.Printf("%d===%c\n", index, val) 
    } 
 
init 函数 
每个源文件都可以包含一个 init 函数，该函数会在 main 函数执行前调用； 
如果 main.go 和 util.go 都含有变量定义，执行顺序是 util.go 中的变量定义init
函数main.go 中的变量定义init 函数main 函数 
 
 
 
 
 
匿名函数 
1. 在定义匿名函数时就直接调用； 
2. 将匿名函数赋给一个变量，再通过该变量来调用匿名函数； 
3. 全局匿名函数； 
 
 
 
go web 
net/http 包 
err := http.ListenAndServe(":9090", nil) //设置监听的端口 
Enable Go modules integration GOPROXY=https://goproxy.cn 
go mod init 项目路径 
go env -w GOPROXY=https://goproxy.cn,direct 
go env –w GO111MODULE=on 
go get -u github.com/gin-gonic/gin 
 
gin 
框架提供的特性， 
1. 路由(Routing)：将请求映射到函数，支持动态路由。例如'/hello/:name； 
2. 模板(Templates)：使用内置模板引擎提供模板渲染机制； 
3. 工具集(Utilites)：提供对 cookies，headers 等处理机制； 
4. 插件(Plugin)：Bottle 本身功能有限，但提供了插件机制。可以选择安装到全
局，也可以只针对某几个路由生效。 
 
jsonp 和 json 区别是，jsonp 可以传入回调函数，并且将参数传给回调函数； 
http.StatusOK ---200 
context.XML(http.StatusOK, obj)  ---返回 xml 数据 
 
路由分组 
defaultRouter := r.Group("/") 
{ 
   defaultRouter.GET("/", func(context *gin.Context) 
{ 
      context.String(http.StatusOK, "值%v", "您好 gin") 
   }) 
   defaultRouter.GET("/new", func(context 
*gin.Context) { 
      context.String(http.StatusOK, "值%v", "您好 gin") 
   }) 
} 
 
路由中间件 
路由中多个 HandlerFunc 参数，可以作为中间件； 
r.GET(“/”, InitMiddleWare, func(context *gin.Context){}) 
context.Next() ---调用该请求的剩余处理程序； 
context.Abort() ----终止该请求的剩余处理程序； 
r.use(middleWare1, middleWare2)  ---全局中间件 
r.Group()  ---可以在里面加路由分组中间件 
 
gin 中路由 
在 Gin 中，路由是指将请求的 URL 映射到相应的处理函数上。Gin 提供了多
种方式来定义路由，包括： 
1. GET 方法 
使用 GET 方法可以定义 GET 请求的路由，例如： 
router.GET("/hello", func(c *gin.Context) { 
    c.String(http.StatusOK, "Hello, world!") 
}) 
上面的代码定义了一个 GET 请求的路由，当请求的 URL 为 "/hello" 时，会调
用后面的处理函数返回 "Hello, world!"。 
2. POST 方法 
使用 POST 方法可以定义 POST 请求的路由，例如： 
router.POST("/users", func(c *gin.Context) { 
    // 处理 POST 请求 
}) 
上面的代码定义了一个 POST 请求的路由，当请求的 URL 为 "/users" 时，会
调用后面的处理函数处理 POST 请求。 
3. PUT 方法 
使用 PUT 方法可以定义 PUT 请求的路由，例如： 
router.PUT("/users/:id", func(c *gin.Context) { 
    // 处理 PUT 请求 
}) 
上面的代码定义了一个 PUT 请求的路由，当请求的 URL 为 "/users/:id" 时，
会调用后面的处理函数处理 PUT 请求。其中，":id" 表示一个参数，可以通过 
c.Param("id") 获取该参数的值。 
4. DELETE 方法 
使用 DELETE 方法可以定义 DELETE 请求的路由，例如： 
router.DELETE("/users/:id", func(c *gin.Context) { 
    // 处理 DELETE 请求 
}) 
上面的代码定义了一个 DELETE 请求的路由，当请求的 URL 为 "/users/:id" 
时，会调用后面的处理函数处理 DELETE 请求。其中，":id" 表示一个参数，可
以通过 c.Param("id") 获取该参数的值。 
5. PATCH 方法 
使用 PATCH 方法可以定义 PATCH 请求的路由，例如： 
router.PATCH("/users/:id", func(c *gin.Context) { 
    // 处理 PATCH 请求 
}) 
上面的代码定义了一个 PATCH 请求的路由，当请求的 URL 为 "/users/:id" 时，
会调用后面的处理函数处理 PATCH 请求。其中，":id" 表示一个参数，可以通
过 c.Param("id") 获取该参数的值。 
6. Any 方法 
使用 Any 方法可以定义任何请求方法的路由，例如： 
router.Any("/users/:id", func(c *gin.Context) { 
    // 处理任何请求方法 
}) 
上面的代码定义了一个任何请求方法的路由，当请求的 URL 为 "/users/:id" 时，
会调用后面的处理函数处理所有请求方法。其中，":id" 表示一个参数，可以通
过 c.Param("id") 获取该参数的值。 
7. Group 方法 
使用 Group 方法可以将多个路由分组，例如： 
users := router.Group("/users") 
{ 
    users.GET("/", func(c *gin.Context) { 
        // 处理 GET 请求 
    }) 
    users.POST("/", func(c *gin.Context) { 
        // 处理 POST 请求 
    }) 
    users.PUT("/:id", func(c *gin.Context) { 
        // 处理 PUT 请求 
    }) 
    users.DELETE("/:id", func(c *gin.Context) { 
        // 处理 DELETE 请求 
    }) 
} 
上面的代码将 "/users" 路由下的多个请求方法分组处理，可以更好地组织代码。 
8. Use 方法 
使用 Use 方法可以为路由添加中间件，例如： 
router.Use(authMiddleware) 
router.GET("/hello", func(c *gin.Context) { 
    c.String(http.StatusOK, "Hello, world!") 
}) 
上面的代码为 "/hello" 路由添加了一个 authMiddleware 中间件，可以在处理请
求前进行身份验证等操作。 
以上是 Gin 中定义路由的常用方式，可以根据实际需求选择适合的方式。 
 
 
go 包 
ini 依赖包 
go get -u github.com/go-ini/ini 
 
com 依赖包 
go get -u github.com/unknwon/com 
gorm 依赖包 
go get -u github.com/jinzhu/gorm 
mysql 驱动依赖包 
go get -u github.com/go-sql-driver/mysql 
validation 依赖包 
go get -u github.com/astaxie/beego/validation 
 
swagger 使用 
在 Router 函数中加上 
docs.SwaggerInfo.BasePath = "" 
r.GET("/swagger/*any", 
ginSwagger.WrapHandler(swaggerFiles.Handler)) 
在对应 handler 上加上 swagger 注释，然后命令行执行 swag init，启动服务。 
浏 览 器 访 问
http://localhost:8080/swagger/index.html
看 到
swagger UI ，
http://localhost:8080/swagger/doc.json 看到 json 样式； 
 
gorm 加上 logger 
go get –u gorm.io/gorm/logger 
newLogger := logger.New( 
   log.New(os.Stdout, "\r\n", log.LstdFlags), 
   logger.Config{ 
      SlowThreshold: time.Second, //慢 SQL 阈值 
      LogLevel: logger.Info, //日志级别 
      Colorful: true, //彩色 
   }) 
 
DB, _ = 
gorm.Open(mysql.Open(viper.GetString("mysql.dsn")), 
   &gorm.Config{Logger: newLogger}) 
访问接口，终端会有 sql 语句打印； 
 
gorm 里面如何批量插入某个字段 
在 GORM 中，可以使用 CreateInBatches 方法来批量插入数据。如果要批量插
入 某 个 字 段 ， 可 以 先 构 造 一 个 包 含 该 字 段 的 结 构 体 切 片 ， 然 后 使 用 
CreateInBatches 方法进行批量插入。 
 
下面是一个示例代码： 
type User struct { 
    ID   uint 
    Name string 
    Age  int 
    City string 
} 
 
// 构造包含 City 字段的结构体切片 
users := []User{ 
    {Name: "Alice", Age: 20, City: "New York"}, 
    {Name: "Bob", Age: 25, City: "Los Angeles"}, 
    {Name: "Charlie", Age: 30, City: "Chicago"}, 
} 
 
// 批量插入数据，只插入 City 字段 
result := db.CreateInBatches(users, len(users)).Select("City") 
 
if result.Error != nil { 
    // 处理错误 
} 
 
// 输出插入的记录数 
fmt.Printf("Inserted %d records\n", result.RowsAffected) 
在上面的代码中，我们先构造了一个包含 City 字段的结构体切片，然后使用 
CreateInBatches 方法进行批量插入。在调用 CreateInBatches 方法时，我们指定
了要插入的记录数和要选择的字段（即只插入 City 字段）。最后，我们可以通
过 result.RowsAffected 获取插入的记录数。 
 
gorm 里面更新有几种方式？ 
在 GORM 中，更新数据有以下几种方式： 
1. 使用 Update 方法更新单条记录 
Update 方法可以用于更新单条记录，它接收一个结构体或 map 参数，表示要更
新的字段和值。例如： 
db.Model(&User{}).Where("id = ?", 1).Update("name", "Alice") 
上面的代码会将 id 为 1 的 User 记录的 name 字段更新为 "Alice"。 
2. 使用 Updates 方法更新单条记录 
Updates 方法可以用于更新单条记录，它接收一个结构体或 map 参数，表示要
更新的多个字段和值。例如： 
db.Model(&User{}).Where("id = ?", 1).Updates(map[string]interface{}{"name": 
"Alice", "age": 20}) 
上面的代码会将 id 为 1 的 User 记录的 name 字段更新为 "Alice"，age 字段
更新为 20。 
3. 使用 UpdateColumn 方法更新单个字段 
UpdateColumn 方法可以用于更新单个字段，它接收两个参数，第一个参数表示
要更新的字段名，第二个参数表示要更新的值。例如： 
db.Model(&User{}).Where("id = ?", 1).UpdateColumn("name", "Alice") 
上面的代码会将 id 为 1 的 User 记录的 name 字段更新为 "Alice"。 
4．使用 UpdateColumns 方法更新多个字段 
UpdateColumns 方法可以用于更新多个字段，它接收一个结构体或 map 参数，
表示要更新的多个字段和值。与 Updates 方法不同的是，UpdateColumns 方法只
更新指定的字段，不会更新其他字段。例如： 
db.Model(&User{}).Where("id 
= 
?", 
1).UpdateColumns(map[string]interface{}{"name": "Alice", "age": 20}) 
上面的代码会将 id 为 1 的 User 记录的 name 字段更新为 "Alice"，age 字段
更新为 20。其他字段不会被更新。 
5. 使用 Save 方法更新记录 
Save 方法可以用于更新记录，它接收一个结构体参数，表示要更新的记录。如
果该记录的主键已经存在，则会更新该记录；否则会插入一条新记录。例如： 
user := User{ID: 1, Name: "Alice", Age: 20} 
db.Save(&user) 
上面的代码会将 id 为 1 的 User 记录的 name 字段更新为 "Alice"，age 字段
更新为 20。如果该记录不存在，则会插入一条新记录。 
需要注意的是，以上方法在执行时都会生成 SQL 语句并执行，可以通过 
db.Debug().Updates() 等方法查看生成的 SQL 语句。 
 
 
GIN 怎么做参数校验？ 
go 采用 validator 作参数校验。 
它具有以下独特功能： 
1. 使用验证 tag 或自定义 validator 进行跨字段 Field 和跨结构体验证； 
2. 允许切片、数组和哈希表，多维字段的任何或所有级别进行校验； 
3. 能够对哈希表 key 和 value 进行验证； 
4. 通过在验证之前确定它的基础类型来处理类型接口； 
5. 别名验证标签，允许将多个验证映射到单个标签，以便更轻松地定义结构体上
的验证； 
6. gin web 框架的默认验证器； 
 
 
 
你项目有优雅的启停吗？ 
所谓「优雅」启停就是在启动退出服务时要满足以下几个条件： 
1. 不可以关闭现有连接（进程） 
2. 新的进程启动并「接管」旧进程 
3. 连接要随时响应用户请求，不可以出现拒绝请求的情况 
4. 停止的时候，必须处理完既有连接，并且停止接收新的连接。 
为此我们必须引用信号来完成这些目的： 
启动： 
1. 监听 SIGHUP（在用户终端连接(正常或非正常)结束时发出）； 
2. 收到信号后将服务监听的文件描述符传递给新的子进程，此时新老进程同时
接收请求； 
退出： 
1. 监听 SIGINT 和 SIGSTP 和 SIGQUIT 等。 
2. 父进程停止接收新请求，等待旧请求完成（或超时）； 
3. 父进程退出。 
 
 
RPC 
grpc 是 Google 公司开源的一种高性能、跨语言的远程过程调用（RPC）框架。
它可以让不同语言的应用程序之间进行通信，支持多种语言，包括 Go、Java、
C++、Python 等。grpc 使用了 Google 开源的 Protocol Buffers 作为数据格式，这
种数据格式比 JSON 和 XML 更加高效，更加紧凑。 
grpc 的主要特点是高效、可靠、跨平台、易于扩展。它使用 HTTP/2 协议进行通
信，可以在客户端和服务器之间建立长连接，从而提高通信的效率。它还支持 TLS
加密，可以保证通信的安全性。另外，grpc 还支持流式传输和双向流式传输，可
以在客户端和服务器之间进行大规模的数据交换。 
在 Go 语言中使用 grpc 非常简单。首先需要安装 grpc 和 protobuf 的 Go 语言库。
然后，定义一个 protobuf 文件，用于描述 RPC 接口和数据类型。接下来，使用
protobuf 的编译器将 protobuf 文件编译成 Go 语言代码。最后，使用 Go 语言代码
实现 RPC 服务端和客户端。 
RPC 工作原理 
远程过程调用协议，是一种通过网络从远程计算机程序上请求服务，而不需要了
解底层网络技术的协议。它假定某些传输协议的存在，如 TCP 或 UDP，以便为
通信程序之间携带信息数据。通过它可以使函数调用模式网络化。在 OSI 网络通
信模型中，RPC 跨越了传输层和应用层。RPC 使得开发包括网络分布式多程序
在内的应用程序更加容易。 
RPC 工作流程图 
 
运行时,一次客户机对服务器的 RPC 调用,其内部操作大致有如下十步： 
1. 调用客户端句柄；执行传送参数； 
2. 调用本地系统内核发送网络消息； 
3. 消息传送到远程主机； 
4. 服务器句柄得到消息并取得参数； 
5. 执行远程过程； 
6. 执行的过程将结果返回服务器句柄； 
7. 服务器句柄返回结果，调用远程系统内核； 
8. 消息传回本地主机； 
9. 客户句柄由内核接收消息； 
10. 客户接收句柄返回的数据。 
gRPC 是什么？ 
基于 go 的远程过程调用。RPC 框架的目标就是让远程服务调用更加简单、透明，
RPC 框架负责屏蔽底层的传输方式（TCP 或者 UDP）、序列化方式（XML/Json/ 
二进制）和通信细节。服务调用者可以像调用本地接口一样调用远程的服务提供
者，而不需要关心底层通信细节和调用过程。 
 
 
grpc 为啥好，基本原理是什么，和 http 比呢 
官方介绍：gRPC 是一个现代开源的高性能远程过程调用 (RPC) 框架，可以在
任何环境中运行。它可以通过对负载平衡、跟踪、健康检查和身份验证的可插拔
支持有效地连接数据中心内和跨数据中心的服务。它也适用于分布式计算的最后
一英里，将设备、移动应用程序和浏览器连接到后端服务。 
区别： - rpc 是远程过程调用，就是本地去调用一个远程的函数，而 http 是通过 
url 和符合 restful 风格的数据包去发送和获取数据； - rpc 的一般使用的编解码
协议更加高效，比如 grpc 使用 protobuf 编解码。而 http 的一般使用 json 进行编
解码，数据相比 rpc 更加直观，但是数据包也更大，效率低下； - rpc 一般用在
服务内部的相互调用，而 http 则用于和用户交互； 相似点： 都有类似的机制，
例如 grpc 的 metadata 机制和 http 的头机制作用相似，而且 web 框架，和 rpc 框
架中都有拦截器的概念。grpc 使用的是 http2.0 协议。  
 
面试题 
 
= 和 := 的区别？ok 
=是赋值变量，:=是定义变量。 
❤ 如何高效地拼接字符串 ok 
拼接字符串的方式有：+ , fmt.Sprintf , strings.Builder, bytes.Buffer, strings.Join 
1、"+" 
使用+操作符进行拼接时，会对字符串进行遍历，计算并开辟一个新的空间来存
储原来的两个字符串。 
2、fmt.Sprintf 
由于采用了接口参数，必须要用反射获取值，因此有性能损耗。 
3、strings.Builder： 
用 WriteString()进行拼接，内部实现是指针+切片，同时 String()返回拼接后的字
符串，它是直接把[]byte 转换为 string，从而避免变量拷贝。 
4、bytes.Buffer 
bytes.Buffer 是一个一个缓冲 byte 类型的缓冲器，这个缓冲器里存放着都是 byte， 
bytes.buffer 底层也是一个[]byte 切片。 
5、strings.join 
strings.join 也是基于 strings.builder 来实现的，并且可以自定义分隔符，在 join 方
法内调用了 b.Grow(n)方法，这个是进行初步的容量分配，而前面计算的 n 的长
度就是我们要拼接的 slice 的长度，因为我们传入切片长度固定，所以提前进行
容量分配可以减少内存分配，很高效。 
性能比较： 
strings.Join ≈ strings.Builder > bytes.Buffer > "+" > fmt.Sprintf 
5 种拼接方法的实例代码 
func main(){ 
 
a := []string{"a", "b", "c"} 
 
//方式 1：+ 
 
ret := a[0] + a[1] + a[2] 
 
//方式 2：fmt.Sprintf 
 
ret := fmt.Sprintf("%s%s%s", a[0],a[1],a[2]) 
 
//方式 3：strings.Builder 
 
var sb strings.Builder 
 
sb.WriteString(a[0]) 
 
sb.WriteString(a[1]) 
 
sb.WriteString(a[2]) 
 
ret := sb.String() 
 
//方式 4：bytes.Buffer 
 
buf := new(bytes.Buffer) 
 
buf.Write(a[0]) 
 
buf.Write(a[1]) 
 
buf.Write(a[2]) 
 
ret := buf.String() 
 
//方式 5：strings.Join 
 
ret := strings.Join(a,"") 
} 
什么是 rune 类型 ok 
ASCII 码只需要 7 bit 就可以完整地表示，但只能表示英文字母在内的 128 个字
符，为了表示世界上大部分的文字系统，发明了 Unicode， 它是 ASCII 的超集，
包含世界上书写系统中存在的所有字符，并为每个代码分配一个标准编号（称为
Unicode CodePoint），在 Go 语言中称之为 rune，是 int32 类型的别名。 
Go 语言中，字符串的底层表示是 byte (8 bit) 序列，而非 rune (32 bit) 序列。 
golang 中 string 底层是通过 byte 数组实现的。中文字符在 unicode 下占 2 个字
节，在 utf-8 编码下占 3 个字节，而 golang 默认编码正好是 utf-8。 
func main() { 
 
var str = "Go 编程语言" 
 
for i := 0;i < len(str);i++ { 
 
 
fmt.Printf("%c ", str[i]) 
 
} 
 
fmt.Println() 
 
runes := []rune(str) 
 
for i := 0;i < len(runes);i++ { 
 
 
fmt.Printf("%c", runes[i]) 
 
} 
} 
打印： 
G o ç ¼ –  ç ¨ ‹  è ¯  - è ¨ 
Go 编程语言 
# 为什么会出现这种情况呢，原因就是 UTF-8 编码的中文它不是只占一个字节。因此
我们试图打印字符，假设每个代码点都是一个字节长，这是错误的。 
在 UTF-8 编码中，一个代码点可以占用 1 个以上的字节。 
rune 是 Go 中的内置类型，它是 int32 的别名。rune 代表 Go 中的 unicode 代码点。
代码点占用多少字节并不重要，可以用一个符文来表示。 
如何判断 map 中是否包含某个 key ？ok 
var sample map[int]int 
if _, ok := sample[10]; ok { 
 
} else { 
 
} 
Go 支持默认参数或可选参数吗？ok 
不支持。但是可以利用结构体参数，或者...传入参数切片数组。 
// 这个函数可以传入任意数量的整型参数 
func sum(nums ...int) { 
  total := 0 
  for _, num := range nums { 
      total += num 
  } 
  fmt.Println(total) 
} 
defer 的执行顺序 
defer 执行顺序和调用顺序相反，类似于栈后进先出(LIFO)。 
defer 在 return 之后执行，但在函数退出之前，defer 可以修改返回值。下面是一
个例子： 
func test() int { 
 
i := 0 
 
defer func() { 
 
 
fmt.Println("defer1") 
 
}() 
 
defer func() { 
 
 
i += 1 
 
 
fmt.Println("defer2") 
 
}() 
 
return i 
} 
 
func main() { 
 
fmt.Println("return", test()) 
} 
 
// defer2 
// defer1 
// return 0 
上面这个例子中，test 返回值并没有修改，这是由于 Go 的返回机制决定的，执
行 Return 语句后，Go 会创建一个临时变量保存返回值。如果是有名返回（也就
是指明返回值 func test() (i int)） 
func test() (i int) { 
 
i = 0 
 
defer func() { 
 
 
i += 1 
 
 
fmt.Println("defer2") 
 
}() 
 
return i 
} 
 
func main() { 
 
fmt.Println("return", test()) 
} 
// defer2 
// return 1 
这个例子中，返回值被修改了。对于有名返回值的函数，执行 return 语句时，并
不会再创建临时变量保存，因此，defer 语句修改了 i，即对返回值产生了影响。 
func main() { 
 
var a bool = true 
 
defer func(){ 
 
 
fmt.Println("1") 
 
}() 
 
if a == true { 
 
 
fmt.Println("2") 
 
 
return 
 
} 
 
defer func(){ 
 
 
fmt.Println("3") 
 
}() 
} 
// 输出 2 1 
// defer 关键字后面的函数或者方法想要执行必须先注册，return 之后的 defer 
是不能注册的， 也就不能执行后面的函数或方法 
 
如何交换 2 个变量的值？ok 
对于变量而言 a,b = b,a； 对于指针而言*a,*b = *b, *a 
Go 语言 tag 的用处？ 
tag 可以为结构体成员提供属性。常见的： 
1. json 序列化或反序列化时字段的名称 
2. db: sqlx 模块中对应的数据库字段名 
3. form: gin 框架中对应的前端的数据字段名 
4. binding: 搭配 form 使用, 默认如果没查找到结构体中的某个字段则不报错值
为空, binding 为 required 代表没找到返回错误给前端 
 
如何获取一个结构体的所有 tag？ 
利用反射： 
import reflect 
type Author struct { 
 
Name         int      `json:Name` 
 
Publications []string `json:Publication,omitempty` 
} 
 
func main() { 
 
t := reflect.TypeOf(Author{}) 
 
for i := 0; i < t.NumField(); i++ { 
 
 
name := t.Field(i).Name 
 
 
s, _ := t.FieldByName(name) 
 
 
fmt.Println(name, s.Tag) 
 
} 
} 
上述例子中，reflect.TypeOf 方法获取对象的类型，之后 NumField()获取结构体成
员的数量。 通过 Field(i)获取第 i 个成员的名字。 再通过其 Tag 方法获得标签。 
结构体打印时，%v 和 %+v 的区别 ok 
%v 输出结构体各成员的值； 
%+v 输出结构体各成员的名称和值； 
%#v 输出结构体名称和结构体各成员的名称和值 
 
Go 语言中如何表示枚举值(enums)？ 
在常量中用 iota 可以表示枚举。iota 从 0 开始。 
const ( 
 
B = 1 << (10 * iota) 
 
KiB  
 
MiB 
 
GiB 
 
TiB 
 
PiB 
 
EiB 
) 
空 struct{} 的用途 ok 
1、用 map 模拟一个 set，那么就要把值置为 struct{}，struct{}本身不占任何空间，
可以避免任何多余的内存分配。 
type Set map[string]struct{} 
 
func main() { 
 
set := make(Set) 
 
 
for _, item := range []string{"A", "A", "B", "C"} { 
 
 
set[item] = struct{}{} 
 
} 
 
fmt.Println(len(set)) // 3 
 
if _, ok := set["A"]; ok { 
 
 
fmt.Println("A exists") // A exists 
 
} 
} 
2、有时候给通道发送一个空结构体,channel<-struct{}{}，也是节省了空间。 
func main() { 
 
ch := make(chan struct{}, 1) 
 
go func() { 
 
 
<-ch 
 
 
// do something 
 
}() 
 
ch <- struct{}{} 
 
// ... 
} 
3、仅有方法的结构体 
type Lamp struct{} 
go 里面的 int 和 int32 是同一个概念吗？ok 
不是一个概念！千万不能混淆。go 语言中的 int 的大小是和操作系统位数相关的，
如果是 32 位操作系统，int 类型的大小就是 4 字节。如果是 64 位操作系统，int
类型的大小就是 8 个字节。除此之外 uint 也与操作系统有关。 
int8 占 1 个字节，int16 占 2 个字节，int32 占 4 个字节，int64 占 8 个字节。 
init() 函数是什么时候执行的？ok 
简答： 在 main 函数之前执行。 
详细：init()函数是 go 初始化的一部分，由 runtime 初始化每个导入的包，初始化
不是按照从上到下的导入顺序，而是按照解析的依赖关系，没有依赖的包最先初
始化。 
每个包首先初始化包作用域的常量和变量（常量优先于变量），然后执行包的 init()
函数。同一个包，甚至是同一个源文件可以有多个 init()函数。init()函数没有入参
和返回值，不能被其他函数调用，同一个包内多个 init()函数的执行顺序不作保
证。 
执行顺序：import –> const –> var –>init()–>main() 
一个文件可以有多个 init()函数！ 
init 函数非常特殊： 
• 
初始化不能采用初始化表达式初始化的变量； 
• 
程序运行前执行注册 
• 
实现 sync.Once 功能 
• 
不能被其它函数调用 
• 
init 函数没有入口参数和返回值： 
• 
每个包可以有多个 init 函数，每个源文件也可以有多个 init 函数。 
• 
同一个包的 init 执行顺序，golang 没有明确定义，编程时要注意程序不要依
赖这个执行顺序。 
• 
不同包的 init 函数按照包导入的依赖关系决定执行顺序。 
 
❤new 和 make 的区别？ 
 
make 
make(T, args) 返回的是初始化之后的 T 类型的值，这个新值并不是 T 类型的零
值，也不是指针*T，是经过初始化之后的 T 的引用。make 也是内建函数； 
slice := make([]int, 0, 100) 
hash := make(map[int]bool, 10) 
ch := make(chan int, 5) 
make 只能用于 slice,map,channel 三种类型, 并且只能是这三种对象 
 
new 
i := new(int) 
// 两者等价 
var v int 
i := &v 
new(T)为一个 T 类型新值分配空间并将此空间初始化为 T 的零值,返回的是新值
的地址,也就是 T 类型的指针*T,该指针指向 T 的新分配的零值； 
 
make 和 new 的区别 
1. new(T) 返回 T 的指针*T 并指向 T 的零值； 
2. make(T)返回的初始化的 T，只能用于 slice、map、channel，要获得一个显式的
指针，使用 new 进行分配，或者显式地使用一个变量的地址； 
3. new 函数分配内存，make 函数初始化。 
请你讲一下 Go 面向对象是如何实现的？ ok 
Go 实现面向对象的两个关键是 struct 和 interface。 
封装：对于同一个包，对象对包内的文件可见；对不同的包，需要将对象以大写
开头才是可见的。 
继承：继承是编译时特征，在 struct 内加入所需要继承的类即可： 
type A struct{} 
type B struct{  
A 
} 
多态：多态是运行时特征，Go 多态通过 interface 来实现。类型和接口是松耦合
的，某个类型的实例可以赋给它所实现的任意接口类型的变量。 
Go 支持多重继承，就是在类型中嵌入所有必要的父类型。 
 
uint 型变量值分别为 1，2，它们相减的结果是多
少？ 
var a uint = 1 
var b uint = 2 
fmt.Println(a - b) // 结果会溢出，打印 18446744073709551615，如果是 32 位系统，结
果是 2^32-1，如果是 64 位系统，结果 2^64-1； 
fmt.Println(math.MinInt, uint(math.MaxInt * 2)) //-9223372036854775808 
18446744073709551614 
uint 范围：32 位系统 4 个字节--0~2^32-1；64 位系统 8 个字节—0~2^64-1。 
下面这句代码是什么作用，为什么要定义一个空
值？ 
type GobCodec struct{ 
conn io.ReadWriteCloser 
buf *bufio.Writer 
dec *gob.Decoder 
enc *gob.Encoder 
} 
 
type Codec interface { 
io.Closer 
ReadHeader(*Header) error 
ReadBody(interface{}) error 
Write(*Header, interface{}) error 
} 
 
var _ Codec = (*GobCodec)(nil) 
答：将 nil 转换为 GobCodec 类型，然后再转换为 Codec 接口，如果转换失
败，说明 GobCodec 没有实现 Codec 接口的所有方法。 
 
需要面试者有一定的大型项目经验，了解使用微服务，etcd，gin，gorm，
gRPC 等典型框架等模型或框架。 
微服务了解吗？ 
微服务是一种开发软件的架构和组织方法，其中软件由通过明确定义的 API 
进行通信的小型独立服务组成。微服务架构使应用程序更易于扩展和更快地开
发，从而加速创新并缩短新功能的上市时间。 
 
微服务示意图 
微服务有着自主，专用，灵活性等优点。 
参考资料：什么是微服务？| AWS 
服务发现是怎么做的？ 
主要有两种服务发现机制：客户端发现和服务端发现。 
客户端发现模式：当我们使用客户端发现的时候，客户端负责决定可用服务实
例的网络地址并且在集群中对请求负载均衡, 客户端访问服务登记表，也就是
一个可用服务的数据库，然后客户端使用一种负载均衡算法选择一个可用的服
务实例然后发起请求。该模式如下图所示： 
 
客户端发现模式 
服务端发现模式：客户端通过负载均衡器向某个服务提出请求，负载均衡器查
询服务注册表，并将请求转发到可用的服务实例。如同客户端发现，服务实例
在服务注册表中注册或注销。 
服务端发现模式 
参考资料：「Chris Richardson 微服务系列」服务发现的可行方案以及实践案
例 
ETCD 用过吗？ok 
etcd 是一个高度一致的分布式键值存储，它提供了一种可靠的方式来存储需要
由分布式系统或机器集群访问的数据。它可以优雅地处理网络分区期间的领导
者选举，即使在领导者节点中也可以容忍机器故障。 
etcd 是用 Go 语言编写的，它具有出色的跨平台支持，小的二进制文件和强大
的社区。etcd 机器之间的通信通过 Raft 共识算法处理。 
 
etcd 是一个高可用的键值存储系统，用于共享配置和服务发现。下面是 etcd 
搭建和使用的简单步骤： 
1. 下载安装 etcd。 
2. 配置 etcd 集群，在生产环境中为了高可用性，往往需要将 etcd 部署成集
群形式，避免单点故障。。 
3. 配置 etcd TLS 加密通讯。etcd 支持通过 TLS 协议的加密通讯，TLS 通
道可以用于加密伙伴间的内部集群通讯，也可以用于加密客户端请求。 
4. 编写客户端代码，使用 etcd 提供的 API 访问 etcd。etcd 提供多种语言
的客户端库，可以根据需要选择使用。具体使用方法可以参考 etcd 的官方文
档。 
总之，etcd 的搭建和使用需要一定技术水平和经验，需要仔细阅读相关文档和
资料，并进行适当的实践。 
 
中间件用过吗？ 
Middleware 是 Web 的重要组成部分，中间件（通常）是一小段代码，它们接
受一个请求，对其进行处理，每个中间件只处理一件事情，完成后将其传递给
另一个中间件或最终处理程序，这样就做到了程序的解耦。 
 
持久化怎么做的？ 
所谓持久化就是将要保存的字符串写到硬盘等设备。 
 
最简单的方式就是采用 ioutil 的 WriteFile()方法将字符串写到磁盘上，这种方法
面临格式化方面的问题。 
 
更好的做法是将数据按照固定协议进行组织再进行读写，比如 JSON，XML，
Gob，csv 等。 
 
如果要考虑高并发和高可用，必须把数据放入到数据库中，比如 MySQL，
PostgreDB，MongoDB 等。 
参考链接：Golang 持久化 
 
该试题需要面试者有非常丰富的项目阅历和底层原理经验，熟练使用微服务，
etcd，gin，gorm，gRPC 等典型框架等模型或框架。 
 
map 的底层实现 
源码位于 src\runtime\map.go 中。 
go 的 map 和 C++map 不一样，底层实现是哈希表，包括两个部分：hmap 和
bucket。 
里面最重要的是 buckets（桶），buckets 是一个指针，最终它指向的是一个结
构体： 
// A bucket for a Go map. 
type bmap struct { 
    tophash [bucketCnt]uint8 
} 
每个 bucket 固定包含 8 个 key 和 value(可以查看源码 bucketCnt=8).实现上面
是一个固定的大小连续内存块，分成四部分：每个条目的状态，8 个 key 值，8
个 value 值，指向下个 bucket 的指针。 
创建哈希表使用的是 makemap 函数.map 的一个关键点在于，哈希函数的选
择。在程序启动时，会检测 cpu 是否支持 aes，如果支持，则使用 aes 
hash，否则使用 memhash。这是在函数 alginit() 中完成，位于路径：
src/runtime/alg.go 下。 
map 查找就是将 key 哈希后得到 64 位（64 位机）用最后 B 个比特位计算在哪
个桶。在 bucket 中，从前往后找到第一个空位。这样，在查找某个 key 时，
先找到对应的桶，再去遍历 bucket 中的 key。 
关于 map 的查找和扩容可以参考 map 的用法到 map 底层实现分析。 
go GC 的原理知道吗？ 
如果需要从源码角度解释 GC，推荐阅读（非常详细，图文并茂）： 
https://draveness.me/golang/docs/part3-runtime/ch07-memory/golang-
garbage-collector/ 
go 里用过哪些设计模式 ? 
 
工厂方法模式 
问题描述：假设你正在开发一款物流管理应用。 最初版本只能处理卡
车运输， 因此大部分代码都在位于名为 卡车的类中。 
一段时间后， 这款应用变得极受欢迎。 你每天都能收到十几次来自
海运公司的请求， 希望应用能够支持海上物流功能。 
解决方案：我们抽象出一个物流工厂，然后分别实例化陆上，海上物
流等工厂类，再生产对应产品。 
首先写一个表示通用物流的接口： 
type iLogistics interface { 
 
setName(string) 
 
getName() string 
} 
之后就是陆上物流的工厂类： 
type RoadLogistics struct { 
 
name string 
} 
 
func (r *RoadLogistics) setName(name string) { 
 
r.name = name 
} 
 
func (r *RoadLogistics) getName() string { 
 
return r.name 
} 
 
var roadInstance iLogistics = (*RoadLogistics)(nil)  // 验
证 RoadLogistics 是否实习了接口 iLogistics 
以及海上物流的工厂类，因为类似这里就省略了。 
之后就是具体产品了，比如陆上的有汽车，火车和高铁。 
type Vehicle struct { 
 
RoadLogistics 
} 
 
func NewVehicle() (v *Vehicle) { 
 
v = new(Vehicle) 
 
v.RoadLogistics = RoadLogistics{ 
 
 
Name: "vehicle", 
 
} 
 
return v 
} 
上面是汽车的例子，我们再写一个火车的例子： 
type Train struct { 
 
RoadLogistics 
} 
 
func NewTrain() (t *Train) { 
 
t = new(Train) 
 
t.RoadLogistics = RoadLogistics{ 
 
 
Name: "train", 
 
} 
 
return t 
} 
然后我们可以根据类别，直接初始化对应的类： 
func getLogistics(means string) (i iLogistics, err 
error){ 
 
if  means == "vehicle" { 
 
 
return NewVehicle(), nil 
 
}else if means == "train"{ 
 
 
return NewTrain(), nil 
 
} 
 
return nil, errors.New("unknown means of 
transportation") 
} 
客户端使用，直接调用 getLogistics 就好。 
抽象工厂模式 
抽象工厂模式是一种创建型设计模式，它能创建一系列相关的对象，
而无需指定其具体类。 
❓问题描述：假设一下，如果你想要购买一组运动装备，比如一双鞋
与一件衬衫这样由两种不同产品组合而成的套装。相信你会想去购买
同一品牌的商品，这样商品之间能够互相搭配起来。 
解决方案：首先，抽象工厂模式为系列中的每件产品明确声明接口
（例如 T 恤或者鞋子）。然后，确保所有产品变体都继承这些接口。 
下面是一个抽象工厂接口，它能产生工厂类 
type iSportsFactory interface { 
    makeShoe() iShoe 
    makeShirt() iShirt 
} 
 
func getSportsFactory(brand string) (iSportsFactory, 
error) { 
    if brand == "adidas" { 
        return &adidas{}, nil 
    } 
 
    if brand == "nike" { 
        return &nike{}, nil 
    } 
 
    return nil, fmt.Errorf("Wrong brand type passed") 
} 
现在有一个 adidas 的工厂： 
type adidas struct { 
} 
 
func (a *adidas) makeShoe() iShoe { 
    return &adidasShoe{ 
        shoe: shoe{ 
            logo: "adidas", 
            size: 14, 
        }, 
    } 
} 
 
func (a *adidas) makeShirt() iShirt { 
    return &adidasShirt{ 
        shirt: shirt{ 
            logo: "adidas", 
            size: 14, 
        }, 
    } 
} 
和 nike 的工厂（略）。 
然后是抽象的产品，它有尺寸和 logo 两个属性： 
type iShoe interface { 
    setLogo(logo string) 
    setSize(size int) 
    getLogo() string 
    getSize() int 
} 
 
type shoe struct { 
    logo string 
    size int 
} 
 
func (s *shoe) setLogo(logo string) { 
    s.logo = logo 
} 
 
func (s *shoe) getLogo() string { 
    return s.logo 
} 
 
func (s *shoe) setSize(size int) { 
    s.size = size 
} 
 
func (s *shoe) getSize() int { 
    return s.size 
} 
adidas 工厂必须能生产鞋子： 
type adidasShoe struct { 
    shoe 
} 
客户端代码： 
func main() { 
    adidasFactory, _ := getSportsFactory("adidas") 
    nikeFactory, _ := getSportsFactory("nike") 
 
    nikeShoe := nikeFactory.makeShoe() 
    nikeShirt := nikeFactory.makeShirt() 
 
    adidasShoe := adidasFactory.makeShoe() 
    adidasShirt := adidasFactory.makeShirt() 
} 
工厂方法模式和抽象工厂模式的区别在于：前者实例化具体的产品，
后者实例化具体的工厂，每个工厂再实例化同样的产品系列。 
 
单例模式 
假设一下，如果你想要为你的工程建立一个日志 Logger 模块，但你
只需要全局唯一的日志系统，不希望日志被记录到乱七八糟的位置。 
解决方案：我们需要考虑两个问题：1.如何确保全局唯一，2.如何保证
并发控制。 
go 里面有 sync.Once 方法，能非常优雅的解决这些问题。 
type Logger struct { 
} 
 
var logger *Logger 
 
var once sync.Once 
 
func getLoggerInstance() *Logger { 
 
if logger == nil { 
 
 
once.Do( 
 
 
 
func() { 
 
 
 
 
logger = &Logger{} 
 
 
 
}) 
 
} 
 
return logger 
} 
sync.Once 内部原理是使用了一个互斥锁，每次检查该变量有无被分
配（是否为 nil），只有为 nil 才初始化实例。 
假设你的构造函数有很多参数，那么调用该函数将非常不方便。在 C#
和 python 这样支持重载的语言还好，对于 go 来说就是灾难。 
生成器模式 
❓问题描述：假设一下，我们需要在游戏里设计不同的虚拟房屋，每
个房子有不同的门和窗户等属性。现在有两种类型的房屋 normal 和
igloo（木制）。 
解决方案：我们需要考虑两个问题：1.如何确保全局唯一，2.如何保证
并发控制。 
定义生成器接口： 
type iBuilder interface { 
    setWindowType() 
    setDoorType() 
    setNumFloor() 
    getHouse() house 
} 
 
func getBuilder(builderType string) iBuilder { 
    if builderType == "normal" { 
        return &normalBuilder{} 
    } 
 
    if builderType == "igloo" { 
        return &iglooBuilder{} 
    } 
    return nil 
} 
具体的房屋生成器（以 normal 为例子）： 
type normalBuilder struct { 
    windowType string 
    doorType   string 
    floor      int 
} 
 
func newNormalBuilder() *normalBuilder { 
    return &normalBuilder{} 
} 
 
func (b *normalBuilder) setWindowType() { 
    b.windowType = "Wooden Window" 
} 
 
func (b *normalBuilder) setDoorType() { 
    b.doorType = "Wooden Door" 
} 
 
func (b *normalBuilder) setNumFloor() { 
    b.floor = 2 
} 
 
func (b *normalBuilder) getHouse() house { 
    return house{ 
        doorType:   b.doorType, 
        windowType: b.windowType, 
        floor:      b.floor, 
    } 
} 
房屋（产品）： 
type house struct { 
    windowType string 
    doorType   string 
    floor      int 
} 
定义一个主管，他手下有可以修建所有类型房屋的工人。 
type director struct { 
    builder iBuilder 
} 
 
func newDirector(b iBuilder) *director { 
    return &director{ 
        builder: b, 
    } 
} 
 
func (d *director) setBuilder(b iBuilder) { 
    d.builder = b 
} 
 
func (d *director) buildHouse() house { 
    d.builder.setDoorType() 
    d.builder.setWindowType() 
    d.builder.setNumFloor() 
    return d.builder.getHouse() 
} 
客户端代码： 
func main() { 
    normalBuilder := getBuilder("normal") 
    iglooBuilder := getBuilder("igloo") 
 
    director := newDirector(normalBuilder) 
    normalHouse := director.buildHouse() 
 
    fmt.Printf("Normal House Door Type: %s\n", 
normalHouse.doorType) 
    fmt.Printf("Normal House Window Type: %s\n", 
normalHouse.windowType) 
    fmt.Printf("Normal House Num Floor: %d\n", 
normalHouse.floor) 
 
    director.setBuilder(iglooBuilder) 
    iglooHouse := director.buildHouse() 
 
    fmt.Printf("\nIgloo House Door Type: %s\n", 
iglooHouse.doorType) 
    fmt.Printf("Igloo House Window Type: %s\n", 
iglooHouse.windowType) 
    fmt.Printf("Igloo House Num Floor: %d\n", 
iglooHouse.floor) 
} 
原型模式 
原型模式使你能够复制已有对象，无需使代码依赖它们所属的类。 
❓问题描述：假设一下，你有一个原型，你想复制出一个一模一样的
复制品，但不巧的是，类的某些成员（比如登录模块）是私有的。 
解决方案：在原型类实现公共方法 clone()能够返回对象的复制。 
让我们尝试通过基于操作系统文件系统的示例来理解原型模式。 操作
系统的文件系统是递归的： 文件夹中包含文件和文件夹， 其中又包
含文件和文件夹， 以此类推。 
每个文件和文件夹都可用一个 inode 接口来表示。  inode 接口中同
样也有 clone 克隆功能。 
file 文件和 folder 文件夹结构体都实现了 print 打印和 clone 方
法， 因为它们都是 inode 类型。 同时， 注意 file 和 folder 中
的 clone 方法。 这两者的 clone 方法都会返回相应文件或文件夹的
副本。 同时在克隆过程中， 我们会在其名称后面添加 “_clone” 
字样。 
原型接口： 
type inode interface { 
    print(string) 
    clone() inode 
} 
文件原型： 
type file struct { 
    name string 
} 
 
func (f *file) print(indentation string) { 
    fmt.Println(indentation + f.name) 
} 
 
func (f *file) clone() inode { 
    return &file{name: f.name + "_clone"} 
} 
文件夹原型： 
type folder struct { 
    children []inode 
    name      string 
} 
 
func (f *folder) print(indentation string) { 
    fmt.Println(indentation + f.name) 
    for _, i := range f.children { 
        i.print(indentation + indentation) 
    } 
} 
 
func (f *folder) clone() inode { 
    cloneFolder := &folder{name: f.name + "_clone"} 
    var tempChildren []inode 
    for _, i := range f.children { 
        copy := i.clone() 
        tempChildren = append(tempChildren, copy) 
    } 
    cloneFolder.children = tempChildren 
    return cloneFolder 
} 
客户端代码： 
func main() { 
    file1 := &file{name: "File1"} 
    file2 := &file{name: "File2"} 
    file3 := &file{name: "File3"} 
 
    folder1 := &folder{ 
        children: []inode{file1}, 
        name:      "Folder1", 
    } 
 
    folder2 := &folder{ 
        children: []inode{folder1, file2, file3}, 
        name:      "Folder2", 
    } 
    fmt.Println("\nPrinting hierarchy for Folder2") 
    folder2.print("  ") 
 
    cloneFolder := folder2.clone() 
    fmt.Println("\nPrinting hierarchy for clone Folder") 
    cloneFolder.print("  ") 
} 
 
 
Go 设计模式常见面试题【2022 版】7 赞同 · 4 评论文章 
go 的调试/分析工具用过哪些。 
go 的自带工具链相当丰富， 
 
go cover : 测试代码覆盖率； 
 
godoc: 用于生成 go 文档； 
 
pprof：用于性能调优，针对 cpu，内存和并发； 
 
race：用于竞争检测； 
进程被 kill，如何保证所有 goroutine 顺利退出 
goroutine 监听 SIGKILL 信号，一旦接收到 SIGKILL，则立刻退出。可采用
select 方法。 
var wg = &sync.WaitGroup{} 
 
func main() { 
 
wg.Add(1) 
 
 
go func() { 
 
 
c1 := make(chan os.Signal, 1) 
 
 
signal.Notify(c1, syscall.SIGINT, syscall.SIGTERM, syscall.SIGQUIT) 
 
 
fmt.Printf("goroutine 1 receive a signal : %v\n\n", <-c1) 
 
 
wg.Done() 
 
}() 
 
 
wg.Wait() 
 
fmt.Printf("all groutine done!\n") 
} 
说说 context 包的作用？你用过哪些，原理知道
吗？ 
context 可以用来在 goroutine 之间传递上下文信息，相同的 context 可以传递给
运行在不同 goroutine 中的函数，上下文对于多个 goroutine 同时使用是安全的，
context 包定义了上下文类型，可以使用 background、TODO 创建一个上下文，在
函数调用链之间传播 context，也可以使用 WithDeadline、WithTimeout、WithCancel 
或 WithValue 创建的修改副本替换它，听起来有点绕，其实总结起就是一句话：
context 的作用就是在不同的 goroutine 之间同步请求特定的数据、取消信号以及
处理请求的截止日期。 
context 携带数据： 
const ( 
 KEY = "trace_id" 
) 
 
func NewRequestID() string { 
 return strings.Replace(uuid.New().String(), "-", "", -1) 
} 
 
func NewContextWithTraceID() context.Context { 
 ctx := context.WithValue(context.Background(), KEY,NewRequestID()) 
 return ctx 
} 
 
func PrintLog(ctx context.Context, message string)  { 
 fmt.Printf("%s|info|trace_id=%s|%s",time.Now().Format("2006-01-02 15:04:05") , 
GetContextValue(ctx, KEY), message) 
} 
 
func GetContextValue(ctx context.Context,k string)  string{ 
 v, ok := ctx.Value(k).(string) 
 if !ok{ 
  return "" 
 } 
 return v 
} 
 
func ProcessEnter(ctx context.Context) { 
 PrintLog(ctx, "Golang 梦工厂") 
} 
 
 
func main()  { 
 ProcessEnter(NewContextWithTraceID()) 
} 
 
超时控制： 
ProcessEnter(NewContextWithTraceID()) 
} 
func main()  { 
 HttpHandler() 
} 
 
func NewContextWithTimeout() (context.Context,context.CancelFunc) { 
 return context.WithTimeout(context.Background(), 3 * time.Second) 
} 
 
func HttpHandler()  { 
 ctx, cancel := NewContextWithTimeout() 
 defer cancel() 
 deal(ctx) 
} 
 
func deal(ctx context.Context)  { 
 for i:=0; i< 10; i++ { 
  time.Sleep(1*time.Second) 
  select { 
  case <- ctx.Done(): 
   fmt.Println(ctx.Err()) 
   return 
  default: 
   fmt.Printf("deal time is %d\n", i) 
  } 
 } 
} 
 
// deal time is 0 
// deal time is 1 
// context deadline exceeded 
Go 中发生熔断怎么做的 
在 Go 中，熔断通常是由于一段服务的连续失败引起的，为避免故障扩散，需
要使用熔断机制保护底层资源。Go 语言提供了一些库和框架来实现熔断机
制，例如： 
Hystrix：Hystrix 是 Netflix 开源的一款熔断器组件，可以在 Go 程序中使用。
它通过统计系统的服务指标（如请求成功率、平均响应时间等）来观察是否需
要进行熔断，一旦达到设定的阈值就会执行熔断操作。 
Gobreaker：Gobreaker 是一个 Go 实现的熔断器库，支持自定义熔断器状态存
储和熔断器策略等功能，可以用于保护底层服务或资源不被过度使用。 
Resilience4j：Resilience4j 是一个面向函数式编程的熔断器库，支持多种熔断
器策略和监控方式，可以帮助开发者实现高可用的服务治理。 
总之，Go 提供了多种熔断器库和框架，开发者可以根据具体情况选择并使用
这些库来实现熔断机制，保障程序稳定性和可靠性。 
服务降级怎么搞 
当 Go 服务发生压力剧增时，为了保证核心业务的正常高效运行，需要采取服
务降级措施。下面是一些具体做法： 
针对不同服务和页面进行策略性地降级：通过对实际业务使用情况和流量的分
析，针对不同服务和页面进行策略性地降级，从而释放服务器资源，提高服务
可用性。 
对某些服务和页面采用简单的处理方式：对于一些重要但非核心的服务和页
面，可以采用一些简单的处理方式，如缓存数据、使用轻量级组件等，从而减
轻服务器压力。 
通过技术手段实现服务降级：可以通过技术手段实现服务降级，例如使用 
Hystrix 等熔断框架，当系统出现故障或超负荷时，自动切换到备份或降级服
务，避免发生系统瘫痪。 
总之，针对不同的场景和业务需求，开发人员需要根据实际情况采取适当的服
务降级措施，确保系统稳定运行。 
 
1 亿条数据动态增长，取 top10，怎么实现 
处理 1 亿条数据动态增长并取 TOP10 可以使用堆的方法。具体的做法如下： 
定义一个大根堆，初始化它的大小为 10，用于存放前 10 大的数据。 
遍历数据，对于每个新来的数据，与堆顶元素进行比较，如果新数据大于堆顶
元素，则将新数据插入到堆中，并弹出堆顶元素，以保证堆中始终是前 10 大
的数据。 
遍历完所有数据后，堆中剩余元素就是前 10 大的数据，按照从大到小的顺序
输出即可。 
由于堆的大小固定为 10，因此算法的时间复杂度为 O(nlogk)，其中 k 为堆的
大小，也就是 10。 
需要注意的是，如果数据量非常大，可能会涉及到内存限制问题，因此可以采
用分布式计算、MapReduce 等方法来处理大规模数据。 
 
 
 
总结 
Go 面试复习应该有所侧重，关注切片，通道，异常处理，Goroutine，GMP 模
型，字符串高效拼接，指针，反射，接口，sync。对于比较难懂的部分，GMP
模型和 GC 和内存管理，应该主动去看源码，然后慢慢理解。业务代码写多
了，自然就有理解了。 
 
fallthrough 
如果在执行完每个分支的代码后，还希望继续执行后续分支的代码，可以使
用 fallthrough 关键字来达到目的。 
 
 
nil 
nil 只能赋值给指针、chan、func、interface、map 或 slice 类型的变量，也可以
赋给 error； 
 
iota 
func main() { 
 
k := 6 
 
switch k { 
 
case 4: 
 
 
fmt.Println("was <= 4") 
 
 
fallthrough 
 
case 5: 
 
 
fmt.Println("was <= 5") 
 
 
fallthrough 
 
case 6: 
 
 
fmt.Println("was <= 6") 
 
 
fallthrough 
 
case 7: 
 
 
fmt.Println("was <= 7") 
 
 
fallthrough 
 
case 8: 
 
 
fmt.Println("was <= 8") 
 
 
fallthrough 
 
default: 
 
 
fmt.Println("default case") 
 
} 
} 
// was <= 6 
// was <= 7 
// was <= 8 
// default case 
1、 iota 只能在常量的表达式中使用； 
2、 每次 const 出现时，都会让 iota 初始化为 0.【自增长】； 
Go 中 Label 使用 
Go 语言中有 goto 这个功能，在处理多级嵌套时非常有用。 
Go 语言支持 label（标签）语法：分别是 break label 和 goto label 、continue label； 
break label 
break 一般用来跳出当前所在的循环，但是我们有业务场景，需要使用到跳出带
外层循环怎么办？break label 跳出循环不再执行 for 循环里的代码。 
func main() { 
LABEL1: 
 
for i := 0;i < 3;i++ { 
 
 
if i == 2 { 
 
 
 
break LABEL1 
 
 
} 
 
 
fmt.Println("i==", i) 
 
} 
} 
//i== 0 
//i== 1 
break 标签只能用于 for 循环，不能和 switch 使用，在其他语言里 switch 与 break
是搭档； 
goto label 
goto 可以无条件的跳转执行的位置，但是不能跨函数，需要配合标签使用。 
func main() { 
 
fmt.Println("start") 
 
goto LABEL1 
 
fmt.Println("goto ...")    //not run 
LABEL1: 
 
fmt.Println("label1...") 
 
goto LABEL1 
 
fmt.Println("end")  //not run 
} 
//start 
//label1 
//label1 
//...  一直循环 label1 
continue label 
continue 是继续循环下一个迭代，继续的是最外层循环。 
func main() { 
LABEL1: 
 
for i := 0;i < 3;i++{ 
 
 
for j := 0;j < 3;j++{ 
 
 
 
if j == 1{ 
 
 
 
 
continue LABEL1 
 
 
 
} 
 
 
 
fmt.Printf("i==%v, j==%v\n", i, j) 
 
 
} 
 
} 
} 
//i==0, j==0 
//i==1, j==0 
//i==2, j==0 
 
 
切片 
数组 
定义：arr := [...]int{1, 2, 3}或 arr := [3]int{1, 2, 3}     
如果数组中元素的个数小于或者等于 4 个，那么所有的变量会直接在栈上初始
化，如果数组元素大于 4 个，变量就会在静态存储区初始化然后拷贝到栈上； 
数组是固定产长度的，不能动态扩容，在编译期就确定大小。 
 
 
numbers = append(numbers, 2,3,4) ---往 numbers 中添加多个元素 
将一个切片 append 到另一个切片中  append(slice1, slice...)，返回新的切片 
copy(numbers1,numbers) ---拷贝 numbers 的内容到 numbers1 
delete() 函数用于删除集合的元素, 参数为 map 和其对应的 key 
当切片作为参数传递给函数时，函数内部所做的更改在函数外部也可见；而数组
不可见； 
切片初始化三种方式： 
1、使用下标获取数组或者切片的一部分；不会拷贝原数组或者原切片中的数据，
它只会创建一个指向原数组的切片结构体，所以修改新切片的数据也会修改原切
片。 
2、字面定义；sl := []int{1, 2, 3} --创建一个数组返回一个切片引用； 
3、make([]T, length, capacity)    必须要有 length 参数，len() ---长度 ，cap() ---
容量 
 
切片初始化加索引 
 
 
append 使用 
func main() { 
 
var a = []int{2: 3, 4, 0: 0} 
 
fmt.Println(a) 
} 
// 索引 0 值为 0，索引 2 值为 3，没有指定索引的元素会在前一个索引基础之上
加一 
切片在扩容时，容量的扩展规律是按容量的 2 倍数进行扩充。 
 
 
切片底层 
 
 
切片拷贝三种方式 
1、使用=操作符拷贝切片，这种就是浅拷贝 
2、使用[:]下标的方式复制切片，这种也是浅拷贝 
3、使用 Go 语言的内置函数 copy()进行切片拷贝，这种就是深拷贝 
深浅拷贝都是进行复制，区别在于复制出来的新对象与原来的对象在它们发生改
s := make([]int, 5)  # s = [0 0 0 0 0] 
r := append(s, 1, 2, 3) # r = [0 0 0 0 0 1 2 3] 
fmt.Println(r, len(r), cap(r)) # len(r)=8, cap(r)=10 
 
// 两个切片追加在一起 
s1 := []int{1, 2, 3} 
s2 := []int{4, 5} 
fmt.Println(append(s1, s2...))  # [1 2 3 4 5] 
 
a := [5]int{1, 2, 3, 4, 5} 
t := a[3:4:4] # 意思切取索引 3-->4(不包含 4)，第三个参数用来限制新
切片的容量，切片容量为第三个参数-第一个参数，如果第二个参数省略的话，
默认为切片的长度； 
fmt.Println(t[0]) # 4 
 
s1 := []int{1, 2, 3} 
 
s2 := s1[1:] 
 
s2[1] = 5 
 
fmt.Println(s1, "\n", s2) 
// golang 切片底层的数据结构是数组，当使用 s1[1:] 获得切片 s2，和 s1 共享
同一个底层数组，这会导致 s2[1] = 4 语句影响 s1 
变时，是否会相互影响，本质区别就是复制出来的对象与原对象是否会指向同一
个地址 
 
扩容策略 
在 Go 语言中，切片的扩容是通过 append 函数实现的。当我们向一个切片中
添加元素时，如果当前切片的容量不足以存储新的元素，Go 会自动为该切片分
配一块新的内存空间，然后将原来的数据复制到新分配的内存空间中，并将新的
元素添加进去。这个过程被称为切片的扩容。 
具体来说，当我们使用 append 函数向一个切片添加元素时，Go 会先判断当
前切片的容量是否足够存储新元素。如果足够，则直接将新元素添加到切片的末
尾；如果不足，则需要进行扩容操作。 
在进行扩容操作时，Go 会先根据当前切片的长度和容量计算出新的容量。具体
的计算方式是，1.17 之前 
代码的扩容策略可以简述为以下三个规则： 
1.当期望容量>两倍的旧容量时，直接使用期望容量作为新切片的容量 
2.如果旧容量< 1024（注意这里单位是元素个数）,那么直接翻倍旧容量 
3.如果旧容量> 1024，那么会进入一个循环，每次增加 25%直到大于期望容量 
可以看到，原来的 go 对于切片扩容后的容量判断有一个明显的 magic number：
1024，在 1024 之前，增长的系数是 2，而 1024 之后则变为 1.25。关于为什么会
这么设计，社区的相关讨论 1 给出了几点理由： 
1.如果只选择翻倍的扩容策略，那么对于较大的切片来说，现有的方法可以更好
的节省内存。 
2.如果只选择每次系数为 1.25 的扩容策略，那么对于较小的切片来说扩容会很低
效。 
3.之所以选择一个小于 2 的系数，在扩容时被释放的内存块会在下一次扩容时更
容易被重新利用 
1.18 之后 
到了 Go1.18 时，又改成不和 1024 比较了，而是和 256 比较；并且扩容的增量也
有所变化，不再是每次扩容 1/4，而是（oldCap + 3 * 256）/4； 
然后，Go 会为新的容量分配一块内存空间，并将原来的数据复制到这个新的内
存空间中，最后将新的元素添加到切片的末尾。 
需要注意的是，切片的扩容操作可能会导致原来的切片和新的切片共享同一块内
存空间。这种情况下，如果修改了原来的切片或新的切片中的数据，都会影响到
另一个切片。因此，在使用切片时，需要注意切片的扩容和共享内存的情况，避
免引发不必要的错误。 
 
 
如何判断 2 个字符串切片（slice) 是相等的？ 
reflect.DeepEqual() ， 但反射非常影响性能。 
 
map 
map 基本用法 
x := map[string]string{"one": "1", "two": "2"} 
if v, ok := x["two"]; ok { 
   fmt.Println("ok==", ok, v) 
} 
x["two]返回----值，是否存在 
 
通过 make 函数定义 map 
make(map[string]int) 
mapCreated := make(map[string]float32)相当于：mapCreated := map[string]float32{}. 
 
 
如果只是 var 声明一个 map，此时不能添加新 key 到 map 中。 
如果 key 没有在 map 中，取值时去 type 的默认值； 
m := map[string]int{"1": 1, "2": 2} 
fmt.Println("value is", m["3"]) 
//value is 0 
 
delete(map, key)  --移除 map 中的元素，如果 key 不存在，该操作不会产生错误； 
len(map) ---可以获得 map 的长度 
map 和 slice 一样时引用类型 
不能通过==进行比较，==只能判断 map 是否是 nil； 
 
 
 
map 的排序 
// for-range 遍历 map 
for key, value := range map1 { 
} 
// 如果只想获取 key，可以这么使用： 
for key := range map1 { 
} 
map 默认是无序的，想为 map 排序，需要将 key（或者 value）拷贝到一个切片，
再对切片排序，然后可以使用切片的 for-range 方法打印出所有的 key 和 value。 
 
 
 
 
go 里面的 map 是并发安全的吗？如何并发安全 
Go 中的 map 是非并发安全的，多个 goroutine 对同一个 map 进行并发读写操作时可能
会导致数据竞争和并发问题。为了保证 map 的并发安全性，可以使用以下两种方式： 
 
1. 使用 sync 包中的 Map 类型 
sync 包中的 Map 类型是一个并发安全的 map，可以用于多个 goroutine 对同一个 map 
进行并发读写操作。例如： 
var m sync.Map 
 
m.Store("key", "value") 
value, ok := m.Load("key") 
func main() { 
 
barVal := map[string]int{ 
 
 
"alpha": 34, "bravo": 56, "charlie": 23, 
 
 
"delta": 87, "echo": 56, "foxtrot": 12, 
 
 
"golf": 34, "hotel": 16, "indio": 87, 
 
 
"juliet": 65, "kili": 43, "lima": 98, 
 
} 
 
i := 0 
 
keys := make([]string, len(barVal)) 
 
for k, _ := range barVal{ 
 
 
keys[i] = k 
 
 
i++ 
 
} 
 
sort.Strings(keys) 
 
fmt.Println("sorted keys==", keys) 
 
for _, key := range keys{ 
 
 
fmt.Printf("key=%v, value=%v\n", key, barVal[key]) 
 
} 
} 
m.Delete("key") 
上面的代码使用 sync.Map 类型实现了一个并发安全的 map，可以在多个 goroutine 中对
其进行并发读写操作。 
 
2.. 使用读写锁进行保护 
另一种方式是使用读写锁（sync.RWMutex）对 map 进行保护，实现并发安全。例如： 
var mu sync.RWMutex 
var m map[string]string 
 
func read(key string) string { 
    mu.RLock() 
    defer mu.RUnlock() 
    return m[key] 
} 
 
func write(key, value string) { 
    mu.Lock() 
    defer mu.Unlock() 
    m[key] = value 
} 
上面的代码使用读写锁对 map 进行保护，read 函数使用读锁进行保护，write 函数使用写
锁进行保护，可以在多个 goroutine 中对其进行并发读写操作。 
 
需要注意的是，使用读写锁进行保护时，需要根据实际情况选择读锁或写锁，以保证并发安
全和性能的平衡。同时，也可以使用 sync.Map 类型来简化代码，避免使用锁时出现的一些
问题，例如死锁等。 
 
解决 hash 碰撞的方法 
1、开放寻址法； 
这种方法的核心思想是依次探测和比较数组中的元素以判断目标键值对是否存
在于哈希表中。实现哈希表的底层数据接口是数组。 
哈希函数：index := hash(“key1”) % array.len 
当我们向当前哈希表写入新的数据时，如果发生了冲突，就会将键值对写入到下
一个索引不为空的位置，如果位置已经被占用了，则继续向下寻找，如果找到最
后还是被占用的话，则从头开始寻找位置。 
2、拉链法。 
实现哈希表的底层数据结构是链表数组。 
哈希函数：index := hash(“key1”) % array.len 
经过 hash 函数找到一个桶，然后就可以遍历当前桶的链表了，在遍历链表的过
程中会遇到以下两种情况： 
a、找到键相同的键值对 — 更新键对应的值； 
b、没有找到键相同的键值对 — 在链表的末尾追加新的键值对； 
channel 通道 
channel（通道）用于在 goroutine 之间传递数据和同步操作。 channel 可以阻塞
发送方直到接收者准备好接收数据，并且可以阻塞接收方直到有可用的数据发送。
它是 Go 中实现并发的重要机制之一。 
channel 死锁的场景 ok 
1. 当一个 channel 中没有数据，而直接读取时，会发生死锁： 
q := make(chan int,2) 
<-q 
解决方案是采用 select 语句，再 default 放默认处理方式： 
q := make(chan int,2) 
select{ 
   case val:=<-q: 
   default: 
         ... 
 
} 
2. 当 channel 数据满了，再尝试写数据会造成死锁； 
q := make(chan int,2) 
q<-1 
q<-2 
q<-3 
解决方法，采用 select 
func main() { 
 
q := make(chan int, 2) 
 
q <- 1 
 
q <- 2 
 
select { 
 
case q <- 3: 
 
 
fmt.Println("ok") 
 
default: 
 
 
fmt.Println("wrong") 
 
} 
 
} 
3. 向一个关闭的 channel 写数据。 
注意：一个已经关闭的 channel，只能读数据，不能写数据。 
对已经关闭的 chan 进行读写会怎么样？ 
1. 读已经关闭的 chan 能一直读到东西，但是读到的内容根据通道内关闭前是否
有元素而不同。如果 chan 关闭前，buffer 内有元素还未读,会正确读到 chan 内的
值，且返回的第二个 bool 值（是否读成功）为 true。如果 chan 关闭前，buffer 内
有元素已经被读完，chan 内无值，接下来所有接收的值都会非阻塞直接成功，返
回 channel 元素的零值，但是第二个 bool 值一直为 false。 
2. 写已经关闭的 chan 会 panic。 
channel 底层实现？是否线程安全。 
channel 底层实现在 src/runtime/chan.go 中 
channel 内部是一个循环链表。内部包含 buf, sendx, recvx, lock ,recvq, sendq 几个
部分； 
buf 是有缓冲的 channel 所特有的结构，用来存储缓存数据。是个循环链表； 
sendx 和 recvx 用于记录 buf 这个循环链表中的发送或者接收的 index； 
lock 是个互斥锁； 
recvq 和 sendq 分别是接收(<-channel)或者发送(channel <- xxx)的 goroutine 抽象
出来的结构体(sudog)的队列。是个双向链表。 
channel 是线程安全的。 
参考资料：Kitou：Golang 深度剖析 -- channel 的底层实现 
当 select 监控多个 chan 同时到达就绪态时，如何
先执行某个任务？ 
可以在子 case 再加一个 for select 语句。 
func priority_select(ch1, ch2 <-chan string) { 
 
for { 
 
 
select { 
 
 
case val := <-ch1: 
 
 
 
fmt.Println(val) 
 
 
case val2 := <-ch2: 
 
 
priority: 
 
 
 
for { 
 
 
 
 
select { 
 
 
 
 
case val1 := <-ch1: 
 
 
 
 
 
fmt.Println(val1) 
 
 
 
 
default: 
 
 
 
 
 
break priority 
 
 
 
 
} 
 
 
 
} 
 
 
 
fmt.Println(val2) 
 
 
} 
 
} 
} 
 
select 的实现原理？ 
select 源码位于 src\runtime\select.go，最重要的 scase 数据结构为： 
type scase struct { 
 
c    *hchan         // chan 
 
elem unsafe.Pointer // data element 
} 
scase.c 为当前 case 语句所操作的 channel 指针，这也说明了一个 case 语句只能
操作一个 channel。 
scase.elem 表示缓冲区地址： 
caseRecv ： scase.elem 表示读出 channel 的数据存放地址； 
caseSend ： scase.elem 表示将要写入 channel 的数据存放地址； 
select 的主要实现位于：select.go 函数：其主要功能如下： 
\1. 锁定 scase 语句中所有的 channel 
\2. 按照随机顺序检测 scase 中的 channel 是否 ready 
2.1 如果 case 可读，则读取 channel 中数据，解锁所有的 channel，然后返回(case 
index, true) 
2.2 如果 case 可写，则将数据写入 channel，解锁所有的 channel，然后返回(case 
index, false) 
2.3 所有 case 都未 ready，则解锁所有的 channel，然后返回（default index, false） 
\3. 所有 case 都未 ready，且没有 default 语句 
3.1 将当前协程加入到所有 channel 的等待队列 
3.2 当将协程转入阻塞，等待被唤醒 
\4. 唤醒后返回 channel 对应的 case index 
4.1 如果是读操作，解锁所有的 channel，然后返回(case index, true) 
4.2 如果是写操作，解锁所有的 channel，然后返回(case index, false) 
参考资料：Go select 的使用和实现原理. 
无缓冲的 channel 和有缓冲的 channel 的区别？ 
对于无缓冲区 channel： 
发送的数据如果没有被接收方接收，那么发送方阻塞；如果一直接收不到发送方
的数据，接收方阻塞； 
有缓冲的 channel： 
发送方在缓冲区满的时候阻塞，接收方不阻塞；接收方在缓冲区为空的时候阻塞，
发送方不阻塞。 
可以类比生产者与消费者问题。 
 
 
Go 语言中可以使用 channel 和 mutex 实现阻塞队列 
package main 
 
import ( 
 
"fmt" 
 
"sync" 
) 
 
type BlockingQueue struct { 
 
queue     []interface{} 
 
capacity  int 
 
mutex     sync.Mutex 
 
notEmpty *sync.Cond 
 
notFull  *sync.Cond 
} 
 
func NewBlockingQueue(n int) *BlockingQueue { 
 
bq := &BlockingQueue{ 
 
 
queue:    make([]interface{}, 0, n), 
 
 
capacity: n, 
 
} 
 
bq.notEmpty = sync.NewCond(&bq.mutex) 
 
bq.notFull = sync.NewCond(&bq.mutex) 
 
return bq 
} 
 
func (bq *BlockingQueue) Push(item interface{}) { 
 
bq.mutex.Lock() 
 
defer bq.mutex.Unlock() 
 
for len(bq.queue) == bq.capacity { 
 
 
bq.notFull.Wait() 
 
} 
 
bq.queue = append(bq.queue, item) 
 
bq.notEmpty.Signal() 
} 
 
func (bq *BlockingQueue) Pop() interface{} { 
 
bq.mutex.Lock() 
 
defer bq.mutex.Unlock() 
 
for len(bq.queue) == 0 { 
 
 
bq.notEmpty.Wait() 
 
} 
 
item := bq.queue[0] 
 
bq.queue = bq.queue[1:] 
 
bq.notFull.Signal() 
 
return item 
} 
 
func main() { 
 
bq := NewBlockingQueue(3) 
 
for i := 0; i < 5; i++ { 
 
 
go func(i int) { 
 
 
 
bq.Push(i) 
 
 
 
fmt.Printf("Push %d, queue size: %d\n", i, len(bq.queue)) 
 
 
}(i) 
 
} 
 
for i := 0; i < 5; i++ { 
 
 
go func() { 
 
 
 
item := bq.Pop() 
 
 
 
fmt.Printf("Pop %v, queue size: %d\n", item, len(bq.queue)) 
 
 
}() 
 
} 
} 
在上述代码中，使用了一个 slice 来存放队列元素，同时通过 mutex 来保证线程
安全，当队列满时生产者需要等待，当队列空时消费者需要等待。使用 sync.Cond
实现等待通知机制，当队列满时，生产者调用 notFull.Wait()方法进行等待，当队
列非满时，生产者调用 notEmpty.Signal()方法通知消费者；当队列为空时，消费
者调用 notEmpty.Wait()方法进行等待，当队列非空时，消费者调用 notFull.Signal()
方法通知生产者。 
该阻塞队列可以用于多线程环境下的任务分发、消息传递等场景。 
 
channel 为什么需要两个队列实现？ 
在 Go 中，每个 channel 都包含两个队列：发送队列和接收队列。这是因为 
channel 的发送和接收操作是异步进行的，发送方和接收方可能会以不同的顺序
执行。 
当发送方向一个未满的 channel 发送数据时，该数据会被添加到发送队列中。如
果接收方正在等待从 channel 接收数据，则该数据将从发送队列中移除并发送
给接收方。否则，该数据将一直留在发送队列中，直到有接收方准备好接收。 
 
类似地，当接收方从一个非空的 channel 接收数据时，该数据会从接收队列中取
出并发送给接收方。如果发送方正在等待向该 channel 发送数据，则该数据将直
接从发送方传递给接收方，而不会先放入接收队列。 
因此，通过使用这两个队列，channel 可以有效地实现多个 goroutine 之间的同
步和通信。 
 
异常处理 
Go 有异常类型吗？ok 
有。Go 用 error 类型代替 try...catch 语句，这样可以节省资源。同时增加代码可
读性： 
_, err := funcDemo() 
if err != nil { 
  fmt.Println(err) 
  return 
} 
也可以用 errors.New()来定义自己的异常。errors.Error()会返回异常的字符串表示。
只要实现 error 接口就可以定义自己的异常， 
type errorString struct { 
s string 
} 
 
func (e *errorString) Error() string { 
return e.s 
} 
 
// 多一个函数当作构造函数 
func New(text string) error { 
return &errorString{text} 
} 
 
 
 
Goroutine 
什么是协程（Goroutine）与线程区别 
协程是用户态轻量级线程，它是线程调度的基本单位。通常在函数前加上 go 关
键字就能实现并发。 
调度方式不同： 
Go 语言的协程是由 Go 语言的运行时（runtime）进行调度的，而线程是由操作
系统进行调度的。Go 语言的协程调度器采用的是 M:N 调度模型，即将 M 个协
程映射到 N 个操作系统线程上执行，这样可以更高效地利用 CPU 资源。 
内存占用： 
一个 Goroutine 会以一个很小的栈启动 2KB 或 4KB，当遇到栈空间不足时，栈会
自动伸缩，因此可以轻易实现成千上万个 goroutine 同时启动。独立的栈空间、
共享程序堆空间、调度由用户控制、协程是轻量级的线程。同一个程序中的所有 
goroutine 共享同一个地址空间。 
系统线程都会有一个固定大小的栈大小 2M，这个栈保存函数递归调用时的参数
和局部变量，固定大小出现两个问题，需要栈空间小时是浪费，需要栈空间较大
时会溢出；  
切换代价不同： 
线程的切换需要保存和恢复线程的上下文，包括寄存器、栈指针等，这个过程需
要耗费一定的时间和资源。而协程的切换则只需要保存和恢复协程的上下文，这
个过程非常快速，通常只需要几百纳秒。 
适用场景： 
由于协程可以快速切换并发执行的任务，因此比线程更适合处理 I/O 密集型的
任务。线程则更适合处理 CPU 密集型任务。在 CPU 密集型任务下，Go 协程的
优势要小很多，甚至可能更差。 
 
go 通道和锁的使用场景？ 
在 Go 语言中，协程（Goroutine）之间的通信通常使用通道（Channel）来实现，
而不需要显式地加锁。这是因为通道本身就是一种并发安全的数据结构，它可以
保证在多个协程之间进行数据传递时不会出现竞态条件（Race Condition）。 
通道的实现方式是基于消息传递的模型，即一个协程向通道中发送消息，另一个
协程从通道中接收消息。在这个过程中，通道会自动进行同步和互斥操作，保证
每个消息只能被一个协程接收，从而避免了竞态条件的发生。 
通道适用于以下场景： 
1. 协程之间需要进行数据传递和同步操作。 
2. 多个协程需要共享数据，但是不需要进行复杂的同步和互斥操作。 
3. 协程之间的数据传递是单向的，即一个协程只负责发送数据，另一个协程只负
责接收数据。 
而锁适用于以下场景： 
1. 多个协程需要共享数据，并且需要进行复杂的同步和互斥操作。 
2. 协程之间的数据传递是双向的，即一个协程既可以发送数据，也可以接收数
据。 
3. 需要对共享数据进行读写操作，而通道只能进行单向的数据传递。 
总之，在 Go 语言中，通道是一种更加高效、安全和简单的并发编程方式，通常
优先考虑使用通道来进行协程之间的数据传递和同步操作。而锁则适用于一些复
杂的同步和互斥操作，或者需要进行读写操作的场景。 
 
select 
select 可以监听 channel 上的数据流动。select 默认是阻塞的，只有当监听的 channel
中有发送或接收可以进行时才会运行，当多个 channel 都准备好的时候，select 是
随机的选择一个执行的。 
 
goroutine 什么情况会发生内存泄漏？如何避免。 
在 Go 中内存泄露分为暂时性内存泄露和永久性内存泄露。 
暂时性内存泄露 
1. 获取长字符串中的一段导致长字符串未释放 
2. 获取长 slice 中的一段导致长 slice 未释放 
3. 在长 slice 新建 slice 导致泄漏 
4. string 相比切片少了一个容量的 cap 字段，可以把 string 当成一个只读的切片
类型。获取长 string 或者切片中的一段内容，由于新生成的对象和老的 string 或
者切片共用一个内存空间，会导致老的 string 和切片资源暂时得不到释放，造成
短暂的内存泄漏； 
永久性内存泄露 
1. goroutine 永久阻塞而导致泄漏 
2. time.Ticker 未关闭导致泄漏 
3. 不正确使用 Finalizer（Go 版本的析构函数）导致泄漏 
如果若干个 goroutine，有一个 panic 会怎么做？ 
有一个 panic，那么剩余 goroutine 也会退出，程序退出。如果不想程序退出，那
么必须通过调用 recover() 方法来捕获 panic 并恢复将要崩掉的程序。 
 
recover 的执行时机 ok 
recover 必须在 defer 函数中运行。recover 捕获的是祖父级调用时
的异常，直接调用时无效。 
func main() { 
    recover() 
    panic(1) 
} 
// panic: 1 
直接 defer 调用也是无效。 
func main() { 
    defer recover() 
    panic(1) 
} 
// panic: 1 
defer 调用时多层嵌套依然无效。 
func main() { 
 
defer func() { 
 
 
func() { 
 
 
 
recover() 
 
 
 
fmt.Println("recover...") 
 
 
}() 
 
}() 
 
panic(1) 
} 
 
// recover... 
// panic: 1 
必须在 defer 函数中直接调用才有效。 
func main() { 
 
defer func() { 
 
 
recover() 
 
 
fmt.Println("recover...") 
 
}() 
 
panic("") 
} 
 
//recover... 
 
 
参考理解：goroutine 配上 panic 会怎样。 
为什么有协程泄露(Goroutine Leak)？ 
协程泄漏是指协程创建之后没有得到释放。主要原因有： 
1. 缺少接收器，导致发送阻塞 
2. 缺少发送器，导致接收阻塞 
3. 死锁。多个协程由于竞争资源导致死锁。 
4．创建协程的没有回收。 
Go 可以限制运行时操作系统线程的数量吗？ 常见
的 goroutine 操作函数有哪些？ 
可以，使用 runtime.GOMAXPROCS(num int)可以设置线程数目。该值默认为 CPU
逻辑核数，如果设的太大，会引起频繁的线程切换，降低性能。 
runtime.Gosched()，用于让出 CPU 时间片，让出当前 goroutine 的执行权限，调
度器安排其它等待的任务运行，并在下次某个时候从该位置恢复执行。 
runtime.Goexit()，调用此函数会立即使当前的 goroutine 的运行终止（终止协程），
而其它的 goroutine 并不会受此影响。runtime.Goexit 在终止当前 goroutine 前会先
执行此 goroutine 的还未执行的 defer 语句。请注意千万别在主函数调用
runtime.Goexit，因为会引发 panic。 
如何控制协程数目 ok 
The GOMAXPROCS variable limits the number of operating system threads 
that can execute user-level Go code simultaneously. There is no limit to the 
number of threads that can be blocked in system calls on behalf of Go code; 
those do not count against the GOMAXPROCS limit. 
从官方文档的解释可以看到，GOMAXPROCS 限制的是同时执行用户态 Go 代
码的操作系统线程的数量，但是对于被系统调用阻塞的线程数量是没有限制的。
GOMAXPROCS 的默认值等于 CPU 的逻辑核数，同一时间，一个核只能绑定
一个线程，然后运行被调度的协程。因此对于 CPU 密集型的任务，若该值过大，
例如设置为 CPU 逻辑核数的 2 倍，会增加线程切换的开销，降低性能。对于 
I/O 密集型应用，适当地调大该值，可以提高 I/O 吞吐率。 
另外对于协程，可以用带缓冲区的 channel 来控制，下面的例子是协程数为 1024
的例子 
var wg sync.WaitGroup 
ch := make(chan struct{}, 1024) 
for i:=0; i<20000; i++{ 
    wg.Add(1) 
    ch<-struct{}{} 
    go func(){ 
        defer wg.Done() 
        <-ch 
    } 
} 
wg.Wait() 
此外还可以用协程池：其原理无外乎是将上述代码中通道和协程函数解耦，并封
装成单独的结构体。常见第三方协程池库，比如 tunny 等。 
defer 可以捕获 goroutine 的子 goroutine 吗？ 
不可以。它们处于不同的调度器 P 中。对于子 goroutine，必须通过 recover() 机
制来进行恢复，然后结合日志进行打印（或者通过 channel 传递 error），下面是
一个例子： 
// 心跳函数 
func Ping(ctx context.Context) error { 
    ... code ... 
  
 
go func() { 
 
 
defer func() { 
 
 
 
if r := recover(); r != nil { 
 
 
 
 
log.Errorc(ctx, "ping panic: %v, stack: %v", r, 
string(debug.Stack())) 
 
 
 
} 
 
 
}() 
  
        ... code ... 
 
}() 
  
    ... code ... 
  
 
return nil 
} 
go 竞态条件了解吗？ 
所谓竞态竞争，就是当两个或以上的 goroutine 访问相同资源时候，对资源进行
读/写。 
比如 var a int = 0，有两个协程分别对 a+=1，我们发现最后 a 不一定为 2.这就是
竞态竞争。 
通常我们可以用 go run -race xx.go 来进行检测。 
解决方法是，对临界区资源上锁，或者使用原子操作(atomics)，原子操作的开销
小于上锁。 
 
（Goroutine）有三个函数，分别打印"cat", 
"fish","dog"要求每一个函数都用一个 goroutine，
按照顺序打印 100 次。 
此题目考察 channel，用三个无缓冲 channel，如果一个 channel 收到信号则通
知下一个。 
package main 
 
import ( 
 
"fmt" 
 
"time" 
) 
 
var dog = make(chan struct{}) 
var cat = make(chan struct{}) 
var fish = make(chan struct{}) 
 
func Dog() { 
 
<-fish 
 
fmt.Println("dog") 
 
dog <- struct{}{} 
} 
 
func Cat() { 
 
<-dog 
 
fmt.Println("cat") 
 
cat <- struct{}{} 
} 
 
func Fish() { 
 
<-cat 
 
fmt.Println("fish") 
 
fish <- struct{}{} 
} 
 
func main() { 
 
for i := 0; i < 100; i++ { 
 
 
go Dog() 
 
 
go Cat() 
 
 
go Fish() 
 
} 
 
fish <- struct{}{} 
 
 
time.Sleep(10 * time.Second) 
} 
两个协程交替打印 10 个字母和数字 
思路：采用 channel 来协调 goroutine 之间顺序。 
主线程一般要 waitGroup 等待协程退出，这里简化了一下直接 sleep。 
package main 
 
import ( 
 
"fmt" 
 
"time" 
) 
 
var word = make(chan struct{}, 1) 
var num = make(chan struct{}, 1) 
 
func printNums() { 
 
for i := 0; i < 10; i++ { 
 
 
<-word 
 
 
fmt.Println(1) 
 
 
num <- struct{}{} 
 
} 
} 
func printWords() { 
 
for i := 0; i < 10; i++ { 
 
 
<-num 
 
 
fmt.Println("a") 
 
 
word <- struct{}{} 
 
} 
} 
 
func main() { 
 
num <- struct{}{} 
 
go printNums() 
 
go printWords() 
 
time.Sleep(time.Second * 1) 
} 
启动 2 个 groutine 2 秒后取消， 第一个协程 1 秒
执行完，第二个协程 3 秒执行完。 
思路：采用 ctx, _ := context.WithTimeout(context.Background(), time.Second*2)实现 2s
取消。协程执行完后通过 channel 通知，是否超时。 
package main 
 
import ( 
 
"context" 
 
"fmt" 
 
"time" 
) 
 
func f1(in chan struct{}) { 
 
 
time.Sleep(1 * time.Second) 
 
in <- struct{}{} 
 
} 
 
func f2(in chan struct{}) { 
 
time.Sleep(3 * time.Second) 
 
in <- struct{}{} 
} 
 
func main() { 
 
ch1 := make(chan struct{}) 
 
ch2 := make(chan struct{}) 
 
ctx, _ := context.WithTimeout(context.Background(), 2*time.Second) 
 
 
go func() { 
 
 
go f1(ch1) 
 
 
select { 
 
 
case <-ctx.Done(): 
 
 
 
fmt.Println("f1 timeout") 
 
 
 
break 
 
 
case <-ch1: 
 
 
 
fmt.Println("f1 done") 
 
 
} 
 
}() 
 
 
go func() { 
 
 
go f2(ch2) 
 
 
select { 
 
 
case <-ctx.Done(): 
 
 
 
fmt.Println("f2 timeout") 
 
 
 
break 
 
 
case <-ch2: 
 
 
 
fmt.Println("f2 done") 
 
 
} 
 
}() 
 
time.Sleep(time.Second * 5) 
} 
GMP 模型 
❤go 如何进行调度的。GMP 中状态流转。 
Go 里面 GMP 分别代表： 
G：表示 goroutine，它是一个待执行的任务； 
M：表示操作系统主线程（物理线程，真正在 CPU 上跑的），它由操作系统的调
度器调度和管理； 
 
P：表示处理器，它可以被看做运行在线程上的本地调度器(协程执行需要的上下
文)。 
 
GMP 模型 
调度器是 M 和 G 之间桥梁。 
go 进行调度过程： 
1. 某个线程尝试创建一个新的 G，那么这个 G 就会被安排到这个线程的 G 本地
队列 LRQ 中，如果 LRQ 满了，就会分配到全局队列 GRQ 中； 
2. 尝试获取当前线程的 M，如果无法获取，就会从空闲的 M 列表中找一个，如
果空闲列表也没有，那么就创建一个 M，然后绑定 G 与 P 运行。 
3. 进入调度循环：找到一个合适的 G，执行 G，完成以后退出 
 
 
Go 什么时候发生阻塞？阻塞时，调度器会怎么做。 
用于原子、互斥量或通道操作导致 goroutine 阻塞，调度器将把当前阻塞的
goroutine 从本地运行队列 LRQ 换出，并重新调度其它 goroutine； 
由于网络请求和 IO 导致的阻塞，Go 提供了网络轮询器（Netpoller）来处理，后
台用 epoll 等技术实现 IO 多路复用。 
其它回答： 
channel 阻塞：当 goroutine 读写 channel 发生阻塞时，会调用 gopark 函数，该 G
脱离当前的 M 和 P，调度器将新的 G 放入当前 M。 
系统调用：当某个 G 由于系统调用陷入内核态，该 P 就会脱离当前 M，此时 P
会更新自己的状态为 Psyscall，M 与 G 相互绑定，进行系统调用。结束以后，若
该 P 状态还是 Psyscall，则直接关联该 M 和 G，否则使用闲置的处理器处理该
G。 
系统监控：当某个 G 在 P 上运行的时间超过 10ms 时候，或者 P 处于 Psyscall 状
态过长等情况就会调用 retake 函数，触发新的调度。 
主动让出：由于是协作式调度，该 G 会主动让出当前的 P（通过 GoSched），更
新状态为 Grunnable，该 P 会调度队列中的 G 运行。 
更多关于 netpoller 的内容可以参看：https://strikefreedom.top/go-netpoll-io-
multiplexing-reactor 
❤Go 中 GMP 有哪些状态？ 
 
G 的状态： 
_Gidle：刚刚被分配并且还没有被初始化，值为 0，为创建 goroutine 后的默认值 
_Grunnable： 没有执行代码，没有栈的所有权，存储在运行队列中，可能在某个
P 的本地队列或全局队列中(如上图)。 
_Grunning： 正在执行代码的 goroutine，拥有栈的所有权(如上图)。 
_Gsyscall：正在执行系统调用，拥有栈的所有权，与 P 脱离，但是与某个 M 绑
定，会在调用结束后被分配到运行队列(如上图)。 
_Gwaiting：被阻塞的 goroutine，阻塞在某个 channel 的发送或者接收队列(如上
图)。 
_Gdead： 当前 goroutine 未被使用，没有执行代码，可能有分配的栈，分布在空
闲列表 gFree，可能是一个刚刚初始化的 goroutine，也可能是执行了 goexit 退出
的 goroutine(如上图)。 
_Gcopystac：栈正在被拷贝，没有执行代码，不在运行队列上，执行权在 
_Gscan ： GC 正在扫描栈空间，没有执行代码，可以与其他状态同时存在。 
P 的状态： 
_Pidle ：处理器没有运行用户代码或者调度器，被空闲队列或者改变其状态的结
构持有，运行队列为空 
_Prunning ：被线程 M 持有，并且正在执行用户代码或者调度器(如上图) 
_Psyscall：没有执行用户代码，当前线程陷入系统调用(如上图) 
_Pgcstop ：被线程 M 持有，当前处理器由于垃圾回收被停止 
_Pdead ：当前处理器已经不被使用 
M 的状态： 
自旋线程：处于运行状态但是没有可执行 goroutine 的线程，数量最多为
GOMAXPROC，若是数量大于 GOMAXPROC 就会进入休眠。 
非自旋线程：处于运行状态有可执行 goroutine 的线程。 
GMP 能不能去掉 P 层？会怎么样？ 
P 层的作用 
每个 P 有自己的本地队列，大幅度的减轻了对全局队列的直接依赖，所带来的
效果就是锁竞争的减少。而 GM 模型的性能开销大头就是锁竞争。 
每个 P 相对的平衡上，在 GMP 模型中也实现了 Work Stealing 算法，如果 P 
的本地队列为空，则会从全局队列或其他 P 的本地队列中窃取可运行的 G 来
运行，减少空转，提高了资源利用率。 
参考资料：https://juejin.cn/post/6968311281220583454 
如果有一个 G 一直占用资源怎么办？什么是 work 
stealing 算法？ 
如果有个 goroutine 一直占用资源，那么 GMP 模型会从正常模式转变为饥饿模
式（类似于 mutex），允许其它 goroutine 使用 work stealing 抢占（禁用自旋
锁）。 
work stealing 算法指，一个线程如果处于空闲状态，则帮其它正在忙的线程分
担压力，从全局队列取一个 G 任务来执行，可以极大提高执行效率。 
 
指针 
指针的作用 ok 
一个指针可以指向任意变量的地址，它所指向的地址在 32 位或 64 位机器上分别
固定占 4 或 8 个字节。指针的作用有： 
1. 获取变量的值 
import fmt 
 
func main(){ 
a := 1 
p := &a//取址& 
fmt.Printf("%d\n", *p);//取值* 
} 
2. 改变变量的值 
// 交换函数 
func swap(a, b *int) { 
    *a, *b = *b, *a 
} 
3. 用指针替代值传入函数，比如类的接收器就是这样的。 
type A struct{} 
 
func (a *A) fun(){} 
函数返回局部变量的指针是否安全？ 
这一点和 C++不同，在 Go 里面返回局部变量的指针是安全的。因为 Go 会进行
逃逸分析，如果发现局部变量的作用域超过该函数则会把指针分配到堆区，避免
内存泄漏。 
非接口的任意类型 T() 都能够调用 *T 的方法吗？
反过来呢？ 
一个 T 类型的值可以调用*T 类型声明的方法，当且仅当 T 是可寻址的。 
反之：*T 可以调用 T()的方法，因为指针可以解引用。 
 
反射 
实现使用字符串函数名，调用函数。 
思路：采用反射的 Call 方法实现。 
package main 
import ( 
 
"fmt" 
    "reflect" 
) 
 
type Animal struct{ 
     
} 
 
func (a *Animal) Eat(){ 
    fmt.Println("Eat") 
} 
 
func main(){ 
    a := Animal{} 
    reflect.ValueOf(&a).MethodByName("Eat").Call([]reflect.Value{}) 
} 
go 的 reflect 底层实现 
go reflect 源码位于 src\reflect\下面，作为一个库独立存在。反射是基于接口实现
的。 
Go 反射有三大法则： 
1. 反射从接口映射到反射对象； 
 
2. 反射从反射对象映射到接口值； 
 
3. 只有值可以修改(settable)，才可以修改反射对象。 
Go 反射基于上述三点实现。我们先从最核心的两个源文件入手 type.go 和
value.go. 
type 用于获取当前值的类型。value 用于获取当前的值。 
参考资料：The Laws of Reflection， 图解 go 反射实现原理 
 
接口 
2 个 interface 可以比较吗？ok 
Go 语言中，interface 的内部实现包含了 2 个字段，类型 T 和 值 V，interface 
可以使用 == 或 != 比较。2 个 interface 相等有以下 2 种情况： 
1. 两个 interface 均等于 nil（此时 V 和 T 都处于 unset 状态）； 
2. 类型 T 相同，且对应的值 V 相等。 
看下面的例子： 
type Stu struct { 
     Name string 
} 
 
type StuInt interface{} 
 
func main() { 
     var stu1, stu2 StuInt = &Stu{"Tom"}, &Stu{"Tom"} 
     var stu3, stu4 StuInt = Stu{"Tom"}, Stu{"Tom"} 
     fmt.Println(stu1 == stu2) // false 
     fmt.Println(stu3 == stu4) // true 
} 
stu1 和 stu2 对应的类型是 *Stu，值是 Stu 结构体的地址，两个地址不同，因
此结果为 false。 stu3 和 stu4 对应的类型是 Stu，值是 Stu 结构体，且各字段
相等，因此结果为 true。 
 
go 的 interface 怎么实现的？ 
go interface 源码在 runtime\iface.go 中。 
go 的接口由两种类型实现 iface 和 eface。iface 是包含方法的接口，而 eface 不包
含方法。 
iface 
对应的数据结构是（位于 src\runtime\runtime2.go）： 
type iface struct { 
 
tab  *itab 
 
data unsafe.Pointer 
} 
可以简单理解为，tab 表示接口的具体结构类型，而 data 是接口的值。 
itab： 
type itab struct { 
 
inter *interfacetype //此属性用于定位到具体 interface 
 
_type *_type //此属性用于定位到具体 interface 
 
hash  uint32 // copy of _type.hash. Used for type switches. 
 
_     [4]byte 
 
fun   [1]uintptr // variable sized. fun[0]==0 means _type does not implement 
inter. 
} 
属性 interfacetype 类似于_type，其作用就是 interface 的公共描述，类似的还有
maptype、arraytype、chantype…其都是各个结构的公共描述，可以理解为一种外
在的表现信息。interfaetype 和 type 唯一确定了接口类型，而 hash 用于查询和类
型判断。fun 表示方法集。 
eface 
与 iface 基本一致，但是用_type 直接表示类型，这样的话就无法使用方法。 
type eface struct { 
 
_type *_type 
 
data  unsafe.Pointer 
} 
这里篇幅有限，深入讨论可以看：深入研究 Go interface 底层实现 
 
2 个 nil 可能不相等吗？ ok 
可能不等。interface 在运行时绑定值，只有值为 nil 接口值才为 nil，但是与指针
的 nil 不相等。举个例子： 
var p *int = nil 
var i interface{} = nil 
if(p == i){ 
fmt.Println("Equal") 
} 
两者并不相同。总结：两个 nil 只有在类型相同时才相等。 
 
sync 
说说 atomic 底层怎么实现的. 
atomic 源码位于 sync\atomic。 
通过阅读源码可知，atomic 采用 CAS（CompareAndSwap）的方式实现的。所谓
CAS 就是使用了 CPU 中的原子性操作。在操作共享变量的时候，CAS 不需要对
其进行加锁，而是通过类似于乐观锁的方式进行检测，总是假设被操作的值未曾
改变（即与旧值相等），并一旦确认这个假设的真实性就立即进行值替换。本质
上是不断占用 CPU 资源来避免加锁的开销。 
❤mutex 有几种模式？ 
mutex 有两种模式：normal 和 starvation 
正常模式 
所有 goroutine 按照 FIFO 的顺序进行锁获取，被唤醒的 goroutine 和新请求锁的
goroutine 同时进行锁获取，通常新请求锁的 goroutine 更容易获取锁(持续占有
cpu)，被唤醒的 goroutine 则不容易获取到锁。公平性：否。 
饥饿模式 
所有尝试获取锁的 goroutine 进行等待排队，新请求锁的 goroutine 不会进行锁获
取(禁用自旋)，而是加入队列尾部等待获取锁。公平性：是。 
参考链接：Go Mutex 饥饿模式，GO 互斥锁（Mutex）原理 
 
GC 和内存管理 
你是否主动关闭过 http 连接，为啥要这样做？ok 
有关闭，不关闭会程序可能会消耗完 socket 描述符。有如下 2 种关闭方式： 
1. 直接设置请求变量的 Close 字段值为 true，每次请求结束后就会主动关闭连
接。设置 Header 请求头部选项 Connection: close，然后服务器返回的响应头部
也会有这个选项，此时 HTTP 标准库会主动断开连接 
// 主动关闭连接 
func main() { 
 req, err := http.NewRequest("GET", "http://golang.org", nil) 
 checkError(err) 
 
 req.Close = true 
 //req.Header.Add("Connection", "close") // 等效的关闭方式 
 
 resp, err := http.DefaultClient.Do(req) 
 if resp != nil { 
  defer resp.Body.Close() 
 } 
 checkError(err) 
 
 body, err := ioutil.ReadAll(resp.Body) 
 checkError(err) 
 
 fmt.Println(string(body)) 
} 
2. 你可以创建一个自定义配置的 HTTP transport 客户端，用来取消 HTTP 全局
的复用连接。 
func main() { 
 tr := http.Transport{DisableKeepAlives: true} 
 client := http.Client{Transport: &tr} 
 
 resp, err := client.Get("https://golang.google.cn/") 
 if resp != nil { 
  defer resp.Body.Close() 
 } 
 checkError(err) 
 
 fmt.Println(resp.StatusCode) // 200 
 
 body, err := ioutil.ReadAll(resp.Body) 
 checkError(err) 
 
 fmt.Println(len(string(body))) 
} 
 
Go GC 有几个阶段 
目前的 go GC 采用三色标记法和混合写屏障技术。 
Go GC 有四个阶段: 
1. STW，开启混合写屏障，扫描栈对象； 
2. 将所有对象加入白色集合，从根对象开始，将其放入灰色集合。每次从灰色集
合取出一个对象标记为黑色，然后遍历其子对象，标记为灰色，放入灰色集合； 
如此循环直到灰色集合为空。剩余的白色对象就是需要清理的对象。 
3. STW，关闭混合写屏障； 
4. 在后台进行 GC（并发）。 
 
1.标记阶段（Marking Phase）：标记阶段是垃圾收集器的第一个阶段，主要任务
是识别不再使用的对象并将其标记为“垃圾”。 
2.清扫阶段（Sweeping Phase）：清扫阶段是垃圾收集器的第二个阶段，主要任务
是回收被标记为“垃圾”的对象所占用的内存。 
3.整理阶段（Compacting Phase）：整理阶段是垃圾收集器的最后一个阶段，主要
任务是对已经回收的空间进行整理，以便在之后的内存分配中可以更容易地找到
连续的可用内存块。请注意，整理阶段只有在使用“压缩式垃圾回收”时才会发生。 
 
❤golang 的内存管理的原理清楚吗？简述 go 内存
管理机制。 
golang 内存管理基本是参考 tcmalloc 来进行的。go 内存管理本质上是一个内存
池，只不过内部做了很多优化：自动伸缩内存池大小，合理的切割内存块。 
一些基本概念： 
页 Page：一块 8K 大小的内存空间。Go 向操作系统申请和释放内存都是以页
为单位的。 
span : 内存块，一个或多个连续的 page 组成一个 span。如果把 page 比喻成
工人， span 可看成是小队，工人被分成若干个队伍，不同的队伍干不同的
活。  
sizeclass : 空间规格，每个 span 都带有一个 sizeclass ，标记着该 span 中
的 page 应该如何使用。使用上面的比喻，就是 sizeclass 标志着 span 是一
个什么样的队伍。  
object : 对象，用来存储一个变量数据内存空间，一个 span 在初始化时，会被
切割成一堆等大的 object 。假设 object 的大小是 16B ， span 大小是 
8K ，那么就会把 span 中的 page 就会被初始化 8K/16B = 512 个 object 。所
谓内存分配，就是分配一个 object 出去。 
mheap 
一开始 go 从操作系统索取一大块内存作为内存池，并放在一个叫 mheap 的内存
池进行管理，mheap 将一整块内存切割为不同的区域，并将一部分内存切割为合
适的大小。 
mheap.spans ：用来存储 page 和 span 信息，比如一个 span 的起始地址是多少，
有几个 page，已使用了多大等等。 
mheap.bitmap 存储着各个 span 中对象的标记信息，比如对象是否可回收等等。 
mheap.arena_start : 将要分配给应用程序使用的空间。 
mcentral 
用途相同的 span 会以链表的形式组织在一起存放在 mcentral 中。这里用途用
sizeclass 来表示，就是该 span 存储哪种大小的对象。 
找到合适的 span 后，会从中取一个 object 返回给上层使用。 
mcache 
为了提高内存并发申请效率，加入缓存层 mcache。每一个 mcache 和处理器 P 对
应。Go 申请内存首先从 P 的 mcache 中分配，如果没有可用的 span 再从 mcentral
中获取。 
参考资料：Go 语言内存管理（二）：Go 内存管理 
 
05 ❤简述 Go 语言 GC(垃圾回收)的工作原理 ok 
垃圾回收机制是 Go 一大特(nan)色(dian)。Go1.3 采用标记清除法， Go1.5 采用
三色标记法，Go1.8 采用三色标记法+混合写屏障。 
*标记清除法* 
分为两个阶段：标记和清除 
标记阶段：从根对象出发寻找并标记所有存活的对象。 
清除阶段：遍历堆中的对象，回收未标记的对象，并加入空闲链表。 
缺点是需要暂停程序 STW。 
*三色标记法*： 
将对象标记为白色，灰色或黑色。 
白色：不确定对象（默认色）；黑色：存活对象。灰色：存活对象，子对象待处
理。 
标记开始时，先将所有对象加入白色集合（需要 STW）。首先将根对象标记为
灰色，然后将一个对象从灰色集合取出，遍历其子对象，放入灰色集合。同时将
取出的对象放入黑色集合，直到灰色集合为空。最后的白色集合对象就是需要清
理的对象。 
这种方法有一个缺陷，如果对象的引用被用户修改了，那么之前的标记就无效了。
因此 Go 采用了写屏障技术，当对象新增或者更新会将其着色为灰色。 
一次完整的 GC 分为四个阶段： 
1. 准备标记（需要 STW），开启写屏障。 
2. 开始标记 
3. 标记结束（STW），关闭写屏障 
4. 清理（并发） 
基于插入写屏障和删除写屏障在结束时需要 STW 来重新扫描栈，带来性能瓶颈。
混合写屏障分为以下四步： 
1. GC 开始时，将栈上的全部对象标记为黑色（不需要二次扫描，无需 STW）； 
2. GC 期间，任何栈上创建的新对象均为黑色 
3. 被删除引用的对象标记为灰色 
4. 被添加引用的对象标记为灰色 
总而言之就是确保黑色对象不能引用白色对象，这个改进直接使得 GC 时间从 
2s 降低到 2us。 
02 ❤如何知道一个对象是分配在栈上还是堆上？ 
Go 和 C++不同，Go 局部变量会进行逃逸分析。如果变量离开作用域后没有被引
用，则优先分配到栈上，否则分配到堆上。那么如何判断是否发生了逃逸呢？ 
go build -gcflags '-m -m -l' xxx.go. 
关于逃逸的可能情况：变量大小不确定，变量类型不确定，变量分配的内存超过
用户栈最大值，暴露给了外部指针。 
 
 
go 工具包 
gorm—gorm.io/gorm 
 
mysql_driver—gorm.io/driver/mysql 
 
gin-- go get -u github.com/gin-gonic/gin 
 
viper-- github.com/spf13/viper 
 
swagger--go get -u github.com/swaggo/swag/cmd/swag 
go get -u github.com/swaggo/gin-swagger 
go get -u github.com/swaggo/files 
 
validator 
go get github.com/asaskevich/govalidator 
 
 
3. 计算机网络 
简单一次完整的 HTTP 请求所经历的步骤？ 
1、DNS 解析，通过访问的域名找出其 IP 地址，具体过程包括浏览器搜索自身的
DNS 缓存、搜索操作系统的 DNS 缓存、读取本地的 Host 文件和向本地 DNS 服
务器进行查询等，如果本地域名服务器并未缓存该网址映射关系，那么将根据其
设置发起递归查询或者迭代查询； 
2、HTTP 请求，当输入一个请求时，建立一个 Socket 连接发起 TCP 的 3 次握手。 
如果是 HTTPS 请求，会略微有不同； 
3.1、客户端向服务器发送请求命令（一般是 GET 或 POST 请求）。客户端的网
络层不用关心应用层或者传输层的东西，主要做的是通过查找路由表确定如何 
到达服务器，期间可能经过多个路由器，就是通过查找路由表决定通过那个路径
到达服务器。客户端的链路层，包通过链路层发送到路由器，通过邻居协议查找
给定 IP 地址的 MAC 地址，然后发送 ARP 请求查找目的地址，如果得到回应后
就可以使用 ARP 的请求应答交换的 IP 数据包现在就可以传输了，然后发送 IP 
数据包到达服务器的地址； 
3.2、客户端发送请求头信息和数据。  
4.1、服务器发送应答头信息。 
4.2、服务器向客户端发送数据。  
5、服务器关闭 TCP 连接（4 次挥手）。这里是否关闭 TCP 连接，也根据 HTTP 
Keep-Alive 机制有关。 同时，客户端也可以主动发起关闭 TCP 连接。 
6、客户端根据返回的 HTML、CSS、JS 进行渲染。 
 
DNS 解析的过程 
1. 在浏览器中输入 www.qq.com 域名，操作系统会先检查自己本地的 hosts 文件
是否有这个网址映射关系，如果有，就先调用这个 IP 地址映射，完成域名解析。 
2. 如果 hosts 里没有这个域名的映射，则查找本地 DNS 解析器缓存，是否有这
个网址映射关系，如果有，直接返回，完成域名解析。 
3. 如果 hosts 与本地 DNS 解析器缓存都没有相应的网址映射关系，首先会找
TCP/IP 参数中设置的首选 DNS 服务器，在此我们叫它本地 DNS 服务器，此服
务器收到查询时，如果要查询的域名，包含在本地配置区域资源中，则返回解析
结果给客户机，完成域名解析，此解析具有权威性。 
4. 如果要查询的域名，不由本地 DNS 服务器区域解析，但该服务器已缓存了此
网址映射关系，则调用这个 IP 地址映射，完成域名解析，此解析不具有权威性。 
5. 如果本地 DNS 服务器本地区域文件与缓存解析都失效，则根据本地 DNS 服
务器的设置（是否设置转发器）进行查询，如果未用转发模式，本地 DNS 就把
请求发至 “根 DNS 服务器”，“根 DNS 服务器”收到请求后会判断这个域名(.com)
是谁来授权管理，并会返回一个负责该顶级域名服务器的一个 IP。本地 DNS 服
务器收到 IP 信息后，将会联系负责.com 域的这台服务器。这台负责.com 域的服
务器收到请求后，如果自己无法解析，它就会找一个管理.com 域的下一级 DNS
服务器地址(qq.com)给本地 DNS 服务器。当本地 DNS 服务器收到这个地址后，
就会找 qq.com 域服务器，重复上面的动作，进行查询，直至找到 www.qq.com 主
机。 
6. 如果用的是转发模式，此 DNS 服务器就会把请求转发至上一级 DNS 服务器，
由上一级服务器进行解析，上一级服务器如果不能解析，或找根 DNS 或把转请
求转至上上级，以此循环。不管本地 DNS 服务器用的是转发，还是根提示，最
后都是把结果返回给本地 DNS 服务器，由此 DNS 服务器再返回给客户机。 
 
所谓 递归查询过程 就是 “查询的递交者” 更替, 而 迭代查询过程 则是 “查询
的递交者”不变。 
 
 
 
 
TCP 
HTTP 在应用层，TCP 传输层，TSL or SSL 安全层，IP 网络层； 
TCP 会按序、无差错地承载 HTTP 数据，TCP 为 HTTP 提供了一条可靠的比特
传输管道。从 TCP 连接一端填入的字节会从另一端以原有顺序、正确地传送出
来。HTTP 要传送一条报文时，会以流的形式将报文数据的内容通过一条打开的
TCP 连接按序传输。TCP 收到数据流之后，会将数据流砍成被称为段的小数据
块，并将段封装在 IP 分组中，通过因特网进行传输。 
每个 TCP 段都是由 IP 分组承载，从一个 IP 地址发送到另一个 IP 地址的。 
TCP 和 UDP 区别 
1、TCP 协议是有连接的，有连接的意思是开始传输实际数据之前 TCP 的客户端
和服务器端必须通过三次握手建立连接，会话结束后也要结束连接。而 UDP 是
无连接的； 
2、TCP 协议保证数据发送，按序送达，提供超时重传保证数据可靠性，但是 UDP
不保证按序到达，甚至不能保证到达，即便是按序发送的序列，也不保证按序送
到； 
 3、TCP 协议所需资源多，TCP 首部需 20 个字节（不算可选项），UDP 首部字
段只需 8 个字节;  
4、TCP 有流量控制和拥塞控制，UDP 没有。网络拥堵不会影响发送端的发送速
率;  
5、TCP 面向的字节流的服务，UDP 面向的是报文的服务。 
TCP 应用场景： 
效率要求相对低，但对准确性要求相对高的场景。因为传输中需要对数据确认、
重发、排序等操作，相比之下效率没有 UDP 高。举几个例子：文件传输、接受
邮件、远程登录。 
UDP 应用场景： 
效率要求相对高，对准确性要求相对低的场景。举几个例子：QQ 聊天、在线视
频、网络语音电话、广播通信（广播、多播）。 
 
 
TCP 协议如何保证可靠性 
TCP 主要提供了检验和、序列号/确认应答、超时重传、滑动窗口、拥塞控制和 
流量控制等方法实现了可靠性传输。 
检验和：通过检验和的方式，接收端可以检测出来数据是否有差错和异常，假如
有差错就会直接丢弃 TCP 段，重新发送。 
序列号/确认应答：序列号的作用不仅仅是应答的作用，有了序列号能够将接收
到的数据根据序列号排序，并且去掉重复序列号的数据。TCP 传输的过程中，每
次接收方收到数据后，都会对传输方进行确认应答。也就是发送 ACK 报文，这
个 ACK 报文当中带有对应的确认序列号，告诉发送方，接收到了哪些数据，下
一次的数据从哪里发。 
滑动窗口：滑动窗口既提高了报文传输的效率，也避免了发送方发送过多的数据
而导致接收方无法正常处理的异常。 
超时重传：超时重传是指发送出去的数据包到接收到确认包之间的时间，如果超
过了这个时间会被认为是丢包了，需要重传。最大超时时间是动态计算的。 
拥塞控制：在数据传输过程中，可能由于网络状态的问题，造成网络拥堵，此时
引入拥塞控制机制，在保证 TCP 可靠性的同时，提高性能。 
流量控制：如果主机 A 一直向主机 B 发送数据，不考虑主机 B 的接受能力，则
可能导致主机 B 的接受缓冲区满了而无法再接受数据，从而会导致大量的数据
丢包，引发重传机制。而在重传的过程中，若主机 B 的接收缓冲区情况仍未好
转，则会将大量的时间浪费在重传数据上，降低传送数据的效率。所以引入流量
控制机制，主机 B 通过告诉主机 A 自己接收缓冲区的大小，来使主机 A 控制发
送的数据量。流量控制与 TCP 协议报头中的窗口大小有关。 
详细讲一下 TCP 的滑动窗口 
在进行数据传输时，如果传输的数据比较大，就需要拆分为多个数据包进行发送。
TCP 协议需要对数据进行确认后，才可以发送下一个数据包。这样一来，就会在
等待确认应答包环节浪费时间。 
为了避免这种情况，TCP 引入了窗口概念。窗口大小指的是不需要等待确认应答
包而可以继续发送数据包的最大值。 
滑动窗口左边的是已发送并且被确认的分组，滑动窗口右边是还没有轮到的分组。 
滑动窗口里面也分为两块，一块是已经发送但是未被确认的分组，另一块是窗口
内等待发送的分组。随着已发送的分组不断被确认，窗口内等待发送的分组也会
不断被发送。整个窗口就会往右移动，让还没轮到的分组进入窗口内。 
可以看到滑动窗口起到了一个限流的作用，也就是说当前滑动窗口的大小决定了
当前 TCP 发送包的速率，而滑动窗口的大小取决于拥塞控制窗口和流量控制窗
口的两者间的最小值。 
详细讲一下拥塞控制 
TCP 一共使用了四种算法来实现拥塞控制： 
慢开始 (slow-start)； 
拥塞避免 (congestion avoidance)； 
快速重传 (fast retransmit)； 
快速恢复 (fast recovery)。 
发送方维持一个叫做拥塞窗口 cwnd（congestion window）的状态变量。当
cwndssthresh 时，改用拥塞避免算法。 
慢开始：不要一开始就发送大量的数据，由小到大逐渐增加拥塞窗口的大小。 
拥塞避免：拥塞避免算法让拥塞窗口缓慢增长，即每经过一个往返时间 RTT 就
把发送方的拥塞窗口 cwnd 加 1 而不是加倍。这样拥塞窗口按线性规律缓慢增长。 
快重传：我们可以剔除一些不必要的拥塞报文，提高网络吞吐量。比如接收方在
收到一个失序的报文段后就立即发出重复确认，而不要等到自己发送数据时捎带
确认。快重传规定：发送方只要一连收到三个重复确认就应当立即重传对方尚未
收到的报文段，而不必继续等待设置的重传计时器时间到期。 
快恢复：主要是配合快重传。当发送方连续收到三个重复确认时，就执行“乘法
减小”算法，把 ssthresh 门限减半（为了预防网络发生拥塞），但接下来并不执行
慢开始算法，因为如果网络出现拥塞的话就不会收到好几个重复的确认，收到三
个重复确认说明网络状况还可以。 
 
 
TCP 中的流量控制和拥塞控制 
流量控制 
如果发送者发送数据过快，接收者来不及接收，那么就会出现分组丢失，为了避
免分组丢失，控制发送者的发送速度，使得接收者来得及接收，这就是流量控制。 
流量控制的目的是：防止分组丢失，是构成 TCP 可靠性的一方面。 
如何实现流量控制 
由滑动窗口协议（连续 ARQ 协议）实现，滑动窗口协议即保证了分组无差错，
有序接收，也实现了流量控制。主要的方式就是接收方返回的 ACK 会包含自己
的接受窗口大小，并利用大小来控制发送方的数据发送。 
拥塞控制 
拥塞控制是作用于网络的，它是防止过多的数据注入网络，避免出现网络负载过
大的情况，常见的方法就是慢开始、避免拥塞、快重传、快恢复； 
 
 
 
三次握手和四次挥手 
三次握手 
首先 Client 端发送连接请求报文，Server 端接收连接后回复 ACK 报文，并为这
次连接分配资源。Client 端接收到 ACK 报文后也向 Server 段发送 ACK 报文，并
分配资源，这样 TCP 连接就建立了。 
 
详细过程： 
第一次握手：起初两端都处于 CLOSED 关闭状态，Client 将标志位 SYN 置为 1，
随机产生一个值 seq=x，并将该数据包发送给 Server，Client 进入 SYN-SENT 状
态，等待 Server 确认；  
第二次握手：Server 收到数据包后由标志位 SYN=1 得知 Client 请求建立连接，
Server 将标志位 SYN 和 ACK 都置为 1，ack=x+1，随机产生一个值 seq=y，并将
该数据包发送给 Client 以确认连接请求，Server 进入 SYN-RCVD 状态，此时操
作系统为该 TCP 连接分配 TCP 缓存和变量；  
第三次握手：Client 收到确认后，检查 ack 是否为 x+1，ACK 是否为 1，如果正
确则将标志位 ACK 置为 1，ack=y+1，并且此时操作系统为该 TCP 连接分配 TCP
缓存和变量，并将该数据包发送给 Server，Server 检查 ack 是否为 y+1，ACK 是
否为 1，如果正确则连接建立成功，Client 和 Server 进入 ESTABLISHED 状态，
完成三次握手，随后 Client 和 Server 就可以开始传输数据。  
TCB 传输控制块 Transmission Control Block，存储每一个连接中的重要信息，如
TCP 连接表，到发送和接收缓存的指针，到重传队列的指针，当前的发送和接收
序号。 
四次挥手过程 
1）A 的应用进程先向其 TCP 发出连接释放报文段（FIN=1，序号 seq=u），并停
止再发送数据，主动关闭 TCP 连接，进入 FIN-WAIT-1（终止等待 1）状态，等
待 B 的确认。  
2）B 收到连接释放报文段后即发出确认报文段，（ACK=1，确认号 ack=u+1，
序号 seq=v），B 进入 CLOSE-WAIT（关闭等待）状态，此时的 TCP 处于半关闭
状态，A 到 B 的连接释放。  
3）A 收到 B 的确认后，进入 FIN-WAIT-2（终止等待 2）状态，等待 B 发出的连
接释放报文段。  
4）B 没有要向 A 发出的数据，B 发出连接释放报文段（FIN=1，ACK=1，序号
seq=w，确认号 ack=u+1），B 进入 LAST-ACK（最后确认）状态，等待 A 的确
认。  
5）A 收到 B 的连接释放报文段后，对此发出确认报文段（ACK=1，seq=u+1，
ack=w+1），A 进入 TIME-WAIT（时间等待）状态。此时 TCP 未释放掉，需要
经过时间等待计时器设置的时间 2MSL 后，A 才进入 CLOSED 状态。 
 
 
TCP 协议为什么需要三次握手 
1. 通信双方都必须要维护一个序列号，去标记已经发送出去的数据包，哪些是已
经被对方签收的； 
2. TCP 协议就要在一个不可靠的网络环境下，也要实现可靠的数据传输。通信双
方须要通过某种手段来实现一个可靠的数据传输通道，而三次通信是建立这样通
道的最小值； 
3. 防止历史的重复连接初始化造成的混乱问题，两次握手端只能选择接受或者
拒绝这个连接请求。 
 
 
四次挥手释放连接时，等待 2MSL 的意义 
第一，为了保证 A 发送的最后一个 ACK 报文段能够到达 B。这个 ACK 报文段
有可能丢失，因而使处在 LAST-ACK 状态的 B 收不到对已发送的 FIN 和 ACK 
报文段的确认。B 会超时重传这个 FIN 和 ACK 报文段，而 A 就能在 2MSL 时间
内收到这个重传的 ACK+FIN 报文段。接着 A 重传一次确认。  
第二，就是防止上面提到的已失效的连接请求报文段出现在本连接中，A 在发送
完最有一个 ACK 报文段后，再经过 2MSL，就可以使本连接持续的时间内所产
生的所有报文段都从网络中消失。 
HTTPS 原理详解 
HTTPS 是对 HTTP 的扩展，保证了通信安全，二者关系如下： 
 
也就是说 HTTPS = HTTP + SSL / TLS。 
 
图 5. HTTPS 加密、解密、验证及数据传输过程 
HTTPS 的整个通信过程可以分为两大阶段：证书验证和数据传输阶段，数据传
输阶段又可以分为非对称加密和对称加密两个阶段。具体流程按图中的序号讲解。 
1.客户端请求 HTTPS 网址，然后连接到 server 的 443 端口 (HTTPS 默认端口，
类似于 HTTP 的 80 端口)。 
2.采用 HTTPS 协议的服务器必须要有一套数字 CA (Certification Authority)证书，
证书是需要申请的，并由专门的数字证书认证机构(CA)通过非常严格的审核之后
颁发的电子证书。颁发证书的同时会产生一个私钥和公钥。私钥由服务端自己保
存，不可泄漏。公钥则是附带在证书的信息中，可以公开的。证书本身也附带一
个证书电子签名，这个签名用来验证证书的完整性和真实性，可以防止证书被篡
改。 
3.服务器响应客户端请求，将证书传递给客户端，证书包含公钥和大量其他信息，
比如证书颁发机构信息，公司信息和证书有效期等。Chrome 浏览器点击地址栏
的锁标志再点击证书就可以看到证书详细信息。 
 
图 6. B 站 CA 证书 
4.客户端解析证书并对其进行验证。如果证书不是可信机构颁布，或者证书中的
域名与实际域名不一致，或者证书已经过期，就会向访问者显示一个警告，由其
选择是否还要继续通信。就像下面这样： 
 
图 7. 浏览器安全警告 
如果证书没有问题，客户端就会从服务器证书中取出服务器的公钥 A。然后客户
端还会生成一个随机码 KEY，并使用公钥 A 将其加密。 
5.客户端把加密后的随机码 KEY 发送给服务器，作为后面对称加密的密钥。 
6.服务器在收到随机码 KEY 之后会使用私钥 B 将其解密。经过以上这些步骤，
客户端和服务器终于建立了安全连接，完美解决了对称加密的密钥泄露问题，接
下来就可以用对称加密愉快地进行通信了。 
7.服务器使用密钥 (随机码 KEY)对数据进行对称加密并发送给客户端，客户端
使用相同的密钥 (随机码 KEY)解密数据。 
8.双方使用对称加密愉快地传输所有数据。 
 
 
 
对称加密 
对称加密是指加密和解密都使用的同一个密钥， 
一方通过密钥将信息加密后，把密文传给另一个方，另一方通过这个相同的密钥
将密文解密，转换成可以理解的明文。他们之间的关系如下 
明文 -> 密钥 -> 密文 
这种方式存在的最大的问题就是密钥发送问题，即如何安全的将密钥发送给对方。 
 
非对称加密 
上面提到的是对称加密，其实还有一种是非对称加密，非对称加密是通过两个密
钥（公钥-私钥）来实现对数据的加密和解密的，公钥用于加密，私钥用于解密。 
 
过程如下： 
首先服务器会颁发一个公钥放在网络中，同时它自己还有一份私钥，然后客户端
可以直接获取到对应的公钥，然后将客户端的数据进行公钥的加密，加密后传输
的服务器中，服务器在进行私钥解密，得到最终的数据。 
 
由于非对称加密的方式不需要发送用来解密的私钥，所以可以保证安全性，但是
和对称加密比起来，它非常慢，所以我们还是要用对称加密来传送消息，但是对
称加密使用的密钥我们通过非对称加密的方式发送出去。这个结果就变成了： 
 
但是我们需要注意的是，此时交换的两个公钥不一定正确，因为可能会被中间人
截获，同时掉包 
例如：中间人虽然不知道小红的私钥是什么，但是在截获了小红的公钥 Key1 之
后，却可以偷天换日，自己另外生成一对公钥私钥，把自己的公钥 Key3 发送给
小灰。 
 
这一次通信再次被中间人截获，中间人先用自己的私钥解开了 Key3 的加密，获
得 Key2，然后再用当初小红发来的 Key1 重新加密，再发给小红 
 
 
证书机制 
这个时候我们需要做的就是从指定的机构出获取公钥，而不是任由其在网络传输 
 
作为服务器端的小红，首先先把自己的公钥给证书颁发机构，向证书颁发机构申
请证书 
 
证书颁发机构自己也有一堆公钥和私钥。机构利用自己的私钥来解密 Key1，通
过服务端网址等信息生成一个证书签名，证书签名同样经过机构的私钥加密。证
书制作完成后，机构把证书发送给服务端的小红。 
 
当小灰向小红请求通信的时候，小红不再直接返回自己的公钥，而是把自己申请
的证书返回给小灰。 
 
小灰收到证书以后，要做的第一件事就是验证证书的真伪，需要说明的是，各大
浏览器和操作系统已经维护了所有权威证书机构的名称和公钥，所以小灰只需要
知道是哪个机构颁发的证书，就可以从本地找到对应的机构公钥，解密出证书签
名。 
 
 
 
ARP 
ARP 协议是属于网络层的协议，主要作用是实现从 IP 地址转换为 MAC 地址，
在每个主机或者路由器中都建有一个 ARP 缓存表，表中有 IP 地址及 IP 地址对
应的 MAC 地址。 
ARP 的工作流程 
1. 局域网内，主机 A 要向主机 B 发送 IP 数据报时，首先会在主机 A 的 ARP 缓
存表中查找是否有 IP 地址及其对应的 MAC 地址，如果有，则将 MAC 地址写入
到 MAC 帧的首部，并通过局域网将 MAC 帧发送到 MAC 地址所在的主机 B; 
2. 主机 A 的 ARP 缓存表中没有主机 B 的 IP 地址及所对应的 MAC 地址，主机
A 会在局域网内广播发送一个 ARP 请求分组，局域网内的所有主机都会受到这
个 ARP 请求分组； 
3. 在看到主机 A 发送的 ARP 请求分组中有自己的 IP 地址，会向主机 A 以单播
的方式发送一个带有自己 MAC 地址的响应分组； 
4. 收到主机 B 的响应分组后，会在 ARP 缓存表中写入主机 B 的 IP 地址及其 IP
地址对应的 MAC 地址； 
5. 主机 A 和主机 B 不在同一个局域网内，即使知道主机 B 的 MAC 地址也是不
能直接通信的，必须通过路由器转发到主机 B 的局域网才能通过 B 的 MAC 地
址找到主机 B。并且主机 A 和主机 B 已经可以通信的情况下，主机 A 的 ARP 缓
存表中存的并不是主机 B 的 IP 地址及其对应的 MAC，而是主机 B 的 IP 地址及
该通信链路上的下一跳路由器的 MAC 地址。 
6. 主机 A 和主机 B 不在同一局域网，这时主机 A 需要先广播找到路由器的 MAC
地址，再由此路由器找到主机 B 所在的下一跳路由器的 MAC 地址，最后这个路
由器再广播到主机 B 的 MAC 地址，建立起通信链路。 
 
大流量 tcp 和 http 连接怎么排查 
tcpdump 
tcpdump 可以将网络中传送的数据包的头完全截取下来提供分析。它支持针对
网络层、协议、主机、网络或者端口的过滤。 
-n 禁止 IP 名称解析。  
-nn 禁止 IP 和端口名称解析。 
-i 指定捕获哪个网卡的网络数据包。  
-w 指定将包写入哪个文件，如果文件不存在则创建该文件；如果存在则覆盖其
内容。  
-f 指定过滤表达式，例如指定捕获哪个端口，哪个协议等。  
-r 指定从哪个文件读取网络数据包文件。  
-F 指定使用哪个文件的过滤表达式抓包。  
-D 列出所有可以使用 tcpdump 抓包的网卡。  
-c 指定捕获或者读取包的个数，-c 后面直接接数字即可。  
-l 抓包时保存到文件的同时查看包的内容。  
-t 不打印时间戳。 -tt 秒级时间戳。 -ttt 打印时间戳到微秒或者纳秒，取决于 –
time-stamp-precision option 选项。  
-s 指定每个包捕获的字节数。-s0 将不限制大小，如果想捕获完整的包可以这么
设置。 -S 打印绝对的 tcp 序列号，而不是相对的序列号。  
-v/-vv/-vvv 打印详细信息，v 的个数越多， 打印内容越详细。 
OSI 的七层模型都有哪些 
OSI 七层模型一般指开放系统互连参考模型 (Open System Interconnect 简称 OSI)
是国际标准化组 织(ISO)和国际电报电话咨询委员会(CCITT)联合制定的开放系
统互连参考模型,为开放式互连信息系 统提供了一种功能结构的框架。  
应用层：为应用程序提供交互服务，各种应用程序协议，比如 HTTP、HTTPS、
FTP、SOCKS 安全套接字协议、DNS 域名系统、GDP 网关发现协议等等。  
表示层：主要负责数据格式的转换，如加密解密、转换翻译、压缩解压缩等。比
如 LPP 轻量级表示协议。  
会话层：负责在网络中的两节点之间建立、维持和终止通信，如服务器验证用户
登录便是由会话层完成的，比如 SSL 安全套接字层协议、TLS 传输层安全协议、
RPC 远程过程调用协议等等。 
传输层：接受上一层的数据，在必要的时候对数据进行分割，并将这些数据交给
网络层，保证这些数据段有效到达对端，比如 TCP 传输控制协议、UDP 数据报
协议。  
网络层：选择合适的路由和交换结点，确保数据及时传送，控制子网的运行：逻
辑编址、分组传输、路由选择，比如 IP、IPV6、SLIP 等等。  
数据链路层：将网络层传下来的 IP 数据包组装成帧，并再相邻节点的链路上传
送帧。物理寻址，同时将原始比特流转变为逻辑传输路线，比如 XTP 压缩传输
协议、 PPTP 点对点隧道协议等等。  
物理层：现相邻节点间比特流的透明传输，尽可能屏蔽传输介质和通信手段的差
异。机械、电子、定时接口通信信道上的原始比特流传输，比如 IEEE802.2 等
等。 
 
 
TCP/IP 4 层模型 
应用层 
传输层 
网络层 
网络接口层 
 
为什么要 Time_Wait 
谁先关闭谁先进入 time_wait 状态 
可靠的终止 TCP 连接。保证让迟来的 TCP 报文有足够的时间被识别并丢弃，让
网络上的数据包自动消亡，防止旧连接初始了新的连接 这个期间这个连接的四
元组不能被使用，可以设置端口重用（慎用） 
要是没有三次握手会怎么样 
三次握手的首要原因是为了防止旧的重复连接初始化造成混乱。（防止历史连接
初始化了连接）同步双方初始序列号 避免资源浪费 
三次握手的目的是建立可靠的通信信道，三次握手最主要的目的就是双方确认自
己与对方的发送与接收是正常的。 
第三次握手是为了防止失效的连接请求到达服务器，让服务器错误打开连接。 
要是没有四次挥手会怎么样 
防止旧连接的数据包 保证连接正确关闭 握手报文里都有哪些关键字段 
 
为什么要四次挥手？ 
TCP 是全双工通信，可以双向传输数据。任何一方都可以在数据传送结束后发出
连接释放的通知，待对方确认后进入半关闭状态。当另一方也没有数据再发送的
时候，则发出连接释放通知，对方确认后就完全关闭了 TCP 连接。 
举个例子：A 和 B 打电话，通话即将结束后。 
第一次挥手 ： A 说“我没啥要说的了” 
第二次挥手 ：B 回答“我知道了”，但是 B 可能还会有要说的话，A 不能要求 
B 跟着自己的节奏结束通话 
第三次挥手 ：于是 B 可能又巴拉巴拉说了一通，最后 B 说“我说完了” 
第四次挥手 ：A 回答“知道了”，这样通话才算结束。 
 
为什么需要三次握手，而不是两次？ 
主要有三个原因： 
1. 防止已过期的连接请求报文突然又传送到服务器，因而产生错误和资源浪费。 
在双方两次握手即可建立连接的情况下，假设客户端发送 A 报文段请求建立连
接，由于网络原因造成 A 暂时无法到达服务器，服务器接收不到请求报文段就
不会返回确认报文段。 
客户端在长时间得不到应答的情况下重新发送请求报文段 B，这次 B 顺利到达
服务器，服务器随即返回确认报文并进入 ESTABLISHED 状态，客户端在收到 
确认报文后也进入 ESTABLISHED 状态，双方建立连接并传输数据，之后正常
断开连接。 
此时姗姗来迟的 A 报文段才到达服务器，服务器随即返回确认报文并进入 
ESTABLISHED 状态，但是已经进入 CLOSED 状态的客户端无法再接受确认
报文段，更无法进入 ESTABLISHED 状态，这将导致服务器长时间单方面等待，
造成资源浪费。 
2. 三次握手才能让双方均确认自己和对方的发送和接收能力都正常。 
第一次握手：客户端只是发送处请求报文段，什么都无法确认，而服务器可以确
认自己的接收能力和对方的发送能力正常； 
第二次握手：客户端可以确认自己发送能力和接收能力正常，对方发送能力和接
收能力正常； 
第三次握手：服务器可以确认自己发送能力和接收能力正常，对方发送能力和接
收能力正常； 
可见三次握手才能让双方都确认自己和对方的发送和接收能力全部正常，这样就
可以愉快地进行通信了。 
3. 告知对方自己的初始序号值，并确认收到对方的初始序号值。 
TCP 实现了可靠的数据传输，原因之一就是 TCP 报文段中维护了序号字段和
确认序号字段，通过这两个字段双方都可以知道在自己发出的数据中，哪些是已
经被对方确认接收的。这两个字段的值会在初始序号值得基础递增，如果是两次
握手，只有发起方的初始序号可以得到确认，而另一方的初始序号则得不到确认。 
 
为什么要三次握手，而不是四次？ 
因为三次握手已经可以确认双方的发送接收能力正常，双方都知道彼此已经准备
好，而且也可以完成对双方初始序号值得确认，也就无需再第四次握手了。 
第一次握手：服务端确认“自己收、客户端发”报文功能正常。 
第二次握手：客户端确认“自己发、自己收、服务端收、客户端发”报文功能正常，
客户端认为连接已建立。 
第三次握手：服务端确认“自己发、客户端收”报文功能正常，此时双方均建立连
接，可以正常通信。 
三次握手建立连接时，发送方再次发送确认的必要
性？ 
主要是为了防止已失效的连接请求报文段突然又传到了 B,因而产生错误。假定
出现一种异常情况，即 A 发出的第一个连接请求报文段并没有丢失，而是在某
些网络结点长时间滞留了，一直延迟到连接释放以后的某个时间才到达 B，本来
这是一个早已失效的报文段。但 B 收到此失效的连接请求报文段后，就误认为是
A 又发出一次 新的连接请求，于是就向 A 发出确认报文段，同意建立连接。假
定不采用三次握手，那么只要 B 发出确认，新的连接就建立了，这样一直等待 A
发来数据，B 的许多 资源就这样白白浪费了。 
 
三次握手连接阶段，最后一次 ACK 包丢失，会发生
什么？ 
服务端： 
第三次的 ACK 在网络中丢失，那么服务端该 TCP 连接的状态为 SYN_RECV,并
且会根据 TCP 的超时重传机制，会等待 3 秒、6 秒、12 秒后重新发送 SYN+ACK
包，以便客户端重新发送 ACK 包。 
如果重发指定次数之后，仍然未收到 客户端的 ACK 应答，那么一段时间后，服
务端自动关闭这个连接。 
客户端： 
客户端认为这个连接已经建立，如果客户端向服务端发送数据，服务端将以 RST
包（Reset，标示复位，用于异常的关闭连接）响应。此时，客户端知道第三次握
手失败。 
为什么连接的时候是三次握手，关闭的时候却是四
次握手？ 
服务器在收到客户端的 FIN 报文段后，可能还有一些数据要传输，所以不能马
上关闭连接，但是会做出应答，返回 ACK 报文段. 
接下来可能会继续发送数据，在数据发送完后，服务器会向客户单发送 FIN 报
文，表示数据已经发送完毕，请求关闭连接。服务器的 ACK 和 FIN 一般都会分
开发送，从而导致多了一次，因此一共需要四次挥手。 
CLOSE-WAIT 状态问题 
客户端发送了 FIN 连接释放报文之后，服务器收到了这个报文，就进入了 
CLOSE-WAIT 状态。这个状态是为了让服务器端发送还未传送完毕的数据，传
送完毕之后，服务器会发送 FIN 连接释放报文。 
TIME-WAIT 状态问题 
客户端接收到服务器端的 FIN 报文后进入此状态，此时并不是直接进入 
CLOSED 状态，还需要等待一个时间计时器设置的时间 2MSL。这么做有两个
理由： 
确保最后一个确认报文能够到达。如果 B 没收到 A 发送来的确认报文，那么
就会重新发送连接释放请求报文，A 等待一段时间就是为了处理这种情况的发
生。 
等待一段时间是为了让本连接持续时间内所产生的所有报文都从网络中消失，使
得下一 个新的连接不会出现旧的连接请求报文。 
通信双方建立 TCP 连接后，主动关闭连接的一方就会进入 TIME_WAIT 状态。 
如果已经建立了连接，但是客户端出现故障了怎么
办？ 
或者说，如果三次握手阶段、四次挥手阶段的包丢失了怎么办？如“服务端重发 
FIN 丢失”的问题。 
简而言之，通过定时器 + 超时重试机制，尝试获取确认，直到最后会自动断开
连接。 
具体而言，TCP 设有一个保活计时器。服务器每收到一次客户端的数据，都会重
新复位这个计时器，时间通常是设置为 2 小时。若 2 小时还没有收到客户端的
任何数据，服务器就开始重试：每隔 75 分钟发送一个探测报文段，若一连发送 
10 个探测报文后客户端依然没有回应，那么服务器就认为连接已经断开了。 
TIME-WAIT 状态过多会产生什么后果？怎样处理？ 
从服务器来讲，短时间内关闭了大量的 Client 连接，就会造成服务器上出现大量
的 TIME_WAIT 连接，严重消耗着服务器的资源，此时部分客户端就会显示连接
不上。 
从客户端来讲，客户端 TIME_WAIT 过多，就会导致端口资源被占用，因为端口
就 65536 个，被占满就会导致无法创建新的连接。 
解决办法： 
服务器可以设置 SO_REUSEADDR 套接字选项来避免 TIME_WAIT 状态，此套
接字选项告诉内核，即使此端口正忙（处于 TIME_WAIT 状态），也请继续并重
用它。 
调整系统内核参数，修改/etc/sysctl.conf 文件，即修改 net.ipv4.tcp_tw_reuse 和 
tcp_timestamps 
net.ipv4.tcp_tw_reuse = 1 表示开启重用。允许将 TIME-WAIT sockets 重新用于新
的 TCP 连接，默认为 0，表示关闭； 
net.ipv4.tcp_tw_recycle = 1 表示开启 TCP 连接中 TIME-WAIT sockets 的快速回
收，默认为 0，表示关闭。 
强制关闭，发送 RST 包越过 TIME_WAIT 状态，直接进入 CLOSED 状态。 
TIME_WAIT 是服务器端的状态?还是客户端的状态? 
TIME_WAIT 是主动断开连接的一方会进入的状态，一般情况下，都是客户端所
处的状态；服务器端一般设置不主动关闭连接。 
TIME_WAIT 需要等待 2MSL，在大量短连接的情况下，TIME_WAIT 会太多，
这也会消耗很多系统资源。对于服务器来说，在 HTTP 协议里指定 KeepAlive
（浏览器重用一个 TCP 连接来处理多个 HTTP 请求），由浏览器来主动断开
连接，可以一定程度上减少服务器的这个问题。 
 
第 2 次握手传回了 ACK，为什么还要传回 SYN？ 
服务端传回发送端所发送的 ACK 是为了告诉客户端：“我接收到的信息确实就
是你所发送的信号了”，这表明从客户端到服务端的通信是正常的。回传 SYN 则
是为了建立并确认从服务端到客户端的通信。 
SYN 同步序列编号(Synchronize Sequence Numbers) 是 TCP/IP 建立连接时使用
的握手信号。在客户机和服务器之间建立正常的 TCP 网络连接时，客户机首先
发出一个 SYN 消息，服务器使用 SYN-ACK 应答表示接收到了这个消息，最
后客户机再以 ACK(Acknowledgement）消息响应。这样在客户机和服务器之间
才能建立起可靠的 TCP 连接，数据才可以在客户机和服务器之间传递。 
 
什么是 SYN 洪泛攻击？如何防范？ 
SYN 洪泛攻击属于 DOS 攻击的一种，它利用 TCP 协议缺陷，通过发送大量的
半连接请求，耗费 CPU 和内存资源。 
原理： 
• 
在三次握手过程中，服务器发送 [SYN/ACK] 包（第二个包）之后、收到客
户端的 [ACK] 包（第三个包）之前的 TCP 连接称为半连接（half-open connect），
此时服务器处于 SYN_RECV（等待客户端响应）状态。如果接收到客户端的 
[ACK]，则 TCP 连接成功，如果未接受到，则会不断重发请求直至成功。 
• 
SYN 攻击的攻击者在短时间内伪造大量不存在的 IP 地址，向服务器不断
地发送 [SYN] 包，服务器回复 [SYN/ACK] 包，并等待客户的确认。由于源地
址是不存在的，服务器需要不断的重发直至超时。 
• 
这些伪造的 [SYN] 包将长时间占用未连接队列，影响了正常的 SYN，导致
目标系统运行缓慢、网络堵塞甚至系统瘫痪。 
检测：当在服务器上看到大量的半连接状态时，特别是源 IP 地址是随机的，基
本上可以断定这是一次 SYN 攻击。 
防范： 
• 
通过防火墙、路由器等过滤网关防护。 
• 
通过加固 TCP/IP 协议栈防范，如增加最大半连接数，缩短超时时间。 
• 
SYN cookies 技术。SYN Cookies 是对 TCP 服务器端的三次握手做一些修
改，专门用来防范 SYN 洪泛攻击的一种手段。 
 
ISN 代表什么？意义何在？ 
ISN，发送方的字节数据编号的原点，让对方生成一个合法的接收窗口。 
ISN 是固定不变的吗？动态随机。 
 
什么是网络编程  
网络编程的本质是多台计算机之间的数据交换。数据传递本身没有多大的难度，
不就是把一个设备 中的数据发送给其他设备，然后接受另外一个设备反馈的数
据。现在的网络编程基本上都是基于请 求/响应方式的，也就是一个设备发送请
求数据给另外一个，然后接收另一个设备的反馈。在网络编程中，发起连接程序，
也就是发送第一次请求的程序，被称作客户端(Client)，等待其他程序连接 的程
序被称作服务器(Server)。客户端程序可以在需要的时候启动，而服务器为了能够
时刻相应连 接，则需要一直启动。 
网络编程中两个主要的问题 
1、一个是如何准确的定位网络上一台或多台主机，  
2、另一个就是找到主机后如何可靠高效的进行数据传输。  
在 TCP/IP 协议中 IP 层主要负责网络主机的定位，数据传输的路由，由 IP 地址
可以唯一地确定 Internet 上的一台主机。 
而 TCP 层则提供面向应用的可靠（TCP）的或非可靠（UDP）的数据传输机制，
这是网络编程的主 要对象，一般不需要关心 IP 层是如何处理数据的。 目前较
为流行的网络编程模型是客户机/服务器（C/S）结构。即通信双方一方作为服务
器等待客户 提出请求并予以响应。客户则在需要服务时向服务器提 出申请。服
务器一般作为守护进程始终运 行，监听网络端口，一旦有客户请求，就会启动
一个服务进程来响应该客户，同时自己继续监听服 务端口，使后来的客户也 能
及时得到服务。 
 
 
为什么网络要分层？ 
说到分层，我们先从我们平时使用框架开发一个后台程序来说，我们往往会按照
每一层做不 同的事情的原则将系统分为 三层（复杂的系统分层可能会更多）: 
Repository（数据库操作） 
Service（业务操作） 
Controller（数据交互） 
网络分层的原则：每一层独立于其它层完成自己的工作，而不需要相互依赖，上
下层之间通 过标准结构来互相通信，简单易用又具有拓展性。复杂的系统需要
分层，因为每一层都需要专注于一类事情。我们的网络分层的原因也是一 样，
每一层只专注于做一类事情。 
为什么计算机网络要分层呢？ ,我们再来较为系统的说一说： 
1. 各层之间相互独立：各层之间相互独立，各层之间不需要关心其他层是如何实现
的，只 需要知道自己如何调用下层提供好的功能就可以了（可以简单理解为接
口调用）。这个 和我们对开发时系统进行分层是一个道理。 
2. 提高了整体灵活性 ：每一层都可以使用最适合的技术来实现，你只需要保证你
提供的功能以及暴露的接口的规则没有改变就行了。这个和我们平时开发系统的
时候要求的高内 聚、低耦合的原则也是可以对应上的。 
3. 大问题化小 ：分层可以将复杂的网络间题分解为许多比较小的、界线比较清晰
简单的小问题来处理和解决。这样使得复杂的计算机网络系统变得易于设计，实
现和标准化。这 个和我们平时开发的时候，一般会将系统功能分解，然后将复
杂的问题分解为容易理解 的更小的问题是相对应的，这些较小的问题具有更好
的边界（目标和接口）定义。 
 
 
IP 地址分为几类，每类都代表什么，私网是哪些？  
大致上分为公共地址和私有地址两大类，公共地址可以在外网中随意访问，私有
地址只能在内网访 问只有通过代理服务器才可以和外网通信。  
公共地址： 1.0.0.1～126.255.255.254 128.0.0.1～191.255.255.254 192.0.0.1～
223.255.255.254 224.0.0.1～239.255.255.254 240.0.0.1～255.255.255.254  
私有地址： 10.0.0.0～10.255.255.255 172.16.0.0～172.31.255.255 192.168.0.0～
192.168.255.255 0.0.0.0 路由器转发使用  
127.x.x.x 保留  
255.255.255.255 局域网下的广播地址 
cidrs 
cidrs 地址计算 
当给定一个 IP 地址，比如 18.232.133.86/22，需要求一下这个 IP 所在网络的网络地址、
子网掩码、广播 i 地址、 
这个网络的第一台主机的 IP 地址： 
斜线后是 22 并不是 8 的整数倍，直接很难看出结果，所以需要通过一系列的计算。 
1.先用 8 的整数倍对 22 进行切割：22=16+6 ，所以这个 IP 地址的前 16 位保持不动即
18.232. 
2.发现问题出在了第三个 8 位上，这 8 位中前面 6 位被拿来做了网络号，后面 2 位被拿
去做了主机号， 
所以将这 8 位转化为二进制得到 10000101，拿出前 6 位为<100001>。这是得到了全部
的网络号为 18.232.<100001> 
3.将主机号全部置 0 便是网络地址，18.232.<100001><00>.<00000000>即网络地址为
18.232.132.0 
4.同时也得到了这个网络的第一台主机的 ip 地址，18.232.<100001><00>.<00000001>即
18.232.132.1 
5.将主机位全部置 1 便是广播地址，18.232.<100001><11>.<11111111>即 18.232.135.255 
6.子网掩码可以直接使用 22 计算即可，即前 22 位都为 1，其余为 0，即 255.255.252.0 
再举一例: 
10.42.115.24/20 
表示前面 20 位都是网路号，前 16 位固定，10.42 网段的，在这 115 用二进制表示位
01110011，再前 4 位固定， 
也就是说最小的主机 ip 地址位 10.42.112.0，后面 12 位全为 1 时，即最大主机号位
10.42.127.255。 
 
IPv6 的 128 位地址通常写成 8 组，每组为四个十六进制数的形式。 
 
 
 
http 
HTTP 是一个属于应用层的面向对象的协议，由于其简捷、快速的方式，适用于
分布式超媒体信息系统。 
HTTP 协议的主要特点可概括如下： 
1.支持客户/服务器模式。 
2.简单快速：客户向服务器请求服务时，只需传送请求方法和路径。请求方法常
用的有 GET、HEAD、POST。每种方法规定了客户与服务器联系的类型不同。
由于 HTTP 协议简单，使得 HTTP 服务器的程序规模小，因而通信速度很快。 
3.灵活：HTTP 允许传输任意类型的数据对象。正在传输的类型由 Content-Type
加以标记。 
4.无连接：无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的
请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。 
5.无状态：HTTP 协议是无状态协议。无状态是指协议对于事务处理没有记忆能
力。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导
致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答
就较快。 
 
HTTP 和 HTTPS 有什么区别？ 
1. 端口号 ：HTTP 默认是 80，HTTPS 默认是 443。 
2. URL 前缀 ：HTTP 的 URL 前缀是 http://，HTTPS 的 URL 前缀是 https://。
3. 安全性和资源消耗 ： HTTP 协议运行在 TCP 之上，所有传输的内容都是明
文，客户端和服务器端都无法验证对方的身份。HTTPS 是运行在 SSL/TLS 之
上的 HTTP 协议，SSL/TLS 运行在 TCP 之上。所有传输的内容都经过加密，
加密采用对称加密，但对称加密的密钥用服务器方的证书进行了非对称加密。所
以说，HTTP 安全性没有 HTTPS 高，但是 HTTPS 比 HTTP 耗费更多服务器
资源。 
 
http 请求方法 
HTTP 请求 8 种方法介绍 HTTP/1.1 协议中共定义了 8 种 HTTP 请求方法，HTTP
请求方法也被叫做“请求动作”，不同的方法规定了不同的操作指定的资源方式。
服务端也会根据不同的请求方法做不同的响应。 
GET 
GET 请求会显示请求指定的资源。一般来说 GET 方法应该只用于数据的读取，
而不应当用于会产生副作用的非幂等的操作中。 
GET 方法请求指定的页面信息，并返回响应主体，GET 被认为是不安全的方法，
因为 GET 方法会被网络蜘蛛等任意的访问。 
HEAD 
HEAD 方法与 GET 方法一样，都是向服务器发出指定资源的请求。但是，服务
器在响应 HEAD 请求时不会回传资源的内容部分，即：响应主体。这样，我们可
以不传输全部内容的情况下，就可以获取服务器的响应头信息。HEAD 方法常被
用于客户端查看服务器的性能。 
POST 
POST 请求会 向指定资源提交数据，请求服务器进行处理，如：表单数据提交、
文件上传等，请求数据会被包含在请求体中。POST 方法是非幂等的方法，因为
这个请求可能会创建新的资源或/和修改现有资源。 
PUT 
PUT 请求会身向指定资源位置上传其最新内容，PUT 方法是幂等的方法。通过
该方法客户端可以将指定资源的最新数据传送给服务器取代指定的资源的内容。 
DELETE 
DELETE 请求用于请求服务器删除所请求 URI（统一资源标识符，Uniform 
Resource Identifier）所标识的资源。DELETE 请求后指定资源会被删除，DELETE
方法也是幂等的。 
CONNECT 
CONNECT 方法是 HTTP/1.1 协议预留的，能够将连接改为管道方式的代理服务
器。通常用于 SSL 加密服务器的链接与非加密的 HTTP 代理服务器的通信。 
OPTIONS 
OPTIONS 请求与 HEAD 类似，一般也是用于客户端查看服务器的性能。 这个
方法会请求服务器返回该资源所支持的所有 HTTP 请求方法，该方法会用’*’来
代替资源名称，向服务器发送 OPTIONS 请求，可以测试服务器功能是否正常。
JavaScript 的 XMLHttpRequest 对象进行 CORS 跨域资源共享时，就是使用
OPTIONS 方法发送嗅探请求，以判断是否有对指定资源的访问权限。 允许 
TRACE 
TRACE 请求服务器回显其收到的请求信息，该方法主要用于 HTTP 请求的测试
或诊断。 
HTTP/1.1 之后增加的方法 
在 HTTP/1.1 标准制定之后，又陆续扩展了一些方法。其中使用中较多的是 
PATCH 方法： 
PATCH 
PATCH 方法出现的较晚，它在 2010 年的 RFC 5789 标准中被定义。PATCH 请
求与 PUT 请求类似，同样用于资源的更新。二者有以下两点不同： 
但 PATCH 一般用于资源的部分更新，而 PUT 一般用于资源的整体更新。 当资
源不存在时，PATCH 会创建一个新的资源，而 PUT 只会对已在资源进行更新。 
方法 
作用 
GET 
获取资源 
POST 
传输实体主体 
PUT 
上传文件 
DELETE 
删除文件 
HEAD 
和 GET 方法类似，但只返回报文首部，不返回报文实体主体部分 
PATCH 
对资源进行部分修改 
OPTIONS 
查询指定的 URL 支持的方法 
CONNECT 
要求用隧道协议连接代理 
TRACE 
服务器会将通信路径返回给客户端 
http 请求中 get post 区别 
1．get 请求只能提交 1kb 以下的数据，post 请求可以提交大数据； GET 提交有
数据大小的限制，一般是不超过 1024 个字节，而这种说法也不完全准确，HTTP
协议并没有设定 URL 字节长度的上限，而是浏览器做了些处理，所以长度依据
浏览器的不同有所不同；POST 请求在 HTTP 协议中也没有做说明，一般来说是
没有设置限制的，但是实际上浏览器也有默认值。总体来说，少量的数据使用 GET，
大量的数据使用 POST。 
2．get 请求，请求的参数会在浏览器上显示，post 请求它的数据不会再浏览器
上显示（安全）；  
3．get 请求用来从服务器上获得资源，而 post 是用来向服务器提交数据；  
4．get 将表单中数据按照 name=value 的形式，添加到 action 所指向的 URL 后
面，并且两者使用"?"连接，而各个变量之间使用"&"连接；post 是将表单中的
数据放在 HTTP 协议的请求头或消息体中，传递到 action 所指向 URL； 
5. 对于 GET 方式，服务器端用 Request.QueryString 获取变量的值，对于 POST
方式，服务器端用 Request.Form 获取提交的数据； 
6. GET 是幂等的，即读取同一个资源，总是得到相同的数据，POST 不是幂等
的； 
 
 
 
 
列出常见的 http 状态码和意义 
状态代码有三位数字组成，第一个数字定义响应的类别，共分 5 种类型 
1xx:提示信息--表示请求接受，继续处理 
2xx:成功表示请求成功接收，理解，接受 
3xx:重定向要完成请求必须更进一步操作 
4xx:客户端错误，请求有语法错误或请求无法实现 
5xx:服务器端错误--服务器没有实现合法请求 
 
200 OK-----请求正常处理完毕 
204 No Content-----请求成功处理，没有实体的主体返回 
206 Partial Content-----GET 范围请求已成功处理 
301 Moved Permanently-----永久重定向，比如建设一个网站后，将网站的 url 变换了，重
新申请一个域名， 
但是希望之前的用户访问之前 url 仍然可以访问到，就可以做一个重定向新的 url 下面。 
302 Found-----临时重定向，比如用户在未登录时访问个人中心页面，这时可以临时重定
向到登录的 url 
303 See Other-----临时重定向，期望使用 GET 定向获取 
304 Not Modified-----发送的附带条件请求未满足,当客户端拥有可能过期的缓存时，会携
带缓存的标识 etag、时间等信息询问服务器缓存是否仍可复用，而 304 是告诉客户端可
以复用缓存 
307 Temporary Redirect-----临时重定向，POST 不会变成 GET 
400 Bad Request-----请求报文语法错误或参数错误，服务器无法理解此请求。不作修改，
客户程序就无法重复此请求 
401 Unauthorized-----需要通过 HTTP 认证，或认证失败 
403 Forbidden-----请求资源被拒绝,系统中某些页面只有在某些权限下才能访问，当用户
去访问了一个本身没有访问权限的 url，回报 403 错误 
404 Not Found-----无法找到请求资源（服务器无理由拒绝）,一般是自己输入了一个 url，
这个 url 并不合法。404 找不到，Web 服务器找不到您所请求的文件或脚本。请检查
URL 以确保路径正确; 
500 Internal Server Error-----服务器故障或 Web 应用故障,比如服务器某一个函数代码出
错了，有没有捕获异常，这时候会报 500 错误。500 服务器的内部错误，Web 服务器不
能执行此请求。请稍后重试此请求 
502 Bad Gateway 
此错误响应表明服务器作为网关需要得到一个处理这个请求的响应，但是得到一个错误
的响应。 
503 Service Unavailable-----服务器超负载或停机维护,系统正在维护或者服务器暂停的时
候，回报 500 错误 
504 Gateway Timeout 
当服务器充当网关且无法及时获得响应时，会给出此错误响应。 
幂等 Idempotence 
HTTP 方法的幂等性是指一次和多次请求某一个资源应该具有同样的副作用。(注
意是副作用)；一个方法被多次重复执行的时候所期望的结果要和第一次执行所
期望的结果保持一致；简单来说就是一个逻辑即使被执行多次，也不影响最终结
果的一致性。 
以下两种行为都有可能导致接口被重复执行： 
a. 重复提交或者恶意攻击； 
b. 超时重试机制； 
幂等性的核心思想，其实就是保证这个接口的执行结果只影响一次，后续即使再
次调用，也不能对数据产生影响。 
如何解决幂等性问题 
两种思路：接口只允许调用一次，比如唯一约束、基于 redis 的锁机制；对数据
的影响只会触发一次，比如乐观锁等。 
1. 使用数据库的唯一约束来实现幂等 
比如说对于数据插入的场景而言，假设我们要去创建一个订单，订单号肯定是唯
一的，如果我们多次去触发数据库的唯一约束，它就会产生异常，从而避免一个
请求创建多个订单的问题； 
2. 可以使用 redis 提供的 setNX 指令； 
比如我们 MQ 消息的场景，我们避免 MQ 重复消费，从而导致数据多次被修改
的问题，可以在接收 MQ 消息的时候，把这个消息通过 setNX 写入到 redis 中，
一旦这个消息被消费，我们就不会再次消费； 
3. 使用状态机来实现幂等 
状态机指的是一条数据的完整的运行状态的转化流程，比如说订单的状态，因为
它的状态只会向前变更，所以多次修改同一条数据的时候，一旦状态发生变更，
那么这条数据修改造成的影响也就之后发生一次， 
 
GET http://www.bank.com/account/123456，不会改变资源的状态，不论调用一次还是
N 次都没有副作用。请注意，这里强调的是一次和 N 次具有相同的副作用，而不
是每次 GET 的结果相同。GET http://www.news.com/latest-news 这个 HTTP 请求可
能会每次得到不同的结果，但它本身并没有产生任何副作用，因而是满足幂等性
的。 
DELETE 方法用于删除资源，有副作用，但它应该满足幂等性。比如：DELETE 
http://www.forum.com/article/4231，调用一次和 N 次对系统产生的副作用是相同的，
即删掉 id 为 4231 的帖子；因此，调用者可以多次调用或刷新页面而不必担心引
起错误。 
POST 所对应的 URI 并非创建的资源本身，而是资源的接收者。比如：POST 
http://www.forum.com/articles 的语义是在 http://www.forum.com/articles 下创建一篇帖
子，HTTP 响应中应包含帖子的创建状态以及帖子的 URI。两次相同的 POST 请
求会在服务器端创建两份资源，它们具有不同的 URI；所以，POST 方法不具备
幂等性。 
PUT
所 对 应 的
URI
是 要 创 建 或 更 新 的 资 源 本 身 。 比 如 ： PUT 
http://www.forum/articles/4231 的语义是创建或更新 ID 为 4231 的帖子。对同一 URI
进行多次 PUT 的副作用和一次 PUT 是相同的；因此，PUT 方法具有幂等性 
 
 
============================================================= 
HTTP 报文详解？详细说一下请求报文，以及 HTTP 和 TCP 的区别 
HTTP 有两种报文：请求报文和响应报文 HTTP 请求报文主要包括请求行、请求
头部以及请求的数据（实体）三部分请求行（HTTP 请求报文的第一行）请求行
由方法字段、URL 字段和 HTTP 协议版本字段。其中，方法字段严格区分大小
写，当前 HTTP 协议中的方法都是大写，方法字段如下介绍如下： 
请求头部：位于请求行的下面, 是一个个的 key-value 值 
空行(CR+LF)：请求报文用空行表示 header 和请求数据的分隔 请求数据：GET
方法没有携带数据， POST 方法会携带一个 body 
HTTP 的响应报文包括：状态行，响应头部，相应的数据(响应体) 
状态行包括：HTTP 版本号，状态码和状态值组成。响应头类似请求头，是一系
列 key-value 值 
空白行：同上，响应报文也用空白行来分隔 header 和数据 响应体：响应的数据 
HTTP 请求报文和响应报文的格式？ 
请求报文格式： 
1. 请求行（请求方法+URI 协议+版本） 
2. 请求头部 
3. 空行 
4. 请求主体 
GET/sample.jspHTTP/1.1 请求行 
Accept:image/gif.image/jpeg, 请求头部 
Accept-Language:zh-cn 
Connection:Keep-Alive 
Host:localhost 
User-Agent:Mozila/4.0(compatible;MSIE5.01;Window NT5.0) 
Accept-Encoding:gzip,deflate 
 
username=jinqiao&password=1234 请求主体 
响应报文： 
1. 状态行（版本+状态码+原因短语） 
2. 响应首部 
3. 空行 
4. 响应主体 
HTTP/1.1 200 OK 
Server:Apache Tomcat/5.0.12 
Date:Mon,6Oct2003 13:23:42 GMT 
Content-Length:112 
 
<html> 
    <head> 
        <title>HTTP 响应示例<title> 
    </head> 
    <body> 
        Hello HTTP! 
    </body> 
</html> 
说说 HTTP 协议与 TCP/IP 协议的关系  
HTTP 的长连接和短连接本质上是 TCP 长连接和短连接。 HTTP 属于应用层协
议，在传输层使用 TCP 协议，在网络层使用 IP 协议。 IP 协议主要解决网络路
由和寻址问题， TCP 协议主要解决如何在 IP 层之上可靠地传递数据包，使得网
络上接收端收到发送端所发出的所有包，并且顺序与发送顺序一致。TCP 协议是
可靠的、面向连接的。 
如何理解 HTTP 协议是无状态的？  
HTTP 协议是无状态的，指的是协议对于事务处理没有记忆能力，服务器不知道
客户端是什么状态。 也就是说，打开一个服务器上的网页和上一次打开这个服
务器上的网页之间没有任何联系。HTTP 是 一个无状态的面向连接的协议，无
状态不代表 HTTP 不能保持 TCP 连接，更不能代表 HTTP 使用的是 UDP 协议
（无连接）。 
解释一下 HTTP 长连接和短连接 
在 HTTP/1.0 中，默认使用的是短连接。也就是说，浏览器和服务器每进行一次
HTTP 操作，就建立一次连接，但任务结束就中断连接。如果客户端浏览器访问
的某个 HTML 或其他类型的 Web 页中包含有其他的 Web 资源，如 JavaScript 文
件、图像文件、CSS 文件等；当浏览器每遇到这样一个 Web 资源，就会建立一
个 HTTP 会话。 
但从 HTTP/1.1 起，默认使用长连接，用以保持连接特性。使用长连接的 HTTP
协议，会在响应头有加入这行代码：Connection:keep-alive 
在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输
HTTP 数据的 TCP 连接不会关闭，如果客户端再次访问这个服务器上的网页，
会继续使用这一条已经建立的连接。Keep-Alive 不会永久保持连接，它有一个保
持时间，可以在不同的服务器软件（如 Apache）中设定这个时间。实现长连接要
客户端和服务端都支持长连接。 
HTTP 协议的长连接和短连接，实质上是 TCP 协议的长连接和短连接。 
HTTP 的 Keep-Alive 和 TCP 的 Keep-Alive 有些不同，两个意图不一样。前者主
要是 TCP 连接复用，避免建立过多的 TCP 连接。而 TCP 的 Keep-Alive 的意图
是在于保持 TCP 连接的存活，就是发送心跳包，隔一段时间给连接对端发送一
个探测包，如果接收到对方回应的 ACK，则认为连接还是存活的，在超过一定
重试次数之后还是没有收到对方的回应，则丢弃该 TCP 连接。 
 
长连接和短连接的优缺点？  
长连接可以省去较多的 TCP 建立和关闭的操作，减少浪费，节约时间 。对于频
繁请求资源的客户来 说，较适用长连接。不过这里存在一个问题，存活功能的
探测周期太长，还有就是它只是探测 TCP 连接的存活，属于比较斯文的做法，
遇到恶意的连接时，保活功能就不够使了。在长连接的应用场 景下，client 端一
般不会主动关闭它们之间的连接，Client 与 server 之间的连接如果一直不关闭的 
话，会存在一个问题，随着客户端连接越来越多，server 早晚有扛不住的时候，
这时候 server 端需 要采取一些策略，如关闭一些长时间没有读写事件发生的连
接，这样可 以避免一些恶意连接导致 server 端服务受损；如果条件再允许就可
以以客户端机器为颗粒度，限制每个客户端的最大长连接 数，这样可以完全避
免某个蛋疼的客户端连累后端服务。 短连接对于服务器来说管理较为简单，存
在的连接都是有用的连接，不需要额外的控制手段。但如 果客户请求频繁，将
在 TCP 的建立和关闭操作上浪费时间和带宽。 
说说长连接短连接的操作过程  
短连接的操作步骤是：建立连接——数据传输——关闭连接...建立连接——数据
传输——关闭连 接长连接的操作步骤是：建立连接——数据传输...（保持连接）...
数据传输——关闭连接 
如何将长链接转换成短链接，并发送短信？  
短 URL 从生成到使用分为以下几步： 有一个服务,将要发送给你的长 URL 对
应到一个短 URL 上.例如 www.baidu.com -> www.t.cn/ 1。 把短 url 拼接到短
信等的内容上发送。 用户点击短 URL ,浏览器用 301 / 302 进行重定向,访问到
对应的长 URL。 展示对应的内容。  
长链接和短链接如何互相转换？  
思路是建立一个发号器。每次有一个新的长 URL 进来，我们就增加一。并且将
新的数值返回.第一 个来的 url 返回"www.x.cn/0",第二个返回"www.x.cn/1"。  
长链接和短链接的对应关系如何存储？  
如果数据量小且 QPS 低，直接使用数据库的自增主键就可以实现。 还可以将
最近/最热门的对应关 系存储在 K-V 数据库中,这样子可以节省空间的同时,加
快响应速度。 
# Accept:指浏览器或其他客户可以接爱的 MIME 文件格式。可以根据它判断并返回适当
的文件格式。 
# Accept-Charset：指出浏览器可以接受的字符编码。英文浏览器的默认值是 ISO-8859-
1. 
# Accept-Language：指出浏览器可以接受的语言种类，如 en 或 en-us，指英语。 
# Accept-Encoding：指出浏览器可以接受的编码方式。编码方式不同于文件格式，它是
为了压缩文件并加速文件传递速度。浏览器在接收到 Web 响应之后先解码，然后再检
查文件格式。 
# Cache-Control：设置关于请求被代理服务器存储的相关选项。一般用不到。 
# Connection：用来告诉服务器是否可以维持固定的 HTTP 连接。HTTP/1.1 使用 Keep-
Alive 为默认值，这样，当浏览器需要多个文件时(比如一个 HTML 文件和相关的图形文
件)，不需要每次都建立连接。 
# Content-Type ： 用 来 表 名 request 的 内 容 类 型 。 可 以 用 HttpServletRequest 的
getContentType()方法取得。 
# Cookie：浏览器用这个属性向服务器发送 Cookie。Cookie 是在浏览器中寄存的小型数
据体，它可以记载和服务器相关的用户信息，也可以用来实现会话功能。 
 
 
 
# 浏览器向服务器发送的请求格式如下： 
GET / HTTP/1.1 
Host: www.baidu.com 
Connection: keep-alive 
Cache-Control: max-age=0 
Upgrade-Insecure-Requests: 1 
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, 
like Gecko) Chrome/88.0.4324.190 Safari/537.36 
Accept: 
text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*
/*;q=0.8,application/signed-exchange;v=b3;q=0.9 
Sec-Fetch-Site: none 
Sec-Fetch-Mode: navigate 
Sec-Fetch-User: ?1 
Sec-Fetch-Dest: document 
Accept-Encoding: gzip, deflate, br 
Accept-Language: zh,zh-TW;q=0.9,en-US;q=0.8,en;q=0.7,zh-CN;q=0.6 
Cookie: 
__yjs_duid=1_c940e71be451d3762878fbddc4c2e2141614435162110; 
BAIDUID=6E788B30D916990EF40140461FD2CD6E:FG=1; 
BAIDUID_BFESS=6E788B30D916990E3A8E1C6C2313936A:FG=1; 
BIDUPSID=6E788B30D916990EF40140461FD2CD6E; 
PSTM=1614773571; 
BD_HOME=1; 
H_PS_PSSID=33512_33272_31253_33594_33570_33601_26350; 
BD_UPN=12314753; BA_HECTOR=al0k00250ha10kah971g3uvfq0r 
     
# User-Agent 为浏览器版本； 
     
# 服务器向浏览器返回格式：     
HTTP/1.1 200 OK 
Bdpagetype: 1 
Bdqid: 0xfd3c646400008152 
Cache-Control: private 
Connection: keep-alive 
Content-Encoding: gzip 
Content-Type: text/html;charset=utf-8 
Date: Wed, 03 Mar 2021 12:17:50 GMT 
Expires: Wed, 03 Mar 2021 12:17:50 GMT 
Server: BWS/1.1 
Set-Cookie: BDSVRTM=23; path=/ 
Set-Cookie: BD_HOME=1; path=/ 
Set-Cookie: 
H_PS_PSSID=33512_33272_31253_33594_33570_33601_26350; 
path=/; 
domain=.baidu.com 
Strict-Transport-Security: max-age=172800 
Traceid: 1614773870073621863418247570170857947474 
X-Ua-Compatible: IE=Edge,chrome=1 
Transfer-Encoding: chunked 
Http 和 Https 的区别 
超文本传输协议 HTTP 协议被用于在 Web 浏览器和网站服务器之间传递信息，
HTTP 协议以明文方式发送内容，不提供任何方式的数据加密 
安全套接字层超文本传输协议 HTTPS，为了数据传输的安全，HTTPS 在 HTTP
的基础上加入了 SSL（Secure Sockets Layer 安全套接层）协议，SSL 依靠证书
来验证服务器的身份，并为浏览器和服务器之间的通信加密。 
http 和 https 使用的是完全不同的连接方式，用的端口也不一样，前者是 80，后
者是 443。 
什么是 Cookie 和 Session ? 
什么是 Cookie 
HTTP Cookie（也叫 Web Cookie 或浏览器 Cookie）是服务器发送到用户浏览器
并保存在本地的一小块数据，它会在浏览器下次向同一服务器再发起请求时被携
带并发送到服务器上。通常，它用于告知服务端两个请求是否来自同一浏览器，
如保持用户的登录状态。Cookie 使基于无状态的 HTTP 协议记录稳定的状态信
息成为了可能。 
Cookie 主要用于以下三个方面： 
 
会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息） 
 
个性化设置（如用户自定义设置、主题等） 
 
浏览器行为跟踪（如跟踪分析用户行为等） 
什么是 Session 
Session 代表着服务器和客户端一次会话的过程。Session 对象存储特定用户会
话所需的属性及配置信息。这样，当用户在应用程序的 Web 页之间跳转时，存
储在 Session 对象中的变量将不会丢失，而是在整个用户会话中一直存在下去。
当客户端关闭会话，或者 Session 超时失效时会话结束。 
Cookie 和 Session 是如何配合的呢？ 
用户第一次请求服务器的时候，服务器根据用户提交的相关信息，创建对应的 
Session ，请求返回时将此 Session 的唯一标识信息 SessionID 返回给浏览器，
浏览器接收到服务器返回的 SessionID 信息后，会将此信息存入到 Cookie 中，
同时 Cookie 记录此 SessionID 属于哪个域名。 
当用户第二次访问服务器的时候，请求会自动判断此域名下是否存在 Cookie 信
息，如果存在自动将 Cookie 信息也发送给服务端，服务端会从 Cookie 中获取 
SessionID，再根据 SessionID 查找对应的 Session 信息，如果没有找到说明用户
没有登录或者登录失效，如果找到 Session 证明用户已经登录可执行后面操作。 
根据以上流程可知，SessionID 是连接 Cookie 和 Session 的一道桥梁，大部分
系统也是根据此原理来验证用户登录状态。 
如何考虑分布式 Session 问题？ 
在互联网公司为了可以支撑更大的流量，后端往往需要多台服务器共同来支撑前
端用户请求，那如果用户在 A 服务器登录了，第二次请求跑到服务 B 就会出
现登录失效问题。 
分布式 Session 一般会有以下几种解决方案： 
 
客户端存储：直接将信息存储在 cookie 中，cookie 是存储在客户端上的一小段数
据，客户端通过 http 协议和服务器进行 cookie 交互，通常用来存储一些不敏感
信息 
 
Nginx ip_hash 策略：服务端使用 Nginx 代理，每个请求按访问 IP 的 hash 分
配，这样来自同一 IP 固定访问一个后台服务器，避免了在服务器 A 创建 
Session，第二次分发到服务器 B 的现象。 
 
Session 复制：任何一个服务器上的 Session 发生改变（增删改），该节点会把
这个 Session 的所有内容序列化，然后广播给所有其它节点。 
 
共享 Session：服务端无状态话，将用户的 Session 等信息使用缓存中间件（如
Redis）来统一管理，保障分发到每一个服务器的响应结果都一致。 
建议采用共享 Session 的方案。 
cookie 和 session 的区别 
1，session 在服务器端，cookie 在客户端（浏览器） 
2、session 的运行依赖 session id，而 session id 是存在 cookie 中的，也就是说，
如果浏览器禁用了 cookie ，同时 session 也会失效，存储 Session 时，键与 Cookie
中的 sessionid 相同，值是开发人员设置的键值对信息，进行了 base64 编码，过
期时间由开发人员设置 
3、cookie 安全性比 session 差 
4、session 默认存在服务器上的文件里面（也可以是内存，数据库）； 
5、用户验证通常会用 session，维持一个会话核心就是客户端的唯一标识，即
session_id 
Session,Cookie 的理解 
为什么要使用会话管理 
众所周知，HTTP 协议是一个无状态的协议，也就是说每个请求都是一个独立的
请求，请求与请求之间并无关系。但在实际的应用场景，这种方式并不能满足我
们的需求。举个大家都喜欢用的例子，把商品加入购物车，单独考虑这个请求，
服务端并不知道这个商品是谁的，应该加入谁的购物车？因此这个请求的上下文
环境实际上应该包含用户的相关信息，在每次用户发出请求时把这一小部分额外
信息，也做为请求的一部分，这样服务端就可以根据上下文中的信息，针对具体
的用户进行操作。所以这几种技术的出现都是对 HTTP 协议的一个补充，使得我
们可以用 HTTP 协议+状态管理构建一个的面向用户的 WEB 应用。 
Session 和 Cookie 的区别 
个人认为 session 与 cookies 最核心区别在于额外信息由谁来维护。利用 cookies
来实现会话管理时，用户的相关信息或者其他我们想要保持在每个请求中的信息，
都是放在 cookies 中,而 cookies 是由客户端来保存，每当客户端发出新请求时，
就会稍带上 cookies,服务端会根据其中的信息进行操作。 当利用 session 来进行
会话管理时，客户端实际上只存了一个由服务端发送的 session_id,而由这个
session_id,可以在服务端还原出所需要的所有状态信息，从这里可以看出这部分
信息是由服务端来维护的。 
除此以外，session 与 cookies 都有一些自己的缺点： 
cookies 的安全性不好，攻击者可以通过获取本地 cookies 进行欺骗或者利用
cookies 进行 CSRF 攻击。使用 cookies 时,在多个域名下，会存在跨域问题。 session 
在一定的时间里，需要存放在服务端，因此当拥有大量用户时，也会大幅度降低
服务端的性能，当有多台机器时，如何共享 session 也会是一个问题.(redis 集群)
也就是说，用户第一个访问的时候是服务器 A，而第二个请求被转发给了服务器
B，那服务器 B 如何得知其状态。实际上，session 与 cookies 是有联系的，比如
我们可以把 session_id 存放在 cookies 中的。 
对 cookies 与 session 的了解？他们能单独用吗？ 
Session 采用的是在服务器端保持状态的方案，而 Cookie 采用的是在客户端保持
状态的方案。但是禁用 Cookie 就不能得到 Session。因为 Session 是用 Session ID
来确定当前对话所对应的服务器 Session，而 Session ID 是通过 Cookie 来传递的，
禁用 Cookie 相当于 SessionID,也就得不到 Session。 
讲一下对称加密算法和非对称加密算法？ 
对称加密：密钥只有一个，加密解密为同一个密码，且加解密速度快，典型的对
称 加密算法有 DES、AES 等； 
非对称密钥加密，加密和解密使用不同的密钥。通信发送方获得接收方的公开密
钥之后，就 可以使用公开密钥进行加密，接收方收到通信内容后使用私有密钥
解密。可以更安全地将公 开密钥传输给通信发送方；运算速度慢。典型的非对
称加密算法有 RSA、DSA 等 
HTTPS 采用混合的加密机制。所有传输的内容都经过加密，加密采用对称加密，
但对称加密的密钥用服务器方的证书进行了非对称加密。 
 
 
 
WSGI 
CGI 全称是“公共网关接口”(CommonGateway Interface)，HTTP 服务器与你的或
其它机器上的程序进行“交谈”的一种工具，其程序须运行在网络服务器上。 
WSGI(Web Server Gateway Interface)是一种 CGI，用于连接 WEB 服务器与应用
程序，WSGI 专指 Python 应用程序；WSGI 的其中一个目的就是让用户可以用统
一的语言(Python)编写前后端。 
 
 
 
 
谈一下你对 uWSGI 和 nginx 的理解 
1.uWSGI 是一个 Web 服务器，它实现了 WSGI 协议、uwsgi、http 等协议。Nginx
中 HttpUwsgiModule 的作用是与 uWSGI 服务器进行交换。WSGI 是一种 Web 服
务器网关接口。它是一个 Web 服务器（如 nginx，uWSGI 等服务器）与 web 应
用（如用 Flask 框架写的程序）通信的一种规范。 
要注意 WSGI/uwsgi/uWSGI 这三个概念的区分。 
WSGI 是一种通信协议。 
uwsgi 是一种线路协议而不是通信协议，在此常用于在 uWSGI 服务器与其他网
络服务器的数据通信。 
uWSGI 是实现了 uwsgi 和 WSGI 两种协议的 Web 服务器。 
nginx 是一个开源的高性能的 HTTP 服务器和反向代理： 
1.作为 web 服务器，它处理静态文件和索引文件效果非常高 
2.它的设计非常注重效率，最大支持 5 万个并发连接，但只占用很少的内存空间 
3.稳定性高，配置简洁。 
4.强大的反向代理和负载均衡功能，平衡集群中各个服务器的负载压力应用 
 
 
 
简述浏览器通过 WSGI 请求动态资源的过程? 
浏览器发送的请求被 Nginx 监听到，Nginx 根据请求的 URL 的 PATH 或者后缀
把请求静态资源的分发到静态资源的目录，别的请求根据配置好的转发到相应端
口。 实现了 WSGI 的程序会监听某个端口，监听到 Nginx 转发过来的请求接收
后(一般用 socket 的 recv 来接收 HTTP 的报文)以后把请求的报文封装成 environ
的字典对象，然后再提供一个 start_response 的方法。把这两个对象当成参数传入
某个方法比如 wsgi_app(environ, start_response) 或者实现了 __call__(self, environ, 
start_response)方法的某个实例。这个实例再调用 start_response 返回给实现了 WSGI
的中间件，再由中间件返回给 Nginx。 
 
 
简述 QQ 登陆过程 
qq 登录，在我们的项目中分为了三个接口， 
第一个接口是请求 qq 服务器返回一个 qq 登录的界面; 
第二个接口是通过扫码或账号登陆进行验证，qq 服务器返回给浏览器一个 code
和 state,利用这个 code 通过本地服务器去向 qq 服务器获取 access_token 覆返回
给本地服务器，凭借 access_token 再向 qq 服务器获取用户的 openid(openid 用户
的唯一标识) 
第三个接口是判断用户是否是第一次 qq 登录，如果不是的话直接登录返回的 jwt-
token 给用户，对没有绑定过本网站的用户，对 openid 进行加密生成 token 进行
绑定 
 
 
 
分别从前端、后端、数据库阐述 web 项目的性能优化 
前端优化： 
1、减少 http 请求、例如制作精灵图 
2、html 和 CSS 放在页面上部，javascript 放在页面下面，因为 js 加载比 HTML
和 Css 加载慢，所以要优先加载 html 和 css,以防页面显示不全，性能差，也影响
用户体验差 
后端优化： 
1、缓存存储读写次数高，变化少的数据，比如网站首页的信息、商品的信息等。
应用程序读取数据时，一般是先从缓存中读取，如果读取不到或数据已失效，再
访问磁盘数据库，并将数据再次写入缓存。 
2、异步方式，如果有耗时操作，可以采用异步，比如 celery 
3、代码优化，避免循环和判断次数太多，如果多个 if else 判断，优先判断最有
可能先发生的情况 
数据库优化： 
1、如有条件，数据可以存放于 redis，读取速度快 
2、建立索引、外键等 
什么是 rpc 
一个通俗的描述是：客户端在不知道调用细节的情况下，调用存在于远程计算机
上的某个对象，就像调用本地应用程序中的对象一样。 
 
比较正式的描述是：一种通过网络从远程计算机程序上请求服务，而不需要了解
底层网络技术的协议。 
远程过程调用 (RPC) 是一种协议，程序可使用这种协议向网络中的另一台计算
机上的程序请求服务 
1.RPC 采用客户机/服务器模式。请求程序就是一个客户机，而服务提供程序就是
一个服务器。 
2.首先，客户机调用进程发送一个有进程参数的调用信息到服务进程，然后等待
应答信息。 
2.在服务器端，进程保持睡眠状态直到调用信息到达为止。当一个调用信息到达，
服务器获得进程参数，计算结果，发送答复信息，然后等待下一个调用信息， 
3.最后，客户端调用进程接收答复信息，获得进程结果，然后调用执行继续进行。 
SOAP 
SOAP（原为 Simple Object Access Protocol 的首字母缩写，即简单对象访问协议）
是交换数据的一种协议规范，使用在计算机网络 Web 服务（web service）中，交
换带结构信息。SOAP 为了简化网页服务器（Web Server）从 XML 数据库中提
取数据时，节省去格式化页面时间，以及不同应用程序之间按照 HTTP 通信协议，
遵从 XML 格式执行资料互换，使其抽象于语言实现、平台和硬件。 
RESTful API 
REST 指 Representational State Transfer，可以翻译为“表现层状态转化” 
主要思想 
 
对网络 上的 所有资 源，都 有一 个 统一 资源标 识符  URI(Uniform Resource 
Identifier)； 
 
这些资源可以有多种表现形式，即 REST 中的“表现层”Representation，比如，文
本可以用 txt 格式表现，也可以用 HTML 格式、XML 格式、JSON 格式表现。
URI 只代表资源的实体，不代表它的形式； 
 
“无状态(Stateless)”思想：服务端不应该保存客户端状态，只需要处理当前的请求，
不需了解请求的历史，客户端每一次请求中包含处理该请求所需的一切信息； 
 
客户端使用 HTTP 协议中的 GET/POST/PUT/DELETE 方法对服务器的资源进行
操作，即 REST 中的”状态转化“ 
设计原则 
 
URL 设计 
o 最好只使用名词，而使用 GET/POST/PUT/DELETE 方法的不同表示不同的操作；
比如使用 POST /user 代替/user/create 
o GET：获取资源；POST：新建/更新资源；PUT：更新资源；DELETE：删除资源； 
o 对于只支持 GET/POST 的客户端，使用 X-HTTP-Method-Override 属性，覆盖 POST
方法； 
o 避 免 多 级
URL ， 比 如 使 用
GET /authors/12?categories=2
代 替
GET 
/authors/12/categories/2； 
o 避免在 URI 中带上版本号。不同的版本，可以理解成同一种资源的不同表现形
式，所以应该采用同一个 URI，版本号可以在 HTTP 请求头信息的 Accept 字段
中进行区分 
 
状态码：服务器应该返回尽可能精确的状态码，客户端只需查看状态码，就可以
判断出发生了什么情况。 
 
服务器回应：在响应中放上其它 API 的链接，方便用户寻找 
总结:服务提供的两大流派.传统意义以方法调用为导向通称 RPC。为了企业 SOA,
若干厂商联合推出 webservice,制定了 wsdl 接口定义,传输 soap.当互联网时代,臃
肿 SOA 被简化为 http+xml/json.但是简化出现各种混乱。以资源为导向,任何操作
无非是对资源的增删改查，于是统一的 REST 出现了。 
RestFul 和 RPC 的区别 
1、从本质区别上看，RPC 是基于 TCP 实现的，RestFul 是基于 HTTP 来实现的。 
2、从传输速度上来看，因为 HTTP 封装的数据量更多所以数据传输量更大，所
以 RPC 的传输速度是比 RestFul 更快的。 
3、因为 HTTP 协议是各个框架都普遍支持的。在 toC 情况下，因为不知道情况
来源的框架、数据形势是什么样的，所以在网关可以使用 RestFul 利用 http 来接
受。而在微服务内部的各模块之间因为各协议方案是公司内部自己定的，所以知
道各种数据方式，可以使用 TCP 传输以使各模块之间的数据传输更快。所以可
以网关和外界的数据传输使用 RestFul，微服务内部的各模块之间使用 RPC。 
4、RestFul 的 API 的设计上是面向资源的，对于同一资源的获取、传输、修改可
以使用 GET、POST、PUT 来对同一个 URL 进行区别，而 RPC 通常把动词直接
体现在 URL 上 
 
apache 和 nginx 的区别 
nginx 相对 apache 的优点： 
 
轻量级，同样起 web 服务，比 apache 占用更少的内存及资源 
 
抗并发，nginx 处理请求是异步非阻塞的，支持更多的并发连接，而 apache 则是
阻塞型的，在高并发下 nginx 能保持低资源低消耗高性能 
 
配置简洁 
 
高度模块化的设计，编写模块相对简单 
 
社区活跃 
apache 相对 nginx 的优点： 
 
rewrite ，比 nginx 的 rewrite 强大 
 
模块超多，基本想到的都可以找到 
 
少 bug ，nginx 的 bug 相对较多 
 
超稳定 
XSRF 和 XSS 
 
CSRF(Cross-site request forgery)跨站请求伪造 
 
XSS(Cross Site Scripting)跨站脚本攻击 
CSRF 重点在请求,XSS 重点在脚本 
Socket  
1、网络上的两个程序通过一个双向的通讯连接实现数据的交换，这个双向链路
的一端称为一个 Socket。Socket 通常用来实现客户方和服务方的连接。Socket 是
TCP/IP 协议的一个十分流行的编程界面，一个 Socket 由一个 IP 地址和一个端口
号唯一确定。  
2、但是，Socket 所支持的协议种类也不光 TCP/IP、UDP，因此两者之间是没有
必然联系的。在 Java 环境 下，Socket 编程主要是指基于 TCP/IP 协议的网络编
程。  
3、socket 连接就是所谓的长连接，客户端和服务器需要互相连接，理论上客户
端和服务器端一旦建立起连接将不会主动断掉的，但是有时候网络波动还是有可
能的 。 
4、Socket 偏向于底层。一般很少直接使用 Socket 来编程，框架底层使用 Socket
比较多 
4. docker 
云原生 
Cloud Native，Cloud 表示应用程序位于云中，而不是传统的数据中心；Native 表
示应用程序从设计之初即考虑到云的环境。 
云原生四要素： 
微服务：单个应用程序由许多松散耦合且可独立部署的较小组件或服务组成。这
些服务通常有自己的堆栈，包括数据库和数据模型；通过 REST API，事件流和
消息代理的组合相互通信；它们是按业务能力组织的，分隔服务的线通常称为有
界上下文。 
容器化：为微服务提供支持以及起到隔离的作用，k8s 就是容器的编排系统，它
用于容器的管理和容器内部的负载均衡； 
DevOps：开发和运维的合体，还包括测试，为云原生提供可持续交付的能力； 
持续交付：又叫 CICD，实现在线不停机的更新，开发版本和稳定版本并存，需
要标准的流程和工具来支撑，如 jenkins； 
 
centos 安装 docker 
1.卸载旧版本 docker 和 docker-engine 
2.使用存储库安装 yum install yum-utils device-mapper-persistent-data lvm2 
3.yum-config-manager —add-repo https://download.docker.com/linux/centos/docker-
ce.repo  
4.yum install -y docker-ce  
 
docker 容器与主机时间保持同步 
1.共享主机的 localtime 
创 建 容 器 指 定 启 动 参 数 ， 挂 载
localtime
文 件 到 容 器 内    -v 
/etc/localtime:/etc/localtime:ro  
2.复制主机的 localtime 
3.创建 dockerfile   
RUN 
/bin/cp 
/usr/share/zoneinfo/Asia/Shanghai 
/etc/localtime 
&& 
echo 
‘Asia/Shanghai’ > /etc/timezone 
 
 
 
docker 隔离原理 
docker 本质上是宿主机上的进程，通过 namespace 实现资源隔离，通过 cgroup 实
现了资源限制，通过写时复制实现了高效文件操作。 
 
6 项资源进行隔离： 
主机名和域名； 
信号量，消息队列，共享内存； 
进程编号； 
网络设备，网络栈，端口等； 
挂载点即文件系统； 
用户和用户组； 
namespace 的 API 主要包括 clone()__创建独立的 namespace；setns()__加入一个
已存在的 namespace，即执行 docker exec；unshare()__在原先进程上进行隔离，
必须要启动一个新进程。 
 
cgroups 
可以对任务使用资源总额进行限制； 
通过分配的 CPU 时间片数量以及磁盘 IO 带宽限制任务运行的优先级； 
统计系统资源使用量； 
对任务执行挂起恢复操作。 
 
网络模式 
 
bridge 模式：使用--network  bridge 指定，默认使用 docker0 
host 模式：使用--network host 指定 
none 模式：使用--network none 指定 
container 模式：使用--network container:NAME 或者容器 ID 指定 
bridge  
Docker 服务默认会创建一个 docker0 网桥（其上有一个 docker0 内部接口），该
桥接网络的名称为 docker0，它在内核层连通了其他的物理或虚拟网卡，这就将
所有容器和本地主机都放到同一个物理网络。Docker 默认指定了 docker0 接口 
的 IP 地址和子网掩码，让主机和容器之间可以通过网桥相互通信。 
# 查看 bridge 网络的详细信息，并通过 grep 获取名称项 
1．Docker 使用 Linux 桥接，在宿主机虚拟一个 Docker 容器网桥(docker0)，Docker
启动一个容器时会根据 Docker 网桥的网段分配给容器一个 IP 地址，称为
Container-IP，同时 Docker 网桥是每个容器的默认网关。因为在同一宿主机内的
容器都接入同一个网桥，这样容器之间就能够通过容器的 Container-IP 直接通信。 
2．docker run 的时候，没有指定 network 的话默认使用的网桥模式就是 bridge，
使用的就是 docker0。在宿主机 ifconfig,就可以看到 docker0 和自己 create 的
network(后面讲)eth0，eth1，eth2……代表网卡一，网卡二，网卡三……，lo 代表
127.0.0.1，即 localhost，inet addr 用来表示网卡的 IP 地址 
  
3．网桥 docker0 创建一对对等虚拟设备接口一个叫 veth，另一个叫 eth0，成对匹
配。 
3.1 整个宿主机的网桥模式都是 docker0，类似一个交换机有一堆接口，每个接口
叫 veth，在本地主机和容器内分别创建一个虚拟接口，并让他们彼此联通（这样
一对接口叫 veth pair）； 
3.2 每个容器实例内部也有一块网卡，每个接口叫 eth0； 
3.3 docker0 上面的每个 veth 匹配某个容器实例内部的 eth0，两两配对，一一匹
配。 
 通过上述，将宿主机上的所有容器都连接到这个内部网络上，两个容器在同一个
网络下,会从这个网关下各自拿到分配的 ip，此时两个容器的网络是互通的。 
 
host  
直接使用宿主机的 IP 地址与外界进行通信，不再需要额外进行 NAT 转换。 
容器将不会获得一个独立的 Network Namespace， 而是和宿主机共用一个
Network Namespace。容器将不会虚拟出自己的网卡而是使用宿主机的 IP 和端口。 
 
    docker 启动时指定--network=host 或-net=host，如果还指定了-p 映射端口，那
这个时候就会有此警告，并且通过-p 设置的参数将不会起到任何作用，端口号会
以主机端口号为主，重复时则递增。 
解决: 
解决的办法就是使用 docker 的其他网络模式，例如--network=bridge，这样就可
以解决问题，或者直接无视。 
none  
在 none 模式下，并不为 Docker 容器进行任何网络配置。  
也就是说，这个 Docker 容器没有网卡、IP、路由等信息，只有一个 lo 
需要我们自己为 Docker 容器添加网卡、配置 IP 等。 
禁用网络功能，只有 lo 标识(就是 127.0.0.1 表示本地回环) 
container 
container⽹络模式  
新建的容器和已经存在的一个容器共享一个网络 ip 配置而不是和宿主机共享。
新创建的容器不会创建自己的网卡，配置自己的 IP，而是和一个指定的容器共享
IP、端口范围等。同样，两个容器除了网络方面，其他的如文件系统、进程列表
等还是隔离的。 
 
 
Docker-compose 容器编排  
Compose 是 Docker 公司推出的一个工具软件，可以管理多个 Docker 容器组成
一个应用。你需要定义一个 YAML 格式的配置文件 docker-compose.yml，写好多
个容器之间的调用关系。然后，只要一个命令，就能同时启动/关闭这些容器。 
负责实现对 Docker 容器集群的快速编排。 
 
为什么需要 docker-compose 
 docker 建议我们每一个容器中只运行一个服务,因为 docker 容器本身占用资源极
少，所以最好是将每个服务单独的分割开来但是这样我们又面临了一个问题？ 
如果我需要同时部署好多个服务,难道要每个服务单独写 Dockerfile 然后在构建
镜像,构建容器,这样累都累死了,所以 docker 官方给我们提供了 docker-compose
多服务部署的工具 
  
例如要实现一个 Web 微服务项目，除了 Web 服务容器本身，往往还需要再加上
后端的数据库 mysql 服务容器，redis 服务器，注册中心 eureka，甚至还包括负载
均衡容器等等。。。。。。 
Compose 允许用户通过一个单独的 docker-compose.yml 模板文件（YAML 格式）
来定义一组相关联的应用容器为一个项目（project）。 
可以很容易地用一个配置文件定义一个多容器的应用，然后使用一条指令安装这
个应用的所有依赖，完成构建。Docker-Compose 解决了容器与容器之间如何管
理编排的问题。  
 
 
Compose 核心概念 
一文件 docker-compose.yml 
两要素  
服务（service）：一个个应用容器实例，比如订单微服务、库存微服务、mysql
容器、nginx 容器或者 redis 容器 
工程（project）：由一组关联的应用容器组成的一个完整业务单元，在 docker-
compose.yml 文件中定义。 
 
Compose 使用的三个步骤 
1. 编写 Dockerfile 定义各个微服务应用并构建出对应的镜像文件 
2. 使用 docker-compose.yml 定义一个完整业务单元，安排好整体应用中的各个
容器服务。 
3. 最后，执行 docker-compose up 命令 来启动并运行整个应用程序，完成一键部
署上线 
 
Compose 常用命令 
docker-compose -h                           # 查看帮助 
docker-compose up                           # 启动所有 docker-compose 服务 
docker-compose up -d                        # 启动所有 docker-compose 服务并后台运行 
docker-compose down                         # 停止并删除容器、网络、卷、镜像。 
docker-compose exec  yml 里面的服务 id                 # 进入容器实例内部  docker-
compose exec docker-compose.yml 文件中写的服务 id /bin/bash 
docker-compose ps                      # 展示当前 docker-compose 编排过的运行的所有
容器 
docker-compose top                     # 展示当前 docker-compose 编排过的容器进程 
  
docker-compose logs  yml 里面的服务 id     # 查看容器输出日志 
docker-compose config     # 检查配置 
docker-compose config -q  # 检查配置，有问题才有输出 
docker-compose restart   # 重启服务 
docker-compose start     # 启动服务 
docker-compose stop      # 停止服务 
 
 
 
DockerFile 解析 
 
Dockerfile 是用来构建 Docker 镜像的文本文件，是由一条条构建镜像所需的指令
和参数构成的脚本。 
  
 
构建三步骤 
编写 Dockerfile 文件 
docker build 命令构建镜像 
docker run 依镜像运行容器实例 
 
Dockerfile 内容基础知识 
1：每条保留字指令都必须为大写字母且后面要跟随至少一个参数 
2：指令按照从上到下，顺序执行 
3：#表示注释 
4：每条指令都会创建一个新的镜像层并对镜像进行提交 
 
Docker 执行 Dockerfile 的大致流程 
（1）docker 从基础镜像运行一个容器 
（2）执行一条指令并对容器作出修改 
（3）执行类似 docker commit 的操作提交一个新的镜像层 
（4）docker 再基于刚提交的镜像运行一个新容器 
（5）执行 dockerfile 中的下一条指令直到所有指令都执行完成 
  
从应用软件的角度来看，Dockerfile、Docker 镜像与 Docker
容器分别代表软件的三个不同阶段， 
*  Dockerfile 是软件的原材料 
*  Docker 镜像是软件的交付品 
*  Docker 容器则可以认为是软件镜像的运行态，也即依照镜
像运行的容器实例 
Dockerfile 面向开发，Docker 镜像成为交付标准，Docker 容
器则涉及部署与运维，三者缺一不可，合力充当 Docker 体系
的基石。 
 
1 Dockerfile，需要定义一个 Dockerfile，Dockerfile 定义了进
程需要的一切东西。Dockerfile 涉及的内容包括执行代码或
者是文件、环境变量、依赖包、运行时环境、动态链接库、
操作系统的发行版、服务进程和内核进程(当应用进程需要和
系统服务和内核进程打交道，这时需要考虑如何设计
namespace 的权限控制)等等; 
  
2 Docker 镜像，在用 Dockerfile 定义一个文件之后，docker 
build 时会产生一个 Docker 镜像，当运行 Docker 镜像时会
真正开始提供服务; 
  
3 Docker 容器，容器是直接提供服务的。 
  
  
DockerFile 常用保留字指令 
FROM 
基础镜像，当前新镜像是基于哪个镜像的，指定一个已经存在的镜像作为模板，
第一条必须是 from 
MAINTAINER 
镜像维护者的姓名和邮箱地址 
RUN 
容器构建时需要运行的命令 
两种格式 
shell 格式 
  
 
RUN yum -y install vim 
exec 格式 
 
RUN 是在 docker build 时运行 
EXPOSE 
当前容器对外暴露出的端口 
WORKDIR 
指定在创建容器后，终端默认登陆的进来工作目录，一个落脚点 
USER 
指定该镜像以什么样的用户去执行，如果都不指定，默认是 root 
ENV 
用来在构建镜像过程中设置环境变量 
ENV MY_PATH /usr/mytest 
这个环境变量可以在后续的任何 RUN 指令中使用，这就如同在命令前面指定了
环境变量前缀一样； 
也可以在其它指令中直接使用这些环境变量， 
比如：WORKDIR $MY_PATH 
ADD 
将宿主机目录下的文件拷贝进镜像且会自动处理 URL 和解压 tar 压缩包 
COPY 
类似 ADD，拷贝文件和目录到镜像中。 将从构建上下文目录中 <源路径> 的文
件/目录复制到新的一层的镜像内的 <目标路径> 位置 
COPY src dest 
COPY ["src", "dest"] 
<src 源路径>：源文件或者源目录 
<dest 目标路径>：容器内的指定路径，该路径不用事先建好，路径不存在的话，
会自动创建。 
VOLUME 
容器数据卷，用于数据保存和持久化工作 
CMD 
指定容器启动后的要干的事情 
  
 
注意 
Dockerfile 中可以有多个 CMD 指令，但只有最后一个生效，CMD 会被 docker 
run 之后的参数替换 
官网最后一行命令 
 
我们演示自己的覆盖操作 
 
它和前面 RUN 命令的区别 
CMD 是在 docker run 时运行。 
RUN 是在 docker build 时运行。 
ENTRYPOINT 
也是用来指定一个容器启动时要运行的命令 
类似于 CMD 指令，但是 ENTRYPOINT 不会被 docker run 后面的命令覆盖， 而
且这些命令行参数会被当作参数送给 ENTRYPOINT 指令指定的程序 
命令格式和案例说明 
  
命令格式：
 
ENTRYPOINT 可以和 CMD 一起用，一般是变参才会使用 CMD ，这里的 CMD 
等于是在给 ENTRYPOINT 传参。 
当指定了 ENTRYPOINT 后，CMD 的含义就发生了变化，不再是直接运行其命
令而是将 CMD 的内容作为参数传递给 ENTRYPOINT 指令，他两个组合会变成
 
  
案例如下：假设已通过 Dockerfile 构建了 nginx:test 镜像： 
 
是
否 按照 dockerfile 编写 传参运行 
传参 
执行 
Docke
r 命令 
docker 
run  nginx:test 
docker 
run  nginx:test -c 
/etc/nginx/new.co
nf 
衍
生
出
的
实
际
命令 
nginx 
-c 
/etc/nginx/nginx.co
nf 
nginx 
-c 
/etc/nginx/new.co
nf 
  
优点 
在执行 docker run 的时候可以指定 ENTRYPOINT 运行所需的参数。 
注意 
如果 Dockerfile 中如果存在多个 ENTRYPOINT 指令，仅最后一个生效。 
小总结 
  
 
案例 
自定义镜像 mycentosjava8 
要求 
Centos7 镜像具备 vim+ifconfig+jdk8 
JDK 的下载镜像地址 
官网 
  
 
 
  
FROM centos 
MAINTAINER zzyy<zzyybs@126.com> 
  
ENV MYPATH /usr/local 
WORKDIR $MYPATH 
  
###  18.1. <a name='vim'></a>vim 编辑器 
RUN yum -y install vim 
###  18.2. <a name='ifconfigIP'></a>ifconfig 命令查看网络 IP 
RUN yum -y install net-tools 
###  18.3. <a name='java8lib'></a>java8 及 lib 库 
RUN yum -y install glibc.i686 
RUN mkdir /usr/local/java 
####  18.3.1. <a name='jarjdk-8u171-linux-'></a>是 相 对 路 径 jar, 把 jdk-8u171-linux-
x64.tar.gz 添 加 到 容 器 中 , 安 装 包 必 须 要 和
Dockerfile 文件在同一位置 
ADD jdk-8u171-linux-x64.tar.gz /usr/local/java/ 
###  18.4. <a name='java'></a>java 环境变量 
ENV JAVA_HOME /usr/local/java/jdk1.8.0_171 
ENV JRE_HOME $JAVA_HOME/jre 
ENV 
CLASSPATH 
$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.j
ar:$JRE_HOME/lib:$CLASSPATH 
ENV PATH $JAVA_HOME/bin:$PATH 
  
EXPOSE 80 
  
CMD echo $MYPATH 
CMD echo "success--------------ok" 
CMD /bin/bash 
  
大写字母 D 
构建 
docker build -t 新镜像名字:TAG . 
docker build -t centosjava8:1.5 . 
  
 
 
 
注意，上面 TAG 后面有个空格，有个点 
运行 
docker run -it 新镜像名字:TAG 
 docker run -it centosjava8:1.5 /bin/bash 
  
 
再体会下 UnionFS（联合文件系统） 
UnionFS（联合文件系统）：Union 文件系统（UnionFS）是一
种分层、轻量级并且高性能的文件系统，它支持对文件系统
的修改作为一次提交来一层层的叠加，同时可以将不同目录
挂载到同一个虚拟文件系统下(unite several directories into a 
single virtual filesystem)。Union 文件系统是 Docker 镜像的
基础。镜像可以通过分层来进行继承，基于基础镜像（没有
父镜像），可以制作各种具体的应用镜像。 
  
特性：一次同时加载多个文件系统，但从外面看起来，只能
看到一个文件系统，联合加载会把各层文件系统叠加起来，
这样最终的文件系统会包含所有底层的文件和目录 
  
 
docker 是一个 client-server 结构的系统，docker 守护进程运行在主机上，然后通
过 socker 连接从客户端访问，守护进程从客户端接收命令并管理主机上的容器，
容器是个运行时环境。 
docker 命令 
# docker exec 执行多条命令 
docker exec -it -u root container_name bash -c "cd /home && mkdir dx" 
 
# 如果容器使用 host 网络驱动，意味着容器共享宿主机的网络栈，双方在网络名称空间
并没有隔离。 
docker run --network=host 
 
 
docker version 
----docker 版本信息 
docker info 
----docker 各种配置信息的描述 
docker images 
----列出本地主机上的所有镜像； 
docker images -qa 
----列出所有的镜像 id； 
docker search 镜像名字 
----在 docker hub 上查找某个镜像； 
docker search -s 30 tomcat----列出 docker hub 上点赞数超过 30 的镜像； 
docker pull 镜像名 
----从配置的仓库拉取镜像； 
docker rmi 镜像名/id 
----从本机中删除某个镜像； 
docker rmi -f 镜像名 
----强制删除； 
docker rmi -f $(docker images -qa)----删除多个镜像； 
docker run [option] 镜像 [command] [args] 
----新建并启动容器；-it----启动交互式容器并打开一个伪终 端；docker run -d 镜
像名----已后台进程运行容器； 
 
退出容器 
----1. exit----容器停止退出；2. ctrl+P+Q----容器不停止退出； 
进入正在运行的容器并以命令行交互----1. docker exec -it 容器 id；2. docker attach 
容 器 id； docker ps [options]----列出当前所有正在运行的容器； docker start 容
器名/id----启动容器；docker restart 容器/id----重启容器；docker stop 容器名/id； 
docker kill 容器名/id----强制停止容器；docker rm 容器名/id----删除已停止容器；
一次性删除多个容器--- -1. docker rm -f (docker ps -a -q)；2. docker ps -a -q |xargs 
docker rm； docker logs 容器----列出容器的运行日志；-f----跟随最新的日志打印；
-t----加入时间戳；--tial 数字----显 示最后多少条；docker events----打印出实时的
系统事件；docker history image----打印出指定镜像的历 史版本信息，即构建该
镜像的每一层镜像的命令记录； docker top 容器----查看容器中运行的进程； 
docker inspect 容器----查看容器的内部细节； docker cp 容器：容器内路径目的
主机路径----从容器内拷贝文件到主机； docker run -it -p 8888:8080 tomcat----指
的是以交互式方式运行 tomcat 并且将主机的端口 8888 映射到 docker 内部的
8080 端口的 tomcat，外部访问 tomcat 就通过 8888 端口访问； docker commit -
m="提交的描述信息" -a=“作者名” 容器 id 要创建的目标镜像名:标签名----提交
容器副本 使其成为一个新的镜像； docker run -it -v 主机目录:容器目录 镜像名
----指的是根据一个镜像运行你一个容器，-v 是达成主机目录和 容器目录实现数
据共享； ----数据卷的一种实现； 镜像原理： 镜像是一种轻量级、可执行的独
立软件包，用来打包软件运行环境和基于运行环境开发的软件，它包含运行某个
软件所需的所有内容，包括代码、运行时、库、环境变量和配置文件。 unionFS
（联合文件系统），对文件系统的修改作为一次提交来一层层叠加，同时将不同
文件目录挂载到同一虚拟文件系统下。 docker 镜像实际上是由一层层的文件系
统组成，这种层级的文件系统就是 unionFS；bootfs 和 rootfs---- bootfs 就是引导
加载 kernel，rootfs 在 bootfs 之上，就是各种目录和文件；镜像每一层都可以被
共享； 容器数据卷： 卷就是目录或文件，存在于一个或多个容器中，由 docker
挂载到容器，但不属于联合文件系统，因此能够绕过 Union File System 提供一
些用于持续存储或共享数据的特性： 卷的设计目的就是数据的持久化，完全独
立于容器的生存周期，因此 Docker 不会在容器删除时删除其挂载的数据 卷 特
点： 1：数据卷可在容器之间共享或重用数据 2：卷中的更改可以直接生效 3：
数据卷中的更改不会包含在镜像的更新中 4：数据卷的生命周期一直持续到没有
容器使用它为止 例如： 执行此命令 docker run -it -v /dx:/dx ubuntu 后，主机和
容器都会生成/dx 目录，并且 docker inspect 容器 id 之 后的结果显示，主机的目
录已经挂载到容器中，并且是可读写的： 
 
此时，两个文件夹可以共享资源； 如果命令变为 docker run -it -v /dx:/dx:ro ubuntu-
---表示容器中的文件/dx 是 readonly 文件，在容器中不能进行写操作，只能读；
但是在主机上在/dx 中写操作，容器中可以实时看到； 数据卷的另一种实现: 
1. /home 目录下创建 dockerfile 文件，指的是在 dockerfile 中使用 VOLUME 命令给
镜像添加一个或多个数据卷： 
 
\2. 使用 docker build 构造镜像 docker build -f /home/dockerfile -t dx/centos .----指
的是在当前路径下通过 dockerfile 文件构建一个 tag 为 dx/centos 的镜像，-f----
dockerfile 文件路径，-t----添加 tag； 
 
3. 运 行 容 器 ， 发 现 容 器 中 有 两 天 在 dockerfile 文 件 中 添 加 的 
数 据 卷 ,dataVolumeContainer01 和 dataVolumeContainer02： 
 
4. 而相应地挂载到容器中的主机的目录为，docker inspect 容器查看即得： 
 
数据卷容器： 命名的容器挂载数据卷，其它容器通过挂载这个(父容器)实现数据
共享，挂载数据卷的容器，称之为数据卷 容器容器间传递共享： 
1. 先启动一个父容器 container01: docker run -it --name container01 dx/centos docker
拉取 kolla 的 openstack 镜像 
2. 其它容器继承自 container01，使用命令：docker run -it --name container02 --
volumes-from container01 dx/centos 
3. 容器之间配置信息的传递，数据卷的声明周期一直持续到没有容器使用它为止，
也就是说，主要通过-- volumes-from 命令运行的容器，父容器的删除，其执行的
操作文件的读写一直存在，不会因为某个容器 的删除而消除。 
dockerfile 
dockerfile 就是构建镜像的构建文件，是由一系列命令和参数构成的脚本。 构建
三步骤：1. 编写 dockerfile 文件；2. docker build 构建镜像；3. docker run 运行； 
dockerfile 构建过程解析： 
docker 拉取 kolla 的 openstack 镜像 
阿里云镜像加速器 "registry-mirrors": ["https://kbagomoh.mirror.aliyuncs.com"] 
搭建 docker 应用栈 
目标：同一主机下搭建一个包含 6 个节点的 docker 应用栈，其中包含一个代理
节点、两个 web 应用节点、一个主数据库节点和两个从数据库节点； 
 
1. 获取应用栈需要的镜像； 
docker pull ubuntu/django/haproxy/redis/ 
2. 应用栈容器节点互联 
只需要完成容器互联来实现容器间的通信，采用 docker run 命令--link 选项建立
容器间的互联关系。 
docker run -it --name redis-slave1 --link redis-master:master redis /bin/bash 
---启动 redis-slave1 容器，同时将新启动的容器连接到名为 redis-master 的容器上；
启动后该容器中的/etc/hosts 文件记录了名为 master 的连接信息，即 redis-master
容器的 IP 地址。 
# cat /etc/hosts 
172.17.0.5 
应用栈各节点的连接信息如下： 
 
3. 应用栈容器节点启动 
 
docker 核心原理 
docker容器本质上是宿主机上的进程。docker通过namespace实现了资源隔离，
通过 cgroups 实现了资源限制，通过写时复制机制(copy-on-write)实现了高效的
文件操作。 
docker daemon 是 docker 架构中的主要用户接口。首先，它提供了 API server 用
于接收来自 docker client 的请求，其后根据不同的请求分发给 docker daemon 的
不同模块执行相应的工作，其中对容器运行时、volume、镜像以及网络方面的具
体实现已经放到 daemon 以外的模块或者项目中。 
docker daemon 
docker client 
docker client 是一个泛称，用来向 docker daemon 发起请求，执行相应的容器管理
操作。它既可以是命令行工具 docker，也可以是任何遵循了 docker API 的客户
端。 
镜像管理 
docker 通过 distribution、registry、layer、image、reference 等模块实现了 docker
镜像管理，将这些模块统称为镜像管理。 
execdriver、volumedriver、graphdriver 
docker daemon 负责将用户的请求转译成系统调用，进而创建和管理容器，而在
具体实现的过程中，为了将这些系统调用抽象成统一的接口方便调用者使用，
docker 把这些操作分为了容器执行驱动、volume 存储驱动、镜像存储驱动等。 
 
 
 
 
5. 操作系统 
查看 Linux 中被进程打开文件的信息 
不带任何参数执行 lsof 命令会输出当前所有活跃进程打开的所有文件 
lsof | more 来分页显示命令输出结果 
lsof -u tt 命令表示列出 tt 用户已经打开了的文件 
 
 
谈谈对 IO 多路复用机制的理解 
IO 指的是在操作系统中，数据在内核态和用户态之间的读写操作； 
多路大多数情况下指的是多个 TCP 连接(多个 socket 或者多个 channel)； 
复用指的是一个或多个线程资源； 
IO 多路复用指的是一个或多个线程资源处理多个 TCP 连接。无需创建和维护过
多的进程或线程。 
 
 
实现 IO 多路复用的模型 
select 
采用的是轮询加遍历的方式，也就是说，在客户端操作服务器时会创建三种文件
表符(简称 FD)，分别是写描述符、读描述符、异常描述符，而 select 会阻塞监视
这三种描述符，等到有数据可读、可写、出现异常或者超时时都会返回，返回后
通过遍历 FD 集合找到就绪的 FD，然后触发相应的 IO 操作。 
优点：几乎所有的平台都支持； 
缺点：随着 FD 数量增多而导致性能下降。所以每次调用 select 时将这个 FD 集
合从用户空间拷贝到内核空间进行遍历，由内核根据就绪状态修改该集合的内容，
而操作系统对单个进程打开的 FD 数量是有限制的，一般默认 1024 个； 
poll 
和 select 几乎没有区别，区别在于文件描述符的存储方式不同，poll 采用链表的
方式存储； 
优点：没有最大存储数量的限制； 
缺点：和 select 一样； 
epoll 
采用时间通知机制来触发相应的 IO 操作，没有 FD 的限制，从用户态拷贝到内
核态只需要一次，因为它主要通过调用系统底层的函数来实现注册、激活 FD，
这样大大提供了执行性能。主要通过调用以下三个系统函数： 
第一个是 epoll_create()函数，它在系统启动的时候会在 linux 内核里面申请一个
B+树结构的文件系统，然后再返回 epoll 对象，也就是一个 FD 对象； 
第二个是 epoll_ctl()函数，它会在没新建一个连接的时候会同步更新 epoll 对象中
FD，并且去绑定一个 callback 回调函数； 
第三个是 epoll_wait()函数，它会轮询所有的 callback 集合，并且去触发对应的 IO
操作； 
优点：轮询改成了回调，大大提供了 CPU 执行效率，也不会随 FD 数量的增加
而导致效率下降； 
缺点：只能在 linux 下工作； 
 
 
 
CPU 突然飙高，系统反应慢怎么排查 
CPU 是整个电脑的最核心的资源，对于一个应用程序来说，CPU 的最小执行单
元是线程，导致 CPU 飙升的原因有以下两个： 
1. CPU 的上下文切换过多； 
同一时刻下每个 CPU 核心只能运行一个线程，如果有多个线程要执行，CPU 只
能通过上下文切换的方式来切换不同的线程。上下文切换分两部分：保存运行线
程的执行状态和让处于等待中的线程执行，这两部分需要 CPU 执行内核相关的
指令实现状态保存。如果较多的上下文切换就会占用大量的 CPU 资源从而使得
CPU 无法去执行用户进程中的指令，而导致 CPU 的响应速度下降。文件 IO、网
络 IO、锁等待都会导致线程阻塞，从而去触发 CPU 的上下文切换。 
2. CPU 资源过度消耗； 
在我们的程序中创建了大量的线程或者是有线程一直占用 CPU 资源，无法被释
放，比如说死循环，当我们的 CPU 利用过高之后，就会导致应用程序中的线程
无法获取 CPU 的调度，从而影响 CPU 的执行效率； 
解决： 
可以通过 Top 命令找到 CPU 利用率过高的进程，通过 shift+H 找到进程中 CPU
消耗过高的线程。 
在查找过程中有两种情况： 
a. CPU 利用率过高的线程一直是同一个，说明程序中存在线程长期占用 CPU 没
有释放的情况，通过 jstack 获取线程的 dump 日志，定位到线程日志后，可以找
到对应的问题代码； 
b. CPU 利用率过高的线程 ID 一直变化，说明线程创建过多，就要去挑选几个线
程 ID，再通过 jstack 命令去排查，最后排查时可能发现程序正常，只是在 CPU
飙高的那一刻用户访问量大，从而导致系统资源不够。 
 
 
 
 
 
查看打开的线程 
ps -T -p <pid>   # 列出了由进程号为<pid>的进程创建的所有线程 
top -H -p <pid> # 输出某个特定进程<pid>并检查该进程内运行的线程状况 
htop 查看单个进程的线程 
内存泄漏怎么排查 
pdb 是专门用于 python 代码调试，模仿 gdb。使用 pdb 可以查看堆栈，打印变量等。 
使用 pdb 加载 python 程序 
.venv/bin/python -m pdb  orange.py 
> /Users/lanyang/workspace/orange/orange.py(3)<module>() 
-> import inspect 
(Pdb) 
启动程序 
(Pdb)c 
相关的命令有 
bt 打印堆栈 
q 退出 
pp 打印变量 
c(ont(inue)) 继续执行 
 
objgraph 
(Pdb) objgraph.show_growth(limit=10) 
function             22749    +22749 
dict                 15515    +15515 
tuple                12332    +12332 
weakref               6680     +6680 
list                  5517     +5517 
type                  3449     +3449 
getset_descriptor     3408     +3408 
cell                  2565     +2565 
set                   2496     +2496 
ModuleSpec            1588     +1588 
show_growth()打印两次调用之间增加的类型。如果这其中有自己定义的类型，很可能
就是问题所在。如果都是 python 内置类型，可能要花费更多功夫了。 
 
一般排查问题时，在程序开始执行时，调用 show_growth()，程序跑一段时间后，再次
调用 show_growth()，查看哪些对象增长最快。 
 
如果使用 pdb 在命令行下调试，ctrl+c 停止程序的时候，注意观察上下文，保证跟上次
import objgraph 时一样 
查看某个类型 
(Pdb) objgraph.by_type('list') 
 
pympler 
查看内存占用 
(Pdb) from pympler import tracker 
(Pdb) tr = tracker.SummaryTracker() 
(Pdb) tr.print_diff() 
                 types |   # objects |   total size 
======================= | =========== | ============ 
          <class 'list |       12769 |     1.18 MB 
           <class 'str |       12769 |   950.47 KB 
           <class 'int |       2513 |     68.71 KB 
          <class 'code |           1 |   144     B 
 function (store_info) |           1 |    136     B 
          <class 'cell |           2 |     96     B 
         <class 'tuple |           1 |     64     B 
        <class 'method |         -1 |   -64     B 
          <class 'dict |           0 |   -128     B 
(Pdb) tr.print_diff() 
        types |   # objects |   total size 
============== | =========== | ============ 
 <class 'list |           1 |     88     B 
  <class 'str |           1 |     70     B 
(Pdb) tr.print_diff() 
 types |   # objects |   total size 
======= | =========== | 
tracker 对象初始化的时候会创建一个 summary，每次调用 tracker.print_diff()的时候又
会创建一个 summary，当前的 summary 与上次的 summary 做比较，并打印两者之间的
不同。 
 
 
 
进程 
进程的异常控制流：陷阱、中断、异常和信号 
陷阱是有意造成的“异常”，是执行一条指令的结果。陷阱是同步的。陷阱的主要
作用是实现系统调用。比如，进程可以执行 syscall n 指令向内核请求服务。当进
程执行这条指令后，会中断当前的控制流，陷入到内核态，执行相应的系统调用。
内核的处理程序在执行结束后，会将结果返回给进程，同时退回到用户态。进程
此时继续执行下一条指令。 
中断由处理器外部的硬件产生，不是执行某条指令的结果，也无法预测发生时机。
由于中断独立于当前执行的程序，因此中断是异步事件。中断包括 I/O 设备发
出的 I/O 中断、各种定时器引起的时钟中断、调试程序中设置的断点等引起的
调试中断等。 
异常是一种错误情况，是执行当前指令的结果，可能被错误处理程序修正，也可
能直接终止应用程序。异常是同步的。这里特指因为执行当前指令而产生的错误
情况，比如除法异常、缺页异常等。有些书上为了区分，也将这类“异常”称为“故
障”。 
信号是一种更高层的软件形式的异常，同样会中断进程的控制流，可以由进程进
行处理。一个信号代表了一个消息。信号的作用是用来通知进程发生了某种系统
事件。 
进程与线程的切换流程 
进程切换分两步： 
1、切换页表以使用新的地址空间，一旦去切换上下文，处理器中所有已经缓存
的内存地址一瞬间都作废了。 
2、切换内核栈和硬件上下文。 
对于 linux 来说，线程和进程的最大区别就在于地址空间，对于线程切换，第 1
步是不需要做的，第 2 步是进程和线程切换都要做的。 
因为每个进程都有自己的虚拟地址空间，而线程是共享所在进程的虚拟地址空间
的，因此同一个进程中的线程进行线程切换时不涉及虚拟地址空间的转换。 
为什么虚拟地址空间切换会比较耗时？ 
进程都有自己的虚拟地址空间，把虚拟地址转换为物理地址需要查找页表，页表
查找是一个很慢的过程，因此通常使用 Cache 来缓存常用的地址映射，这样可以
加速页表查找，这个 Cache 就是 TLB（translation Lookaside Buffer，TLB 本质上
就是一个 Cache，是用来加速页表查找的）。 
由于每个进程都有自己的虚拟地址空间，那么显然每个进程都有自己的页表，那
么当进程切换后页表也要进行切换，页表切换后 TLB 就失效了，Cache 失效导
致命中率降低，那么虚拟地址转换为物理地址就会变慢，表现出来的就是程序运
行会变慢，而线程切换则不会导致 TLB 失效，因为线程无需切换地址空间，因
此我们通常说线程切换要比较进程切换块，原因就在这里。 
同一进程中的线程可以共享哪些数据？ 
 
进程代码段 
 
进程的公有数据（全局变量、静态变量...） 
 
进程打开的文件描述符 
 
进程的当前目录 
 
信号处理器/信号处理函数：对收到的信号的处理方式 
 
进程 ID 与进程组 ID 
单工/半双工/全双工 
单工----数据只能往一个方向，比如只能收或者只能发； 
半双工----可以收，也可以发，同一时刻只能收或者发； 
全双工----可以收，也可以发； 
 
进程间通信有哪些方式 
a) 管道/匿名管道(Pipes)：管道是半双工的，数据只能向一个方向流动；双方通
信时，需要建立起两个管道；一个进程向管道中写的内容被管道另一端的进程读
出。写入的内容每次都添加在管道缓冲区的末尾，并且每次都是从缓冲区的头部
读出数据；用于具有亲缘关系的父子进程间或者兄弟进程之间的通信。 
b) 有名管道(Names Pipes): 匿名管道由于没有名字，只能用于亲缘关系的进程间
通信。为了克服这个缺点，提出了有名管道。有名管道严格遵循先进先出(first in 
first out)。有名管道以磁盘文件的方式存在，可以实现本机任意两个进程通信。 
c)消息队列(Message Queuing)：消息队列是消息的链表，具有特定的格式，存放
在内存中并由消息队列标识符标识。管道和消息队列的通信数据都是先进先出的
原则。与管道（无名管道：只存在于内存中的文件；命名管道：存在于实际的磁
盘介质或者文件系统）不同的是消息队列存放在内核中，只有在内核重启(即，操
作系统重启)或者显示地删除一个消息队列时，该消息队列才会被真正的删除。
消息队列可以实现消息的随机查询，消息不一定要以先进先出的次序读取，也可
以按消息的类型读取，比 FIFO 更有优势。消息队列克服了信号承载信息量少，
管道只能承载无格式字节流以及缓冲区大小受限等缺点。 
d) 信号(Signal)：信号是一种比较复杂的通信方式，用于通知接收进程某个事件
已经发生；（对于异常情况下的工作模式，就需要用「信号」的方式来通知进程，
信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令）。
比如，Ctrl+C 产生 SIGINT 信号，表示终止该进程，Ctrl+Z 产生 SIGSTP，表
示停止该进程，但还未结束） 
e) 信号量(Semaphores)：信号量是一个计数器，用于多进程对共享数据的访问，
信号量的意图在于进程间同步。这种通信方式主要用于解决与同步相关的问题并
避免竞争条件。（信号量其实是一个整型的计数器，主要用于实现进程间的互斥
与同步，而不是用于缓存进程间通信的数据。） 
f) 共享内存(Shared memory)：使得多个进程可以访问同一块内存空间，不同进程
可以及时看到对方进程中对共享内存中数据的更新。这种方式需要依靠某种同步
操作，如互斥锁和信号量等。可以说这是最有用的进程间通信方式。（共享内存
的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中） 
h) 套接字(Sockets): 此方法主要用于在客户端和服务器之间通过网络进行通信。
套接字是支持 TCP/IP 的网络通信的基本操作单元，可以看做是不同主机之间的
进程进行双向通信的端点，简单的说就是通信的两方的一种约定，用套接字中的
相关函数来完成通信过程。 
int socket(int domain, int type, int protocal) 
优缺点： 
管道：速度慢，容量有限； 
Socket：任何进程间都能通讯，但速度慢； 
消息队列：容量受到系统限制，且要注意第一次读的时候，要考虑上一次没有读
完数据的问题； 
信号量：不能传递复杂消息，只能用来同步； 
共享内存区：能够很容易控制容量，速度快，但要保持同步，比如一个进程在写
的时候，另一个进程要注意读写的问题，相当于线程中的线程安全，当然，共享
内存区同样可以用作线程间通讯，不过没这个必要，线程间本来就已经共享了同
一进程内的一块内存。 
进程同步问题 
进程的同步是目的，而进程间通信是实现进程同步的手段 
管程 Monitor 
管程将共享变量以及对这些共享变量的操作封装起来，形成一个具有一定接口的
功能模块，这样只能通过管程提供的某个过程才能访问管程中的资源。进程只能
互斥地使用管程，使用完之后必须释放管程并唤醒入口等待队列中的进程。 
当一个进程试图进入管程时，在入口等待队列等待。若 P 进程唤醒了 Q 进程，
则 Q 进程先执行，P 在紧急等待队列中等待。（HOARE 管程） 
wait 操作：执行 wait 操作的进程进入条件变量链末尾，唤醒紧急等待队列或者
入口队列中的进程；signal 操作：唤醒条件变量链中的进程，自己进入紧急等待
队列，若条件变量链为空，则继续执行。（HOARE 管程） 
MESA 管程：将 HOARE 中的 signal 换成了 notify（或者 broadcast 通知所有满足
条件的），进行通知而不是立马交换管程的使用权，在合适的时候，条件队列首
位的进程可以进入，进入之前必须用 while 检查条件是否合适。优点：没有额外
的进程切 
生产者-消费者问题 
问题描述：使用一个缓冲区来存放数据，只有缓冲区没有满，生产者才可以写入
数据；只有缓冲区不为空，消费者才可以读出数据 
代码实现： 
// 伪代码描述  
// 定义信号量 full 记录缓冲区物品数量 empty 代表缓冲区空位数量 mutex 为互斥量 
semaphore full = 0, empty = n, mutex = 1; 
 
// 生产者进程 
void producer(){ 
 
do{ 
    
  P(empty); 
 
  P(mutex); 
 
     // 生产者进行生产 
    
 
    
  V(mutex); 
    
  V(full); 
  
} while(1); 
} 
 
void consumer(){ 
 
do{ 
 
  P(full); 
 
  P(mutex); 
 
     
// 消费者进行消费 
 
 
  V(mutex); 
 
  V(empty); 
  
} while(1); 
} 
进程间同步的方式有哪些？ 
1、临界区：通过对多线程的串行化来访问公共资源或一段代码，速度快，适合
控制数据访问。 
优点：保证在某一时刻只有一个线程能访问数据的简便办法。 
缺点：虽然临界区同步速度很快，但却只能用来同步本进程内的线程，而不可用
来同步多个进程中的线程。 
2、互斥量：为协调共同对一个共享资源的单独访问而设计的。互斥量跟临界区
很相似，比临界区复杂，互斥对象只有一个，只有拥有互斥对象的线程才具有访
问资源的权限。 
优点：使用互斥不仅仅能够在同一应用程序不同线程中实现资源的安全共享，而
且可以在不同应用程序的线程之间实现对资源的安全共享。 
缺点： 
 
互斥量是可以命名的，也就是说它可以跨越进程使用，所以创建互斥量需要的资
源更多，所以如果只为了在进程内部是用的话使用临界区会带来速度上的优势并
能够减少资源占用量。 
 
通过互斥量可以指定资源被独占的方式使用，但如果有下面一种情况通过互斥量
就无法处理，比如现在一位用户购买了一份三个并发访问许可的数据库系统，可
以根据用户购买的访问许可数量来决定有多少个线程/进程能同时进行数据库操
作，这时候如果利用互斥量就没有办法完成这个要求，信号量对象可以说是一种
资源计数器。 
3、信号量：为控制一个具有有限数量用户资源而设计。它允许多个线程在同一
时刻访问同一资源，但是需要限制在同一时刻访问此资源的最大线程数目。互斥
量是信号量的一种特殊情况，当信号量的最大资源数=1 就是互斥量了。 
优点：适用于对 Socket（套接字）程序中线程的同步。 
缺点: 
 
信号量机制必须有公共内存，不能用于分布式操作系统，这是它最大的弱点； 
 
信号量机制功能强大，但使用时对信号量的操作分散， 而且难以控制，读写和
维护都很困难，加重了程序员的编码负担； 
 
核心操作 P-V 分散在各用户程序的代码中，不易控制和管理，一旦错误，后果严
重，且不易发现和纠正。 
4、事件： 用来通知线程有一些事件已发生，从而启动后继任务的开始。 
优点：事件对象通过通知操作的方式来保持线程的同步，并且可以实现不同进程
中的线程同步操作。 
同步与互斥的概念？ 
 
同步：多个进程因为合作而使得进程的执行有一定的先后顺序。比如某个进程需
要另一个进程提供的消息，获得消息之前进入阻塞态； 
 
互斥：多个进程在同一时刻只有一个进程能进入临界区 
并发、并行、异步的区别？ 
并发：在一个时间段中同时有多个程序在运行，但其实任一时刻，只有一个程序
在 CPU 上运行，宏观上的并发是通过不断的切换实现的； 
多线程：并发运行的一段代码。是实现异步的手段 
并行（和串行相比）：在多 CPU 系统中，多个程序无论宏观还是微观上都是同
时执行的 
异步（和同步相比）：同步是顺序执行，异步是在等待某个资源的时候继续做自
己的事 
进程有哪几种状态？ 
进程一共有 5 种状态，分别是创建、就绪、运行（执行）、终止、阻塞。 
就绪状态：就是说进程已处于准备运行的状态，即进程获得了除 CPU 之外的一
切所需资源，一旦得到 CPU 即可运行。 
运行状态：就是进程正在 CPU 上运行。在单处理机环境下，每一时刻最多只有
一个进程处于运行状态。处于此状态的进程数小于等于 CPU 数 
阻塞状态：就是进程正在等待某一事件而暂停运行，比如等待某资源为可用或等
待 I/O 完成。即使 CPU 空闲，该进程也不能运行。 
运行态→阻塞态：往往是由于等待外设，等待主存等资源分配或等待人工干预而
引起的。 阻塞态→就绪态：则是等待的条件已满足，只需分配到处理器后就能
运行。 运行态→就绪态：不是由于自身原因，而是由外界原因使运行状态的进
程让出处理器，这时候就变成就绪态。例如时间片用完，或有更高优先级的进程
来抢占处理器等。 就绪态→运行态：系统按某种策略选中就绪队列中的一个进
程占用处理器，此时就变成了运行态。 
进程调度策略有哪些 
1. 批处理系统： 
先来先服务 first-come first-serverd（FCFS） 
按照请求的顺序进行调度。非抢占式，开销小，无饥饿问题，响应时间不确定（可
能很慢）； 
对短进程不利，对 IO 密集型进程不利。 
最短作业优先 shortest job first（SJF） 
按估计运行时间最短的顺序进行调度。非抢占式，吞吐量高，开销可能较大，可
能导致饥饿问题； 
对短进程提供好的响应时间，对长进程不利。 
最短剩余时间优先 shortest remaining time next（SRTN） 
按剩余运行时间的顺序进行调度。(最短作业优先的抢占式版本)。吞吐量高，开
销可能较大，提供好的响应时间； 
可能导致饥饿问题，对长进程不利。 
最高响应比优先 Highest Response Ratio Next（HRRN） 
响应比 = 1+ 等待时间/处理时间。同时考虑了等待时间的长短和估计需要的执
行时间长短，很好的平衡了长短进程。非抢占，吞吐量高，开销可能较大，提供
好的响应时间，无饥饿问题。 
2. 交互式系统 交互式系统有大量的用户交互操作，在该系统中调度算法的目标是
快速地进行响应。 
时间片轮转 Round Robin 
将所有就绪进程按 FCFS 的原则排成一个队列，用完时间片的进程排到队列最
后。抢占式（时间片用完时），开销小，无饥饿问题，为短进程提供好的响应时
间； 
若时间片小，进程切换频繁，吞吐量低；若时间片太长，实时性得不到保证。 
优先级调度算法 
为每个进程分配一个优先级，按优先级进行调度。为了防止低优先级的进程永远
等不到调度，可以随着时间的推移增加等待进程的优先级。 
多级反馈队列调度算法 Multilevel Feedback Queue 
设置多个就绪队列 1、2、3...，优先级递减，时间片递增。只有等到优先级更高
的队列为空时才会调度当前队列中的进程。如果进程用完了当前队列的时间片还
未执行完，则会被移到下一队列。 
抢占式（时间片用完时），开销可能较大，对 IO 型进程有利，可能会出现饥饿
问题。 
 
用户态和内核态 
为了限制不同程序的访问能力，防止一些程序访问其它程序的内存数据，CPU 划
分了用户态和内核态两个权限等级。 
用户态：用户态运行的程序只能受限地访问内存，只能直接读取用户程序的数据，
并且不允许访问外围设备，用户态下的 CPU 不允许独占，也就是说 CPU 能够被
其他程序获取。 
内核态：内核态运行的程序可以访问计算机的任何数据和资源，不受限制，包括
外围设备，比如网卡、硬盘等。处于内核态的 CPU 可以从一个程序切换到另外
一个程序，并且占用 CPU 不会发生抢占情况。。 
所有用户程序都运行在用户态，但有时需要进行一些内核态的操作，比如从硬盘
或者键盘读数据，这时就需要进行系统调用，使用陷阱指令，CPU 切换到内核
态，执行相应的服务，再切换为用户态并返回系统调用的结果。 
这些系统调用按功能大致可分为如下几类： 
1. 设备管理。完成设备的请求或释放，以及设备启动等功能。 
2. 文件管理。完成文件的读、写、创建及删除等功能。 
3. 进程控制。完成进程的创建、撤销、阻塞及唤醒等功能。 
4. 进程通信。完成进程之间的消息传递或信号传递等功能。 
5. 内存管理。完成内存的分配、回收以及获取作业占用内存区大小及地址等功
能。 
 
 
 
 
什么叫优先级反转？如何解决？ 
高优先级的进程等待被一个低优先级进程占用的资源时，就会出现优先级反转，
即优先级较低的进程比优先级较高的进程先执行。此处详细解释优先级反转带来
的问题：如果有一个中等优先级的进程将低优先级的进程抢占，那么此时低优先
级的进程无法正常进行并在后续释放被占用的资源，导致高优先级的任务一直被
挂起，直到中等优先级的进程完成后，低优先级的进程才可以继续并在后续释放
占用的资源，最后高优先级的进程才可以执行。导致的问题就是高优先级的进程
在中等优先级的进程调度之后。 
解决方法： 
 
优先级天花板(priority ceiling)：当任务申请某资源时，把该任务的优先级提升到
可访问这个资源的所有任务中的最高优先级，这个优先级称为该资源的优先级天
花板。简单易行。 
 
优先级继承(priority inheritance)：当任务 A 申请共享资源 S 时，如果 S 正在被任
务 C 使用，通过比较任务 C 与自身的优先级，如发现任务 C 的优先级小于自身
的优先级，则将任务 C 的优先级提升到自身的优先级，任务 C 释放资源 S 后，
再恢复任务 C 的原优先级。 
什么是僵尸进程？ 
一个子进程结束后，它的父进程并没有等待它（调用 wait 或者 waitpid），那么
这个子进程将成为一个僵尸进程。僵尸进程是一个已经死亡的进程，但是并没有
真正被销毁。它已经放弃了几乎所有内存空间，没有任何可执行代码，也不能被
调度，仅仅在进程表中保留一个位置，记载该进程的进程 ID、终止状态以及资
源利用信息(CPU 时间，内存使用量等等)供父进程收集，除此之外，僵尸进程不
再占有任何内存空间。这个僵尸进程可能会一直留在系统中直到系统重启。 
危害：占用进程号，而系统所能使用的进程号是有限的；占用内存。 
以下情况不会产生僵尸进程： 
 
该进程的父进程先结束了。每个进程结束的时候，系统都会扫描是否存在子进程，
如果有则用 Init 进程接管，成为该进程的父进程，并且会调用 wait 等待其结束。 
 
父进程调用 wait 或者 waitpid 等待子进程结束（需要每隔一段时间查询子进程是
否结束）。wait 系统调用会使父进程暂停执行，直到它的一个子进程结束为止。
waitpid 则可以加入 WNOHANG(wait-no-hang)选项，如果没有发现结束的子进程，
就会立即返回，不会将调用 waitpid 的进程阻塞。同时，waitpid 还可以选择是等
待任一子进程（同 wait），还是等待指定 pid 的子进程，还是等待同一进程组下
的任一子进程，还是等待组 ID 等于 pid 的任一子进程； 
 
子进程结束时，系统会产生 SIGCHLD(signal-child)信号，可以注册一个信号处理
函数，在该函数中调用 waitpid，等待所有结束的子进程（注意：一般都需要循环
调用 waitpid，因为在信号处理函数开始执行之前，可能已经有多个子进程结束
了，而信号处理函数只执行一次，所以要循环调用将所有结束的子进程回收）； 
 
也可以用 signal(SIGCLD, SIG_IGN)(signal-ignore)通知内核，表示忽略 SIGCHLD 信
号，那么子进程结束后，内核会进行回收。 
什么是孤儿进程？ 
一个父进程已经结束了，但是它的子进程还在运行，那么这些子进程将成为孤儿
进程。孤儿进程会被 Init（进程 ID 为 1）接管，当这些孤儿进程结束时由 Init 完
成状态收集工作。 
线程 
线程的分类？ 
从线程的运行空间来说，分为用户级线程（user-level thread, ULT）和内核级线程
（kernel-level, KLT） 
内核级线程：这类线程依赖于内核，又称为内核支持的线程或轻量级进程。无论
是在用户程序中的线程还是系统进程中的线程，它们的创建、撤销和切换都由内
核实现。比如英特尔 i5-8250U 是 4 核 8 线程，这里的线程就是内核级线程 
用户级线程：它仅存在于用户级中，这种线程是不依赖于操作系统核心的。应用
进程利用线程库来完成其创建和管理，速度比较快，操作系统内核无法感知用户
级线程的存在。 
线程同步有哪些方式？ 
为什么需要线程同步：线程有时候会和其他线程共享一些资源，比如内存、数据
库等。当多个线程同时读写同一份共享资源的时候，可能会发生冲突。因此需要
线程的同步，多个线程按顺序访问资源。 
 
互斥量 Mutex：互斥量是内核对象，只有拥有互斥对象的线程才有访问互斥资源
的权限。因为互斥对象只有一个，所以可以保证互斥资源不会被多个线程同时访
问；当前拥有互斥对象的线程处理完任务后必须将互斥对象交出，以便其他线程
访问该资源； 
 
信号量 Semaphore：信号量是内核对象，它允许同一时刻多个线程访问同一资源，
但是需要控制同一时刻访问此资源的最大线程数量。信号量对象保存了最大资源
计数和当前可用资源计数，每增加一个线程对共享资源的访问，当前可用资源计
数就减 1，只要当前可用资源计数大于 0，就可以发出信号量信号，如果为 0，则
将线程放入一个队列中等待。线程处理完共享资源后，应在离开的同时通过
ReleaseSemaphore 函数将当前可用资源数加 1。如果信号量的取值只能为 0 或 1，
那么信号量就成为了互斥量； 
 
事件 Event：允许一个线程在处理完一个任务后，主动唤醒另外一个线程执行任
务。事件分为手动重置事件和自动重置事件。手动重置事件被设置为激发状态后，
会唤醒所有等待的线程，而且一直保持为激发状态，直到程序重新把它设置为未
激发状态。自动重置事件被设置为激发状态后，会唤醒一个等待中的线程，然后
自动恢复为未激发状态。 
 
临界区 Critical Section：任意时刻只允许一个线程对临界资源进行访问。拥有临
界区对象的线程可以访问该临界资源，其它试图访问该资源的线程将被挂起，直
到临界区对象被释放。 
互斥量和临界区有什么区别？ 
互斥量是可以命名的，可以用于不同进程之间的同步；而临界区只能用于同一进
程中线程的同步。创建互斥量需要的资源更多，因此临界区的优势是速度快，节
省资源。 
什么是临界区，如何解决冲突？ 
每个进程中访问临界资源的那段程序称为临界区，一次仅允许一个进程使用的资
源称为临界资源。 
解决冲突的办法： 
 
如果有若干进程要求进入空闲的临界区，一次仅允许一个进程进入，如已有进程
进入自己的临界区，则其它所有试图进入临界区的进程必须等待； 
 
进入临界区的进程要在有限时间内退出。 
 
如果进程不能进入自己的临界区，则应让出 CPU，避免进程出现“忙等”现象。 
线程独占哪些资源？ 
 
线程 ID 
 
一组寄存器的值 
 
线程自身的栈（堆是共享的） 
 
错误返回码：线程可能会产生不同的错误返回码，一个线程的错误返回码不应该
被其它线程修改； 
 
信 号 掩 码 / 信 号 屏 蔽 字 (Signal mask) ： 表 示 是 否 屏 蔽 / 阻 塞 相 应 的 信 号
（SIGKILL,SIGSTOP 除外） 
协程 
协程多与线程进行比较？ 
1. 一个线程可以拥有多个协程，一个进程也可以单独拥有多个协程，这样 python 中
则能使用多核 CPU。 
2. 线程进程都是同步机制，而协程则是异步 
3. 协程能保留上一次调用时的状态，每次过程重入时，就相当于进入上一次调用的
状态 
IO 模型 
 
同步阻塞 IO（Blocking IO）：用户线程发起 IO 读/写操作之后，线程阻塞，直到
可以开始处理数据；对 CPU 资源的利用率不够； 
 
同步非阻塞 IO（Non-blocking IO）：发起 IO 请求之后可以立即返回，如果没有
就绪的数据，需要不断地发起 IO 请求直到数据就绪；不断重复请求消耗了大量
的 CPU 资源； 
 
IO 多路复用 
 
异步 IO（Asynchronous IO）：用户线程发出 IO 请求之后，继续执行，由内核进
行数据的读取并放在用户指定的缓冲区内，在 IO 完成之后通知用户线程直接使
用。 
 
什么是水平触发？什么是边缘触发？ 
水平触发（LT，Level Trigger）模式下，只要一个文件描述符就绪，就会触发通
知，如果用户程序没有一次性把数据读写完，下次还会通知； 
 
边缘触发（ET，Edge Trigger）模式下，当描述符从未就绪变为就绪时通知一次，
之后不会再通知，直到再次从未就绪变为就绪（缓冲区从不可读/写变为可读/写）。 
 
区别：边缘触发效率更高，减少了被重复触发的次数，函数不会返回大量用户程
序可能不需要的文件描述符。 
 
为什么边缘触发一定要用非阻塞（non-block）IO：避免由于一个描述符的阻塞读
/阻塞写操作让处理其它描述符的任务出现饥饿状态。 
 
文件描述符 
文件描述符（File Descriptor）是计算机科学中的一个术语，是用一个表述指向文
件的引用的抽象化概念。 
文件描述符在形式上是一个非负函数。实际上，它是一个索引，指向内核中每一
个进程所维护的该进程打开文件的记录表，当程序打开一个现有文件或者创建一
个新文件时，内核向进程返回一个文件描述符。在程序设计中，一些涉及底层的
程序编写往往会围绕着文件描述符展开。但是文件描述符这一概念只适用于
Unix 和 Linux 这样的操作系统。 
内核通过文件描述符来访问文件。文件描述符指向一个文件。 
什么是 IO 多路复用？怎么实现？ 
IO 多路复用（IO Multiplexing）是指单个进程/线程就可以同时处理多个 IO 请求。 
实现原理：用户将想要监视的文件描述符（File Descriptor）添加到 select/poll/epoll
函数中，由内核监视，函数阻塞。一旦有文件描述符就绪（读就绪或写就绪），
或者超时（设置 timeout），函数就会返回，然后该进程可以进行相应的读/写操
作。 
 
select/poll/epoll 三者的区别？ 
 
select ：将文件描述符放入一个集合中，调用 select 时，将这个集合从用户空间拷
贝到内核空间（缺点 1：每次都要复制，开销大），由内核根据就绪状态修改该
集合的内容。（缺点 2）集合大小有限制，32 位机默认是 1024（64 位：2048）；
采用水平触发机制。select 函数返回后，需要通过遍历这个集合，找到就绪的文
件描述符（缺点 3：轮询的方式效率较低），当文件描述符的数量增加时，效率
会线性下降； 
 
poll ：和 select 几乎没有区别，区别在于文件描述符的存储方式不同，poll 采用
链表的方式存储，没有最大存储数量的限制； 
 
epoll ：通过内核和用户空间共享内存，避免了不断复制的问题；支持的同时连接
数上限很高（1G 左右的内存支持 10W 左右的连接数）；文件描述符就绪时，采
用回调机制，避免了轮询（回调函数将就绪的描述符添加到一个链表中，执行
epoll_wait 时，返回这个链表）；支持水平触发和边缘触发，采用边缘触发机制
时，只有活跃的描述符才会触发回调函数。 
总结，区别主要在于： 
 
一个线程/进程所能打开的最大连接数 
 
文件描述符传递方式（是否复制） 
 
水平触发 or 边缘触发 
 
查询就绪的描述符时的效率（是否轮询） 
什么时候使用 select/poll，什么时候使用 epoll？ 
当连接数较多并且有很多的不活跃连接时，epoll 的效率比其它两者高很多；但
是当连接数较少并且都十分活跃的情况下，由于 epoll 需要很多回调，因此性能
可能低于其它两者。 
 
我们使用一张图来总结 select、poll、epoll 的区别 
 
select 
poll 
epoll 
操作方式 
遍历 
遍历 
回调 
底层实现 
数组 
链表 
哈希表 
IO 效率 
每 次 调 用 都
进 行 线 性 遍
历，时间复杂
度为 O(n) 
每次调用都进
行线性遍历，
时间复杂度为
O(n) 
事件通知方式，每当 fd 就
绪，系统注册的回调函数就
会被调用，将就绪 fd 放到
readyList 里面，时间复杂度
为 O(1) 
最 大 连 接
数 
1024 或 2048 
无上限 
无上限 
fd 拷贝 
每 次 调 用
select，都需
要把 fd 集合
每 次 调 用
poll，都需要
把 fd 集合从
调用 epoll_ctl 时，拷贝进内
核 并 保 存 ， 之 后 每 次
epoll_wait 不拷贝 
 
select 
poll 
epoll 
从 用 户 态 拷
贝到内核态 
用户态拷贝到
内核态 
select 和 poll 即使只有一个描述符就绪，也要遍历整个集合。如果集合中活跃的
描述符很少，遍历过程的开销就会变得很大，而如果集合中大部分的描述符都是
活跃的，遍历过程的开销又可以忽略。 
为什么要分用户态和内核态？ 
 
安全性：防止用户程序恶意或者不小心破坏系统/内存/硬件资源； 
 
封装性：用户程序不需要实现更加底层的代码； 
 
利于调度：如果多个用户程序都在等待键盘输入，这时就需要进行调度；统一交
给操作系统调度更加方便。 
 
如何从用户态切换到内核态？ 
所有的用户进程都是运行在用户态的，但是我们上面也说了，用户程序的访问能
力有限，一些比较重要的比如从硬盘读取数据，从键盘获取数据的操作则是内核
态才能做的事情，而这些数据却又对用户程序来说非常重要。所以就涉及到两种
模式下的转换，即用户态 -> 内核态 -> 用户态，而唯一能够做这些操作的只有 
系统调用，而能够执行系统调用的就只有 操作系统。 
一般用户态 -> 内核态的转换我们都称之为 trap 进内核，也被称之为 陷阱指令
(trap instruction)。 
他们的工作流程如下： 
 
首先用户程序会调用 glibc 库，glibc 是一个标准库，同时也是一套核心库，库
中定义了很多关键 API。 
 
glibc 库知道针对不同体系结构调用系统调用的正确方法，它会根据体系结构应
用程序的二进制接口设置用户进程传递的参数，来准备系统调用。 
 
然后，glibc 库调用软件中断指令(SWI) ，这个指令通过更新 CPSR 寄存器将模式
改为超级用户模式，然后跳转到地址 0x08 处。 
 
到目前为止，整个过程仍处于用户态下，在执行 SWI 指令后，允许进程执行内
核代码，MMU 现在允许内核虚拟内存访问 
 
从地址 0x08 开始，进程执行加载并跳转到中断处理程序，这个程序就是 ARM 
中的 vector_swi()。 
 
在 vector_swi() 处，从 SWI 指令中提取系统调用号 SCNO，然后使用 SCNO 
作为系统调用表 sys_call_table 的索引，调转到系统调用函数。 
 
执行系统调用完成后，将还原用户模式寄存器，然后再以用户模式执行。 
系统调用：比如读取命令行输入。本质上还是通过中断实现 
 
用户程序发生异常时：比如缺页异常 
 
外围设备的中断：外围设备完成用户请求的操作之后，会向 CPU 发出中断信号，
这时 CPU 会转去处理对应的中断处理程序 
 
内存管理 
操作系统的内存管理主要负责内存的分配与回收（malloc 函数：申请内存，free 
函数：释放内存），另外地址转换也就是将逻辑地址转换成相应的物理地址等功
能也是操作系统内存管理做的事情。 
 
操作系统的内存管理机制了解吗？内存管理有哪几
种方式? 
简单分为连续分配管理方式和非连续分配管理方式这两种。连续分配管理方式是
指为一个用户程序分配一个连续的内存空间，常见的如 块式管理 。同样地，非
连续分配管理方式允许一个程序使用的内存分布在离散或者说不相邻的内存中，
常见的如页式管理 和 段式管理。 
块式管理： 远古时代的计算机操作系统的内存管理方式。将内存分为几个固定
大小的块，每个块中只包含一个进程。如果程序运行需要内存的话，操作系统就
分配给它一块，如果程序运行只需要很小的空间的话，分配的这块内存很大一部
分几乎被浪费了。这些在每个块中未被利用的空间，我们称之为碎片。 
页式管理：把主存分为大小相等且固定的一页一页的形式，页较小，相比于块式
管理的划分粒度更小，提高了内存利用率，减少了碎片。页式管理通过页表对应
逻辑地址和物理地址。 
段式管理：页式管理虽然提高了内存利用率，但是页式管理其中的页并无任何实
际意义。 段式管理把主存分为一段段的，段是有实际意义的，每个段定义了一
组逻辑信息，例如,有主程序段 MAIN、子程序段 X、数据段 D 及栈段 S 等。 
段式管理通过段表对应逻辑地址和物理地址。简单来说：页是物理单位，段是逻
辑单位。分页可以有效提高内存利用率，分段可以更好满足用户需求。 
段页式管理机制 。段页式管理机制结合了段式管理和页式管理的优点。简单来
说段页式管理机制就是把主存先分成若干段，每个段又分成若干页，也就是说 段
页式管理机制 中段与段之间以及段的内部的都是离散的。 
 
硬盘分区分别是做什么 
/swap 分区是交换分区，是有一定磁盘空间（分区或文件），用于将部分内存中
的数据交换下来，以腾出内存空间用于其它需求。在一个系统中，物理内存快使
用完时，操作系统会使用交换分区。当系统内存紧张时，操作系统根据一定算法
规则，将一部分最近没有使用的内存页面保存到交换分区，从而为需要内存的程
序留出足够的内存空间，在 swap 中的内存页面被访问时，系统会将其重新载入
到物理内存中去运行。 
/var/lib/placements 创建共享存储，实现镜像共享。 
 
 
什么是分页？ 
把内存空间划分为大小相等且固定的块，作为主存的基本单位。因为程序数据存
储在不同的页面中，而页面又离散的分布在内存中，因此需要一个页表来记录映
射关系，以实现从页号到物理块号的映射。 
访问分页系统中内存数据需要两次的内存访问 (一次是从内存中访问页表，从中
找到指定的物理块号，加上页内偏移得到实际物理地址；第二次就是根据第一次
得到的物理地址访问内存取出数据)。 
 
什么是分段？ 
分页是为了提高内存利用率，而分段是为了满足程序员在编写代码的时候的一些
逻辑需求(比如数据共享，数据保护，动态链接等)。 
分段内存管理当中，地址是二维的，一维是段号，二维是段内地址；其中每个段
的长度是不一样的，而且每个段内部都是从 0 开始编址的。由于分段管理中，每
个段内部是连续内存分配，但是段和段之间是离散分配的，因此也存在一个逻辑
地址到物理地址的映射关系，相应的就是段表机制。 
 
分页和分段有什么区别？ 
 
页式存储：用户空间划分为大小相等的部分称为页（page），内存空间划分为同
样大小的区域称为页框，分配时以页为单位，按进程需要的页数分配，逻辑上相
邻的页物理上不一定相邻； 
 
段式存储：用户进程地址空间按照自身逻辑关系划分为若干个段（segment）（如
代码段，数据段，堆栈段），内存空间被动态划分为长度不同的区域，分配时以
段为单位，每段在内存中占据连续空间，各段可以不相邻； 
 
段页式存储：用户进程先按段划分，段内再按页划分，内存划分和分配按页。 
区别： 
 
目的不同：分页的目的是管理内存，用于虚拟内存以获得更大的地址空间；分段
的目的是满足用户的需要，使程序和数据可以被划分为逻辑上独立的地址空间； 
 
大小不同：段的大小不固定，由其所完成的功能决定；页的大小固定，由系统决
定； 
 
地址空间维度不同：分段是二维地址空间（段号+段内偏移），分页是一维地址
空间（每个进程一个页表/多级页表，通过一个逻辑地址就能找到对应的物理地
址）； 
 
分段便于信息的保护和共享；分页的共享收到限制； 
 
碎片：分段没有内碎片，但会产生外碎片；分页没有外碎片，但会产生内碎片（一
个页填不满） 
什么是交换空间？ 
操作系统把物理内存(physical RAM)分成一块一块的小内存，每一块内存被称为
页(page)。当内存资源不足时，Linux 把某些页的内容转移至硬盘上的一块空间
上，以释放内存空间。硬盘上的那块空间叫做交换空间(swap space),而这一过程
被称为交换(swapping)。物理内存和交换空间的总容量就是虚拟内存的可用容量。 
用途： 
 
物理内存不足时一些不常用的页可以被交换出去，腾给系统。 
 
程序启动时很多内存页被用来初始化，之后便不再需要，可以交换出去。 
物理地址、逻辑地址、有效地址、线性地址、虚拟地址的区别? 
物理地址就是内存中真正的地址，它就相当于是你家的门牌号，你家就肯定有这
个门牌号，具有唯一性。不管哪种地址，最终都会映射为物理地址。 
在实模式下，段基址 + 段内偏移经过地址加法器的处理，经过地址总线传输，
最终也会转换为物理地址。 
但是在保护模式下，段基址 + 段内偏移被称为线性地址，不过此时的段基址不能
称为真正的地址，而是会被称作为一个选择子的东西，选择子就是个索引，相当
于数组的下标，通过这个索引能够在 GDT 中找到相应的段描述符，段描述符记
录了段的起始、段的大小等信息，这样便得到了基地址。如果此时没有开启内存
分页功能，那么这个线性地址可以直接当做物理地址来使用，直接访问内存。如
果开启了分页功能，那么这个线性地址又多了一个名字，这个名字就是虚拟地址。 
不论在实模式还是保护模式下，段内偏移地址都叫做有效地址。有效抵制也是逻
辑地址。 
线性地址可以看作是虚拟地址，虚拟地址不是真正的物理地址，但是虚拟地址会
最终被映射为物理地址。下面是虚拟地址 -> 物理地址的映射。 
编程一般只有可能和逻辑地址打交道，比如在 C 语言中，指针里面存储的数值就
可以理解成为内存里的一个地址，这个地址也就是我们说的逻辑地址，逻辑地址
由操作系统决定。 
  
什么是虚拟内存？ 
每个程序都拥有自己的地址空间，这个地址空间被分成大小相等的页，这些页被
映射到物理内存；但不需要所有的页都在物理内存中，当程序引用到不在物理内
存中的页时，由操作系统将缺失的部分装入物理内存。这样，对于程序来说，逻
辑上似乎有很大的内存空间，只是实际上有一部分是存储在磁盘上，因此叫做虚
拟内存。 
虚拟内存的优点是让程序可以获得更多的可用内存。 
虚拟内存的实现方式、页表/多级页表、缺页中断、不同的页面淘汰算法： 
虚拟内存的实现方式有哪些? 
虚拟内存中，允许将一个作业分多次调入内存。釆用连续分配方式时，会使相当
一部分内存空间都处于暂时或永久的空闲状态，造成内存资源的严重浪费，而且
也无法从逻辑上扩大内存容量。因此，虚拟内存的实需要建立在离散分配的内存
管理方式的基础上。虚拟内存的实现有以下三种方式： 
 
请求分页存储管理。 
 
请求分段存储管理。 
 
请求段页式存储管理。 
如何进行地址空间到物理内存的映射？ 
内存管理单元（MMU）管理着逻辑地址和物理地址的转换，其中的页表（Page 
table）存储着页（逻辑地址）和页框（物理内存空间）的映射表，页表中还包含
包含有效位（是在内存还是磁盘）、访问位（是否被访问过）、修改位（内存中
是否被修改过）、保护位（只读还是可读写）。逻辑地址：页号+页内地址（偏
移）；每个进程一个页表，放在内存，页表起始地址在 PCB/寄存器中。 
有哪些页面置换算法？ 
在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页
调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁
盘中来腾出空间。页面置换算法的主要目标是使页面置换频率最低（也可以说缺
页率最低）。 
 
最佳页面置换算法 OPT（Optimal replacement algorithm）：置换以后不需要或者
最远的将来才需要的页面，是一种理论上的算法，是最优策略； 
 
先进先出 FIFO：置换在内存中驻留时间最长的页面。缺点：有可能将那些经常
被访问的页面也被换出，从而使缺页率升高； 
 
第二次机会算法 SCR：按 FIFO 选择某一页面，若其访问位为 1，给第二次机会，
并将访问位置 0； 
 
时钟算法 Clock：SCR 中需要将页面在链表中移动（第二次机会的时候要将这个
页面从链表头移到链表尾），时钟算法使用环形链表，再使用一个指针指向最老
的页面，避免了移动页面的开销； 
 
最近未使用算法 NRU（Not Recently Used）：检查访问位 R、修改位 M，优先置
换 R=M=0，其次是（R=0, M=1）； 
 
最近最少使用算法 LRU（Least Recently Used）：置换出未使用时间最长的一页；
实现方式：维护时间戳，或者维护一个所有页面的链表。当一个页面被访问时，
将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。 
 
最不经常使用算法 NFU：置换出访问次数最少的页面 
 
局部性原理 
 
时间上：最近被访问的页在不久的将来还会被访问； 
 
空间上：内存中被访问的页周围的页也很可能被访问。 
什么是颠簸现象 
颠簸本质上是指频繁的页调度行为。进程发生缺页中断时必须置换某一页。然而，
其他所有的页都在使用，它置换一个页，但又立刻再次需要这个页。因此会不断
产生缺页中断，导致整个系统的效率急剧下降，这种现象称为颠簸。内存颠簸的
解决策略包括： 
 
修改页面置换算法； 
 
降低同时运行的程序的数量； 
 
终止该进程或增加物理内存容量。 
什么是缓冲区溢出？C 语言使用运行时栈来存储过程信息。每个函数的信息存
储在一个栈帧中，包括寄存器、局部变量、参数、返回地址等。C 对于数组引用
不进行任何边界检查，因此**对越界的数组元素的写操作会破坏存储在栈中的状
态信息**，这种现象称为缓冲区溢出。缓冲区溢出会破坏程序运行，也可以被用
来进行攻击计算机，如使用一个指向攻击代码的指针覆盖返回地址。缓冲区溢出
的防范方式 
防范缓冲区溢出攻击的机制有三种：随机化、栈保护和限制可执行代码区域。 
 
随机化：包括栈随机化（程序开始时在栈上分配一段随机大小的空间）和地址空
间布局随机化（Address-Space Layout Randomization，ASLR，即每次运行时程序
的不同部分，包括代码段、数据段、栈、堆等都会被加载到内存空间的不同区域），
但只能增加攻击一个系统的难度，不能完全保证安全。 
 
栈保护：在每个函数的栈帧的局部变量和栈状态之间存储一个随机产生的特殊的
值，称为金丝雀值（canary）。在恢复寄存器状态和函数返回之前，程序检测这
个金丝雀值是否被改变了，如果是，那么程序异常终止。 
 
限制可执行代码区域：内存页的访问形式有三种：可读、可写、可执行，只有编
译器产生的那部分代码所处的内存才是可执行的，其他页限制为只允许读和写。 
 
磁盘调度 
过程：磁头（找到对应的盘面）；磁道（一个盘面上的同心圆环，寻道时间）；
扇区（旋转时间）。为减小寻道时间的调度算法： 
 
先来先服务 
 
最短寻道时间优先 
 
电梯算法：电梯总是保持一个方向运行，直到该方向没有请求为止，然后改变运
行方向。 
fork 函数的作用 
在 Linux 中 fork 函数是非常重要的函数，它的作用是从已经存在的进程中创建
一个子进程，而原进程称为父进程。 
调用 fork()，当控制转移到内核中的 fork 代码后，内核开始做： 
1. 分配新的内存块和内核数据结构给子进程。 
2. 将父进程部分数据结构内容拷贝至子进程。 
3. 将子进程添加到系统进程列表。 
4. fork 返回开始调度器，调度。 
特点： 
1)调用一次，返回两次并发执行 
2)相同但是独立的地址空间 
3)fork 的返回值：fock 函数调用一次却返回两次；向父进程返回子进程的 ID，
向子进程中返回 0， 
4)fork 的子进程返回为 0； 
5)父进程返回的是子进程的 pid。 
fork 调用失败的原因 
1)系统中有太多进程。 
2)实际用户的进程数超过限制。 
 
shell 
 
# 列出文件系统的磁盘使用状况 - df。df –h 
# free 命令,它是用来查看系统内存的命令 
free -h #查看内存使用情况,并且以合适的单位显示大小 
# 查看网络服务和端口 - netstat / ss。 
[root ~]# netstat -nap | grep nginx 
使用 ls -ll，会显示成字节大小，而 ls- lh 会以 KB、MB 等为单位
进行显示 
Linux 查看进程 
1. ps –aux 简单列表的形式显示出进程信息 
a：显示当前终端下的所有进程信息，包括其他用户的进程。 
u：使用以用户为主的格式输出进程信息。 
x：显示当前用户在所有终端下的进程。 
2. ps –elf 
-e：显示系统内的所有进程信息。 
-l：使用长（long）格式显示进程信息。 
-f：使用完整的（full）格式显示进程信息。  
3. top 
以全屏交互式的界面显示进程排名，及时跟踪包括 CPU、内存等系统资源占用情况，默认
情况下每三秒刷新一次，其作用基本类似于 Windows 系统中的任务管理器。 
4. pstree –aup 以树状图的方式展现进程之间的派生关系 
-a：显示每个程序的完整指令，包含路径，参数或是常驻服务的标示；  
-c：不使用精简标示法；  
-G：使用 VT100 终端机的列绘图字符；  
-h：列出树状图时，特别标明现在执行的程序；  
-H<程序识别码>：此参数的效果和指定”-h”参数类似，但特别标明指定的程序；  
-l：采用长列格式显示树状图；  
-n：用程序识别码排序。预设是以程序名称来排序；  
-p：显示程序识别码；  
-u：显示用户名称；  
 
4. uptime 
查看系统的负载情况。 
 
mount 
将 /dev/hda1 挂在 /mnt 之下 
 
ldd 
list dynamic dependencies，列出动态库依赖关系 
ldd 本身不是一个程序，而仅是一个 shell 脚本：ldd 可以列出一个程序
所需要得动态链接库（so） 
ldd 命令通常使用"-v"或"--verbose"选项来显示所依赖的动态连接库
的尽可能的详细信息。 
即可得到/bin/ls 命令的相关共享库文件列表： 
root@xxhui:/home/hui# ldd /bin/ls 
linux-vdso.so.1 (0x00007ffeeffc3000) 
libselinux.so.1 => /lib/x86_64-linux-gnu/libselinux.so.1 
(0x00007f8e631c7000) 
libacl.so.1 => /lib/x86_64-linux-gnu/libacl.so.1 
(0x00007f8e62fbe000) 
libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 
(0x00007f8e62c19000) 
libpcre.so.3 => /lib/x86_64-linux-gnu/libpcre.so.3 
(0x00007f8e629a9000) 
libdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 
(0x00007f8e627a5000) 
/lib64/ld-linux-x86-64.so.2 (0x00005599a18e8000) 
libattr.so.1 => /lib/x86_64-linux-gnu/libattr.so.1 
(0x00007f8e6259f000) 
libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 
(0x00007f8e62382000) 
注意： 在 ldd 命令打印的结果中，“=>”左边的表示该程序需要连
接的共享库之 so 名称，右边表示由 Linux 的共享库系统找到的对应
的共享库在文件系统中的具体位置。默认情况下， /etc/ld.so.conf 
文件中包含有默认的共享库搜索路径。 
ss 
ss 是 Socket Statistics 的缩写。ss 命令可以用来获取 socket 统计
信息 
-h, –help 帮助  
-V, –version 显示版本号  
-t, –tcp 显示 TCP 协议的 sockets  
-u, –udp 显示 UDP 协议的 sockets  
-x, –unix 显示 unix domain sockets，与 -f 选项相同  
-n, –numeric 不解析服务的名称，如 “22” 端口不会显示成 
“ssh”  
-l, –listening 只显示处于监听状态的端口  
-p, –processes 显示监听端口的进程(Ubuntu 上需要 sudo)  
-a, –all 对 TCP 协议来说，既包含监听的端口，也包含建立的连接  
-r, –resolve 把 IP 解释为域名，把端口号解释为协议名称 
 
chmod 
修改/test 下的 aaa.txt 的权限为文件所有者有全部权限，文件所有
者所在的组有读写权限，其他用户只有读的权限。 
chmod u=rwx,g=rw,o=r aaa.txt 或者 chmod 764 aaa.txt 
环境变量修改 
通过 export 命令可以修改指定的环境变量。不过，这种方式修改环境
变量仅仅对当前 shell 终端生效，关闭 shell 终端就会失效。修改完
成之后，立即生效。 
export CLASSPATH=./JAVA_HOME/lib;$JAVA_HOME/jre/lib 
通过 vim 命令修改环境变量配置文件。这种方式修改环境变量永久有
效。vim ~/.bash_profile 
如果修改的是系统级别环境变量则对所有用户生效，如果修改的是用
户级别环境变量则仅对当前用户生效。修改完成之后，需要 source 
命令让其生效或者关闭 shell 终端重新登录。source /etc/profile 
shell 单引号和双引号 
在单引号中所有的特殊符号，如$和反引号都没有特殊含义。在双引号
中，除了"$",""和反引号，其他的字符没有特殊含义。 
 
shell 数组 
array=(1 2 3 4 5); 
# 获取数组长度 
length=${#array[@]} 
# 或者 
length2=${#array[*]} 
#输出数组长度 
echo $length #输出：5 
echo $length2 #输出：5 
# 输出数组第三个元素 
echo ${array[2]} #输出：3 
unset array[1]# 删除下标为 1 的元素也就是删除第二个元素 
for i in ${array[@]};do echo $i ;done # 遍历数组，输出： 1 3 4 5 
unset array; # 删除数组中的所有元素 
for i in ${array[@]};do echo $i ;done # 遍历数组，数组元素为空，
没有任何输出内容 
 
 
 
 
VIM 使用 
 
# vim 
删除：在命令模式下可以用 dd 来删除整行；可以在 dd 前加数字来指定删除的行数；
可以用 d$ 来实现删除从光标处删到 
行尾的操作，也可以通过 d0 来实现从光标处删到行首的操作；如果想删除一个单词，
可以使用 dw ；如果要删除全文， 
可以在输入 :%d （其中 : 用来从命令模式进入末行模式）。 
撤销和恢复：在命令模式下输入 u 可以撤销之前的操作；通过 Ctrl+r 可以恢复被撤销
的操作。 
对内容进行排序：在命令模式下输入 %!sort 。 
查找操作需要输入 / 进入末行模式并提供正则表达式来匹配与之对应的内容，例如： 
/doc.*\. ，输入 n 来向前搜索，也 
可以输入 N 来向后搜索。 
在输入 : 进入末行模式后可以对 vim 进行设定。 
设置 Tab 键的空格数： set ts=4 
设置显示/不显示行号： set nu /  set nonu 
设置启用/关闭高亮语法： syntax on /  syntax off 
设置显示标尺（光标所在的行和列）：  set ruler 
设置启用/关闭搜索结果高亮： set hls /  set nohls 
# 比较多个文件。 
[root ~]# vim -d foo.txt bar.txt 
 
 
# vim 非编辑模式 
yy：复制光标当前行 
p：粘贴 
dd:删除光标当前行 
$:光标跳到当前行的行尾 
^:光标跳到当前行的行首 
:s/原字符串/新字符串/:替换光标当前行内容 
:%s/原字符串/新字符串/g:全文替换 #g 表示 global i 表示 ignore 忽略大小写 
/要查找的内容:从光标当前行向后查找内容 
/d #在文件中查找 d 字母 
?要查找的内容：从光标当前位置向前查找内容 
?d #查找文件中的 d 字母 
CTRL+F:向下翻 1 页 
CTRL+B:向上翻 1 页 
:set nu：显示文件的行号 
:set nonu: 去掉行号显示 
u:撤消 
**:set ff :显示文件的格式 #unix 表示在 unix 上的文件 dos 表示文件是 windows 上的文
件** 
:w ：表示保存文件 
:q :表示退出 vim 命令 
:wq:保存并退出 
:w!:强制保存 
:q!:强制退出但不保存 
:wq!:强制保存并退出 
i:表示进入编辑模式，并且光标在当前行 
o：表示进入编辑模式，并且光标出现的当前行的下一行(新行) 
 
 
 
10 个 Linux 常用命令 
ls  
pwd 
cd 
touch  
rm  
mkdir  
tree  
cp  
mv  
cat  
more  
grep  
echo 
获取登录信息 - w / who / last/ lastb。 
查看命令的说明和位置 - whatis / which / whereis。 
查看帮助文档 - man / info / help / apropos。 
查看系统和主机名 - uname / hostname。 
时间和日期 - date / cal。 
重启和关机 - reboot / shutdown。 
查看文件内容 - cat / tac / head / tail / more / less / rev / od。 
文件重命名 - rename。 
查找文件和查找内容 - find / grep。 
创建链接和查看链接 - ln / readlink。 
将标准输入转成命令行参数 - xargs。 
显示文件或目录 - basename / dirname。 
sort - 对内容排序 
uniq - 去掉相邻重复内容 
tr - 替换指定内容为新内容 
cut/paste - 剪切/黏贴内容 
split - 拆分文件 
file - 判断文件类型 
wc - 统计文件行数、单词数、字节数 
wc -l linux 常用命令.txt #-l 表示 line 行数 计算文件的行数 
wc -w linux 常用命令.txt #-w 表示 word 单词个数 计算文件的单词个数 
iconv - 编码转换 
输出重定向和错误重定向 - > / >> / 2>。 
 
# 多重定向 - tee。 
下面的命令除了在终端显示命令 ls 的结果之外，还会追加输出到 ls.txt 文件中 
ls | tee -a ls.txt 
 
# 别名 alias 
alias ll='ls -l' 
alias frm='rm -rf' 
 
# 创建和删除用户 - useradd / userdel 
# 创建和删除用户组 - groupadd / groupdel。 
useradd hellokitty 
userdel hellokitty 
说明：用户组主要是为了方便对一个组里面所有用户的管理。 
-d - 创建用户时为用户指定用户主目录 
-g - 创建用户时指定用户所属的用户组 
 
# 修改密码 - passwd。 
[root ~]# passwd hellokitty 
New password: 
Retype new password: 
passwd: all authentication tokens updated successfully. 
 
 
# 查看和修改密码有效期 - chage。 
设置 hellokitty 用户 100 天后必须修改密码，过期前 15 天通知该用户，过期后 15 天禁
用该用户。 
chage -M 100 -W 15 -I 15 hellokitty 
 
# 编辑 sudoers 文件 - visudo。 
# 显示用户与用户组的信息 - id。 
# 给其他用户发消息 -write / wall。 
# 查看/设置是否接收其他用户发送的消息 - mesg。 
# chown - 改变文件所有者。 
[root ~]# chown hellokitty readme.txt 
# 磁盘分区表操作 - fdisk。 
# 磁盘分区工具 - parted。 
# 格式化文件系统 - mkfs。 
# 文件系统检查 - fsck。 
# 转换或拷贝文件 - dd 
# 挂载/卸载 - mount / umount。 
# 创建/激活/关闭交换分区 - mkswap / swapon / swapoff。 
网络监听抓包 - tcpdump。 
文件同步工具 - rsync。 
说明：使用 rsync 可以实现文件的自动同步，这个对于文件服务器来说相当重要。 
 
# 用一条命令强制终止正在运行的 Redis 进程。 
ps -ef | grep redis | grep -v grep | awk '{print $2}' | xargs kill -9 
 
# echo 命令 
echo #输出命令，可以输入变量，字符串的值 
echo Hello World #打印 Hello World 
echo $PATH #打印环境变量 PATH 的值,其中$是取变量值的符号，用法：$变量名 或者 
${变量名} 
echo -n #打印内容但不换行 
echo -n Hello World 
 
# >和>>命令 
和>>:输出符号，将内容输出到文件中，>表示覆盖(会删除原文件内容) >>表示追加 
echo Hello World > 1.txt #将 Hello World 输出到当前目录下的 1.txt 文件 
#如果当前目录下没有 1.txt 文件会创建一个新文件， 
#如果当前目录下有 1.txt，则会删除原文件内容，写入 Hello World 
echo 1234 >> 1.txt #将 1234 追加到当前目录下的 1.txt 中，如果文件不存在会创建新文件 
通过>和>>都可以创建文件 
 
 
# zip 
zip 2.zip 2.txt #将 2.txt 压缩到 2.zip 中 
zip data.zip data #只会压缩文件夹,不会压缩文件夹下的内容 
zip da.zip da/* #压缩文件夹和文件夹内的文件(压缩文件夹和它的下一级文件) 
zip -r data.zip date #-r 表示递归地将文件夹及它的子目录文件全部压缩 
unzip 2.zip #将 2.zip 压缩包解压到当前目录下 
unzip -l 压缩文件名 #不解压文件,查看压缩包内的文件 
unzip -l da.zip #查看 da.zip 压缩文件中包含的文件 
unzip da.zip -d 目标目录 #将压缩文件解压到指定目录 
unzip da.zip -d tm/ #将压缩文件 da.zip 解压到 tm 目录下 
tar cvf 压缩文件名 要压缩的文件或目录 
tar cvf 2.tar 2.txt #将 2.txt 压缩为 2.tar 包 
tar cvf data.tar data #将 data 目录夸张到 data.tar 包中 
tar xvf 2.tar #将 2.tar 解压到当前目录 
tar xvf 2.tar -C a/ #将 2.tar 解压到 a 目录 
tar xvf data.tar #解压 data.tar 到当前目录 
tar zcvf 压缩文件名 要压缩的文件 
tar zcvf tm.tar.gz tm #将当前目录下的 tm 目录压缩为 tm.tar.gz 
tar zxvf 压缩文件名 
tar zxvf tm.tar.gz #将 tm.tar.gz 解压到当前目录 
gzip 命令,将文件压缩为.gz 包(可以用来压缩.tar 文件) 
gzip 要压缩的文件 
gzip 2.txt #将 2.txt 压缩为 2.txt.gz 
gzip data.tar #将 data.tar 压缩为 data.tar.gz 
 
 
/etc/profile #linux 上的系统环境变量配置文件 
source /etc/profile #将系统环境变量生效 
 
 
export 导入全局变量(环境变量) 
export 变量名=变量值 
export 变量名 
变量的赋值: 
变量名=变量值 
 
<<EOF 
<<EOF … EOF:将<<EOF 和 EOF 之间的多行内容传给前面的命令, 
其中 EOF 可以是任意字符串,但约定都使用 EOF 
 
 
# cut 
-f 参数,指定列 
-d 参数指定列和列之间的分隔符,默认的分隔符是\t(行向制表符) 
cut -f 1 1.txt #取 1.txt 文件中的第 1 列内容(列分隔符默认为\t) 
cut -f 2 1.txt #取 1.txt 文件中的第 2 列内容 
cut -f 1 -d ',' 3.txt #取 3.txt 文件中的第 1 列(列分隔符为,) 
cut -f 2 -d ',' 3.txt #取 3.txt 第 2 列 
 
# sudo 命令 
sudo 命令,它在非 root 用户下,去调用一些 root 用户的命令,或者修改一些文件 
sudo 命令是需要配置的,sudo 的配置文件是/etc/sudoers 
##  19. <a name='bowsudo'></a>bow 用户配置 sudo 权限 
[root@bow ~]# vim /etc/sudoers 
## 
##  20. <a name='Allowroottorunanycommandsanywhere'></a>Allow root to run any commands anywhere 
root ALL=(ALL) ALL 
##  21. <a name='bowsudo-1'></a>bow 用户设置 sudo 命令权限 
bow ALL=(ALL) ALL 
[root@bow ~]# su - bow 
上一次登录：四 3 月 26 07:30:53 CST 2020pts/0 上 
[bow@bow ~]$ sudo vim /etc/profile 
 
 
# ifconfig 
ifconfig 命令属于 net-tools 软件包,使用前需要安装 net-tools 
net-tools 的安装: 
yum -y install net-tools 
ifconfig 查看 ip 地址 
 
# netstat 
netstat 命令也属于 net-tools 软件包 
netstat -tulp | grep 1521 #查看 oracle 监听器程序是否正常启动 
 
# rpm 
rpm -ivh .rpm 文件的路径 #表示安装软件包 
rpm -qa #查看已安装的软件 
rpm -qa | grep mysql #查看已经安装的 mysql 软件包 
rpm -e --nodeps 安装包名 #卸载软件包 -e 表示卸载 --nodeps 表示不理会的依赖关系 
sed 
字符流编辑器--sed，sed 是操作、过滤和转换文本内容的工具。 
假设有一个名为 fruit.txt 的文件，内容如下所示。 
[root ~]# cat -n fruit.txt 
1 banana 
2 grape 
3 apple 
4 watermelon 
5 orange 
接下来，我们在第 2 行后面添加一个 pitaya。 
[root ~]# sed '2a pitaya' fruit.txt 
banana 
grape 
pitaya 
apple 
watermelon 
orange 
在第 2 行前面插入一个 waxberry。 
[root ~]# sed '2i waxberry' fruit.txt 
banana 
waxberry 
grape 
apple 
watermelon 
orange 
删除第 3 行。 
[root ~]# sed '3d' fruit.txt 
banana 
grape 
watermelon 
orange 
删除第 2 行到第 4 行。 
[root ~]# sed '2,4d' fruit.txt 
banana 
orange 
将文本中的字符 a 替换为@。 
[root ~]# sed 's#a#@#' fruit.txt 
b@nana 
gr@pe 
@pple 
w@termelon 
or@nge 
将文本中的字符 a 替换为@，使用全局模式。 
[root ~]# sed 's#a#@#g' fruit.txt 
b@n@n@ 
gr@pe 
@pple 
w@termelon 
or@nge 
 
sed 可以查找日志文件特定的一段 , 根据时间的一个范围查询，可以按照行号和时间范
围查询 
按照行号 
sed -n '5,10p' filename 这样你就可以只查看文件的第 5 行到第 10 行。 
按照时间段 
sed -n '/2014-12-17 16:17:20/,/2014-12-17 16:17:36/p' test.log 
awk 
模式匹配和处理语言 - awk。 awk 是一种编程语言，也是 Linux 系统中处理文本
最为强大的工具，它的作者之一和现在的维护者就是之前提到过的 Brian 
Kernighan（ken 和 dmr 最亲密的伙伴）。通过该命令可以从文本中提取出指定的
列、用正则表达式从文本中取出我们想要的内容、显示指定的行以及进行统计和
运算，总之它非常强大。 
假设有一个名为 fruit2.txt 的文件，内容如下所示。 
[root ~]# cat fruit2.txt 
1 banana 120 
2 grape 500 
3 apple 1230 
4 watermelon 80 
5 orange 400 
 
# 显示文件的第 3 行。 
[root ~]# awk 'NR==3' fruit2.txt 
3 apple 1230 
 
# 显示文件的第 2 列。 
[root ~]# awk '{print $2}' fruit2.txt 
banana 
grape 
apple 
watermelon 
orange 
 
# 显示文件的最后一列。 
[root ~]# awk '{print $NF}' fruit2.txt 
120 
500 
1230 
80 
400 
 
# 输出末尾数字大于等于 300 的行。 
[root ~]# awk '{if($3 >= 300) {print $0}}' fruit2.txt 
2 grape 500 
3 apple 1230 
5 orange 400 
 
 
 
 
 
find 和 grep 
grep 命令是一种强大的文本搜索工具，grep 搜索内容串可以是正则表达式，允许
对文本文件进行模式查找。如果找到匹配模式，grep 打印包含模式的所有行。 
find 通常用来再特定的目录下搜索符合条件的文件，也可以用来搜索特定用户属
主的文件。 
安装 Python 3.6 
[root ~]# yum install gcc 
[root ~]# wget https://www.python.org/ftp/python/3.6.5/Python-3.6.5.tgz 
[root ~]# gunzip Python-3.6.5.tgz 
[root ~]# tar -xvf Python-3.6.5.tar 
[root ~]# cd Python-3.6.5 
[root ~]# ./configure --prefix=/usr/local/python36 --enable-optimizations 
[root ~]# yum -y install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel 
readline-devel tk-devel gdbm-devel db4-devel libpcap-devel xz-devel 
[root ~]# make && make install 
... 
[root ~]# ln -s /usr/local/python36/bin/python3.6 /usr/bin/python3 
[root ~]# python3 --version 
Python 3.6.5 
[root ~]# python3 -m pip install -U pip 
[root ~]# pip3 --version 
说明：上面在安装好 Python 之后还需要注册 PATH 环境变量，将 Python 安装路
径下 bin 文件夹的绝对路径注册到 PATH 环境变量中。注册环境变量可以修改用
户主目录下的.bash_profile 或者/etc 目录下的 profile 文件，二者的区别在于前者
相当于是用户环境变量，而后者相当于是系统环境变量 
Linux 下的大多数服务都被设置为守护进程（驻留在系统后台运行，但不会因为
服务还在运行而导致 Linux 无法停止运行），所以我们安装的服务通常名字后面
都有一个字母 d ，它是英文单词 daemon 的缩写，例如：防火墙服务叫 firewalld，
我们之前安装的 MySQL 服务叫 mysqld，Apache 服务器叫 httpd 等。在安装好服
务之后，可以使用 systemctl 命令或 service 命令来完成对服务的启动、停止等
操作 
 
 
 
centos7 下编译安装 python3 
1.必须解决编译所需的基础开发环境 
yum install gcc patch libffi-devel python-devel zlib-devel bzip2-devel openssl-devel ncurses-
devel sqlite-devel readline-devel tk-devel gdbm-devel db4-devel libpcap-devel xz-devel -y 
2.下载 python3 的编代码包,解压缩 
wget https://www.python.org/ftp/python/3.7.4/Python-3.7.4.tar.xz 
xz -d Python-3.7.4.tar.xz 
tar -xf Python-3.7.4.tar 
3.进入解压缩生成的源码文件夹 
cd Python-3.7.4 
4.执行编译三部曲的命令 
第一曲：找到一个[配置的可执行文件，configure]，执行它，且指定软件安装位置 
./configure --prefix=/opt/python374/ 
第二曲：在上一步，会生成一个 makefile，编译安装，在 linux 下必须用 gcc 工具去编
译，使用的命令时 
make&&make 
第三曲：这一步是执行安装，会生成一个/opt/python374 文件夹，可用的解释器都在这里
了 
make install 
5.配置环境变量，便于快捷使用 python3 
1.先获取当前的 PATH 变量，然后把 python3 的 bin 目录加进去 
echo $PATH 
/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin:/root/bin 
2.永久修改 PATH 的值 
-直接修改/etc/profile ，系统全局的配置文件，每个用户在登陆系统的时候，都会加载这
个文件 
vim /etc/profile 
-写入新的 PATH 变量 
PATH="/opt/python367/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin:/root/bin 
" 
3.重新登陆，或者手动读取这个/etc/profile 
source /etc/profile # 让这个文件中的变量生效 
 
 
 
Linux 下安装 openJDK 
1. 卸载旧版本 
rpm -qa|grep gcj 
如果有 gcj 文件，yum remove 即可； 
2. 安装 OpenJDK，只是 1.8 以上 
注意：安装 java-1.8.0-openjdk 后只有 jre，必须继续安装 yum install java-1.8.0-openjdk-
devel 
安装完后的路径为：/usr/lib/jvm 
yum install java-1.8.0-openjdk 
yum install java-1.8.0-openjdk-devel 
3. 配置环境变量 
vi /etc/profile 
export JAVA_HOME=/usr/lib/jvm/java-1.8.0 
export JRE_HOME=$JAVA_HOME/jre 
export 
CLASS_PATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib 
export PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin 
 
 
 
虚拟环境 virtualenv 
virtualenv----虚拟环境，就是可以在一个主机上，自定义出多套的 python 环境，
多套环境中使用不同的 python 解析器，环境变量设置，第三方依赖包，执行不
同的测试命令，最重要的是各个环境之间互不影响，相互隔离； 
virtualenv 使用 
1. pip install virtualenv； 
2. cd 到存放虚拟环境的目录，执行 virtualenv ENV----在当前目录下创建名为 ENV
的虚拟环境（如果第三方包 virtualenv 安装在 python3 下面，此时创建的虚拟环
境就是基于 python3 的）; virtualenv -p /usr/local/bin/python2.7 ENV2 参数 -p 指
定 python 版本创建虚拟环境 virtualenv --system-site-packages ENV 参数 --
system-site-packages 指定创建虚拟环境时继承系统三方库 
3. source bin/activate 激活虚拟环境 pip list 查看当前虚拟环境下所安装的第三方
库 deactivate 退出虚拟环境 
4. 删除的话，直接删除虚拟环境所在目录即可。 
 
iptables 使用 
iptables –I INPUT –s 192.168.11.12 –p –tcp m tcp –j DROP 
iptables –D INPUT –s 192.168.11.12 –p –tcp m tcp –j DROP 
iptables –nL |grep 192.168.11.12 
 
 
linux 下的后台进程管理利器 supervisor 
每次文件修改后再 linux 执行 service supervisord restart 
用过 ping 命令么？简单介绍一下。TTL 是什么意思？ 
ping : 查看与某台机器的连接情况。TTL：生存时间。数据报被路由器丢弃之前
允许通过的网段数量。 
怎么判断一个主机是不是开放某个端口？ 
telnet IP 地址 端口 
telnet 127.0.0.1 3389 
 
6. git 
1. 配置 user.name 以及 user.email 
git 使用你的用户名将提交与身份相关联。 git config 命令可用来更改你的 git 配置，
包括你的用户名。 
 
----git config --global user.name dongxiang 
----git config --global user.email dong.xiangxiang@zte.com.cn 
git config --list                  # 列出 Git 可以在该处找到的所有的设置 
2. Git 终端的配置，生成公钥文件 
1. ssh-keygen -t rsa -C (这里是你的邮箱地址) # 之后一路回车即可； 
2. 执行完后，在指定路径生成公钥文件； 
linux 路径：~/.ssh 
windows 路径：c 盘>用户>自己的用户名>.ssh 
3. 将公钥 id_rsa.pub 文本内容拷贝到远端 ssh keys 中。 
3. git 修改上次提交 
修改后执行 git add .； 
然后 git commit --amend，把文件和上次提交合并（--amend 可以保持 change_Id 和上次
一样，如果被删掉的话，这条命令会生成新的 chang_id,此时如果想合并到上次的修改
中，必须复制上次的 Change_Id 作为本次的 Change_id）; 
最后 git push origin HEAD:refs/for/master 
 
git 本地只有在 add+commit 之后才能出现 master 分支； 
 
 
4. git 添加 github 远程仓库 
----- git remote add -m master origin git@github.com:SHANExiang/blog.git 
5. git 本地 master 分支与远程 master 分支关联 
当在本地新建一个已经存在代码的本地仓库时，想将这个仓库与远端的仓库关联，即 
----- git branch --set-upstream-to=origin/master master 
Branch 'master' set up to track remote branch 'master' from 'origin'. 
----- git push origin master 报错 
To github.com:SHANExiang/blog.git 
! [rejected] master -> master (non-fast-forward) 
error: failed to push some refs to 'git@github.com:SHANExiang/blog.git' 
----- git pull 
fatal: refusing to merge unrelated historie 
----- git pull --allow-unrelated-histories 
Merge made by the 'recursive' strategy. 
README.md | 1 + 
1 file changed, 1 insertion(+) 
create mode 100644 README.md 
可以发现将两者合并起来了； 
----- git push origin master 
 
 
 
6. git 版本回退 
本地修改但未 add/commit 
git checkout .      # 撤销对所有已修改但未提交的文件的修改，但不包括新增的文件 
git checkout [filename]     # 撤销对指定文件的修改，[filename]为文件名 
已 add/commit 但未 push 
git revert commitID # 其实，git revert 可以用来撤销任意一次的修改，不一定要是最近一
次 
或 git reset --hard commitID/git reset --hard HEAD^  
# HEAD 表示当前版本，几个^表示倒数第几个版本，倒数第 100 个版本可以用
HEAD~100）； 
# 参数--hard：强制将暂存区和工作区都同步到指定的版本 
git reset 和 git revert 的区别是：reset 是用来回滚的，将 HEAD 的指针指向了想要回滚的
版本，作为最新的版本，而后面的版本也都没有了；而 revert 只是用来撤销某一次更改，
对之后的更改并没有影响，然后再用 git push -f 提交到远程仓库。 
 
已 push 
首先查询这个文件的 log 
其次查找到这个文件的上次 commit id xxx，并对其进行 reset 操作 
再撤销对此文件的修改 
最后 amend 一下，再 push 上去 
$ git log <fileName> 
$ git reset <commit-id> <fileName> 
$ git checkout <fileName> 
$ git commit --amend 
$ git push origin <remoteBranch>  
7. 查看操作记录 
----- git reflog 
8. 工作区和暂存区 
git 管理的问题的修改，它只会提交暂存区的修改来创建版本； 
 
9. 撤销工作区的修改 
----- git checkout -- 文件名 
作了修改，但还没 git add，撤销到上一次提交：git checkout -f -- filename；git checkout -
f -- . 
10. 把暂存区的修改撤销掉，重新放回工作区 
----- git reset HEAD file 
作了修改，并且已经 git add，但还没 git commit： 
先将暂存区的修改撤销：git reset HEAD filename/git reset HEAD；此时修改只存在于工
作区，变为了 "unstaged changes"； 
再利用上面的 checkout 命令从工作区撤销修改 
11. 对比工作区和某个版本中文件的不同 
----- git diff HEAD -- file 
# +表示工作区中的内容，-表示版本中的内容； 
12. 对比两个版本间文件的不同 
----- git diff HEAD HEAD^ -- file 
# +表示 HEAD 版本文件内容，-表示 HEAD^版本文件的内容 
13. 删除一个文件 
----- git rm file 
14. 分支操作 
----- git branch # 查看当前分支 
----- git branch 分支名 # 创建分支 
----- git checkout -b dev # 创建分支 dev，并切换到它上面（也就是将 head 指向当前分
支） 
----- git checkout 分支名 # 切换分支 
----- git merge 分支名 # 合并某分支到当前分支 
----- git branch -d 分支名 # 删除分支 
----- git log --graph --pretty=oneline   # 看到分支的合并情况 
 
fast-forward    # 快速合并--分支管理策略 
1. checkout 一个分支 dev 上做了 commit，之后 checkout master 分支，对同一地方做了修
改，之后再 master 上执行 merge 操作，由于默认执行的是快速合并，这这个快速合并只
能试图把各自的修改合并起来，但是会有冲突，手动解决冲突后， 就是一次新的提交； 
2. 通常，合并分支时，如果可能，git 会用 fast-forward 模式，但是有些快速合并不能成
功而且合并时没有冲突，这个时候会合并之后并做一次新的提交； 
3. 禁用 fast-forward，----- git merge --no-ff -m "禁用 fast-forward 模式" dev  由于本次合
并要创建一个新的 commit,所以加上-m 参数； 
 
15. 工作现场保存 git stash 
----- git stash # 暂时保存工作现场 
----- git stash pop # 回到工作现场 
git stash drop 命令用于删除隐藏的项目。默认情况下，它将删除最后添加的存储项，如
果提供 
参数的话，它还可以删除特定项。 
下面举个例子。 
如果要从隐藏项目列表中删除特定的存储项目，可以使用以下命令： 
git stash list：它将显示隐藏项目列表，如： 
stash@{0}: WIP on master: 049d078 added the index file stash@{1}: WIP on master: c264051 
Revert “added file_size” stash@{2}: WIP on master: 21d80a5 added number to log 
如果要删除名为 stash@{0} 的项目，请使用命令 git stash drop stash@{0}。 
16. git 标签操作 
首先切换到需要打标签的分支上，然后使用 git tag v1.0 就可以在当前 commit 打上 v1.0
的标签 
git tag v1.0 commitID 对特定 commit 打标签 
打标签时加上 message：git tag -a <tagname> -m "message" 
git tag 查看所有标签 
git show [tagname] 查看标签详细信息 
git push origin <tagname>可以推送一个本地标签到远程仓库 
git push origin --tags 可以推送全部未推送过的本地标签 
git tag -d <tagname>可以删除一个本地标签 
git push origin :refs/tags/<tagname>可以删除一个远程标签（先从本地删除） 
17. git pull 和 git fetch 有什么区别？ 
git pull 命令从中央存储库中提取特定分支的新更改或提交，并更新本地存储库中的目
标分支。 
git fetch 也用于相同的目的，但它的工作方式略有不同。当你执行 git fetch 时，它会从
所需的分支中提取所有新提交，并将其存储在本地存储库中的新分支中。如果要在目标
分支中反映这些更改，必须在 git fetch 之后执行 git merge 。只有在对目标分支和获取
的分支进行合并后才会更新目标分支。为了方便起见，请记住以下等式： 
git pull = git fetch + git merge 
18. 如何找到特定提交中已更改的文件列表？ 
要获取特定提交中已更改的列表文件，请使用以下命令： 
git diff-tree -r {hash} 
给定提交哈希，这将列出在该提交中更改或添加的所有文件。 -r 标志使命令列出单个
文件，而不是仅将它们折叠到根目录名称中。 
你还可以包括下面提到的内容，虽然它是可选的，但有助于给面试官留下深刻印象。输
出还将包含一些额外信息，可以通过包含两个标志把它们轻松的屏蔽掉： 
git diff-tree –no-commit-id –name-only -r {hash} 
这里 -no-commit-id 将禁止提交哈希值出现在输出中，而 -name-only 只会打印文件名
而不是它们的路径。 
 
git merge 和 git rebase 之间有什么区别？ 
简单的说，git merge 和 git rebase 都是合并分支的命令。  
git merge branch 会把 branch 分支的差异 内容 pull 到本地，然后与本地分支的内容一并
形成一个 committer 对象提交到主分支上，合并后的分支与主分支一致；  
git rebase branch 会把 branch 分支优先合并到主分支，然后把本地分支的 commit 放到主
分支后面，合并后的分支就好像从合并后主分支又拉了一个分支一样，本地分支本身 不
会保留提交历史。 
 
 
 
7. mysql 
3 类数据读取问题 
脏读 
如果一个事务 A 对数据进行了更改，但是还没有提交，而另一个事务 B 就可以
读到事务 A 尚未提交的更新结果。这样，当事务 A 进行回滚时，那么事务 B 开
始读到的数据就是一笔脏数据。 
不可重复读 
事务内多次查询相同条件返回的结果不同。指在一个事务内多次读同一数据。在
这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两
次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太
一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可
重复读。 
幻读 
事务 A 在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有
看到的行，发现其中插入了被事务 B 提交的行。 
 
 
幻读是怎么解决的 
 
如图所示，分成了 3 个区间，(负无穷,10]、(10,30]、(30,正无穷]，在这 3 个区间
是可以加间隙锁的。 
之后，我用下面的两个事务演示一下加锁过程。 
 
在事务 A 提交之前，事务 B 的插入操作只能等待，这就是间隙锁起得作用。当
事务 A 执行 update user set name='风筝 2 号’ where age = 10; 的时候，由于条件 
where age =10，数据库不仅在 age =10 的行上添加了行锁，而且在这条记录的两
边，也就是(负无穷,10]、(10,30]这两个区间加了间隙锁，从而导致事务 B 插入操
作无法完成，只能等待事务 A 提交。不仅插入 age =10 的记录需要等待事务 A 提
交，age<10、10<age<30 的记录页无法完成，而大于等于 30 的记录则不受影响，
这足以解决幻读问题了。 
这是有索引的情况，如果 age 不是索引列，那么数据库会为整个表加上间隙锁。
所以，如果是没有索引的话，不管 age 是否大于等于 30，都要等待事务 A 提交
才可以成功插入。 
 
2 类数据更新问题 
第 1 类丢失更新：事务 A 撤销时，把已经提交的事务 B 的更新数据覆盖了。 
第 2 类丢失更新：事务 A 覆盖事务 B 已经提交的数据，造成事务 B 所做的操作
丢失。 
不可重复读和幻读区别： 不可重复读的重点是修改比如多次读取一条记录发现
其中某些列的值被修改，幻读的重点在于新增或者删除比如多次读取一条记录发
现记录增多或减少了。 
 
 
 
事务隔离级别 
事务隔离机制的实现基于锁机制和并发调度。 
其中并发调度使用的是 MVCC（多版本并发控制），通过保存修改的旧版本信息
来支持并发一致性读和回滚等特性。 
不同的隔离级别有不同的现象，并有不同的锁定/并发机制，隔离级别越高，数据
库的并发性就越差。 
InnoDB 存储引擎在分布式事务的情况下一般会用到 SERIALIZABLE(可串行
化)隔离级别。 
 
# 查看事务隔离级别设置值 
mysql> show variables like 'transaction_isolation'; 
# 或者 
mysql> SELECT @@tx_isolation; 
+-----------------+ 
| @@tx_isolation | 
+-----------------+ 
| REPEATABLE-READ | 
+-----------------+ 
Read Uncommitted(读未提交)：可以读取其他 session 未提交的脏数据。一个事务
还没提交时，它做的变更就能被别的事务看到。读取未提交的数据，也被称之为
脏读（Dirty Read）。 
Read Committed(读已提交)：提交后，其他会话可以看到提交的数据。允许不可
重复读取，但不允许脏读取。 
Repeatable Read(可重复读)：一个事务执行过程中看到的数据，总是跟这个事务
在启动时看到的数据是一致的。别人改数据的事务已经提交，我在我的事务中也
不去读。可重复读隔离级别，事务 T 启动的时候会创建一个视图 read-view，之
后事务 T 执行期间，即使有其他事务修改了数据，事务 T 看到的仍然跟在启动
时看到的一样。MySQL 默认采用的 REPEATABLE_READ 隔离级别。禁止不可
重复读取和脏读取、以及幻读(innodb 独有)。 
Serializable(可串行化)：事务只能一个接着一个地执行，但不能并发执行。事务
隔离级别最高。 
 
隔离级别 
脏读 
不可重
复读 
幻读 
第一类丢
失更新 
第二类丢
失更新 
READ 
UNCOMMITED 
允许 
允许 
允许 
不允许 
允许 
READ 
COMMITTED 
不允许 
允许 
允许 
不允许 
允许 
REPEATABLE 
READ 
不允许 
不允许 
允许 
不允许 
不允许 
SERIALIZABLE 
不允许 
不允许 
不允
许 
不允许 
不允许 
 
 
 
三范式 
第一范式（1NF，Normal Form）：属性不应该是可分的。举例：如果将“电话”作
为一个属性（一列），是不符合 1NF 的，因为电话这个属性可以分解为家庭电话
和移动电话...如果将“移动电话”作为一个属性，就符合 1NF； 
第二范式 
2NF：每个非主属性完全依赖于主属性集（候选键集）； 
B 完全依赖于 A，就是说 A 中的所有属性唯一决定 B，属性少了就不能唯一决
定，属性多了则有冗余（叫依赖不叫完全依赖）。举例：（学号，课程名）这个
主属性集可以唯一决定成绩，但是对于学生姓名这个属性，（学号，课程名）这
个属性集就是冗余的，所以学生姓名不完全依赖于（学号，课程名）这一属性集； 
可以通过分解来满足 2NF：将（学号，课程名，成绩）做成一张表；（学号，学
生姓名）做成另一张表，避免大量的数据冗余； 满足 1NF 后，要求表中的所有
列，都必须依赖于主键，而不能有任何一列与主键没有关系，也就是说一个表只
描述一件事情； 
第三范式 
3NF：在 2NF 的基础上，非主属性不传递依赖于主属性 
传递依赖：如果 C 依赖于 B，B 依赖于 A，那么 C 传递依赖于 A； 
3NF 在 2NF 的基础上，消除了非主属性之间的依赖；比如一个表中，主属性有
（学号），非主属性有（姓名，院系，院长名），可以看到院长名这个非主属性
依赖于院系，传递依赖于学号。消除的办法是分解。 必须先满足第二范式（2NF），
要求：表中的每一列只与主键直接相关而不是间接相关，（表中的每一列只能依
赖于主键）； 
 
在哪些地方适合创建索引？ 
某列经常作为最大最小值 MIN()， MAX()字段； 
经常被查询的字段； 
经常用作表连接的字段； 
在 where 里使用 >, >=, = , <, <=, is null 和 between 等字段。 
使用不以通配符开始的 like，where A like ‘China%’ 
经常出现在 ORDER BY/GROUP BY/DISDINCT 后面的字段 
 
当前读和快照读 
当前读 
读取的是最新版本，像 UPDATE、DELETE、INSERT、SELECT ... LOCK IN SHARE 
MODE、SELECT ... FOR UPDATE 这些操作都是一种当前读，为什么叫当前读？
就是它读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记
录，会对读取的记录进行加锁。 
快照读 
读取的是快照版本，也就是历史版本，像不加锁的 SELECT 操作就是快照读，即
不加锁的非阻塞读；快照读的前提是隔离级别不是未提交读和序列化读级别，因
为未提交读总是读取最新的数据行，而不是符合当前事务版本的数据行，而序列
化读则会对表加锁。 
共享锁 
多个事务对于同一数据可以共享一把锁，都能访问到数据，但是只能读不能修改。 
事务隔离级别 
实现方式 
未提交读
（RU） 
事务对当前被读取的数据不加锁，都是当前读；  
事务在更新某数据的瞬间（就是发生更新的瞬间）， 
必须先对其加行级共享锁，直到事务结束才释放。 
提交读（RC） 
事务对当前被读取的数据不加锁，且是快照读；  
事务在更新某数据的瞬间（就是发生更新的瞬间）， 
必须先对其加行级排他锁（Record），直到事务结束才
释放。 
通过快照，在这个级别 MySQL 就解决了不可重复读的问
题 
可重复读
（RR） 
事务对当前被读取的数据不加锁，且是快照读；  
事务在更新某数据的瞬间（就是发生更新的瞬间）， 
必须先对其加行级排他锁（Record，GAP，Next-Key）， 
直到事务结束才释放。  
通过间隙锁，在这个级别 MySQL 就解决了幻读的问题 
事务隔离级别 
实现方式 
序列化读（S） 
事务在读取数据时，必须先对其加表级共享锁 ， 
直到事务结束才释放，都是当前读；  
事务在更新数据时，必须先对其加表级排他锁 ， 
直到事务结束才释放。 
MVCC 
MVCC 是为了解决事务操作中多线程并发安全问题的无锁并发控制技术，它的
全称是 Multi-Version Concurrency Control，中文翻译过来就叫多版本并发控制，
简称 MVCC。 
 
为什么需要 MVCC 
对于 MVCC 的理解，可以根据数据库的三种并发场景来分析。 
第一种是读和读的并发，就是两个线程 A 和 B，同时进行读操作，这种情况下不
会产生并发问题，也不需要并发控制。 
第二种就是读写并发，就是两个线程 A 和 B 在同一时刻分别进行读写操作，这
种情况下，可能会造成事务隔离性问题，还可能遇到脏读、幻读和不可重复读的
问题。 
第三种是写和写的并发，也就是两个线程 A 和 B 同时进行写操作，这种情况
下可能出现数据更新丢失的问题； 
MVCC 相当于是为每个修改保存⼀个版本，版本与事务时间戳关联，读操作只
读该事务开始前的数据库的快照。它是通过数据库记录中的隐式字段 Undo 日志、
Read View 来实现的。 
 
MVCC 能解决什么问题 
根据以上的分析，我总结一下 MVCC 可以为数据库解决以下三个方面的问题 
1、在并发读写数据库时，可以做到在读操作时不用阻塞写操作，写操作也不用
阻塞读操作，从而提高数据库的并发读写的处理能力。 
2、能实现读一致性，从而解决脏读、幻读、不可重复读等事务隔离问题，但是
不能解决数据更新丢失的问题。 
3、采用乐观锁或者悲观锁用来解决写和写的冲突，从而最大程度地去提高数据
库的并发性能。 
 
MVCC 实现原理 
为了实现可重复读，Mysql 采用 MVCC(多版本并发控制)的方式； 
同一条记录在系统中可以存在多个版本，这就是 MVCC; 
MVCC 的实现，是通过保存数据在某个时间点的快照来实现的。根据事务开始的
时间不同，每个事务对同一张表，同一时刻看到的数据可能是不一样的。 
对于 InnoDB ，聚簇索引记录中包含 3 个隐藏的列： 
ROW ID：隐藏的自增 ID，如果表没有主键，InnoDB 会自动按 ROW ID 产生一
个聚集索引树。 
事务 ID：记录最后一次修改该记录的事务 ID。 
回滚指针：指向这条记录的上一个版本。 
我们拿上面的例子，对应解释下 MVCC 的实现原理，如下图： 
 
如图，首先 insert 语句向表 t1 中插入了一条数据，a 字段为 1，b 字段为 1， ROW 
ID 也为 1 ，事务 ID 假设为 1，回滚指针假设为 null。当执行 update t1 set b=666 
where a=1 时，大致步骤如下： 
数据库会先对满足 a=1 的行加排他锁； 
然后将原记录复制到 undo 表空间中； 
修改 b 字段的值为 666，修改事务 ID 为 2； 
并通过隐藏的回滚指针指向 undo log 中的历史记录； 
事务提交，释放前面对满足 a=1 的行所加的排他锁。 
在前面实验的第 6 步中，session2 查询的结果是 session1 修改之前的记录，这
个记录就是来自 undolog 中。 
因此可以总结出 MVCC 实现的原理大致是： 
InnoDB 每一行数据都有一个隐藏的回滚指针，用于指向该行修改前的最后一个
历史版本，这个历史版本存放在 undo log 中。如果要执行更新操作，会将原记录
放入 undo log 中，并通过隐藏的回滚指针指向 undo log 中的原记录。其它事务此
时需要查询时，就是查询 undo log 中这行数据的最后一个历史版本。 
update 语句，有索引情况，直接对行数据加锁；update user set age=11 where id = 
1 
update 语句，无索引情况，MySQL 会为这张表中所有行加行锁，没错，是所有
行。但是呢，在加上行锁后，MySQL 会进行一遍过滤，发现不满足的行就释放
锁，最终只留下符合条件的行；update user set age=11 where age=10 
 
 
为什么 MySQL 索引结构采用 B+树 
1、B 树和 B+树 
一般来说，数据库的存储引擎都是采用 B 树或者 B+树来实现索引的存储。首
先来看 B 树，如图所示。
 
B 树是一种多路平衡树，用这种存储结构来存储大量数据，它的整个高度会相
比二叉树来说，会矮很多。 
而对于数据库而言，所有的数据都将会保存到磁盘上，而磁盘 I/O 的效率又比
较低，特别是在随机磁盘 I/O 的情况下效率更低。 
所以，高度决定了磁盘 I/O 的次数，磁盘 I/O 次数越少，对于性能的提升就越
大，这也是为什么采用 B 树作为索引存储结构的原因，如图所示。 
而 MySQL 的 InnoDB 存储引擎，它用了一种增强的 B 树结构，也就是 B+树
来作为索引和数据的存储结构。相比较于 B 树结构来说，B+树做了两个方面的
优化，如图所示。 
 
1、B+树的所有数据都存储在叶子节点，非叶子节点只存储索引。 
2、叶子节点中的数据使用双向链表的方式进行关联。 
2、原因分析 
我认为，MySQL 索引结构采用 B+树，有以下 4 个原因： 
1、从磁盘 I/O 效率方面来看：B+树的非叶子节点不存储数据，所以树的每一
层就能够存储更多的索引数量，也就是说，B+树在层高相同的情况下，比 B 树
的存储数据量更多，间接会减少磁盘 I/O 的次数。 
2、从范围查询效率方面来看：B+树的所有存储在叶子节点的数据使用了双向
链表来关联，所以 B+树在查询的时候只需查两个节点进行遍历就行，而 B 树
需要获取所有节点，因此，B+树在范围查询上效率更高。 
3、从全表扫描方面来看：因为，B+树的叶子节点存储所有数据，所以 B+树的
全局扫描能力更强一些，因为它只需要扫描叶子节点。而 B 树需要遍历整个
树。 
4、从自增 ID 方面来看：基于 B+树的这样一种数据结构，如果采用自增的整
型数据作为主键，还能更好的避免增加数据的时候，带来叶子节点分裂导致的
大量运算的问题。 
 
 
 
 
执行 SQL 响应比较慢，你有哪些排查思路？ 
1、排查思路 
如果执行 SQL 响应比较慢，我觉得可能有以下 4 个原因： 
第 1 个原因：没有索引或者导致索引失效； 
第 2 个原因：单表数据量数据过多，导致查询瓶颈； 
第 3 个原因：网络原因或者机器负载过高； 
第 4 个原因：热点数据导致单点负载不均衡。 
接下来，我针对以上几种情况，分别来聊一聊我的解决方案 
第 1 种情况：索引失效或者没有索引的情况 
首先，可以打开 MySQL 的慢查询日志，收集一段时间的慢查询日志内容，然
后找出耗时最长的 SQL 语句，对这些 SQL 语句进行分析。 
比如可以利用执行计划 explain 去查看 SQL 是否有命中索引。如果发现慢查询
的 SQL 没有命中索引，可以尝试去优化这些 SQL 语句，保证 SQL 走索引执
行。如果 SQL 结构没有办法优化的话，可以考虑在表上再添加对应的索引。
我们在优化 SQL 或者是添加索引的时候，都需要符合最左匹配原则。 
第 2 种情况：单表数据量数据过多，导致查询瓶颈的情况。 
即使 SQL 语句走了索引，表现性能也不会特别好。这个时候我们需要考虑对
表进行切分。表切分规则一般分为两种，一种是水平切分，一种是垂直切分。 
水平切分指的是将同一个表中的记录拆分到多个结构相同的表中。 
比如说，把一张数据行数达到千万级别的大表，按照业务主键切分为多张小
表，这些小表可能达到 100 张甚至 1000 张。已经拆分完 1000 表，然后，把后
缀为 0-100 的表放到同一个数据库实例中，然后，100-200 的表放到另一个数据
库实例中，依此类推把 1000 表存放到 10 个数据库实例中。这样的话，我们就
可以根据业务主键把请求路由到不同数据库实例，从而让每一个数据库实例承
担的流量比较小，达到提高数据库性能的目的。 
表的垂直切分：将一张表按列切分成多个表。可以将不常用的字段单独放在同
一个表中；把大字段独立放入一个表中；或者把经常使用的字段（关系密切
的）放在一张表中。垂直切分之后业务更加清晰，系统之间整合或扩展容易，
数据维护简单； 
 
第 3 种情况：网络原因或者机器负载过高的情况，我们可以进行读写分离 
比如 MySQL 支持一主多从的分布式部署，我们可以将主库只用来处理写数据
的操作，而多个从库只用来处理读操作。在流量比较大的场景中，可以增加从
库来提高数据库的负载能力，从而提升数据库的总体性能。 
第 4 种情况：热点数据导致单点负载不均衡的情况 
这种情况下，除了对数据库本身的调整以外，还可以增加缓存。将查询比较频
繁的热点数据预存到缓存当中，比如 Redis、MongoDB、ES 等，以此来缓解
数据的压力，从而提高数据库的响应速度。 
 
 
MySQL 执行查询的过程 
1. 客户端通过 TCP 连接发送连接请求到 MySQL 连接器，连接器会对该请求
进行权限验证及连接资源分配； 
2. 查缓存。（当判断缓存是否命中时，MySQL 不会进行解析查询语句，而是直
接使用 SQL 语句和客户端发送过来的其他原始信息。所以，任何字符上的不同，
例如空格、注解等都会导致缓存的不命中。在 MySQL 8.0 版本已经将查询缓存
删除，也就是说 MySQL 8.0 版本后不存在此功能。） 
3. 分析器，对 SQL 进行词法分析和语法分析。 如何把语句给到预处理器，检查
数据表和数据列是否存在，解析别名看是否存在歧义。此阶段只是做一些 SQL 解
析，语法校验。所以一般语法错误在此阶段。判断查询的 SQL 字段是否存在也
是在这步； 
4. 优化器。是否使用索引，生成执行计划。是在表里有多个索引的时候，决定使
用哪个索引；或者一个语句中存在多表关联的时候（join），决定各个表的连接
顺序。 
5. 执行器，去引擎层取数据，将数据保存到结果集中，同时会逐步将数据缓存到
查询缓存中，最终将结果集返回给客户端。 
 
连接器 
连接器负责跟客户端建立连接、获取权限、维持和管理连接。 
连接命令一般这样写： 
mysql -h$ip -P$port -u$user -p 
连接命令中的 mysql 是客户端工具，用来跟服务端建立连接。在完成经典的 
TCP 握手后，连接器就要开始认证你的身份，这个时候用的就是你输入的用户
名和密码。 
 
如果用户名或密码不对，你就会收到一个"Access denied for user"的错误，然后客
户端程序结束执行。 
 
如果用户名密码认证通过，连接器会到权限表里面查出你拥有的权限。之后，这
个连接里面的权限判断逻辑，都将依赖于此时读到的权限。 
连接完成后，如果没有后续动作，这个连接处于空闲状态，show processlist 可以
看到；Command 显示 sleep 表示现在系统中有个空闲连接； 
客户端长时间没有动静，连接器就会自动断开，这个参数由 wait_timeout 控制器； 
数据库里面，长连接是指连接成功后，如果客户端持续有请求，则一直使用同一
个连接。短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新
建立一个。 
查询缓存 
MySQL 拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语
句。之前执行过的语句及其结果可能会以 key-value 对的形式，被直接缓存在内
存中。key 是查询的语句，value 是查询的结果。如果你的查询能够直接在这个
缓存中找到 key，那么这个 value 就会被直接返回给客户端。 
如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结果会
被存入查询缓存中。 
查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都
会被清空。因此很可能你费劲地把结果存起来，还没使用呢，就被一个更新全清
空了。对于更新压力大的数据库来说，查询缓存的命中率会非常低。除非你的业
务就是有一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张
表上的查询才适合使用查询缓存。 
好在 MySQL 也提供了这种“按需使用”的方式。你可以将参数 query_cache_type 
设置成 DEMAND，这样对于默认的 SQL 语句都不使用查询缓存。 
MySQL 8.0 版本直接将查询缓存的整块功能删掉了，也就是说 8.0 开始彻底没
有这个功能了。 
分析器 
分析器先会做“词法分析”。你输入的是由多个字符串和空格组成的一条 SQL 语
句，MySQL 需要识别出里面的字符串分别是什么，代表什么。 
MySQL 从你输入的"select"这个关键字识别出来，这是一个查询语句。它也要把
字符串“T”识别成“表名 T”，把字符串“ID”识别成“列 ID”。 
做完了这些识别以后，就要做“语法分析”。根据词法分析的结果，语法分析器会
根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。 
如果你的语句不对，就会收到“You have an error in your SQL syntax”的错误提醒。
比如下面这个语句 select 少打了开头的字母“s”。 
mysql> elect * from t where ID=1; 
ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that 
corresponds to your MySQL server version for the right syntax to use near 'elect * from t where 
ID=1' at line 1 
一般语法错误会提示第一个出现错误的位置，所以你要关注的是紧接“use near”
的内容。 
优化器 
经过了分析器，MySQL 就知道你要做什么了。在开始执行之前，还要先经过优
化器的处理。 
优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多
表关联（join）的时候，决定各个表的连接顺序。 
选择索引是优化器的工作。 
优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语
句。在数据库里面，扫描行数是影响执行代价的因素之一。扫描的行数越少，意
味着访问磁盘数据的次数越少，消耗的 CPU 资源越少。 
扫描行数并不是唯一的判断标准，优化器还会结合是否使用临时表、是否排序等
因素进行综合判断。 
CREATE TABLE `t` ( 
  `id` int(11) NOT NULL, 
  `a` int(11) DEFAULT NULL, 
  `b` int(11) DEFAULT NULL, 
  PRIMARY KEY (`id`), 
  KEY `a` (`a`), 
  KEY `b` (`b`) 
) ENGINE=InnoDB； 
 
select * from t where a between 10000 and 20000; 
对于上面的 select 语句，优化器的选择逻辑是： 
如果使用索引 a，每次从索引 a 上拿到一个值，都要回到主键索引上查出整行数
据，这个代价优化器也要算进去的。而如果选择扫描 10 万行，是直接在主键索
引上扫描的，没有额外的代价。 
优化器会估算这两个选择的代价，从结果看来，优化器认为直接扫描主键索引更
快。当然，从执行时间看来，这个选择并不是最优的。 
执行器 
MySQL 通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进
入了执行器阶段，开始执行语句。 
开始执行的时候，要先判断一下你对这个表 T 有没有执行查询的权限，如果没
有，就会返回没有权限的错误，如下所示 (在工程实现上，如果命中查询缓存，
会在查询缓存返回结果的时候，做权限验证。查询也会在优化器之前调用 
precheck 验证权限)。 
mysql> select * from T where ID=10; 
ERROR 1142 (42000): SELECT command denied to user 'b'@'localhost' for table 'T' 
如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，
去使用这个引擎提供的接口。 
比如我们这个例子中的表 T 中，ID 字段没有索引，那么执行器的执行流程是这
样的： 
1. 调用 InnoDB 引擎接口取这个表的第一行，判断 ID 值是不是 10，如果不是则
跳过，如果是则将这行存在结果集中； 
2. 调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。 
3. 执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客
户端。 
至此，这个语句就执行完成了。 
对于有索引的表，执行的逻辑也差不多。第一次调用的是“取满足条件的第一行”
这个接口，之后循环取“满足条件的下一行”这个接口，这些接口都是引擎中已经
定义好的。 
你会在数据库的慢查询日志中看到一个 rows_examined 的字段，表示这个语句执
行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累
加的。 
在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数
跟 rows_examined 并不是完全相同的。 
 
 
 
索引 
索引指系统根据某种算法，将已有的数据（未来可能新增的数据），单独建立一
个文件，这个文件能够实现快速匹配数据，并且能够快速的找到对应的记录 
官方介绍是帮助 Mysql 高效获取数据的数据结构；一般来说，索引本身也很大，不可能
全部存储在内存中，索引往往存储在磁盘中的文件中(可能在单独的文件中，也可能是
和数据一起存储在数据文件中。) 
使用索引的优点 
1. 大大加快了数据的检索速度； 
2. 可以显著减少查询中分组和排序的时间； 
3. 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性； 
4. 将随机 I/O 变为顺序 I/O（B+Tree 索引是有序的，会将相邻的数据都存储在
一起） 
缺点：建立和维护索引耗费时间空间，更新索引很慢。 
创建索引时需要注意什么？ 
1. 只应建立在小字段上，而不要对大文本或图片建立索引（一页存储的数据越多一
次 IO 操作获取的数据越大效率越高） 
2. 建立索引的字段应该非空，在 MySQL 中，含有空值的列很难进行查询优化，因
为它们使得索引、索引的统计信息以及比较运算更加复杂。应该用 0、一个特殊
的值或者一个空串代替 NULL； 
3. 选择数据密度大（唯一值占总数的百分比很大）的字段作索引； 
4. 当使用索引列进行查询的时候，尽量不要使用表达式，把计算放到业务层而不是
数据库层; 
5. 尽量使用主键查询，而不是其它索引，因为主键查询不会触发回表操作； 
6. 使用索引扫描来进行排序； 
7. union、all、in、or 都能使用索引，但是推荐使用 in； 
8. 范围列可以使用到索引； 
9. 能使用 limit 的时候，尽量使用 limit； 
10. 单表索引建议控制在 5 个以内 
11. 单索引字段不允许超过 5 个（组合索引） 
索引的分类 
 
普通索引 
 
唯一索引 UNIQUE：索引列的值必须唯一，但允许有 null 且 null 可以出现多次； 
 
建表时，加上 unique(列名) 指定 
 
单独创建， create unique index idx_表名_列名 on 表名(列名) 
 
单独创建， alter table 表名 add unique 索引名(列名) 
 
主键索引 PRIMARY KEY：数据库表中对储存数据对象予以唯一和完整标识的
数据列或属性的组合。一个数据列只能有一个主键，必须唯一，不允许空值（是
一种特殊的唯一索引；MySQL 创建主键时默认为聚集索引，但主键也可以是非
聚集索引）； 
 
建表时，加上 primary key(列名) 指定 
 
单列索引和多列索引/复合索引（Composite）：索引的列数； 
单列索引----即一个索引只包含单个列，一个表可以有多个单列索引； 
建表时，加上 key(列名) 指定 
单独创建， create index 索引名 on 表名(列名) 
单独创建， alter table 表名 add index 索引名(列名) 
复合索引----即一个索引包含多个列  
建表时，加上 key(列名列表) 指定 单独创建， create index 索引名 on 表名(列名列表) 
单独创建， alter table 表名 add index 索引名(列名列表) 
 
覆盖（Covering）索引：索引包含了所有满足查询所需要的数据，查询的时候只
需要读取索引而不需要回表读取数据； 
 
聚集（Clustered）索引/非聚集索引：对磁盘上存放数据的物理地址重新组织以使
这些数据按照指定规则排序的一种索引（数据的物理排列顺序和索引排列顺序一
致）。因此每张表只能创建一个聚集索引（因为要改变物理存储顺序）。优点是
查询速度快，因为可以直接按照顺序得到需要数据的物理地址。缺点是进行修改
的速度较慢。对于需要经常搜索范围的值很有效。非聚集索引只记录逻辑顺序，
并不改变物理顺序； 
 
分区索引（？） 
 
虚拟索引（Virtual）：模拟索引的存在而不用真正创建一个索引，用于快速测试
创建索引对执行计划的影响。没有相关的索引段，不增加存储空间的使用 
 
 
为什么使用 MySQL 的最左匹配原则 
最左匹配原则：最左优先，以最左边的为起点任何连续的索引都能匹配上。同时
遇到范围查询(>、<、between、like)就会停止匹配。 
比如 a，b 建立索引时候，是先以 a 建立的索引，此时 b 是无序的，在以 a 建立
之后的 a 的子树上再建立 b 的索引，所以对于整颗 b+树来说，a 是一定有序的，
b 是不一定有序的 
当 b+树的数据项是复合的数据结构，比如(name,age,sex)的时候，b+数是按照从
左到右的顺序来建立搜索树的，比如当(张三,20,F)这样的数据来检索的时候，b+
树会优先比较 name 来确定下一步的所搜方向，如果 name 相同再依次比较 age
和 sex，最后得到检索的数据；但当(20,F)这样的没有 name 的数据来的时候，b+
树就不知道下一步该查哪个节点，因为建立搜索树的时候 name 就是第一个比较
因子，必须要先根据 name 来搜索才能知道下一步去哪里查询。比如当(张三,F)这
样的数据来检索时，b+树可以用 name 来指定搜索方向，但下一个字段 age 的缺
失，所以只能把名字等于张三的数据都找到，然后再匹配性别是 F 的数据了， 这
个是非常重要的性质，即索引的最左匹配特性。 
 
聚簇索引和非聚簇索引 
1、聚簇索引 
所谓聚簇索引，就是指主索引文件和数据文件为同一份文件，聚簇索引主要用在
Innodb 存储引擎中。在该索引实现方式中 B+Tree 的叶子节点上的 data 就是数据
本身，key 为主键，如果是一般索引的话，data 便会指向对应的主索引。 
在 InnoDB 中，只有主键索引是聚簇索引，如果没有主键，则挑选一个唯一键建
立聚簇索引。如果没有唯一键，则隐式的生成一个键来建立聚簇索引。 
聚簇索引的优点 
 
数据访问更快，因为聚簇索引将索引和数据保存在一个 B+树中，因此从聚簇索
引中获取数据比非聚簇索引更快 
 
聚簇索引对主键的排序和范围查找速度非常快 
聚簇索引的缺点 
 
插入速度严重依赖于排序，按照主键的顺序插入是最快的方式，否者会出现页分
裂，严重影响性能。因此，对于 InnoDB 表，我们一般都会定义一个自增的 ID 列
作为主键 
 
更新主键的代价很高，因为将会导致被更新的行移动，因此，对于 InnoDB 表，
我们一般定义主键不可更新 
 
二级索引访问需要两次索引查找，第一次找到主键值，第二次 根据主键值查找
行数据，一般我们需要尽量避免出现索引的二次查找，这个时候，用到的就是索
引的覆盖 
2、非聚簇索引 
非聚簇索引就是指 B+Tree 的叶子节点上的 data，并不是数据本身，而是数据存
放的地址。主索引和辅助索引没啥区别，只是主索引中的 key 一定得是唯一的。
主要用在 MyISAM 存储引擎中。 
非聚簇索引也被称为辅助索引，辅助索引在我们访问数据的时候总是需要两次查
找。辅助索引叶子节点存储的不再是行的物理位置，而是主键值。通过辅助索引
首先找到主键值，然后在通过主键值找到数据行的数据页，在通过数据页中的
Page Directory 找到数据行。 
InnoDB 辅助索引的叶子节点并不包含行记录的全部数据，叶子节点除了包含键
值外，还包含了行数据的聚簇索引键。辅助索引的存在不影响数据在聚簇索引中
的组织，所以一张表可以有多个辅助索引。在 InnoDB 中有时也称为辅助索引为
二级索引  
 
mysql 什么情况下不会使用索引 
1、如果 MySQL 估计使用索引比全表扫描更慢，则不适用索引， 
ex：列 key_part1 均匀的分布在 1-100 之间。下面的 sql 则不会使用索引 
select * from table_name where key_part1 > 1 and key_part1 <90 
2、如果使用 memory/heap 表，并且 where 语句中不适用“=”进行索引，则不会使
用索引。heap 表只有在“=”的条件下，才使用索引。 
3、用 or 分割开的条件，如果 or 左右两个条件中有一个列没有索引，则不会使用
索引。 
ex：select * from table_name where key1='a' or key2='b'； 
如果在 key1 上有索引而在 key2 上没有索引，则该查询也不会走索引 
4、复合索引，如果索引列不是复合索引的第一部分，则不使用索引（即不符合
最左匹配原则/最左前缀原则，最左优先，eg：多列索引 col1、col2 和 col3，则索
引生效的情形包括 col1 或 col1，col2 或 col1，col2，col3） 
ex：复合索引为(key1,key2) ，以下 sql 将不会使用索引 
select * from table_name where key2='b'； 
5、如果 like 是以‘%’开始的，则该列上的索引不会被使用。 
ex：select * from table_name where key1 like '%a'； 
6、如果列为字符串，则 where 条件中必须将字符常量值加引号，否则即使该列
上存在索引，也不会被使用。 
ex：select * from table_name where key1=1; 
如果 key1 列保存的是字符串，即使 key1 上有索引，也不会被使用。 
7、数据类型出现隐式转化（如varchar不加单引号的话可能会自动转换为int型）； 
8、使用不等于查询; 
9、列参与了数学运算或者函数; 
10、当使用联合索引,前面一个条件为范围查询,后面的即使符合最左前缀原则,也
无法使用索引. 
从上面可以看出，即使我们建立了索引，也不一定会被使用，那么我们如何知道
我 们 索 引 的 使 用 情 况 呢 ？ ？ 在 MySQL 中 ， 有 Handler_read_key 和
Handler_read_rnd_key
两 个 变 量 ， 如 果
Handler_read_key
值 很 高 而
Handler_read_rnd_key 的值很低，则表明索引经常不被使用，应该重新考虑建立
索引。可以通过:show status like 'Handler_read%'来查看着连个参数的值. 
 
 
 
索引下推 
以市民表的联合索引（name, age）为例。如果现在有一个需求：检索出表中“名
字第一个字是张，而且年龄是 10 岁的所有男孩”。那么，SQL 语句是这么写的： 
mysql> select * from tuser where name like '张 %' and age=10 and ismale=1; 
这个语句在搜索索引树的时候，只能用 “张”，找到第一个满足条件的记录 ID3。
当然，这还不错，总比全表扫描要好。 
然后呢？ 
当然是判断其他条件是否满足。 
在 MySQL 5.6 之前，只能从 ID3 开始一个个回表。到主键索引上找出数据行，
再对比字段值。 
而 MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍
历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少
回表次数。 
图 3 和图 4，是这两个过程的执行流程图。 
 
 
在图 3 和 4 这两个图里面，每一个虚线箭头表示回表一次。 
图 3 中，在 (name,age) 索引里面我特意去掉了 age 的值，这个过程 InnoDB 并
不会去看 age 的值，只是按顺序把“name 第一个字是’张’”的记录一条条取出来
回表。因此，需要回表 4 次。 
图 4 跟图 3 的区别是，InnoDB 在 (name,age) 索引内部就判断了 age 是否等
于 10，对于不等于 10 的记录，直接判断并跳过。在我们的这个例子中，只需
要对 ID4、ID5 这两条记录回表取数据判断，就只需要回表 2 次。 
 
 
事务特性 
一般来说，事务是必须满足 4 个条件（ACID）：原子性（Atomicity，或称不可
分割性）、一致性（Consistency）、隔离性（Isolation，又称独立性）、持久性
（Durability）。 
原子性（Atomicity）：一个事务（transaction）中的所有操作，要么全部完成，要
么全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回
滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。 
一致性（Consistency）：在事务开始之前和事务结束以后，数据库的完整性没有
被破坏。这表示写入的资料必须完全符合所有的预设规则，这包含资料的精确度、
串联性以及后续数据库可以自发性地完成预定的工作。事务执行的结果必须是使
数据库从一个一致性状态变到另一个一致性状态。因此当数据库只包含成功事务
提交的结果时，就说数据库处于一致性状态。如果数据库系统运行中发生故障，
有些事务尚未完成就被迫中断，这些未完成事务对数据库所做的修改有一部分已
写入物理数据库，这时数据库就处于一种不正确的状态，或者说是不一致的状态。 
隔离性（Isolation）：数据库允许多个并发事务同时对其数据进行读写和修改的
能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。
事务隔离分为不同级别，包括读未提交（Read uncommitted）、读提交（read 
committed）、可重复读（repeatable read）和串行化（Serializable）。 
持久性（Durability）：事务处理结束后，对数据的修改就是永久的，即便系统故
障也不会丢失。 
事务控制语句： 
BEGIN 或 START TRANSACTION；显式地开启一个事务； 
COMMIT；也可以使用 COMMIT WORK，不过二者是等价的。COMMIT 会提交
事务，并使已对数据库进行的所有修改成为永久性的； 
ROLLBACK；有可以使用 ROLLBACK WORK，不过二者是等价的。回滚会结
束用户的事务，并撤销正在进行的所有未提交的修改； 
SAVEPOINT identifier；SAVEPOINT 允许在事务中创建一个保存点，一个事务
中可以有多个 SAVEPOINT； 
RELEASE SAVEPOINT identifier；删除一个事务的保存点，当没有指定的保存点
时，执行该语句会抛出一个异常； 
ROLLBACK TO identifier；把事务回滚到标记点； 
SET TRANSACTION；用来设置事务的隔离级别。InnoDB 存储引擎提供事务的
隔离级别有 READ UNCOMMITTED、READ COMMITTED、REPEATABLE 
READ 和 SERIALIZABLE。 
事务操作，分为两种：自动事务（默认的），手动事务。 
MYSQL 事务处理主要有两种方法： 
1、用 BEGIN, ROLLBACK, COMMIT 来实现 
 
BEGIN 开始一个事务 
 
ROLLBACK 事务回滚 
 
COMMIT 事务确认 
2、直接用 SET 来改变 MySQL 的自动提交模式: 
 
SET AUTOCOMMIT=0 禁止自动提交 
 
SET AUTOCOMMIT=1 开启自动提交 
接下来，我们简单分析一下 MySQL 的操作过程： 
Step 1：客户端与服务端建立连接，同时开启一个临时的事务日志，此事务日志
只作用于当前用户的当次连接； 
Step 2：在客户端用 SQL 语句执行写操作，客户端收到 SQL 语句，执行，将
结果直接写入到数据表，并将数据表同步到数据库； 
Step 3：我们在客户端开启事务，则服务端原来的操作机制被改变，后续所有操
作都会被先写入到临时日志文件； 
Step 4：在客户端执行 SQL 语句（例如写操作），服务端收到 SQL 语句，执行，
将结果写入到临时日志文件，并不将结果同步到数据库； 
Step 5：在客户端执行查询操作，服务端直接从临时日志文件中捞取数据，返回
给客户端； 
Step 6：在客户端执行 commit 或者 rollback 命令，清空临时日志文件，如果是
commit 命令，则将结果同步到数据库；如果是 rollback 命令，则不同步。 
MySQL 使用的默认存储引擎是 InnoDB，而 InnoDB 默认使用的锁机制是行
锁（锁住操作的当前行），但是如果在事务操作的过程中，我们没有使用索引字
段，那么系统就会自动进行全表检索，也就是其自动将行锁升级为表锁（锁住操
作的当前表）。 
 
数据库主键使用自增主键还是 UUID 
自增主键 
a. 字段长度较 uuid 小很多，可以是 bigint 甚至是 int 类型，占用空间小，易排序，
在程序中传递也方便； 
b. 每次插入新的记录，记录就会索引到当前索引节点的位置，直接添加，要是一
业务写满，就自动开辟一个新的页，提高写入的速度；innodb 中的主键是聚簇索
引，会把相邻主键的数据安放在相邻的物理存储上。它只需要一页一页地写，索
引结构相对紧凑 0 磁盘碎片少，效率也高。如果主键不是自增，而是随机的，那
么频繁的插入会使 innodb 频繁地移动磁盘块，而影响写入性能。 
c. 如果通过非系统增加记录时，可以不用指定该字段，不用担心主键重复问题； 
缺点： 
a．如果存在大量的数据，可能会超出自增长的取值范围； 
b. 分库分表不友好； 
对于一些敏感数据，比如用户 id，订单 id，如果使用自增主键的话，外部通过抓
包，很容易知道新进用户量，成单量这些信息，所以需要谨慎使用； 
 
UUID 
a. 地球唯一的 uuid，绝对不会冲突。数据拆分、合并存储的时候，能达到全局的
唯一性； 
b. 可以在应用层生成，提高数据库吞吐能力； 
c. 是 string 类型，写代码的时候方便很多； 
缺点： 
a. innodb 中的主键是聚簇索引，会把相邻主键的数据安放在相邻的物理存储上。
如果主键不是自增，而是随机的，到来的 ID 与原来的大小不确定，会造成非常
多的数据插入，那么频繁的插入会使 innodb 频繁地移动磁盘块，然后导致产生
很多的内存碎片，而影响写入性能。 
b. uuid 占空间大， 如果你建的索引越多， 影响越严重； 
c. 读取出来的数据也是没有规律的，通常需要 order by，其实也很消耗数据库资
源； 
分布式情况下，首选 uuid； 
 
SnowFlake 
是一种介于自增长和 UUID 之间的一种主键（存储空间小、速度快、分布式、时
间序列）它有如下优点 
1.所有生成的 id 按时间趋势递增； 
2.整个分布式系统内不会产生 ID 碰撞（重复 id，因为有 datacenterId 和 workerId
来做区分）； 
3.id 生成的效率高； 
 
 
使用 B 树和 B+树的比较 
InnoDB 的索引使用的是 B+树实现，B+树对比 B 树的好处： 
1. 磁盘 IO 次数少：B+树的非叶子节点只有其子树（根节点）中的最大（或最小）
关键字和指向下一个节点的索引，数据都存在叶子结点中，所以同样大小的磁盘
页可以容纳更多的节点元素，如此一来，相同数量的数据下，B+树就相对来说索
引树更加矮胖，一次性读入内存中的需要查找的关键字也就越多； 
2. 范围查询效率更高：B+树所有叶子节点形成有序(自小而大)链表，便于范围查
询。B 树需要中序遍历整个树，B+树只需要遍历叶结点中的链表； 
3. 查询效率更加稳定：B+树每次查询都需要从根结点到叶结点，路径长度相同，
所以每次查询的效率都差不多，而 B 树每次查询则不一样，越靠近根节点的记录
查找时间越快，只要找到关键字即可确定记录的存在，最好的情况是根节点，最
坏的情况是叶子节点，没有 B+树稳定 
 
磁盘 IO 
系统从磁盘读取数据到内存时是以磁盘块（block）为单位的，位于同一磁盘块中
的数据会被一次性读取出来，而不是需要什么取什么。InnoDB 存储引擎中有页
(Page)的概念，页是其磁盘管理的最小单位。InnoDB 每次申请磁盘空间时都会是
若干地址连续磁盘块来达到页的大小，InnoDB 在把磁盘数据读入到磁盘时会以
页为基本单位，在查询数据时如果一个页中每条数据都有助于定位数据记录的位
置，这将会减少磁盘 I/O 次数，提高效率。 
一句话说：就是多个块填充到一页大小 
 
B 树 
 
B+树 
 
 
使用哈希索引、有序数组、二叉搜索树、平衡二叉
树、红黑树、B+树索引的比较 
哈希表 
哈希表是一种以键-值（key-value）存储数据的结构，我们只要输入待查找的值即
key，就可以找到其对应的值即 Value。哈希的思路很简单，把值放在数组里，用
一个哈希函数把 key 换算成一个确定的位置，然后把 value 放在数组的这个位置。 
不可避免地，多个 key 值经过哈希函数的换算，会出现同一个值的情况。处理这
种情况的一种方法是，拉出一个链表。 
数据存放不是有序的，增加元素速度很快，所以哈希索引做区间查询的速度是很
慢的。哈希表这种结构适用于只有等值查询的场景，比如 Memcached 及其他一
些 NoSQL 引擎。哈希索引能以 O(1) 时间进行查找，但是只支持精确查找，但
是无法用于部分查找和范围查找，无法用于排序与分组； 
查询、插入、修改、删除的平均时间复杂度都是 O(1)； 
 
1、哈希表是把索引字段映射成对应的哈希码然后再存放在对应的位置，这样的
话，如果我们要进行模糊查找的话，显然哈希表这种结构是不支持的，只能遍历
这个表。而 B+树则可以通过最左前缀原则快速找 到对应的数据。  
2、如果我们要进行范围查找，例如查找 ID 为 100 ~ 400 的人，哈希表同样不支
持，只能遍历全表。  
3、索引字段通过哈希映射成哈希码，如果很多字段都刚好映射到相同值的哈希
码的话，那么形成的索引结构将会是一条很长的链表，这样的话，查找的时间就
会大大增加。 
 
有序数组 
有序数组在等值查询和范围查询场景中的性能就都非常优秀。查询某个元素，用
二分法就可以快速得到，这个时间复杂度是 O(log(N))。同时很显然，这个索引
结构支持范围查询。如果仅仅看查询效率，有序数组就是最好的数据结构了。但
是，在需要更新数据的时候就麻烦了，你往中间插入一个记录就必须得挪动后面
所有的记录，成本太高。所以，有序数组索引只适用于静态存储引擎，比如你要
保存的是 2017 年某个城市的所有人口信息，这类不会再修改的数据。 
 
 
二叉搜索树 
二叉搜索树示意图如下所示： 
 
二叉搜索树的特点是：每个节点的左儿子小于父节点，父节点又小于右儿子。 
查询、插入、修改、删除的平均时间复杂度都是 O(log2 (n)) 
如果 ID 是持续递增的话，二叉搜索树又会退化到 O(n) 的时间复杂度。 
 
 
平衡二叉树(AVL) 
可以是空树。假如不是空树，任何一个结点的左子树与右子树都是平衡二叉树，
并且高度之差的绝对值不超过 1。 
结构图 
 
可以看出平衡二叉树的缺点就是维护平衡过程的成本代价很高，因为每次删除一
个节点或者增加一个节点的话，需要一次或多次的左旋和右旋去维护平衡状态 
查询的效率不稳定，还要看运气的成分在里面； 
如果节点很多的话，那么这个 AVL 树的高度还是会很高的，查询效率会很低。 
从算法的数学逻辑来讲，二叉树的查找速度和比较次数都是最小的，那为什么我
们选择 BTree?因为 AVL 还有一个问题，那就是磁盘 IO 的问题 
磁盘 IO 的次数，就是由树高来决定的，也即磁盘的 IO 次数最坏的情况下就等于
树的高度。 
因为节点存储的数据太少，没有很好的利用操作系统和磁盘数据交换的特性，也
没有利用好磁盘 IO 的预读能力。因为操作系统和磁盘之间一次数据交换是以页
为单位的，一页=4K，即每次 IO 操作系统会将 4K 数据加载镜像内存。但是在二
叉树每个节点的结构只保存一个关键字和数据区，两个子节点的引用，并不能填
满 4K 的内容，辛辛苦苦的做了一次 IO 操作，却只加载了一个关键字，在树的
高度很高，恰好要搜索的关键字位于叶子节点或支节点的时候，取一个关键字要
做很多次的 IO。因此平衡二叉树不太适合 MySQL 的查询结构。 
解决方法 
我们需要解决的就是树的高度问题，导致磁盘 IO 过多 
那么就需要将树进行压缩，也就是将原来的瘦高->矮胖，通过降低树的高度达到
减少 IO 的次数 
 
 
树可以有二叉，也可以有多叉。多叉树就是每个节点有多个儿子，儿子之间的大
小保证从左到右递增。二叉树是搜索效率最高的，但是实际上大多数的数据库存
储却并不使用二叉树。其原因是，索引不止存在内存中，还要写到磁盘上。 
你可以想象一下一棵 100 万节点的平衡二叉树，树高 20。一次查询可能需要访
问 20 个数据块。在机械硬盘时代，从磁盘随机读一个数据块需要 10 ms 左右
的寻址时间。也就是说，对于一个 100 万行的表，如果使用二叉树来存储，单
独访问一个行可能需要 20 个 10 ms 的时间，这个查询可真够慢的。 
为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么，
我们就不应该使用二叉树，而是要使用“N 叉”树。这里，“N 叉”树中的“N”取决
于数据块的大小。 
以 InnoDB 的一个整数字段索引为例，这个 N 差不多是 1200。这棵树高是 4 
的时候，就可以存 1200 的 3 次方个值，这已经 17 亿了。考虑到树根的数据
块总是在内存中的，一个 10 亿行的表上一个整数字段的索引，查找一个值最多
只需要访问 3 次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁
盘的平均次数就更少了。 
N 叉树由于在读写上的性能优点，以及适配磁盘的访问模式，已经被广泛应用在
数据库引擎中了。 
 
红黑树 
 
 
 
 
B+树 
在 InnoDB 中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表
称为索引组织表。 
每一个索引在 InnoDB 里面对应一棵 B+树。 
假设，我们有一个主键列为 ID 的表，表中有字段 k，并且在 k 上有索引。 
这个表的建表语句是： 
mysql> create table T( 
id int primary key,  
k int not null,  
name varchar(16), 
index (k))engine=InnoDB; 
表中 R1~R5 的 (ID,k) 值分别为 (100,1)、(200,2)、(300,3)、(500,5) 和 (600,6)，
两棵树的示例示意图如下。 
 
从图中不难看出，根据叶子节点的内容，索引类型分为主键索引和非主键索引。 
主键索引的叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索
引（clustered index）。 
非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二
级索引（secondary index）。 
 
数据库为什么要用 B+树结构 
为什么使用 B+树？言简意赅，就是因为： 
（1）索引文件很大，不可能全部存储在内存中，故要存储到磁盘上 
（2）索引的结构组织要尽量减少查找过程中磁盘 I/O 的存取次数（为什么使用
B-/+Tree，还跟磁盘存取原理有关。） 
（3）局部性原理与磁盘预读，预读的长度一般为页（page）的整倍数，（在许多
操作系统中，页得大小通常为 4k）。 
（4）数据库系统巧妙利用了磁盘预读原理，将一个节点的大小设为等于一个页，
这样每个节点只需要一次 I/O 就可以完全载入，(由于节点中有两个数组，所以地
址连续)。而红黑树这种结构，h 明显要深的多。由于逻辑上很近的节点（父子）
物理上可能很远，无法利用局部性。 
一般来说，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文
件的形式存储的磁盘上。这样的话，索引查找过程中就要产生磁盘 I/O 消耗，相
对于内存存取，I/O 存取的消耗要高几个数量级，所以评价一个数据结构作为索
引的优劣最重要的指标就是在查找过程中磁盘 I/O 操作次数的渐进复杂度。换句
话说，索引的结构组织要尽量减少查找过程中磁盘 I/O 的存取次数。 
对于 B-Tree 而言，可知检索一次最多需要访问 h 个节点。数据库系统的设计者
巧妙利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只
需要一次 I/O 就可以完全载入。B 树的每个节点可以存储多个关键字，它将节点
大小设置为磁盘页的大小，充分利用了磁盘预读的功能。每次读取磁盘页时就会
读取一整个节点。也正因每个节点存储着非常多个关键字，树的深度就会非常的
小。进而要执行的磁盘读取操作次数就会非常少，更多的是在内存中对读取进来
的数据进行查找。 
 
为什么红黑树不适合做索引？ 
红黑树这种结构，h 明显要深的多。由于逻辑上很近的节点（父子）物理上可能
很远，无法利用局部性，所以红黑树的 I/O 渐进复杂度也为 O(h)，效率明显比 B-
Tree 差很多。也就是说，使用红黑树（平衡二叉树）结构的话，每次磁盘预读中
的很多数据是用不上的数据。因此，它没能利用好磁盘预读的提供的数据。然后
又由于深度大（较 B 树而言），所以进行的磁盘 IO 操作更多。 
B 树的查询，主要发生在内存中，而平衡二叉树的查询，则是发生在磁盘读取中。
因此，虽然 B 树查询查询的次数不比平衡二叉树的次数少，但是相比起磁盘 IO
速度，内存中比较的耗时就可以忽略不计了。因此，B 树更适合作为索引。 
比 B 树更适合作为索引的结构——B+树 
比 B 树更适合作为索引的结构是 B+树。MySQL 中也是使用 B+树作为索引。它
是 B 树的变种，因此是基于 B 树来改进的。为什么 B+树会比 B 树更加优秀呢？ 
B 树：有序数组+平衡多叉树； B+树：有序数组链表+平衡多叉树； 
从 B-Tree 结构图中可以看到每个节点中不仅包含数据的 key 值，还有 data 值。
而每一个页的存储空间是有限的，如果 data 数据较大时将会导致每个节点（即一
个页）能存储的 key 的数量很小，当存储的数据量很大时同样会导致 B-Tree 的
深度较大，增大查询时的磁盘 I/O 次数，进而影响查询效率。在 B+Tree 中，所
有数据记录节点都是按照键值大小顺序存放在同一层的叶子节点上，而非叶子节
点上只存储 key 值信息，这样可以大大加大每个节点存储的 key 值数量，降低
B+Tree 的高度。 
B+树的关键字全部存放在叶子节点中，非叶子节点用来做索引，而叶子节点中有
一个指针指向一下个叶子节点。做这个优化的目的是为了提高区间访问的性能。
而正是这个特性决定了 B+树更适合用来存储外部数据。 
数据库索引采用 B+树的主要原因是 B 树在提高了磁盘 IO 性能的同时并没有解
决元素遍历的效率低下的问题。正是为了解决这个问题，B+树应运而生。B+树
只要遍历叶子节点就可以实现整棵树的遍历。而且在数据库中基于范围的查询是
非常频繁的，而 B 树不支持这样的操作（或者说效率太低）。 
回表 
建立几个索引，就会生成几棵 B+Tree，但是带有原始数据行的 B+Tree 只有一棵，
另外一棵树上的叶子节点带的是主键值。 
当我们创建了两个索引时，一个是主键，一个是 name，它还会在生成一棵 B+Tree，
这棵树的叶子节点存放的是主键，当我们通过 name 进行查找的时候，会得到一
个主键，然后在通过主键再去上面的这个主键 B+Tree 中进行查找，我们称这个
操作为 ==回表== 
回表就是通过普通列的索引进行检索，然后再去主键列进行检索，这个操作就是
回表。 
尽量避免回表，因为这会造成两次 B+Tree 的查询，假设一次 B+Tree 查询需要三
次 IO 操作，那么查询两次 B+Tree 就需要六次 IO 操作。 
索引覆盖 
select name from tb where name = zhou 
上面的语句就是要输出的列中，就是我们的主键，当我们通过name建立的B+Tree
进行查询的时候， 
我们可以直接找到我们的数据，并得到主键，但是因为我们要返回的就是 name，
此时说明数据存在了，那么就直接把当前的 name 进行返回，而不需要通过主键
再去主键 B+Tree 中进行查询。 
这样一个不需要进行回表操作的过程，我们称为索引覆盖 
explain select id from staffs where id = 1 # 输出末尾子段 Extra 值是 Using index 表示使用
索引覆盖 
explain select * from staffs where id = 1 # extra 字段是 NULL，说明没有使用覆盖索引 
由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是
一个常用的性能优化手段。 
 
不符合范式会出现哪些异常 
冗余数据：某些同样的数据多次出现（如学生姓名）； 
修改异常：修改了一个记录中的信息，另一个记录中相同的信息却没有修改； 
删除异常：删除一个信息，那么也会丢失其它信息（删除一个课程，丢失了一个
学生的信息）； 
插入异常：无法插入（插入一个还没有课程信息的学生） 
 
 
事务 
事务，即一系列将要发生或正在发生的连续操作。以 BEGIN TRANSACTION 开
始，以 ROLLBACK/COMMIT 结束 多条 sql 语句，要么全部成功，要么全部失
败。一个数据库事务通常包含对数据库进行读或写的一个操作序列。它的存在包
含有以下两个目的： 
1、为数据库操作提供了一个从失败中恢复到正常状态的方法，同时提供了数据
库即使在异常状态下仍能保持一致性的方法。  
2、当多个应用程序在并发访问数据库时，可以在这些应用程序之间提供一个隔
离方法，以防止彼此的操作互相干扰。 
 
 
事务的启动方式 
1. 显式启动事务语句， begin 或 start transaction。配套的提交语句是 commit，
回滚语句是 rollback。 
2. set autocommit=0，这个命令会将这个线程的自动提交关掉。意味着如果你只执
行一个 select 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存
在直到你主动执行 commit 或 rollback 语句，或者断开连接。 
建议使用方法一，如果考虑多一次交互问题，可以使用 commit work and chain 语
法。在 autocommit=1 的情况下用 begin 显式启动事务，如果执行 commit 则提交
事务。如果执行 commit work and chain 则提交事务并自动启动下一个事务。 
begin/start transaction 命令并不是一个事务的起点，在执行到它们之后的第一个
操作 InnoDB 表的语句，事务才真正启动。如果你想要马上启动一个事务，可以
使用 start transaction with consistent snapshot 这个命令。 
第一种启动方式，一致性视图是在第执行第一个快照读语句时创建的； 第二种
启动方式，一致性视图是在执行 start transaction with consistent snapshot 时创建
的。 
在可重复读隔离级别下，事务在启动的时候就“拍了个快照”。注意，这个快照是
基于整库的。 
InnoDB 里面每个事务有一个唯一的事务 ID，叫作 transaction id。它是在事务开
始的时候向 InnoDB 的事务系统申请的，是按申请顺序严格递增的。 
而每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的
数据版本，并且把 transaction id 赋值给这个数据版本的事务 ID，记为 row trx_id。
同时，旧的数据版本要保留，并且在新的数据版本中，能够有信息可以直接拿到
它。 
也就是说，数据表中的一行记录，其实可能有多个版本 (row)，每个版本有自己
的 row trx_id。 
 
事务的实现原理 
事务是基于重做日志文件(redo log)和回滚日志(undo log)实现的。 
每提交一个事务必须先将该事务的所有日志写入到重做日志文件进行持久化，数
据库就可以通过重做日志来保证事务的原子性和持久性。 
每当有修改事务时，还会产生 undo log，如果需要回滚，则根据 undo log 的反向
语句进行逻辑操作，比如 insert 一条记录就 delete 一条记录。undo log 主要实现
数据库的一致性。 
 
MySQL 事务日志介绍下 
innodb 事务日志包括 redo log 和 undo log。 
undo log 指事务开始之前，在操作任何数据之前，首先将需操作的数据备份到一
个地方。redo log 指事务中操作的任何数据，将最新的数据备份到一个地方。 
事务日志的目的：实例或者介质失败，事务日志文件就能派上用场。 
redo log 
redo log 不是随着事务的提交才写入的，而是在事务的执行过程中，便开始写入 
redo 中。具体的落盘策略可以进行配置 。防止在发生故障的时间点，尚有脏页
未写入磁盘，在重启 MySQL 服务的时候，根据 redo log 进行重做，从而达到
事务的未入磁盘数据进行持久化这一特性。RedoLog 是为了实现事务的持久性
而出现的产物。 
 
MySQL 里经常说到的 WAL 技术，WAL 的全称是 Write-Ahead Logging，它的
关键点就是先写日志，再写磁盘；具体来说，当有一条记录需要更新的时候，
InnoDB 引擎就会先把记录写到 redo log 里面，并更新内存，这个时候更新就算
完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，
而这个更新往往是在系统比较空闲的时候做。 
InnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件
的大小是 1GB，那么这块 redo log 总共就可以记录 4GB 的操作。从头开始写，
写到末尾就又回到开头循环写，如下面这个图所示。 
 
write pos 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 
0 号文件开头。checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦
除记录前要把记录更新到数据文件。 
write pos 和 checkpoint 之间的是“粉板”上还空着的部分，可以用来记录新的操
作。如果 write pos 追上 checkpoint，表示“粉板”满了，这时候不能再执行新的
更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。 
有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录
都不会丢失，这个能力称为 crash-safe。 
redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 
主要节省的则是随机读磁盘的 IO 消耗。 
当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内
存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。 
undo log 
undo log 用来回滚行记录到某个版本。事务未提交之前，Undo 保存了未提交之
前的版本数据，Undo 中的数据可作为数据旧版本快照供其他并发事务进行快照
读。是为了实现事务的原子性而出现的产物,在 MySQL innodb 存储引擎中用来
实现多版本并发控制。 
 
 
触发器 
触发器：trigger，是指事先为某张表绑定一段代码，当表中的某些内容发生改变
（增、删、改）的时候，系统会自动触发代码并执行。 
触发器包含三个要素，分别为 
· 事件类型：增删改，即 insert、delete 和 update； 
· 触发时间：事件类型前和后，即 before 和 after； 
· 触发对象：表中的每一条记录（行），即整张表。 
-- 创建新触发器 
delimiter $$ -- 临时修改语句结束符 
create trigger after_order_new after insert on orders for each row 
begin -- 触发器内容开始 
-- 触发器内容主体，每行用分号结尾 
update goods set inventory = inventory - NEW.goods_number where id = 
NEW.goods_id; 
end -- 触发器内容结束 
$$ -- 结束语句 
delimiter ; -- 恢复语句结束符 
 
什么是存储过程？有哪些优缺点？ 
存储过程是事先经过编译并存储在数据库中的一段 SQL 语句的集合。想要实现
相应的功能时，只需要调用这个存储过程就行了（类似于函数，输入具有输出参
数）。 
优点： 
预先编译，而不需要每次运行时编译，提高了数据库执行效率； 
封装了一系列操作，对于一些数据交互比较多的操作，相比于单独执行 SQL 语
句，可以减少网络通信量； 
具有可复用性，减少了数据库开发的工作量； 
安全性高，可以让没有权限的用户通过存储过程间接操作数据库； 
更易于维护 
缺点： 
可移植性差，存储过程将应用程序绑定到了数据库上； 
开发调试复杂：没有好的 IDE； 
修改复杂，需要重新编译，有时还需要更新程序中的代码以更新调用 
 
存储过程 
# 建一个简单的表，表里有 a、b 两个字段，并分别建上索引： 
CREATE TABLE `t` ( 
  `id` int(11) NOT NULL, 
  `a` int(11) DEFAULT NULL, 
  `b` int(11) DEFAULT NULL, 
  PRIMARY KEY (`id`), 
  KEY `a` (`a`), 
  KEY `b` (`b`) 
) ENGINE=InnoDB； 
 
# 往表 t 中插入 10 万行记录，取值按整数递增，即：(1,1,1)，(2,2,2)，(3,3,3) 直到 
(100000,100000,100000)。用存储过程来插入数据: 
delimiter ;; 
create procedure idata() 
begin 
  declare i int; 
  set i=1; 
  while(i<=100000)do 
    insert into t values(i, i, i); 
    set i=i+1; 
  end while; 
end;; 
delimiter ; 
call idata(); 
 
 
 
什么是触发器？ 
触发器（TRIGGER）是由事件（比如 INSERT/UPDATE/DELETE）来触发运行的
操作（不能被直接调用，不能接收参数）。在数据库里以独立的对象存储，用于
保证数据完整性（比如可以检验或转换数据）。 
 
MySQL 建表的约束条件有哪些？ 
主键约束（Primay Key Coustraint） 唯一性，非空性 
唯一约束 （Unique Counstraint）唯一性，可以空，但只能有一个 
检查约束 (Check Counstraint) 对该列数据的范围、格式的限制 
默认约束 (Default Counstraint) 该数据的默认值 
外键约束 (Foreign Key Counstraint) 需要建立两表间的关系并引用主表的列 
 
SQL 约束有哪几种？ 
NOT NULL: 用于控制字段的内容一定不能为空（NULL）。 
UNIQUE: 控件字段内容不能重复，一个表允许有多个 Unique 约束。 
PRIMARY KEY: 也是用于控件字段内容不能重复，但它在一个表只允许出现一
个。 
FOREIGN KEY: 用于预防破坏表之间连接的动作，也能防止非法数据插入外键
列，因为它必须是它指向的那个表中的值之一。 
CHECK: 用于控制字段的值范围。 
 
触发器与存储过程区别 
触发器也是 SQL语句集，两者唯一的区别是触发器不能用 EXECUTE 语句调用，
而是在用户执行 Transact-SQL 语句时自动触发（激活）执行。触发器是在一个修
改了指定表中的数据时执行的存储过程。通常通过创建触发器来强制实现不同表
中的逻辑相关数据的引用完整性和一致性。由于用户不能绕过触发器，所以可以
用它来强制实施复杂的业务规则，以确保数据的完整性。触发器不同于存储过程，
触发器主要是通过事件执行触发而被执行的，而存储过程可以通过存储过程名称
名字而直接调用。当对某一表进行诸如 UPDATE、INSERT、DELETE 这些操作
时，SQLSERVER 就会自动执行触发器所定义的 SQL 语句，从而确保对数据的
处理必须符合这些 SQL 语句所定义的规则。 
 
MyISAM 与 InnoDB 区别 
1、InnoDB 支持事务，MyISAM 不支持。事务是一种高级的处理方式，如在一
些列增删改中只要哪个出错还可以回滚还原，而 MyISAM 就不可以了； 
2、MyISAM 适合查询以及插入为主的应用，InnoDB 适合频繁修改以及涉及到安
全性较高的应用； 
3、InnoDB 支持外键，MyISAM 不支持； 
4、对于自增长的字段，InnoDB 中必须包含只有该字段的索引，但是在 MyISAM
表中可以和其他字段一起建立联合索引； 
5、清空整个表时，InnoDB 是一行一行的删除，效率非常慢。MyISAM 则会重
建表； 
6、MyISAM 是默认引擎，InnoDB 需要指定； 
7、InnoDB 不支持 FULLTEXT 类型的索引； 
8、InnoDB 中不保存表的行数，如 select count(*) from table 时，InnoDB；需要
扫描一遍整个表来计算有多少行，但是 MyISAM 只要简单的读出保存好的行数
即可。注意的是，当 count(*)语句包含 where 条件时 MyISAM 也需要扫描整个
表； 
9、InnoDB 支持行锁（某些情况下还是锁整表，如 update table set a=1 where user 
like ‘%lee%’； 
10、Myisam 和 InnoDB 的数据存储方法也有所区别 
Myisam：表、数据和索引全部单独分开存储；每个 MyISAM 在磁盘上存储成三
个文件。my_myisam.frm：存储表的结构；my_myisam.MYD：存储表的数据；
my_myisam.MYI：存储表的索引。在进行 update 时进行表锁，并发量相对较小。
如果执行大量的 SELECT，MyISAM 是更好的选择。 
MyISAM 的索引和数据是分开的，并且索引是有压缩的，内存使用率就对应提高
了不少。能加载更多索引，而 Innodb 是索引和数据是紧密捆绑的，没有使用压
缩从而会造成 Innodb 比 MyISAM 体积庞大不少。 
MyISAM 缓存在内存的是索引，不是数据。而 InnoDB 缓存在内存的是数据，相
对来说，服务器内存越大，InnoDB 发挥的优势越大。 
优点：查询数据相对较快，适合大量的 select，可以全文索引。 缺点：不支持事
务，不支持外键，并发量较小，不适合大量 update。 
InnoDB：只有表结构，数据全部存储到 ibd 文件中。 
而 innodb 是由.frm 文件、表空间（分为独立表空间或者共享表空间）和日志文件
（redo log）组成。 
 
 
对于存储引擎，MySQL 主要使用两种，分别为：InnoDB 和 Myisam，两者均
免费。 
特点 
Myisam 
InnoDB 
BDB 
Memory 
Archive 
批 量 插 入 的 速
度 
高 
低 
高 
高 
非常高 
事务安全 
—— 
支持 
支持 
—— 
—— 
全文索引 
支持 
5.5 版本支持 
—— 
—— 
—— 
锁机制 
表锁 
行锁 
页锁 
表锁 
行锁 
存储限制 
没有 
64TB 
没有 
有 
没有 
B 树索引 
支持 
支持 
支持 
支持 
—— 
哈希索引 
—— 
支持 
—— 
支持 
—— 
集群索引 
—— 
支持 
—— 
—— 
—— 
数据缓存 
—— 
支持 
—— 
支持 
—— 
索引缓存 
支持 
支持 
—— 
支持 
—— 
数据可压缩 
支持 
—— 
—— 
—— 
支持 
空间使用 
低 
高 
低 
N/A 
非常低 
内存使用 
低 
高 
低 
中等 
低 
外键支持 
—— 
支持 
—— 
—— 
—— 
 
 
 
 
 
 
 
四大特性： 
1.插入缓冲（insert buffer) 
2.二次写(double write) 
3.自适应哈希索引(ahi) 
4.预读(read ahead 
优点：支持事务，支持外键，并发量较大，适合大量 update。 缺点：查询数据相
对较快，不适合大量的 select。 
对于支持事务的 InnoDB 类型的表，影响速度的主要原因是 AUTOCOMMIT 默
认设置是打开的，而且程序没有显式调用 BEGIN 开始事务，导致每插入一条都
自动 Commit，严重影响了速度。可以在执行 sql 前调用 begin，多条 sql 形成一
个事物（即使 autocommit 打开也可以），将大大提高性能。 
应用场景： 
MyISAM 管理非事务表。它提供高速存储和检索，以及全文搜索能力。如果应用
中需要执行大量的 SELECT 查询，那么 MyISAM 是更好的选择。 
InnoDB 用于事务处理应用程序，具有众多特性，包括 ACID 事务支持。如果应
用中需要执行大量的 INSERT 或 UPDATE 操作，则应该使用 InnoDB，这样可以
提高多用户并发操作的性能。 
 
 
 
mysql 引擎 
存储引擎 
存储引擎说白了就是如何存储数据、如何为存储的数据建立索引和如何更新、查
询数据等技术的实现方法。因为在关系数据库中数据的存储是以表的形式存储的，
所以存储引擎也可以称为表类型（即存储和操作此表的类型）。 
# 查看 MySQL 提供的所有存储引擎 
show engines; 
 
# 查看 MySQL 当前默认的存储引擎 
我们也可以通过下面的命令查看默认的存储引擎。 
show variables like '%storage_engine%'; 
 
# 查看表的存储引擎 
show table status like "table_name" ; 
列出常见 MYSQL 数据存储引擎 
InnoDB：支持事务处理，支持外键，支持崩溃修复能力和并发控制。如果需要对
事务的完整性要求比较高（比如银行），要求实现并发控制（比如售票），那选
择 InnoDB 有很大的优势。如果需要频繁的更新、删除操作的数据库，也可以选
择 InnoDB，因为支持事务的提交（commit）和回滚（rollback）。 
MyISAM：插入数据快，空间和内存使用比较低。如果表主要是用于插入新记录
和读出记录，那么选择 MyISAM 能实现处理高效率。如果应用的完整性、并发
性要求比较低，也可以使用。 
MEMORY：所有的数据都在内存中，数据的处理速度快，但是安全性不高。如
果需要很快的读写速度，对数据的安全性要求较低，可以选择 MEMOEY。它对
表的大小有要求，不能建立太大的表。所以，这类数据库只使用在相对较小的数
据库表。 
 
 
SQL 语句的优化 
1. 分析慢查询日志：记录了在 MySQL 中响应时间超过阀值 long_query_time 的
SQL 语句，通过日志去找出 IO 大的 SQL 以及发现未命中索引的 SQL； 
2. 使用 Explain 进行分析：通过 explain 命令可以得到表的读取顺序、数据读取
操作的操作类型、哪些索引可以使用；哪些索引被实际使用、表之间的引用以及
被扫描的行数等问题； 
3. 应尽量避免在 where 子句中使用操作符或对字段进行 null 值判断，否则引擎
将放弃使用索引而进行全表扫描；如：select id from t where num is null 可以在
num 上设置默认值 0，确保表中 num 列没有 null 值，然后这样查询：select id 
from t where num=0; 
4. 尽量减少子查询，使用关联查询（left join,right join,inner join）替代； 
5. 减少使用 IN 或者 NOT IN ,使用 exists，not exists 或者关联查询语句替代；
MySQL 对于 IN 做了相应的优化，即将 IN 中的常量全部存储在一个数组里面，
而且这个数组是排好序的。 但是如果数值较多，产生的消耗也是比较大的。再
例如： select id from table_name where num in(1,2,3) 对于连续的数值，能用 
between 就不要用 in 了；再或者使用连接来替换。 
 
select * from 表 A where id in (select id from 表 B) 
 
上面 sql 语句相当于 
 
select * from 表 A where exists(select * from 表 B where 表 B.id=表 A.id) 
 
区分 in 和 exists 主要是造成了驱动顺序的改变（这是性能变化的关键），如果是 exists，
那么以外层表为 
 
驱动表，先被访问，如果是 IN，那么先执行子查询。所以 IN 适合于外表大而内表小的
情况；EXISTS 适合 
 
于外表小而内表大的情况。 
 
关于 not in 和 not exists，推荐使用 not exists，不仅仅是效率问题，not in 可能存在逻辑
问题。如何高效 
 
的写出一个替代 not exists 的 sql 语句？ 
 
原 sql 语句---select colname … from A 表 where a.id not in (select b.id from B 表) 
 
高效的 sql 语句---select colname … from A 表 Left join B 表 on where a.id = b.id where 
b.id is null 
6. or 的查询尽量用 union 或者 union all 代替(在确认没有重复数据或者不用剔除
重复数据时，union all 会更好)； 
7. 应尽量避免在 where 子句中使用!=或<>操作符，否则将引擎放弃使用索引而
进行全表扫描； 
8. 避免在 where 子句中对字段进行表达式操作 
 
select user_id,user_project from table_name where age*2=36; 
 
中对字段就行了算术运算，这会造成引擎放弃使用索引，建议改成 
 
select user_id,user_project from table_name where age=36/2; 
9. 只返回必要的列：最好不要使用 SELECT * 语句；SELECT *增加很多不必要
的消耗（cpu、io、内存、网络带宽）；增加了使用覆盖索引的可能性；当表结构
发生改变时，前端也需要更新。所以要求直接在 select 后面接上字段名。只返回
必要的行：使用 LIMIT 语句来限制返回的数据；这是为了使 EXPLAIN 中 type
列达到 const 类型 
10. 将一个大连接查询分解成对每一个表进行一次单表查询，然后在应用程序中
进行关联，这样做的好处有：让缓存更高效。对于连接查询，如果其中一个表发
生变化，那么整个查询缓存就无法使用。而分解后的多个查询，即使其中一个表
发生变化，对其它表的查询缓存依然可以使用；分解成多个单表查询，这些单表
查询的缓存结果更可能被其它查询使用到，从而减少冗余的查询；减少锁竞争； 
11. 不使用 ORDER BY RAND; 
 
select id from `table_name` order by rand() limit 1000; 
 
# 上面的 sql 语句，可优化为 
 
select id from `table_name` t1 join (select rand() * (select max(id) from `table_name`) as nid) 
t2 ont1.id > t2.nid limit 1000; 
12. 避免隐式类型转换 where 子句中出现 column 字段的类型和传入的参数类
型不一致的时候发生的类型转换，建议先确定 where 中的参数类型。比如：type
字段是 varchar，where type=34； 
13. 对于联合索引来说，要遵守最左前缀法则；举列来说索引含有字段
id,name,school，可以直接用 id 字段，也可以 id,name 这样的顺序，但是 name;school
都无法使用这个索引。所以在创建联合索引的时候一定要注意索引字段顺序，常
用的查询字段放在最前面； 
14. 必要时可以使用 force index 来强制查询走某个索引； 有的时候 MySQL 优
化器采取它认为合适的索引来检索 sql 语句，但是可能它所采用的索引并不是我
们想要 的。这时就可以采用 force index 来强制优化器使用我们制定的索引。 
 
索引的优化 
注意会引起索引失效的情况，以及在适合的地方建立索引； 
数据库表结构的优化 
 
设计表时遵循三大范式； 
 
选择合适的数据类型：尽可能不要存储 NULL 字段；使用简单的数据类型（int, 
varchar/ text）； 
 
表的水平切分（Sharding）：将同一个表中的记录拆分到多个结构相同的表中（策
略：哈希取模；根据 ID 范围来分）。当一个表的数据不断增多时，Sharding 是
必然的选择，它可以将数据分布到集群的不同节点上，从而缓解单个数据库的压
力； 
 
表的垂直切分：将一张表按列切分成多个表。可以将不常用的字段单独放在同一
个表中；把大字段独立放入一个表中；或者把经常使用的字段（关系密切的）放
在一张表中。垂直切分之后业务更加清晰，系统之间整合或扩展容易，数据维护
简单； 
一个好的数据库设计方案对于数据库的性能往往会起到事半功倍的效果。需要考
虑数据冗余、查询和更新的速度、字段的数据类型是否合理等多方面的内容。 
1. 将字段很多的表分解成多个表 
对于字段较多的表，如果有些字段的使用频率很低，可以将这些字段分离出来形
成新表。 
因为当一个表的数据量很大时，会由于使用频率低的字段的存在而变慢。 
1. 增加中间表 
对于需要经常联合查询的表，可以建立中间表以提高查询效率。 
通过建立中间表，将需要通过联合查询的数据插入到中间表中，然后将原来的联
合查询改为对中间表的查询。 
1. 增加冗余字段 
设计数据表时应尽量遵循范式理论的规约，尽可能的减少冗余字段，让数据库设
计看起来精致、优雅。但是，合理的加入冗余字段可以提高查询速度。 
表的规范化程度越高，表和表之间的关系越多，需要连接查询的情况也就越多，
性能也就越差。 
注意： 
冗余字段的值在一个表中修改了，就要想办法在其他表中更新，否则就会导致数
据不一致的问题。 
系统配置的优化 
 
操作系统：增加 TCP 支持的队列数； 
 
MySQL 配置文件优化：缓存池大小和个数设置 
硬件的优化磁盘性能 
固态硬盘； 
CPU：多核且高频； 
内存：增大内存 
1.优化索引、SQL 语句、分析慢查询； 
2.设计表的时候严格根据数据库的设计范式来设计数据库； 
3.使用缓存，把经常访问到的数据而且不需要经常变化的数据放在缓存中，能节
约磁盘 IO； 
4.优化硬件；采用 SSD，使用磁盘队列技术(RAID0,RAID1,RDID5)等； 
5.采用 MySQL 内部自带的表分区技术，把数据分层不同的文件，能够提高磁盘
的读取效率； 
6.垂直分表；把一些不经常读的数据放在一张表里，节约磁盘 I/O； 
7.主从分离读写；采用主从复制把数据库的读操作和写入操作分离开来； 
8.分库分表分机器（数据量特别大），主要的的原理就是数据路由； 
9.选择合适的表引擎，参数上的优化； 
10.进行架构级别的缓存，静态化和分布式； 
11.不采用全文索引； 
12.采用更快的存储方式，例如 NoSQL 存储经常访问的数据 
如何定位及优化 SQL 语句的性能问题？ 
对于低性能的 SQL 语句的定位，最重要也是最有效的方法就是使用执行计划，
MySQL 提供了 explain 命令来查看语句的执行计划。 我们知道，不管是哪种数
据库，或者是哪种数据库引擎，在对一条 SQL 语句进行执行的过程中都会做很
多相关的优化，对于查询语句，最重要的优化方式就是使用索引。 
而执行计划，就是显示数据库引擎对于 SQL 语句的执行的详细情况，其中包含
了是否使用索引，使用什么索引，使用的索引的相关信息等。  
超大分页怎么处理? 
数据库层面,这也是我们主要集中关注的(虽然收效没那么大),类似于 select * from 
table where age > 20 limit 1000000,10 这种查询其实也是有可以优化的余地的. 这条
语句需要 load1000000 数据然后基本上全部丢弃,只取 10 条当然比较慢. 当时
我们可以修改为 select * from table where id in (select id from table where age > 20 limit 
1000000,10).这样虽然也 load 了一百万的数据,但是由于索引覆盖,要查询的所有
字段都在索引中,所以速度会很快。 
解决超大分页,其实主要是靠缓存,可预测性的提前查到内容,缓存至 redis 等 k-V
数据库中,直接返回即可. 
在阿里巴巴《Java 开发手册》中,对超大分页的解决办法是类似于上面提到的第
一种. 
【推荐】利用延迟关联或者子查询优化超多分页场景。 
说明：MySQL 并不是跳过 offset 行，而是取 offset+N 行，然后返回放弃前 offset
行，返回 N 行，那当 offset 特别大的时候，效率就非常的低下，要么控制返回的
总页数，要么对超过特定阈值的页数进行 SQL 改写。 
正例：先快速定位需要获取的 id 段，然后再关联： 
SELECT a.* FROM 表 1 a, (select id from 表 1 where 条件 LIMIT 100000,20 ) b 
where a.id=b.id 
统计过慢查询吗？对慢查询都怎么优化过？ 
在业务系统中，除了使用主键进行的查询，其他的我都会在测试库上测试其耗时，
慢查询的统计主要由运维在做，会定期将业务中的慢查询反馈给我们。 
慢查询的优化首先要搞明白慢的原因是什么？ 是查询条件没有命中索引？是
load 了不需要的数据列？还是数据量太大？ 
所以优化也是针对这三个方向来的， 
 
首先分析语句，看看是否 load 了额外的数据，可能是查询了多余的行并且抛弃
掉了，可能是加载了许多结果中并不需要的列，对语句进行分析以及重写。 
 
分析语句的执行计划，然后获得其使用索引的情况，之后修改语句或者修改索引，
使得语句可以尽可能的命中索引。 
 
如果对语句的优化已经无法进行，可以考虑表中的数据量是否太大，如果是的话
可以进行横向或者纵向的分表。 
如何优化查询过程中的数据访问 
 
访问数据太多导致查询性能下降 
 
确定应用程序是否在检索大量超过需要的数据，可能是太多行或列 
 
确认 MySQL 服务器是否在分析大量不必要的数据行 
 
查询不需要的数据。解决办法：使用 limit 解决 
 
多表关联返回全部列。解决办法：指定列名 
 
总是返回全部列。解决办法：避免使用 SELECT * 
 
重复查询相同的数据。解决办法：可以缓存数据，下次直接读取缓存 
 
是否在扫描额外的记录。解决办法： 使用 explain 进行分析，如果发现查询需要
扫描大量的数据，但只返回少数的行，可以通过如下技巧去优化： 使用索引覆
盖扫描，把所有的列都放到索引中，这样存储引擎不需要回表获取对应行就可以
返回结果。 
 
改变数据库和表的结构，修改数据表范式 
 
重写 SQL 语句，让优化器可以以更优的方式执行查询。 
如何优化关联查询 
 
确定 ON 或者 USING 子句中是否有索引。 
 
确保 GROUP BY 和 ORDER BY 只有一个表中的列，这样 MySQL 才有可能使用
索引。 
MySQL 数据库 cpu 飙升到 500%的话他怎么处理？ 
当 cpu 飙升到 500%时，先用操作系统命令 top 命令观察是不是 MySQLd 占
用导致的，如果不是，找出占用高的进程，并进行相关处理。 
如果是 MySQLd 造成的， show processlist，看看里面跑的 session 情况，是不
是有消耗资源的 sql 在运行。找出消耗高的 sql，看看执行计划是否准确， index 
是否缺失，或者实在是数据量太大造成。 
一般来说，肯定要 kill 掉这些线程(同时观察 cpu 使用率是否下降)，等进行相
应的调整(比如说加索引、改 sql、改内存参数)之后，再重新跑这些 SQL。 
也有可能是每个 sql 消耗资源并不多，但是突然之间，有大量的 session 连进来
导致 cpu 飙升，这种情况就需要跟应用一起来分析为何连接数会激增，再做出
相应的调整，比如说限制连接数等。 
大表怎么优化 
类似的问题：某个表有近千万数据，CRUD 比较慢，如何优化？分库分表了是怎
么做的？分表分库了有什么问题？有用到中间件么？他们的原理知道么？ 
当 MySQL 单表记录数过大时，数据库的 CRUD 性能会明显下降，一些常见的优
化措施如下： 
 
限定数据的范围： 务必禁止不带任何限制数据范围条件的查询语句。比如：我
们当用户在查询订单历史的时候，我们可以控制在一个月的范围内； 
 
优化 shema、sql 语句+索引； 
 
主从复制，读写分离： 经典的数据库拆分方案，主库负责写，从库负责读； 
 
缓存： 使用 MySQL 的缓存，另外对重量级、更新少的数据可以考虑；memcached, 
redis； 
 
通过分库分表的方式进行优化，主要有垂直分表和水平分表。 
 
垂直拆分: 根据数据库里面数据表的相关性进行拆分。 例如，用户表中既有用
户的登录信息又有用户的基本信 息，可以将用户表拆分成两个单独的表，甚至
放到单独的库做分库。 简单来说垂直拆分是指数据表列的拆分，把一张列比较
多的表拆分为多张表。根据你模块的耦合度，将一个大的系统分为多个小的系统，
也就是分布式系统；垂直拆分的优点： 可以使得列数据变小，在查询时减少读
取的 Block 数，减少 I/O 次数。此外， 垂直分区可以简化表的结构，易于维护。 
垂直拆分的缺点： 主键会出现冗余，需要管理冗余列，并会引起 Join 操作，可
以通过在应用层 进行 Join 来解决。此外，垂直分区会让事务变得更加复杂； 
 
水平切分，针对数据量大的表，这一步最麻烦，最能考验技术水平，要选择一个
合理的 sharding key, 为了有好的查询效率，表结构也要改动，做一定的冗余，应
用也要改，sql 中尽量带 sharding key，将数据定位到限定的表上去查，而不是扫
描全部的表；保持数据表结构不变，通过某种策略存储数据分片。这样每一片数
据分散到不同的表或者库中，达 到了分布式的目的。 水平拆分可以支撑非常大
的数据量。 水平拆分是指数据表行的拆分，表的行数超过 200 万行时，就会变
慢，这时可以把一张的表的数据 拆成多张表来存放。举个例子：我们可以将用
户信息表拆分成多个用户信息表，这样就可以避免单 一表数据量过大对性能造
成影响。水平拆分可以支持非常大的数据量。需要注意的一点是：分表仅仅是解
决了单一表数据过大的问 题，但由于表的数据还是在同一台机器上，其实对于
提升 MySQL 并发能力没有什么意义，所以 水平 拆分最好分库 。 水平拆分能
够 支持非常大的数据量存储，应用端改造也少，但 分片事务难以解决 ，跨节
点 Join 性能 较差，逻辑复杂。《Java 工程师修炼之道》的作者推荐 尽量不要对
数据进行分片，因为拆分会带来 逻辑、部署、运维的各种复杂度 ，一般的数据
表在优化得当的情况下支撑千万以下的数据量是没有 太大问题的。如果实在要
分片，尽量选择客户端分片架构，这样可以减少一次和中间件的网络 I/O。 
分库分表 
为什么要分库分表？ 
分表 
比如你单表都几千万数据了，你确定你能扛住么？绝对不行，单表数据量太大，
会极大影响你的 sql 执行的性能，到了后面你的 sql 可能就跑的很慢了。一般来
说，就以我的经验来看，单表到几百万的时候，性能就会相对差一些了，你就得
分表了。 
分表就是把一个表的数据放到多个表中，然后查询的时候你就查一个表。比如按
照用户 id 来分表，将一个用户的数据就放在一个表中。然后操作的时候你对一
个用户就操作那个表就好了。这样可以控制每个表的数据量在可控的范围内，比
如每个表就固定在 200 万以内。 
分库 
分库就是你一个库一般我们经验而言，最多支撑到并发 2000，一定要扩容了，
而且一个健康的单库并发值你最好保持在每秒 1000 左右，不要太大。那么你可
以将一个库的数据拆分到多个库中，访问的时候就访问一个库好了。 
这就是所谓的分库分表。 
用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？ 
这个其实就是看看你了解哪些分库分表的中间件，各个中间件的优缺点是啥？然
后你用过哪些分库分表的中间件。 
比较常见的包括： 
 
cobar 
 
TDDL 
 
atlas 
 
sharding-jdbc 
 
mycat 
cobar 
阿里 b2b 团队开发和开源的，属于 proxy 层方案。早些年还可以用，但是最近
几年都没更新了，基本没啥人用，差不多算是被抛弃的状态吧。而且不支持读写
分离、存储过程、跨库 join 和分页等操作。 
TDDL 
淘宝团队开发的，属于 client 层方案。支持基本的 crud 语法和读写分离，但不
支持 join、多表查询等语法。目前使用的也不多，因为还依赖淘宝的 diamond 配
置管理系统。 
atlas 
360 开源的，属于 proxy 层方案，以前是有一些公司在用的，但是确实有一个很
大的问题就是社区最新的维护都在 5 年前了。所以，现在用的公司基本也很少
了。 
sharding-jdbc 
当当开源的，属于 client 层方案。确实之前用的还比较多一些，因为 SQL 语法
支持也比较多，没有太多限制，而且目前推出到了 2.0 版本，支持分库分表、读
写分离、分布式 id 生成、柔性事务（最大努力送达型事务、TCC 事务）。而且
确实之前使用的公司会比较多一些（这个在官网有登记使用的公司，可以看到从 
2017 年一直到现在，是有不少公司在用的），目前社区也还一直在开发和维护，
还算是比较活跃，个人认为算是一个现在也可以选择的方案。 
mycat 
基于 cobar 改造的，属于 proxy 层方案，支持的功能非常完善，而且目前应该
是非常火的而且不断流行的数据库中间件，社区很活跃，也有一些公司开始在用
了。但是确实相比于 sharding jdbc 来说，年轻一些，经历的锤炼少一些。 
 
简述 mysql 和 redis 区别 
redis： 内存型非关系数据库，数据保存在内存中，速度快 
mysql：关系型数据库，数据保存在磁盘中，检索的话，会有一定的 Io 操作，访
问速度相对慢 
 
 
 
mysql 语句 
基本操作 
mysql -h 地址 -P 端口 -u 用户名 -p 密码  ## /* 连接与断开服务器 */ 
SHOW PROCESSLIST -- 显示哪些线程正在运行 
SHOW VARIABLES -- 显示系统变量信息 
SELECT DATABASE();  # -- 查看当前数据库 
SELECT now(), user(), version(); # -- 显示当前时间、用户名、数据库版本 
CREATE DATABASE[ IF NOT EXISTS] 数据库名 数据库选项 # -- 创建库 
数据库选项： 
CHARACTER SET charset_name 
COLLATE collation_name 
 
# -- 查看已有库 
SHOW DATABASES[ LIKE 'PATTERN'] 
 
# -- 查看当前库信息 
SHOW CREATE DATABASE 数据库名 
# -- 修改库的选项信息 
ALTER DATABASE 库名 选项信息 
# -- 删除库 
DROP DATABASE[ IF EXISTS] 数据库名 
同时删除该数据库相关的目录及其目录内容 
 
# -- 创建表 
CREATE [TEMPORARY] TABLE[ IF NOT EXISTS] [库名.]表名 ( 表的结构定
义 )[ 表选项] 
每个字段必须有数据类型 
最后一个字段后不能有逗号 
TEMPORARY 临时表，会话结束时表自动消失 
对于字段的定义： 
字段名 数据类型 [NOT NULL | NULL] [DEFAULT default_value] 
[AUTO_INCREMENT] [UNIQUE [KEY] | [PRIMARY] KEY] [COMMENT 'string'] 
-- 表选项 
-- 字符集 
CHARSET = charset_name 
如果表没有设定，则使用数据库字符集 
-- 存储引擎 
ENGINE = engine_name 
表在管理数据时采用的不同的数据结构，结构不同会导致处理方式、提供的特性
操作等不同 
SHOW ENGINES -- 显示存储引擎的状态信息 
SHOW ENGINE 引擎名 {LOGS|STATUS} -- 显示存储引擎的日志或状态信息 
-- 自增起始数 
AUTO_INCREMENT = 行数 
-- 数据文件目录 
DATA DIRECTORY = '目录' 
-- 索引文件目录 
INDEX DIRECTORY = '目录' 
-- 表注释 
COMMENT = 'string' 
-- 分区选项 
PARTITION BY ... (详细见手册) 
-- 查看所有表 
SHOW TABLES[ LIKE 'pattern'] 
SHOW TABLES FROM 库名 
-- 查看表结构 
SHOW CREATE TABLE 表名 （信息更详细） 
DESC 表名 / DESCRIBE 表名 / EXPLAIN 表名 / SHOW COLUMNS FROM 表
名 [LIKE 
'PATTERN'] 
SHOW TABLE STATUS [FROM db_name] [LIKE 'pattern'] 
-- 修改表 
-- 修改表本身的选项 
ALTER TABLE 表名 表的选项 
eg: ALTER TABLE 表名 ENGINE=MYISAM; 
-- 对表进行重命名 
RENAME TABLE 原表名 TO 新表名 
RENAME TABLE 原表名 TO 库名.表名 （可将表移动到另一个数据库） 
-- RENAME 可以交换两个表名 
-- 修改表的字段机构（13.1.2. ALTER TABLE 语法） 
ALTER TABLE 表名 操作名 
-- 操作名 
ADD[ COLUMN] 字段定义 -- 增加字段 
AFTER 字段名 -- 表示增加在该字段名后面 
FIRST -- 表示增加在第一个 
ADD PRIMARY KEY(字段名) -- 创建主键 
ADD UNIQUE [索引名] (字段名)-- 创建唯一索引 
ADD INDEX [索引名] (字段名) -- 创建普通索引 
DROP[ COLUMN] 字段名 -- 删除字段 
MODIFY[ COLUMN] 字段名 字段属性 -- 支持对字段属性进行修改，不能修改
字段名 
(所有原有属性也需写上) 
CHANGE[ COLUMN] 原字段名 新字段名 字段属性 -- 支持对字段名修改 
DROP PRIMARY KEY -- 删除主键(删除主键前需删除其 AUTO_INCREMENT
属性) 
DROP INDEX 索引名 -- 删除索引 
DROP FOREIGN KEY 外键 -- 删除外键 
-- 删除表 
DROP TABLE[ IF EXISTS] 表名 ... 
-- 清空表数据 
TRUNCATE [TABLE] 表名 
-- 复制表结构 
CREATE TABLE 表名 LIKE 要复制的表名 
-- 复制表结构和数据 
CREATE TABLE 表名 [AS] SELECT * FROM 要复制的表名 
-- 检查表是否有错误 
CHECK TABLE tbl_name [, tbl_name] ... [option] ... 
-- 优化表 
OPTIMIZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE tbl_name [, tbl_name] ... 
-- 修复表 
REPAIR [LOCAL | NO_WRITE_TO_BINLOG] TABLE tbl_name [, tbl_name] ... 
[QUICK] 
[EXTENDED] [USE_FRM] 
-- 分析表 
ANALYZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE tbl_name [, tbl_name] ... 
 
/* 数据操作 */ ------------------ 
-- 增 
INSERT [INTO] 表名 [(字段列表)] VALUES (值列表)[, (值列表), ...] 
-- 如果要插入的值列表包含所有字段并且顺序一致，则可以省略字段列表。 
-- 可同时插入多条数据记录！ 
REPLACE 与 INSERT 完全一样，可互换。 
INSERT [INTO] 表名 SET 字段名=值[, 字段名=值, ...] 
-- 查 
SELECT 字段列表 FROM 表名[ 其他子句] 
-- 可来自多个表的多个字段 
-- 其他子句可以不使用 
-- 字段列表可以用*代替，表示所有字段 
-- 删 
DELETE FROM 表名[ 删除条件子句] 
没有条件子句，则会删除全部 
-- 改 
UPDATE 表名 SET 字段名=新值[, 字段名=新值] [更新条件] 
 
select 语句 
/* SELECT */ ------------------ 
SELECT [ALL|DISTINCT] select_expr FROM -> WHERE -> GROUP BY [合计函
数] -> HAVING - 
> ORDER BY -> LIMIT 
a. select_expr 
-- 可以用 * 表示所有字段。 
select * from tb; 
-- 可以使用表达式（计算公式、函数调用、字段也是个表达式） 
select stu, 29+25, now() from tb; 
-- 可以为每个列使用别名。适用于简化列标识，避免多个列标识符重复。 
- 使用 as 关键字，也可省略 as. 
select stu+10 as add10 from tb; 
b. FROM 子句 
用于标识查询来源。 
-- 可以为表起别名。使用 as 关键字。 
SELECT * FROM tb1 AS tt, tb2 AS bb; 
-- from 子句后，可以同时出现多个表。 
-- 多个表会横向叠加到一起，而数据会形成一个笛卡尔积。 
SELECT * FROM tb1, tb2; 
-- 向优化符提示如何选择索引 
USE INDEX、IGNORE INDEX、FORCE INDEX 
SELECT * FROM table1 USE INDEX (key1,key2) WHERE key1=1 AND key2=2 
AND 
key3=3; 
SELECT * FROM table1 IGNORE INDEX (key3) WHERE key1=1 AND key2=2 
AND 
key3=3; 
c. WHERE 子句 
-- 从 from 获得的数据源中进行筛选。 
-- 整型 1 表示真，0 表示假。 
-- 表达式由运算符和运算数组成。 
-- 运算数：变量（字段）、值、函数返回值 
-- 运算符： 
=, <=>, <>, !=, <=, <, >=, >, !, &&, ||, 
in (not) null, (not) like, (not) in, (not) between and, is (not), 
and, or, not, xor 
is/is not 加上 ture/false/unknown，检验某个值的真假 
<=>与<>功能相同，<=>可用于 null 比较 
d. GROUP BY 子句, 分组子句 
GROUP BY 字段/别名 [排序方式] 
分组后会进行排序。升序：ASC，降序：DESC 
以下[合计函数]需配合 GROUP BY 使用： 
count 返回不同的非 NULL 值数目 count(*)、count(字段) 
sum 求和 
max 求最大值 
min 求最小值 
avg 求平均值 
group_concat 返回带有来自一个组的连接的非 NULL 值的字符串结果。组内字
符串连接。 
 
e. HAVING 子句，条件子句 
与 where 功能、用法相同，执行时机不同。 
where 在开始时执行检测数据，对原数据进行过滤。 
having 对筛选出的结果再次进行过滤。 
having 字段必须是查询出来的，where 字段必须是数据表存在的。 
where 不可以使用字段的别名，having 可以。因为执行 WHERE 代码时，可能尚
未确定列值。 
where 不可以使用合计函数。一般需用合计函数才会用 having 
SQL 标准要求 HAVING 必须引用 GROUP BY 子句中的列或用于合计函数中的
列。 
f. ORDER BY 子句，排序子句 
order by 排序字段/别名 排序方式 [,排序字段/别名 排序方式]... 
升序：ASC，降序：DESC 
支持多个字段的排序。 
g. LIMIT 子句，限制结果数量子句 
仅对处理好的结果进行数量限制。将处理好的结果的看作是一个集合，按照记录
出现的顺序，索引从 0 开 
始。 
limit 起始位置, 获取条数 
省略第一个参数，表示从索引 0 开始。limit 获取条数 
h. DISTINCT, ALL 选项 
distinct 去除重复记录 
默认为 all, 全部记录 
 
 
/* UNION */ ------------------ 
将多个 select 查询的结果组合成一个结果集合。 
SELECT ... UNION [ALL|DISTINCT] SELECT ... 
默认 DISTINCT 方式，即所有返回的行都是唯一的 
建议，对每个 SELECT 查询加上小括号包裹。 
ORDER BY 排序时，需加上 LIMIT 进行结合。 
需要各 select 查询的字段数量一样。 
每个 select 查询的字段列表(数量、类型)应一致，因为结果中的字段名以第一条
select 语句为准。 
 
 
/* 子查询 */ ------------------ 
- 子查询需用括号包裹。 
-- from 型 
from 后要求是一个表，必须给子查询结果取个别名。 
- 简化每个查询内的条件。 
- from 型需将结果生成一个临时表格，可用以原表的锁定的释放。 
- 子查询返回一个表，表型子查询。 
select * from (select * from tb where id>0) as subfrom where id>1; 
-- where 型 
- 子查询返回一个值，标量子查询。 
- 不需要给子查询取别名。 
- where 子查询内的表，不能直接用以更新。 
select * from tb where money = (select max(money) from tb); 
-- 列子查询 
如果子查询结果返回的是一列。 
使用 in 或 not in 完成查询 
exists 和 not exists 条件 
如果子查询返回数据，则返回 1 或 0。常用于判断条件。 
select column1 from t1 where exists (select * from t2); 
-- 行子查询 
查询条件是一个行。 
select * from t1 where (id, gender) in (select id, gender from t2); 
行构造符：(col1, col2, ...) 或 ROW(col1, col2, ...) 
行构造符通常用于与对能返回两个或两个以上列的子查询进行比较。 
-- 特殊运算符 
!= all() 相当于 not in 
= some() 相当于 in。any 是 some 的别名 
!= some() 不等同于 not in，不等于其中某一个。 
all, some 可以配合其他运算符一起使用。 
 
 
连接查询(join) 
将多个表的字段进行连接，可以指定连接条件。 
-- 内连接(inner join) 
- 默认就是内连接，可省略 inner。 
- 只有数据存在时才能发送连接。即连接结果不能出现空行。 
on 表示连接条件。其条件表达式与 where 类似。也可以省略条件（表示条件永
远为真） 
也可用 where 表示连接条件。 
还有 using, 但需字段名相同。using(字段名) 
-- 交叉连接 cross join 
即，没有条件的内连接。 
select * from tb1 cross join tb2; 
-- 外连接(outer join) 
- 如果数据不存在，也会出现在连接结果中。 
-- 左外连接 left join 
如果数据不存在，左表记录会出现，而右表为 null 填充 
-- 右外连接 right join 
如果数据不存在，右表记录会出现，而左表为 null 填充 
-- 自然连接(natural join) 
自动判断连接条件完成连接。 
相当于省略了 using，会自动查找相同字段名。 
natural join 
natural left join 
natural right join 
select info.id, info.name, info.stu_num, extra_info.hobby, extra_info.sex from 
info, extra_info where info.stu_num = extra_info.stu_id; 
 
selete * from testtable limit 2,1; 
selete * from testtable limit 2 offset 1; 
 
1.数据库数据计算是从 0 开始的 
2.offset X 是跳过 X 个数据，limit Y 是选取 Y 个数据 
3.limit X,Y 中 X 表示跳过 X 个数据，读取 Y 个数据 
IFNULL 语法：IFNULL(A,B)，如果不为空返回第一个参数 A，为空返回参数 B 
 
####  21.1. <a name='-1'></a>消除重复行 
数据表 student 有 id,name,score,city 字段，其中 name 中的名字可有重复，需要消
除重复行,请写 sql 语句 
select distinct name from student; 
 
 
举例 
1.查询所有教师和同学的 name、sex 和 birthday. 
SELECT 
Sname,Ssex,Sbirthday 
FROM 
Students 
UNION 
SELECT 
Tname,Tsex,Tbirthday FROM Teachers; 
 
2.查询所有“女”教师和“女”同学的 name、sex 和 birthday. 
SELECT Sname,Ssex,Sbirthday FROM Students WHERE Ssex='女' UNION SELECT 
Tname,Tsex,Tbirthday FROM Teachers WHERE Tsex='女'; 
 
3.查询成绩比该课程平均成绩低的同学的成绩表。 
SELECT s1.* FROM Scores AS s1 INNER JOIN (SELECT Cno,AVG(Degree) AS 
aDegree FROM Scores GROUP BY Cno) s2 ON(s1.Cno=s2.Cno AND 
s1.Degree<s2.aDegree);  
 
4.查询所有任课教师的 Tname 和 Depart. 
SELECT Tname,Depart FROM Teachers WHERE Tno IN( SELECT Tno FROM 
Courses); 
 
5.查询所有未讲课的教师的 Tname 和 Depart. 
SELECT Tname,Depart FROM Teachers WHERE Tno NOT IN( SELECT Tno FROM 
Courses); 
 
6.查询至少有 2 名男生的班号。 
SELECT Class,COUNT(1) AS boyCount FROM Students WHERE Ssex='男' GROUP 
BY Class HAVING boyCount>=2; 
 
7.查询 Student 表中不姓“王”的同学记录。 
SELECT * FROM Students WHERE Sname NOT LIKE '王%'; 
 
8.查询 Student 表中每个学生的姓名和年龄。 
SELECT Sname,YEAR(NOW())-YEAR(Sbirthday) AS Sage FROM Students; 
 
9.查询 Student 表中最大和最小的 Sbirthday 日期值。 
SELECT MIN(Sbirthday),MAX(Sbirthday) FROM Students; 
 
10.以班号和年龄从大到小的顺序查询 Student 表中的全部记录。 
SELECT * FROM Students ORDER BY Class DESC,Sbirthday ASC; 
 
11.查询“男”教师及其所上的课程。 
SELECT 
Teachers.Tname,Courses.Cname 
FROM 
Teachers 
JOIN 
Courses 
ON(Teachers.Tno=Courses.Tno) WHERE Teachers.Tsex='男'; 
 
12.查询最高分同学的 Sno、Cno 和 Degree 列。 
SELECT * FROM Scores GROUP BY Cno HAVING Degree=Max(Degree); 
 
13.查询和“李军”同性别的所有同学的 Sname. 
SELECT s1.Sname FROM Students AS s1 INNER JOIN Students AS s2 
ON(s1.Ssex=s2.Ssex) WHERE s2.Sname='李军'; 
 
14.查询和“李军”同性别并同班的同学 Sname. 
SELECT s1.Sname FROM Students AS s1 INNER JOIN Students AS s2 
ON(s1.Ssex=s2.Ssex AND s1.Class=s2.Class) WHERE s2.Sname='李军'; 
 
15.查询所有选修“计算机导论”课程的“男”同学的成绩表 
SELECT * FROM Scores WHERE Sno IN ( SELECT Sno FROM Students 
 WHERE Ssex='男') AND Cno IN ( SELECT Cno FROM Courses WHERE Cname='
计算机导论'); 
 
 
 
  
 
# 查看列上有多个不同的值 
mysql> select count(distinct email) as L from SUser; 
 
 
# 查看 4~7 个字节的前缀索引 
mysql> select  
  count(distinct left(email,4)）as L4, 
  count(distinct left(email,5)）as L5, 
  count(distinct left(email,6)）as L6, 
  count(distinct left(email,7)）as L7, 
from SUser; 
 
 
/* 数据类型（列类型） */ ------------------ 
1. 数值类型 
-- a. 整型 ---------- 
类型 字节 范围（有符号位） 
tinyint 1 字节 -128 ~ 127 无符号位：0 ~ 255 
smallint 2 字节 -32768 ~ 32767 
mediumint 3 字节 -8388608 ~ 8388607 
int 4 字节 
bigint 8 字节 
int(M) M 表示总位数 
- 默认存在符号位，unsigned 属性修改 
- 显示宽度，如果某个数不够定义字段时设置的位数，则前面以 0 补填，zerofill 
属性修改 
例：int(5) 插入一个数'123'，补填后为'00123' 
- 在满足要求的情况下，越小越好。 
- 1 表示 bool 值真，0 表示 bool 值假。MySQL 没有布尔类型，通过整型 0 和 1 表
示。常用 tinyint(1)表 
示布尔型。 
-- b. 浮点型 ---------- 
类型 字节 范围 
float(单精度) 4 字节 
double(双精度) 8 字节 
浮点型既支持符号位 unsigned 属性，也支持显示宽度 zerofill 属性。 
不同于整型，前后均会补填 0. 
定义浮点型时，需指定总位数和小数位数。 
float(M, D) double(M, D) 
M 表示总位数，D 表示小数位数。 
M 和 D 的大小会决定浮点数的范围。不同于整型的固定范围。 
M 既表示总位数（不包括小数点和正负号），也表示显示宽度（所有显示符号均
包括）。 
支持科学计数法表示。 
浮点数表示近似值。 
-- c. 定点数 ---------- 
decimal -- 可变长度 
decimal(M, D) M 也表示总位数，D 表示小数位数。 
保存一个精确的数值，不会发生数据的改变，不同于浮点数的四舍五入。 
将浮点数转换为字符串来保存，每 9 位数字保存为 4 个字节。 
2. 字符串类型 
-- a. char, varchar ---------- 
char 定长字符串，速度快，但浪费空间 
varchar 变长字符串，速度慢，但节省空间 
M 表示能存储的最大长度，此长度是字符数，非字节数。 
不同的编码，所占用的空间不同。 
char,最多 255 个字符，与编码无关。 
varchar,最多 65535 字符，与编码有关。 
一条有效记录最大不能超过 65535 个字节。 
utf8 最大为 21844 个字符，gbk 最大为 32766 个字符，latin1 最大为 65532 个字
符 
varchar 是变长的，需要利用存储空间保存 varchar 的长度，如果数据小于 255
个字节，则采用一个 
字节来保存长度，反之需要两个字节来保存。 
varchar 的最大有效长度由最大行大小和使用的字符集确定。 
最大有效长度是 65532 字节，因为在 varchar 存字符串时，第一个字节是空的，
不存在任何数据，然后还 
需两个字节来存放字符串的长度，所以有效长度是 65535-1-2=65532 字节。 
例：若一个表定义为 CREATE TABLE tb(c1 int, c2 char(30), c3 varchar(N)) 
charset=utf8; 问 N 的最大值是多少？ 答：(65535-1-2-4-30*3)/3 
-- b. blob, text ---------- 
blob 二进制字符串（字节字符串） 
tinyblob, blob, mediumblob, longblob 
text 非二进制字符串（字符字符串） 
tinytext, text, mediumtext, longtext 
text 在定义时，不需要定义长度，也不会计算总长度。 
text 类型在定义时，不可给 default 值 
-- c. binary, varbinary ---------- 
类似于 char 和 varchar，用于保存二进制字符串，也就是保存字节字符串而非字
符字符串。 
char, varchar, text 对应 binary, varbinary, blob. 
3. 日期时间类型 
一般用整型保存时间戳，因为 PHP 可以很方便的将时间戳进行格式化。 
datetime 8 字节 日期及时间 1000-01-01 00:00:00 到 9999-12-31 23:59:59 微信搜
索公众号：Java 专栏，获取最新面试手册 
列属性（列约束） 
date 3 字节 日期 1000-01-01 到 9999-12-31 
timestamp 4 字节 时间戳 19700101000000 到 2038-01-19 03:14:07 
time 3 字节 时间 -838:59:59 到 838:59:59 
year 1 字节 年份 1901 - 2155 
datetime YYYY-MM-DD hh:mm:ss 
timestamp YY-MM-DD hh:mm:ss 
YYYYMMDDhhmmss 
YYMMDDhhmmss 
YYYYMMDDhhmmss 
YYMMDDhhmmss 
date YYYY-MM-DD 
YY-MM-DD 
YYYYMMDD 
YYMMDD 
YYYYMMDD 
YYMMDD 
time hh:mm:ss 
hhmmss 
hhmmss 
year YYYY 
YY 
YYYY 
YY 
4. 枚举和集合 
-- 枚举(enum) ---------- 
enum(val1, val2, val3...) 
在已知的值中进行单选。最大数量为 65535. 
枚举值在保存时，以 2 个字节的整型(smallint)保存。每个枚举值，按保存的位置
顺序，从 1 开始逐一递 
增。 
表现为字符串类型，存储却是整型。 
NULL 值的索引是 NULL。 
空字符串错误值的索引值是 0。 
-- 集合（set） ---------- 
set(val1, val2, val3...) 
create table tab ( gender set('男', '女', '无') ); 
insert into tab values ('男, 女'); 
最多可以有 64 个不同的成员。以 bigint 存储，共 8 个字节。采取位运算的形式。 
当创建表时，SET 成员值的尾部空格将自动被删除。 
 
 
/* 列属性（列约束） */ ------------------ 
1. PRIMARY 主键 
- 能唯一标识记录的字段，可以作为主键。 
- 一个表只能有一个主键。 
- 主键具有唯一性。 
- 声明字段时，用 primary key 标识。 
也可以在字段列表之后声明 
例：create table tab ( id int, stu varchar(10), primary key (id)); 
- 主键字段的值不能为 null。 
- 主键可以由多个字段共同组成。此时需要在字段列表后声明的方法。 
例：create table tab ( id int, stu varchar(10), age int, primary key 
(stu, age)); 
2. UNIQUE 唯一索引（唯一约束） 
使得某字段的值也不能重复。 
3. NULL 约束 
null 不是数据类型，是列的一个属性。 
表示当前列是否可以为 null，表示什么都没有。 
null, 允许为空。默认。 
not null, 不允许为空。 
insert into tab values (null, 'val'); 
-- 此时表示将第一个字段的值设为 null, 取决于该字段是否允许为 null 
4. DEFAULT 默认值属性 
当前字段的默认值。 
insert into tab values (default, 'val'); -- 此时表示强制使用默认值。 
create table tab ( add_time timestamp default current_timestamp ); 
-- 表示将当前时间的时间戳设为默认值。 
current_date, current_time 
5. AUTO_INCREMENT 自动增长约束 
自动增长必须为索引（主键或 unique） 
只能存在一个字段为自动增长。 
默认为 1 开始自动增长。可以通过表属性 auto_increment = x 进行设置，或 alter 
table tbl 
auto_increment = x; 
6. COMMENT 注释 
例：create table tab ( id int ) comment '注释内容'; 
7. FOREIGN KEY 外键约束 
用于限制主表与从表数据完整性。 
alter table t1 add constraint `t1_t2_fk` foreign key (t1_id) references 
t2(id); 
-- 将表 t1 的 t1_id 外键关联到表 t2 的 id 字段。 
-- 每个外键都有一个名字，可以通过 constraint 指定 
存在外键的表，称之为从表（子表），外键指向的表，称之为主表（父表）。 
作用：保持数据一致性，完整性，主要目的是控制存储在外键表（从表）中的数
据。 
MySQL 中，可以对 InnoDB 引擎使用外键约束： 
语法： 
foreign key (外键字段） references 主表名 (关联字段) [主表记录删除时的动作] 
[主表记录 
更新时的动作] 
此时需要检测一个从表的外键需要约束为主表的已存在的值。外键在没有关联的
情况下，可以设置为 
null.前提是该外键列，没有 not null。 
可以不指定主表记录更改或更新时的动作，那么此时主表的操作被拒绝。 
如果指定了 on update 或 on delete：在删除或更新时，有如下几个操作可以选择： 
1. cascade，级联操作。主表数据被更新（主键值更新），从表也被更新（外键值
更新）。主表记录被 
删除，从表相关记录也被删除。 
2. set null，设置为 null。主表数据被更新（主键值更新），从表的外键被设置为
null。主表记录 
被删除，从表相关记录外键被设置成 null。但注意，要求该外键列，没有 not null
属性约束。 
3. restrict，拒绝父表删除和更新。 
注意，外键只被 InnoDB 存储引擎所支持。其他引擎是不支持的。 
 
/* TRUNCATE */ ------------------ 
TRUNCATE [TABLE] tbl_name 
清空数据 
删除重建表 
区别： 
1，truncate 是删除表再创建，delete 是逐条删除 
2，truncate 重置 auto_increment 的值。而 delete 不会 
3，truncate 不知道删除了几条，而 delete 知道。 
4，当被用于带分区的表时，truncate 会保留分区 
 
 
 
/* 备份与还原 */ ------------------ 
备份，将数据的结构与表内数据保存起来。 
利用 mysqldump 指令完成。 
-- 导出 
mysqldump [options] db_name [tables] 
mysqldump [options] ---database DB1 [DB2 DB3...] 
mysqldump [options] --all--database 
1. 导出一张表 
mysqldump -u 用户名 -p 密码 库名 表名 > 文件名(D:/a.sql) 
2. 导出多张表 
mysqldump -u 用户名 -p 密码 库名 表 1 表 2 表 3 > 文件名(D:/a.sql) 
3. 导出所有表 
mysqldump -u 用户名 -p 密码 库名 > 文件名(D:/a.sql) 
4. 导出一个库 
mysqldump -u 用户名 -p 密码 --lock-all-tables --database 库名 > 文件名(D:/a.sql) 
可以-w 携带 WHERE 条件 
-- 导入 
1. 在登录 mysql 的情况下： 
source 备份文件 
2. 在不登录的情况下 
mysql -u 用户名 -p 密码 库名 < 备份文件 
 
 
 
-- 事务开启 
START TRANSACTION; 或者 BEGIN; 
开启事务后，所有被执行的 SQL 语句均被认作当前事务内的 SQL 语句。 
-- 事务提交 
COMMIT; 
-- 事务回滚 
ROLLBACK; 
如果部分操作发生问题，映射到事务开启前。 
-- 保存点 
SAVEPOINT 保存点名称 -- 设置一个事务保存点 
ROLLBACK TO SAVEPOINT 保存点名称 -- 回滚到保存点 
RELEASE SAVEPOINT 保存点名称 -- 删除保存点 
-- InnoDB 自动提交特性设置 
SET autocommit = 0|1; 0 表示关闭自动提交，1 表示开启自动提交。 
- 如果关闭了，那普通操作的结果对其他客户端也不可见，需要 commit 提交后
才能持久化数据操作。 
- 也可以关闭自动提交来开启事务。但与 START TRANSACTION 不同的是， 
SET autocommit 是永久改变服务器的设置，直到下次再次修改该设置。(针对当
前连接) 
而 START TRANSACTION 记录开启前的状态，而一旦事务提交或回滚后就需要
再次开启事务。(针对 
当前事务) 
 
 
/* 锁表 */ 
表锁定只用于防止其它客户端进行不正当地读取和写入 
MyISAM 支持表锁，InnoDB 支持行锁 
-- 锁定 
LOCK TABLES tbl_name [AS alias] 
-- 解锁 
UNLOCK TABLES 
 
 
 
/* 用户和权限管理 */ ------------------ 
-- root 密码重置 
1. 停止 MySQL 服务 
2. [Linux] /usr/local/mysql/bin/safe_mysqld --skip-grant-tables & 
[Windows] mysqld --skip-grant-tables 
3. use mysql; 
4. UPDATE `user` SET PASSWORD=PASSWORD("密码") WHERE `user` = "root"; 
5. FLUSH PRIVILEGES; 
用户信息表：mysql.user 
-- 刷新权限 
FLUSH PRIVILEGES; 
-- 增加用户 
CREATE USER 用户名 IDENTIFIED BY [PASSWORD] 密码(字符串) 
- 必须拥有 mysql 数据库的全局 CREATE USER 权限，或拥有 INSERT 权限。 
- 只能创建用户，不能赋予权限。 
- 用户名，注意引号：如 'user_name'@'192.168.1.1' 
- 密码也需引号，纯数字密码也要加引号 
- 要在纯文本中指定密码，需忽略 PASSWORD 关键词。要把密码指定为由
PASSWORD()函数返回的混编 
值，需包含关键字 PASSWORD 
-- 重命名用户 
RENAME USER old_user TO new_user 
-- 设置密码 
SET PASSWORD = PASSWORD('密码') -- 为当前用户设置密码 
SET PASSWORD FOR 用户名 = PASSWORD('密码') -- 为指定用户设置密码 
-- 删除用户 
DROP USER 用户名 
-- 分配权限/添加用户 
GRANT 权限列表 ON 表名 TO 用户名  [IDENTIFIED BY [PASSWORD] 
'password'] 
- all privileges 表示所有权限 
- *.* 表示所有库的所有表 
- 库名.表名 表示某库下面的某表 
GRANT ALL PRIVILEGES ON `pms`.* TO 'pms'@'%' IDENTIFIED BY 'pms0817'; 
-- 查看权限 
SHOW GRANTS FOR 用户名 
-- 查看当前用户权限 
SHOW GRANTS; 或  SHOW GRANTS FOR CURRENT_USER; 或  SHOW 
GRANTS FOR 
CURRENT_USER(); 
-- 撤消权限 
REVOKE 权限列表 ON 表名 FROM 用户名 
REVOKE ALL PRIVILEGES, GRANT OPTION FROM 用户名 -- 撤销所有权限 
-- 权限层级 
-- 要使用 GRANT 或 REVOKE，您必须拥有 GRANT OPTION 权限，并且您必
须用于您正在授予或撤销的权限。 
全局层级：全局权限适用于一个给定服务器中的所有数据库，mysql.user 
GRANT ALL ON *.*和 REVOKE ALL ON *.*只授予和撤销全局权限。 
数据库层级：数据库权限适用于一个给定数据库中的所有目标，mysql.db, 
mysql.host 
GRANT ALL ON db_name.*和 REVOKE ALL ON db_name.*只授予和撤销数据库
权限。 
表层级：表权限适用于一个给定表中的所有列，mysql.talbes_priv 
GRANT ALL ON db_name.tbl_name 和 REVOKE ALL ON db_name.tbl_name 只授
予和撤销表权 
限。 
列层级：列权限适用于一个给定表中的单一列，mysql.columns_priv 
当使用 REVOKE 时，您必须指定与被授权列相同的列。 
-- 权限列表 
ALL [PRIVILEGES] -- 设置除 GRANT OPTION 之外的所有简单权限 
ALTER -- 允许使用 ALTER TABLE 
ALTER ROUTINE -- 更改或取消已存储的子程序 
CREATE -- 允许使用 CREATE TABLE 
CREATE ROUTINE -- 创建已存储的子程序 
CREATE TEMPORARY TABLES -- 允许使用 CREATE TEMPORARY TABLE 
CREATE USER -- 允许使用 CREATE USER, DROP USER, RENAME USER 和
REVOKE ALL 
PRIVILEGES。 
CREATE VIEW -- 允许使用 CREATE VIEW 
DELETE -- 允许使用 DELETE 
DROP -- 允许使用 DROP TABLE 
EXECUTE -- 允许用户运行已存储的子程序 
FILE -- 允许使用 SELECT...INTO OUTFILE 和 LOAD DATA INFILE 
INDEX -- 允许使用 CREATE INDEX 和 DROP INDEX 
INSERT -- 允许使用 INSERT 
LOCK TABLES -- 允许对您拥有 SELECT 权限的表使用 LOCK TABLES 
PROCESS -- 允许使用 SHOW FULL PROCESSLIST 
REFERENCES -- 未被实施 
RELOAD -- 允许使用 FLUSH 
REPLICATION CLIENT -- 允许用户询问从属服务器或主服务器的地址 
REPLICATION SLAVE -- 用于复制型从属服务器（从主服务器中读取二进制日
志事件） 
SELECT -- 允许使用 SELECT 
SHOW DATABASES -- 显示所有数据库 
SHOW VIEW -- 允许使用 SHOW CREATE VIEW 
SHUTDOWN -- 允许使用 mysqladmin shutdown 
SUPER -- 允许使用 CHANGE MASTER, KILL, PURGE MASTER LOGS 和 SET 
GLOBAL 语句， 
mysqladmin debug 命令；允许您连接（一次），即使已达到 max_connections。 
UPDATE -- 允许使用 UPDATE  
USAGE -- “无权限”的同义词 
GRANT OPTION -- 允许授予权限 
 
 
 
员工薪资表 Employee 
Employee_id,First_name,Last_name,Salary,Department 
1. 输出第一个名字(First_name)包含'o'的所有雇员信息,并按薪资降序排序； 
select * from Employee where First_name like "%o%" order by salart desc; 
2. 输出总支出工资大于 1500000 的部门和对应的支出,并按降序排序； 
select Department,sum(salary) as sum_s from Employee group by Department having 
sum_s > 1500000 order by sum_s desc 
 
 
为什么 SELECT COUNT(*) FROM table 在 InnoDB 比 
MyISAM 慢  
对于 SELECT COUNT(*) FROM table 语句，在没有 WHERE 条件的情况下，
InnoDB 比 MyISAM 可 能会慢很多，尤其在大表的情况下。因为，InnoDB 是
去实时统计结果，会全表扫描；而 MyISAM 内部维持了一个计数器，预存了结
果，所以直接返回即可。 
 
explain 
是什么 
查看执行计划：使用 EXPLAIN 关键字可以模拟优化器执行 SQL 查询语句，从
而知道 MySQL 是如何处理 SQL 语句的。分析查询语句或是表结构的性能瓶
颈。  
能干嘛  
表的读取顺序 数据读取操作的操作类型 哪些索引可以使用 哪些索引被实际使
用 表之间的引用 每张表有多少行被优化器查询  
怎么玩  
Explain + SQL 语句。 
explain 显示了 mysql 如何使用索引来处理 select 语句以及连接表。 
explain 输出结果共有 id, select_type, table, type, possible_keys, key,key_len,ref,rows
和 Extra 几列。 
select_type 表示查询中每个 select 语句的类型，可以有下面几种 
a.SIMPLE：最简单的 SELECT 查询，没有使用 UNION 或子查询，  
b.PRIMARY：在嵌套的查询中是最外层的 SELECT 语句，在 UNION 查询中是
最前面的 SELECT 语句。 
c.UNION：UNION 中第二个以及后面的 SELECT 语句。 
d.DERIVED：派生表 SELECT 语句中 FROM 子句中的 SELECT 语句。 
e.UNION RESULT：一个 UNION 查询的结果。 
f.DEPENDENT UNION：顾名思义，首先需要满足 UNION 的条件，及 UNION
中第二个以及后面的 SELECT 语句，同时该语句依赖外部的查询。 
g.SUBQUERY：子查询中第一个 SELECT 语句 
table：显示的这一行信息是关于哪一张表的。 
type，是用来说明表与表之间是如何进行关联操作的，有没有使用索引。 
各字段解释 
1. id：select 查询的序列号，包含一组数字，表示查询中执行 select 子句或操作表的顺
序。 
id 相同，执行顺序由上至下 
id 不同，如果是子查询，id 的序号会递增，id 值越大优先级越高，越先被执行 
id 有相同也有不同：id 如果相同，可以认为是一组，从上往下顺序执行；在所有组中，
id 值 
越大，优先级越高，越先执行 
id 号每个号码，表示一趟独立的查询。一个 sql 的查询趟数越少越好。 
2. select_type：代表查询的类型，主要是用于区别普通查询、联合查询、子查询等的复杂
查询，取值 
范围如下： 
simple：简单的 select 查询，查询中不包含子查询或者 UNION 
primary：查询中若包含任何复杂的子部分，最外层查询则被标记为 primary 
derived：在 FROM 列表中包含的子查询被标记为 DERIVED (衍生)，MySQL 会递归执
行这些 
子查询, 把结果放在临时表里。 
subquery：在 SELECT 或 WHERE 列表中包含了子查询 
depedent subquery：在 SELECT 或 WHERE 列表中包含了子查询，子查询基于外层 
uncacheable subquery：无法使用缓存的子查询 
union：若第二个 SELECT 出现在 UNION 之后，则被标记为 UNION；若 UNION 包
含在 
FROM 子句的子查询中，外层 SELECT 将被标记为：DERIVED 
union result：从 UNION 表获取结果的 SELECT 
3. table：这个数据是基于哪张表的。 
4. type：是查询的访问类型。是较为重要的一个指标，结果值从最好到最坏依次是：
system > const 
> eq_ref > ref > fulltext > ref_or_null > index_merge > unique_subquery > index_subquery > 
range > index > ALL，一般来说，得保证查询至少达到 range 级别，最好能达到 ref。 
只需要记住：system > const > eq_ref > ref > range > index > ALL 就行了，其他的不常 
见。 
system：表只有一行记录（等于系统表），这是 const 类型的特列，平时不会出现，这
个也 
可以忽略不计。 
const：表示通过索引一次就找到了，const 用于比较 primary key 或者 unique 索引。因
为 
只匹配一行数据，所以很快。如将主键置于 where 列表中，MySQL 就能将该查询转换
为一个 
常量。 
eq_ref：唯一性索引扫描，对于每个索引键，表中只有一条记录与之匹配。常见于主键
或唯一 
索引扫描。 
ref：非唯一性索引扫描，返回匹配某个单独值的所有行。本质上也是一种索引访问，它
返回 
所有匹配某个单独值的行，然而，它可能会找到多个符合条件的行，所以他应该属于查
找和扫 
描的混合体。 
range：只检索给定范围的行，使用一个索引来选择行。key 列显示使用了哪个索引一般
就是 
在 where 语句中出现了 between、<、>、in 等的查询这种范围扫描索引扫描比全表扫
描要 
好，因为它只需要开始于索引的某一点，而结束语另一点，不用扫描全部索引。 
index：出现 index 是 sql 使用了索引但是没用索引进行过滤，一般是使用了覆盖索引
或者是 
利用索引进行了排序分组。 
 
all：将遍历全表以找到匹配的行。 
其他 type 如下： 
index_merge：在查询过程中需要多个索引组合使用，通常出现在有 or 关键字的 sql 中。 
ref_or_null：对于某个字段既需要过滤条件，也需要 null 值的情况下。查询优化器会选
择用 
ref_or_null 连接查询。 
index_subquery：利用索引来关联子查询，不再全表扫描。 
unique_subquery：该联接类型类似于 index_subquery。子查询中的唯一索引。 
5. possible_keys：显示可能应用在这张表中的索引，一个或多个。查询涉及到的字段上
若存在索 
引，则该索引将被列出，但不一定被查询实际使用。 
6. key：实际使用的索引。如果为 NULL，则没有使用索引。 
7. key_len：表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度。
key_len 显示的值 
为索引字段的最大可能长度，并非实际使用长度。如何计算 key_len？ 
先看索引上字段的类型 + 长度，比如：int=4; varchar(20)=20; char(20)=20 
如果是 varchar 或者 char 这种字符串字段，视字符集要乘不同的值，比如 utf-8 要乘 
3， 
GBK 要乘 2 
varchar 这种动态字符串要加 2 个字节 
允许为空的字段要加 1 个字节 
8. ref：显示索引的哪一列被使用了，如果可能的话，是一个常数。哪些列或常量被用于
查找索引列上 
的值。 
9. rows：显示 MySQL 认为它执行查询时必须检查的行数。越少越好！ 
10. Extra：其他的额外重要的信息。 
Using filesort：说明 mysql 会对数据使用一个外部的索引排序，而不是按照表内的索引
顺序 
进行读取。MySQL 中无法利用索引完成的排序操作称为“文件排序”。排序字段若通过
索引去 
访问将大大提高排序速度。 
Using temporary：使用临时表保存中间结果，MySQL 在对查询结果排序时使用临时表。
常 
见于排序 order by 和分组查询 group by。 
Using index：表示相应的 select 操作中使用了覆盖索引 (Covering Index)，避免访问了
表的 
数据行，效率不错！如果同时出现 using where，表明索引被用来执行索引键值的查找；
如果 
没有同时出现 using where，表明索引只是用来读取数据而非利用索引执行查找。 
Using where：表明使用了 where 过滤。 
Using join buffer：使用了连接缓存。 
impossible where：where 子句的值总是 false，不能用来获取任何数据。 
select tables optimized away：在没有 group by 子句的情况下，基于索引优化 MIN/MAX 
操 
作或者对于 MyISAM 存储引擎优化 COUNT(*) 操作，不必等到执行阶段再进行计算，
查询执 
行计划生成的阶段即完成优化。 
distinct：优化 distinct 操作，在找到第一匹配的元祖后即停止找同样值的动作。 
analyze table t 命令 
可以用来重新统计索引信息。 
在实践中，如果你发现 explain 的结果预估的 rows 值跟实际情况差距比较大，
可以采用这个方法来处理。 
 
从 MySQL 5.6 版本开始，alter table t engine = InnoDB（也就是 recreate）默认的
就是上面图 4 的流程了； 
 
analyze table t 其实不是重建表，只是对表的索引信息做重新统计，没有修改数
据，这个过程中加了 MDL 读锁； 
 
optimize table t 等于 recreate+analyze。 
 
 
MySQL提供了 explain 命令来查看语句的执行计划,MySQL在执行某个语句之前,
会将该语句过一遍查询优 化器,之后会拿到对语句的分析,也就是执行计划,其中
包含了许多信息. 可以通过其中和索引有关的信息来 分析是否命中了索引,例如
possilbe_key,key,key_len 等字段,分别说明了此语句可能会使用的索引,实际使 用
的索引以及使用的索引长度. 
 
 
 
count(*) 
在不同的 MySQL 引擎中，count(*) 有不同的实现方式。select count(*) from t 
 
MyISAM 引擎把一个表的总行数存在了磁盘上，因此执行 count(*) 的时候会直
接返回这个数，效率很高； 
 
而 InnoDB 引擎就麻烦了，它执行 count(*) 的时候，需要把数据一行一行地从
引擎里面读出来，然后累积计数。 
show table status 命 令 的 话 ， 发 现 这 个 命 令 的 输 出 结 果 里 面 也 有 一 个 
TABLE_ROWS，用于显示这个表当前有多少行，这个命令执行挺快的。索引统
计的值是通过采样来估算的。实际上，TABLE_ROWS 就是从这个采样估算得来
的，因此它也很不准。有多不准呢，官方文档说误差可能达到 40% 到 50%。所
以，show table status 命令显示的行数也不能直接使用。 
假设表 t 中现在有 10000 条记录，我们设计了三个用户并行的会话。 
 
会话 A 先启动事务并查询一次表的总行数； 
 
会话 B 启动事务，插入一行后记录后，查询表的总行数； 
 
会话 C 先启动一个单独的语句，插入一行记录后，查询表的总行数。 
我们假设从上到下是按照时间顺序执行的，同一行语句是在同一时刻执行的。 
 
图 1 会话 A、B、C 的执行流程 
你会看到，在最后一个时刻，三个会话 A、B、C 会同时查询表 t 的总行数，但
拿到的结果却不同。 
这和 InnoDB 的事务设计有关系，可重复读是它默认的隔离级别，在代码上就是
通过多版本并发控制，也就是 MVCC 来实现的。每一行记录都要判断自己是否
对这个会话可见，因此对于 count(*) 请求来说，InnoDB 只好把数据一行一行地
读出依次判断，可见的行才能够用于计算“基于这个查询”的表的总行数。 
InnoDB 是索引组织表，主键索引树的叶子节点是数据，而普通索引树的叶子节
点是主键值。所以，普通索引树比主键索引树小很多。对于 count(*) 这样的操
作，遍历哪个索引树得到的结果逻辑上都是一样的。因此，MySQL 优化器会找
到最小的那棵树来遍历。在保证逻辑正确的前提下，尽量减少扫描的数据量，是
数据库系统设计的通用法则之一。 
count() 是一个聚合函数，对于返回的结果集，一行行地判断，如果 count 函数
的参数不是 NULL，累计值就加 1，否则不加。最后返回累计值。 
count(*)、count(主键 id) 和 count(1) 都表示返回满足条件的结果集的总行数；
而 count(字段），则表示返回满足条件的数据行里面，参数“字段”不为 NULL 的
总个数。 
对于 count(主键 id) 来说，InnoDB 引擎会遍历整张表，把每一行的 id 值都取
出来，返回给 server 层。server 层拿到 id 后，判断是不可能为空的，就按行
累加。 
对于 count(1) 来说，InnoDB 引擎遍历整张表，但不取值。server 层对于返回
的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。 
单看这两个用法的差别的话，你能对比出来，count(1) 执行得要比 count(主键 id) 
快。因为从引擎返回 id 会涉及到解析数据行，以及拷贝字段值的操作。 
对于 count(字段) 来说： 
1. 如果这个“字段”是定义为 not null 的话，一行行地从记录里面读出这个字段，判
断不能为 null，按行累加； 
2. 如果这个“字段”定义允许为 null，那么执行的时候，判断到有可能是 null，还要
把值取出来再判断一下，不是 null 才累加。 
但是 count(*) 是例外，并不会把全部字段取出来，而是专门做了优化，不取值。
count(*) 肯定不是 null，按行累加。 
按照效率排序的话，count(字段)<count(主键 id)<count(1)≈count(*) 
案例： 
# 假设你现在维护了一个交易系统，其中交易记录表 tradelog 包含交易流水号
（tradeid）、交易员 id（operator）、交易时间（t_modified）等字段。为了便于描述，
我们先忽略其他字段。这个表的建表语句如下： 
mysql> CREATE TABLE `tradelog` ( 
  `id` int(11) NOT NULL, 
  `tradeid` varchar(32) DEFAULT NULL, 
  `operator` int(11) DEFAULT NULL, 
  `t_modified` datetime DEFAULT NULL, 
  PRIMARY KEY (`id`), 
  KEY `tradeid` (`tradeid`), 
  KEY `t_modified` (`t_modified`) 
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 
# 要统计发生在所有年份中 7 月份的交易记录总数。 
mysql> select count(*) from tradelog where month(t_modified)=7; 
现象：发现执行了特别久，才返回了结果。 
先说结论：如果对字段做了函数计算，就用不上索引了，这是 MySQL 的规定。 
为什么条件是 where t_modified='2018-7-1’的时候可以用上索引，而改成 where 
month(t_modified)=7 的时候就不行了？ 
下面是这个 t_modified 索引的示意图。方框上面的数字就是 month() 函数对应
的值。 
 
如果你的 SQL 语句条件用的是 where t_modified='2018-7-1’的话，引擎就会按
照上面绿色箭头的路线，快速定位到 t_modified='2018-7-1’需要的结果。 
实际上，B+ 树提供的这个快速定位能力，来源于同一层兄弟节点的有序性。 
但是，如果计算 month() 函数的话，你会看到传入 7 的时候，在树的第一层就
不知道该怎么办了。 
也就是说，对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就
决定放弃走树搜索功能。 
mysql 数据类型转换的规则 
这里有一个简单的方法，看 select “10” > 9 的结果： 
1. 如果规则是“将字符串转成数字”，那么就是做数字比较，结果应该是 1； 
2. 如果规则是“将数字转成字符串”，那么就是做字符串比较，结果应该是 0。 
验证结果如图 3 所示。 
 
图 3 MySQL 中字符串和数字转换的效果示意图 
从图中可知，select “10” > 9 返回的是 1，所以你就能确认 MySQL 里的转换规
则了：在 MySQL 中，字符串和数字做比较的话，是将字符串转换成数字。 
 
 
 
drop,delete 与 truncate 的区别 
drop 直接删掉表，truncate 删除表中数据，再插入时自增长 id 又从 1 开始，delete
删除表中数据，可以加 where 字句。 
1.delete 语句执行删除的过程是每次从表中删除一行，并且同时将该行的删除操
作作为事务记录在日志中保存以便进行回滚操作。truncate table 则一次性地从表
中删除所有的数据并不把单独的删除操作记录记入日志保存，删除行是不能恢复
的。并且在删除的过程中不会激活与表有关的删除触发器，执行速度快。 
2.表和索引所占空间。当表被 truncate 后，这个表和索引所占用的空间会恢复到
初始大小，而 delete 操作不会减少表或索引所占用的空间。drop 语句将表所占用
的空间全释放掉。 
3.一般而言，drop>truncate>delete 
4.应用范围。truncate 只能对 table，delete 可以是 table 和 view 
5.truncate 和 delete 只删除数据，而 drop 则删除整个表（结构和数据) 
6.truncate 与不带 where 的 delete:只删除数据，而不删除表的结构（定义）drop 语
句将删除表的结构被依赖的约束(constrain),触发器（trigger)索引(index);依赖于该
表的存储过程/函数将被保留，但其状态会变为:invalid. 
 
 
 
order_by 
假设这个表的部分定义是这样的： 
CREATE TABLE `t` ( 
  `id` int(11) NOT NULL, 
  `city` varchar(16) NOT NULL, 
  `name` varchar(16) NOT NULL, 
  `age` int(11) NOT NULL, 
  `addr` varchar(128) DEFAULT NULL, 
  PRIMARY KEY (`id`), 
  KEY `city` (`city`) 
) ENGINE=InnoDB; 
这时，你的 SQL 语句可以这么写： 
select city,name,age from t where city='杭州' order by name limit 1000  ; 
在 city 字段上创建索引之后，我们用 explain 命令来看看这个语句的执行情况。 
 
图 1 使用 explain 命令查看语句的执行情况 
Extra 这个字段中的“Using filesort”表示的就是需要排序，MySQL 会给每个线程
分配一块内存用于排序，称为 sort_buffer。 
为了说明这个 SQL 查询语句的执行过程，我们先来看一下 city 这个索引的示
意图。 
 
从图中可以看到，满足 city='杭州’条件的行，是从 ID_X 到 ID_(X+N) 的这些
记录。 
通常情况下，这个语句执行流程如下所示 ： 
1. 初始化 sort_buffer，确定放入 name、city、age 这三个字段； 
2. 从索引 city 找到第一个满足 city='杭州’条件的主键 id，也就是图中的 ID_X； 
3. 到主键 id 索引取出整行，取 name、city、age 三个字段的值，存入 sort_buffer 
中； 
4. 从索引 city 取下一个记录的主键 id； 
5. 重复步骤 3、4 直到 city 的值不满足查询条件为止，对应的主键 id 也就是图中
的 ID_Y； 
6. 对 sort_buffer 中的数据按照字段 name 做快速排序； 
7. 按照排序结果取前 1000 行返回给客户端。 
我们暂且把这个排序过程，称为全字段排序，执行流程的示意图如下所示， 
 
图中“按 name 排序”这个动作，可能在内存中完成，也可能需要使用外部排序，
这取决于排序所需的内存和参数 sort_buffer_size。 
sort_buffer_size，就是 MySQL 为排序开辟的内存（sort_buffer）的大小。如果要
排序的数据量小于 sort_buffer_size，排序就在内存中完成。但如果排序数据量太
大，内存放不下，则不得不利用磁盘临时文件辅助排序。 
SQL 约束有哪几种？ 
 
NOT NULL: 用于控制字段的内容一定不能为空（NULL）。null 值会占用更多
的字节,且会在程序中造成很多与预期不符的情况. 
 
UNIQUE: 控件字段内容不能重复，一个表允许有多个 Unique 约束。 
 
PRIMARY KEY: 也是用于控件字段内容不能重复，但它在一个表只允许出现一
个。 
 
FOREIGN KEY: 用于预防破坏表之间连接的动作，也能防止非法数据插入外键
列，因为它必须是它指向的那个表中的值之一。 
 
CHECK: 用于控制字段的值范围。 
int(11) 中的 11 代表什么涵义？ 
int(11) 中的 11，不影响字段存储的范围，只影响展示效果。 
MySQL 中的 varchar 和 char 有什么区别？ 
1.最大长度，char255 字符，varchar65535 字符； 
2.char 定长，不足的部分用隐藏空格填充，varchar 是变长的,也就是说申请的只
是最大长度,占用的空间为实际字符长度+1,最后一个字符存储使用了多长的空间； 
3.在检索效率上来讲,char > varchar,因此在使用中,如果确定某个字段的值的长
度,可以使用 char,否则应该尽量使用 varchar.例如存储用户 MD5 加密后的密
码,则应该使用 char。 
对效率要求高用 char，对空间使用要求高用 varchar。 
varchar(30) 中 30 的涵义最多存放 30 个字符。varchar(30) 和 (130) 存储 hello 
所占空间一 样，但后者在排序时会消耗更多内存，因为 ORDER BY col 采用 
fixed_length 计算 col 长度 （memory 引擎也一样）。  
 
基于 Redis 和 Mysql 的架构，如何保证数据一致性 
一般情况下，Redis 是作为应用程序和数据库之间读操作的缓存，主要目的是减
少数据库 IO，还可以提升数据查询性能。 
流程：命中缓存，从缓存 redis 中加载数据；没有缓存命中缓存，从 mysql 数据
库中加载数据；加载到的数据写入缓存； 
出现问题：当数据发生变化时，需要同时更新 Redis 和 Mysql。可能出现一方更
新失败，一方更新成功的情况，从而出现数据一致性问题。 
解决： 
1. 先更新数据库，再更新缓存； 
但是会出现问题，假设缓存更新失败，就会导致数据库和缓存中数据不一致。 
2. 先删除缓存，再更新数据库； 
理想情况下，应用程序下次访问 Redis 的时候，发现 Redis 中数据是空的，就从
数据库中去加载，然后再保存到 Redis 中，那么数据是一致的。但是在极端情况
下，并不能保证删除 Redis 中的数据和更新数据库是原子性的。如果在这个过程
中有其它线程来访问，还是会存在数据一致性问题。所以在极端情况下仍要保证
Redis 和 Mysql 的数据一致性，只能采用最终一致性方案----基于 RocketMQ 的可
靠性通信，来实现最终的一致性。可以通过 Cancel 组件监控 Mysql 中的 binlog
日志，把更新后的数据同步到 Redis 中。 
 
 
 
MySQL 中 in 和 exists 区别 
MySQL 中的 in 语句是把外表和内表作 hash 连接，而 exists 语句是对外表作 loop
循环，每次 loop 循环再对内表进行查询。一直大家都认为 exists 比 in 语句的效
率要高，这种说法其实是不准确的。这个是要区分环境的。 
如果查询的两个表大小相当，那么用 in 和 exists 差别不大。 如果两个表中一个
较小，一个是大表，则子查询表大的用 exists，子查询表小的用 in。 not in 和 not 
exists：如果查询语句使用了 not in，那么内外表都进行全表扫描，没有用到索引；
而 not extsts 的子查询依然能用到表上的索引。所以无论那个表大，用 not exists
都比 not in 要快。 
存储时期 
Datatime： 以 YYYY-MM-DD HH:MM:SS 格式存储时期时间， 精确到秒， 占
用 8 个字节得存储空间， datatime 类 型与时区无关  
Timestamp： 以时间戳格式存储，占用 4 个字节，范围小 1970-1-1 到 2038-1-
19， 显示依赖于所指定得时区， 默认 在第一个列行的数据修改时可以自动得
修改 timestamp 列得值  
Date（ 生日）： 占用得字节数比使用字符串.datatime.int 储存要少， 使用 date 
只需要 3 个字节， 存储日期月份， 还 可以利用日期时间函数进行日期间得计
算 Time:存储时间部分得数据  
注意:不要使用字符串类型来存储日期时间数据（ 通常比字符串占用得储存空间
小， 在进行查找过滤可 以利用日期得函数）使用 int 存储日期时间不如使用 
timestamp 类型 
 
 
 
举例说明 SQL 注入和解决办法 
当以字符串格式化书写方式的时候，如果用户输入的有;+SQL 语句，后面的 SQL
语句会执行，比如例子中的 SQL 注入会删除数据库 demo 
>>> input_para = 'dx' 
>>> sql = 'select * from book where name = %s' % input_para 
>>> input_para = 'dx;drop database demo' 
>>> sql01 = 'select * from book where name = %s' % input_para 
解决方式：通过传参数方式解决 SQL 注入 
SQL 注入产生的原因： 程序开发过程中不注意规范书写 sql 语句和对特殊字符
进行过滤，导致客户端可 以通过全局变量 POST 和 GET 提交一些 sql 语句正
常执行。 
防 止  SQL 注 入 的 方 式 ：  开 启 配 置 文 件 中 的  magic_quotes_gpc 和 
magic_quotes_runtime 设置  
执行 sql 语句时使用 addslashes 进行 sql 语句转换 
Sql 语句书写尽量不要省略双引号和单引号。  
过滤掉 sql 语句中的一些关键词： update、insert、delete、select、 * 。  
提高数据库表和字段的命名技巧， 对一些重要的字段根据程序的特点命名， 取
不易被猜到的； 
 
 
 
关联查询(内连接、左连接、右连接) 
将多个表联合起来进行查询，主要有内连接、左连接、右连接、全连接（外连接） 
列举几种表连接方式 
 
内连接（Inner Join）：仅将两个表中满足连接条件的行组合起来作为结果集 
o 自然连接：只考虑属性相同的元组对； 
o 等值连接：给定条件进行查询 
 
外连接（Outer Join） 
o 左连接：左边表的所有数据都有显示出来，右边的表数据只显示共同有的那部分，
没有对应的部分补 NULL； 
o 右连接：和左连接相反； 
o 全外连接（Full Outer Join）：查询出左表和右表所有数据，但是去除两表的重复
数据 
 
交叉连接（Cross Join）：返回两表的笛卡尔积（对于所含数据分别为 m、n 的表，
返回 m*n 的结果） 
 
 
 
1.2.1 SQL 执行过程 
1.2.2 binlog 三种格式类型 
1.2.3 事务两阶段提交 
1.2.4 二叉搜索树、平衡树、红黑树、B 树、B+树区别 
1.2.6 聚集索引与非聚集索引区别 
1.2.7 数据库事务四大特性 ACID 
1.2.9 redo、undo、binlog 数据库日志作用 
1.2.12 数据库行锁、表锁、乐观锁与悲观锁 
1.2.13 幻读是怎么解决的 
1.2.14 SQL 索引优化 
1.2.15 Dao 缓存先更新缓存还是数据库 
1.2.16 Mysql 高可用架构 
1.2.17 最左匹配，遇到范围查询、like 停止匹配 
1.2.18 索引下推 
1.2.19 索引覆盖 
1.2.20 判断 SQL 走了什么索引、加了什么锁 
1.2.21 避免数据库热点更新 
 
 
 
InnoDB 引擎的行锁是怎么实现的？ 
InnoDB 是基于索引来完成行锁 
例: select * from tab_with_index where id = 1 for update; 
for update 可以根据条件来完成行锁锁定，并且 id 是有索引键的列，如果 id 不
是索引键那么 InnoDB 将完成表锁，并发将无从谈起。 
MyISAM 和 InnoDB 存储引擎使用的锁 
 
MyISAM 采用表级锁(table-level locking)。 
 
InnoDB 支持行级锁(row-level locking)和表级锁，默认为行级锁 
 
 
问题 1：MySQL 8.0 - Client does not support authentication protocol requested by 
server; consider upgradingMySQL client 
ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY 'password' 
flush privileges; 
请写一段 Python 连接 Mysql 数据库的代码 
conn = pymysql.connect(host='localhost', port=3306, user='root', passwd='1234', db='user', 
charset='utf8mb4')#声明 mysql 连接对象 
cursor = conn.cursor(cursor=pymysql.cursors.DictCursor)#查询结果以字典的形式 
cursor.execute(sql 语句字符串)#执行 sql 语句 
conn.close()#关闭链接 
Mysql 基本知识点 
至于关系模型，则是一种所谓建立在关系上的模型，其包含三个方面，分别为： 
数据结构：数据存储的形式，二维表（行和列）； 
操作指令集合：所有的 SQL 语句； 
完整性约束：表内数据约束（字段与字段）和表与表之间的约束（外键）。 
非关系型数据库：Memcached、MongoDB 和 Redis 等。 
将 MySQL 数据库服务器的内部对象分为四层，分别为：数据管理系统（DBMS）
–> 数据库（DB）–> 表（Table）–> 字段（Filed） 
计算机仅识别二进制数据，而且人类则更倾向于识别字符（符号），因此就需要
一个二进制与字符的对应关系，也就是字符集。 
SQL 主要分为三种： 
DDL：Data Definition Language，数据定义语言，用来维护存储数据的结构（数
据库、表），代表指令为 create、drop 和 alter 等。 
DML：Data Manipulation Language，数据操作语言，用来对数据进行操作（表
中的内容）代表指令为 insert、delete 和 update 等，不过在 DML 内部又单独进
行了一个分类，即 DQL（Data Query Language），数据查询语言，代表指令为
select. 
DCL：Data Control Language，数据控制语言，主要是负责（用户）权限管理，
代表指令为 grant 和 revoke 等。 
列属性有很多，例如：null、not null、default、primary key、unique key、auto_increment
和 comment 等 
mysql 功能模块 
大体来说，MySQL 可以分为 Server 层和存储引擎层两部分。 
Server 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的
大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），
所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。 
而存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、
MyISAM、Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 
MySQL 5.5.5 版本开始成为了默认存储引擎。 
也就是说，你执行 create table 建表的时候，如果不指定引擎类型，默认使用的
就是 InnoDB。不过，你也可以通过指定存储引擎的类型来选择别的引擎，比如
在 create table 语句中使用 engine=memory, 来指定使用内存引擎创建表。不同
存储引擎的表数据存取方式不同，支持的功能也不同。 
从图中不难看出，不同的存储引擎共用一个 Server 层，也就是从连接器到执行
器的部分。 
 
联合索引是什么?为什么需要注意联合索引中的顺序? 
MySQL 可以使用多个字段同时建立一个索引，做联合索引。联合索引中,如果想
要命中索引，要按照建立索引时的字段顺序挨个使用，则无法命中索引.  
具体原因为: MySQL 使用索引时需要索引有序，设现在建立了"name,age,school"
的联合索引,那么索引的排序为: 先按照 name 排序，果 name 相同，按照 age 排
序，果 age 的值也相等,则按照 school 进行排序. 当进行查询时,此时索引仅仅按
照 name 严格有序，此必须首先使用 name 字段进行等值查询,之后对于匹 配到
的列而言,其按照 age 字段严格有序，此时可以使用 age 字段用做索引查找,,,以此
类推.因此在建立联合索引的时候应该注意索引列的顺序，一般情况下，将查询需
求频繁或者字段选择性高的列放在前面.此外可以根据特例的查询或者表结构进
行单独的调整。 
索引的工作原理及其种类 
数据库索引，是数据库管理系统中一个排序的数据结构，以协助快速查询，更新
数据库表中数据。索引的实现通常使用 B 树以其变种 B+树。 
在数据之外，数据库系统还维护着满足特定查找算法的数据结构，这些数据结构
以某种方式引用（指向）数据，这样就可以在这些数据结构上实现高级查找算法。
这种数据结构，就是索引。 
为表设置索引要付出代价的：一是增加了数据库的存储空间，二是在插入和修改
数据时要花费较多的时间（因为索引也要随之变动） 
所有的关系都是指表与表之间的关系。 
一对一，即一张表的一条记录只能与另外一张表的一条记录相对应，反之亦然。 
一对多，即一张表中的记录可以对应另外一张表中的多条记录，但是反过来，另
外一张表中的一条记录只能对应第一张表中的一条记录。 
多对多，即一张表中的记录可以对应另外一张表中的多条记录，反过来，另外一
张表中的一条记录也可以对应第一张表中的多条记录。 
mysql 的索引怎么使用（索引匹配方式） 
利用 B-Tree 索引进行全局关键字、关键字范围和关键字前缀的查询 
全值匹配 
全值匹配指的是和索引中所有的列进行匹配 
explain select * from staffs where name = 'July' and age = 23 and pos = 'dev' 
而我们建立了一个 包含 name、age、pos 的组合索引，使用上面的 SQL 语句，
就会进行全值匹配 
匹配最左前缀 
只匹配前面的几列 
explain select * from staffs where name = 'July' and age = 23 
这个时候，只使匹配了前面两个列，而没有使用第三个列 
匹配列前缀 
可以匹配某一列值的开头部分 
explain select * from staffs where name = 'J%' 
explain select * from staffs where name = '%y' 
匹配范围值 
可以查找某个范围的数据 
explain select * from staffs where name > 'Mary' 
精确匹配某一列并范围匹配另外一列 
可以查询某一列的全部和第二列的部分 
explain select * from staffs where name = "July" and age > 25 
只访问索引的查询 
查询的时候值需要访问索引，不需要访问数据行，本质上就是索引覆盖 
explain select name,age,pos from staffs where name="July" and age=25 and pos = "dev" 
 
主键索引和唯一键索引区别 
1）主键是一种约束，唯一索引是一种索引，两者在本质上是不同的。 
2）主键创建后一定包含一个唯一性索引，唯一性索引并不一定就是主键。 
3）唯一性索引列允许空值，而主键列不允许为空值。 
4）主键列在创建时，已经默认为空值 + 唯一索引了。 
5）主键可以被其他表引用为外键，而唯一索引不能。 
6）一个表最多只能创建一个主键，但可以创建多个唯一索引。 
7）主键更适合那些不容易更改的唯一标识，如自动递增列、身份证号等。 
8）在 RBO 模式下，主键的执行计划优先级要高于唯一索引。 两者可以提高查
询的速度。 
主键 超键 候选键 外键 
主键：数据库表中对存储数据对象予以唯一和完整标识的数据列或属性的组合。
一个数据列只能有一个主键，且主键的取值不能缺失，即不能为空值(Null). 
超键：在关系中能唯一标识元组的属性集称为关系模式的超键。一个属性可以作
为一个超键，多个属性组合在一起也可以作为一个超键。超键包含候选键和主键。 
候选键：是最小超键，即没有冗余元素的超键。 
外键：在一个表中存在的另一个表的主键称此表的外键。 
唯一键索引和普通索引的选择 
从这两种索引对查询语句和更新语句的性能影响来进行分析。 
 
查询过程 
执行查询的语句是 select id from T where k=5。这个查询语句在索引树上查找的
过程，先是通过 B+ 树从树根开始，按层搜索到叶子节点，也就是图中右下角的
这个数据页，然后可以认为数据页内部通过二分法来定位记录。 
 
对于普通索引来说，查找到满足条件的第一个记录 (5,500) 后，需要查找下一个
记录，直到碰到第一个不满足 k=5 条件的记录。 
 
对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，
就会停止继续检索。 
那么，这个不同带来的性能差距会有多少呢？答案是，微乎其微。 
InnoDB 的数据是按数据页为单位来读写的。也就是说，当需要读一条记录的时
候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。
在 InnoDB 中，每个数据页的大小默认是 16KB。 
更新过程 
当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页
还没有在内存中的话，在不影响数据一致性的前提下，InooDB 会将这些更新操
作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。在下次
查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中
与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。 
虽然名字叫作 change buffer，实际上它是可以持久化的数据。也就是说，change 
buffer 在内存中有拷贝，也会被写入到磁盘上。 
将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 merge。
除了访问这个数据页会触发 merge 外，系统有后台线程会定期 merge。在数据
库正常关闭（shutdown）的过程中，也会执行 merge 操作。 
显然，如果能够将更新操作先记录在 change buffer，减少读磁盘，语句的执行速
度会得到明显的提升。而且，数据读入内存是需要占用 buffer pool 的，所以这
种方式还能够避免占用内存，提高内存利用率。 
那么，什么条件下可以使用 change buffer 呢？ 
对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。
比如，要插入 (4,400) 这个记录，就要先判断现在表中是否已经存在 k=4 的记
录，而这必须要将数据页读入内存才能判断。如果都已经读入到内存了，那直接
更新内存会更快，就没必要使用 change buffer 了。 
因此，唯一索引的更新就不能使用 change buffer，实际上也只有普通索引可以
使用。 
change buffer 用的是 buffer pool 里的内存，因此不能无限增大。change buffer 的
大小，可以通过参数 innodb_change_buffer_max_size 来动态设置。这个参数设置
为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%。 
如果要在这张表中插入一个新记录 (4,400) 的话，InnoDB 的处理流程是怎样的。 
第一种情况是，这个记录要更新的目标页在内存中。这时，InnoDB 的处理流程
如下： 
 
对于唯一索引来说，找到 3 和 5 之间的位置，判断到没有冲突，插入这个值，
语句执行结束； 
 
对于普通索引来说，找到 3 和 5 之间的位置，插入这个值，语句执行结束。 
第二种情况是，这个记录要更新的目标页不在内存中。这时，InnoDB 的处理流
程如下： 
 
对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语
句执行结束； 
 
对于普通索引来说，则是将更新记录在 change buffer，语句执行就结束了。 
将数据从磁盘读入内存涉及随机 IO 的访问，是数据库里面成本最高的操作之一。
change buffer 因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。 
对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时 
change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。 
反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条
件，将更新先记录在 change buffer，但之后由于马上要访问这个数据页，会立即
触发 merge 过程。这样随机访问 IO 的次数不会减少，反而增加了 change buffer 
的维护代价。所以，对于这种业务模式来说，change buffer 反而起到了副作用。 
普通索引和唯一索引应该怎么选择。其实，这两类索引在查询能力上是没差别的，
主要考虑的是对更新性能的影响。所以，我建议你尽量选择普通索引。 
索引选择异常和处理 
一种方法是，像我们第一个例子一样，采用 force index 强行选择一个索引。
MySQL 会根据词法解析的结果分析出可能可以使用的索引作为候选项，然后在
候选列表中依次判断每个索引需要扫描多少行。如果 force index 指定的索引在
候选索引列表中，就直接选择这个索引，不再评估其他索引的执行代价。 
第二种方法就是，我们可以考虑修改语句，引导 MySQL 使用我们期望的索引。 
第三种方法是，在有些场景下，我们可以新建一个更合适的索引，来提供给优化
器做选择，或删掉误用的索引 
字符串字段加索引 
维护一个支持邮箱登录的系统，用户表是这么定义的： 
mysql> create table SUser( 
ID bigint unsigned primary key, 
email varchar(64),  
...  
)engine=innodb;  
mysql> select f1, f2 from SUser where email='xxx'; 
业务代码出现次语句时，如果 email 这个字段没有加索引，那么这个语句就会全
表扫描； 
MySQL 是支持前缀索引的，也就是说，你可以定义字符串的一部分作为索引。
默认地，如果你创建索引的语句不指定前缀长度，那么索引就会包含整个字符串。 
比如，这两个在 email 字段上创建索引的语句： 
mysql> alter table SUser add index index1(email); 
或 
mysql> alter table SUser add index index2(email(6)); 
第一个语句创建的 index1 索引里面，包含了每个记录的整个字符串； 
而第二个语句创建的 index2 索引里面，对于每个记录都是只取前 6 个字节。 
由于 email(6) 这个索引结构中每个邮箱字段都只取前 6 个字节，所以占用的空
间会更小，这就是使用前缀索引的优势。 
但，这同时带来的损失是，可能会增加额外的记录扫描次数。 
接下来，我们再看看下面这个语句，在这两个索引定义下分别是怎么执行的。 
select id,name,email from SUser where email='zhangssxyz@xxx.com'; 
如果使用的是 index1（即 email 整个字符串的索引结构），执行顺序是这样的： 
1. 从 index1 索引树找到满足索引值是’zhangssxyz@xxx.com’的这条记录，取得 
ID2 的值； 
2. 到主键上查到主键值是 ID2 的行，判断 email 的值是正确的，将这行记录加入
结果集； 
3. 取  index1 索 引 树 上 刚 刚 查 到 的 位 置 的 下 一 条 记 录 ， 发 现 已 经 不 满 足 
email='zhangssxyz@xxx.com’的条件了，循环结束。 
这个过程中，只需要回主键索引取一次数据，所以系统认为只扫描了一行。 
如果使用的是 index2（即 email(6) 索引结构），执行顺序是这样的： 
1. 从 index2 索引树找到满足索引值是’zhangs’的记录，找到的第一个是 ID1； 
2. 到 主 键 上 查 到 主 键 值 是  ID1 的 行 ， 判 断 出  email 的 值 不
是’zhangssxyz@xxx.com’，这行记录丢弃； 
3. 取 index2 上刚刚查到的位置的下一条记录，发现仍然是’zhangs’，取出 ID2，再
到 ID 索引上取整行然后判断，这次值对了，将这行记录加入结果集； 
4. 重复上一步，直到在 idxe2 上取到的值不是’zhangs’时，循环结束。 
在这个过程中，要回主键索引取 4 次数据，也就是扫描了 4 行。 
也就是说使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加
太多的查询成本。但是，使用前缀索引就用不上覆盖索引对查询性能的优化了，
这也是你在选择是否使用前缀索引时需要考虑的一个因素。 
比如这个语句，select id,email from SUser where email='zhangssxyz@xxx.com'; 
所以，如果使用 index1（即 email 整个字符串的索引结构）的话，可以利用覆
盖索引，从 index1 查到结果后直接就返回了，不需要回到 ID 索引再去查一次。
而如果使用 index2（即 email(6) 索引结构）的话，就不得不回到 ID 索引再去
判断 email 字段的值。即使将 index2 的定义修改为 email(18) 的前缀索引，
InnoDB 还是要回到 id 索引再查一下。 
实际上，我们在建立索引时关注的是区分度，区分度越高越好。因为区分度越高，
意味着重复的键值越少。因此，我们可以通过统计索引上有多少个不同的值来判
断要使用多长的前缀。 
1. 直接创建完整索引，这样可能比较占用空间； 
2. 创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引； 
3. 倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题； 
4. 创建 hash 字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式
一样，都不支持范围扫描。 
遇到前缀的区分度不够好的情况时，我们要怎么办呢？ 
身份证号，一共 18 位，其中前 6 位是地址码，所以同一个县的人的身份证号
前 6 位一般会是相同的。 
假设你维护的数据库是一个市的公民信息系统，这时候如果对身份证号做长度为 
6 的前缀索引的话，这个索引的区分度就非常低了。 
第一种方式是使用倒序存储。 
如果你存储身份证号的时候把它倒过来存，每次查询的时候，你可以这么写： 
mysql> select field_list from t where id_card = reverse('input_id_card_string'); 
第二种方式是使用 hash 字段。 
你可以在表上再创建一个整数字段，来保存身份证的校验码，同时在这个字段上
创建索引。 
mysql> alter table t add id_card_crc int unsigned, add index(id_card_crc); 
然后每次插入新记录的时候，都同时用 crc32() 这个函数得到校验码填到这个新
字段。由于校验码可能存在冲突，也就是说两个不同的身份证号通过 crc32() 函
数得到的结果可能是相同的，所以你的查询语句 where 部分要判断 id_card 的
值是否精确相同。 
mysql> select field_list from t where id_card_crc=crc32('input_id_card_string') and 
id_card='input_id_card_string' 
这样，索引的长度变成了 4 个字节，比原来小了很多。 
 
 
 
 
 
 
主从复制 
什么是 MySQL 主从同步？ 
主从同步使得数据可以从一个数据库服务器复制到其他服务器上，在复制数据时，
一个服务器充当主服务器（master），其余的服务器充当从服务器（slave）。 
因为复制是异步进行的，所以从服务器不需要一直连接着主服务器，从服务器甚
至可以通过拨号断断续续地连接主服务器。通过配置文件，可以指定复制所有的
数据库，某个数据库，甚至是某个数据库上的某个表。 
MySQL 主从同步的目的？为什么要做主从同步？ 
1. 通过增加从服务器来提高数据库的性能，在主服务器上执行写入和更新，在从服
务器上向外提供读功能，可以动态地调整从服务器的数量，从而调整整个数据库
的性能。 
2. 提高数据安全-因为数据已复制到从服务器，从服务器可以终止复制进程，所以，
可以在从服务器上备份而不破坏主服务器相应数据 
3. 在主服务器上生成实时数据，而在从服务器上分析这些数据，从而提高主服务器
的性能 
4. 数据备份。一般我们都会做数据备份，可能是写定时任务，一些特殊行业可能还
需要手动备份，有些行业要求备份和原数据不能在同一个地方，所以主从就能很
好的解决这个问题，不仅备份及时，而且还可以多地备份，保证数据的安全 
如何实现 MySQL 的读写分离？ 
其实很简单，就是基于主从复制架构，简单来说，就搞一个主库，挂多个从库，
然后我们就单单只是写主库，然后主库会自动把数据给同步到从库上去。 
MySQL 主从复制流程和原理？ 
基本原理流程，是 3 个线程以及之间的关联 
主：binlog 线程——记录下所有改变了数据库数据的语句，放进 master 上的 binlog
中； 
从：io 线程——在使用 start slave 之后，负责从 master 上拉取 binlog 内容，放
进自己的 relay log 中； 
从：sql 执行线程——执行 relay log 中的语句； 
复制过程如下： 
Binary log：主数据库的二进制日志 
Relay log：从服务器的中继日志 
第一步：master 在每个事务更新数据完成之前，将该操作记录串行地写入到 binlog
文件中。 
第二步：salve 开启一个 I/O Thread，该线程在 master 打开一个普通连接，主要工
作是 binlog dump process。如果读取的进度已经跟上了 master，就进入睡眠状态
并等待 master 产生新的事件。I/O 线程最终的目的是将这些事件写入到中继日志
中。 
第三步：SQL Thread 会读取中继日志，并顺序执行该日志中的 SQL 事件，从而
与主数据库中的数据保持一致。 
MySQL 主从同步延时问题如何解决？ 
MySQL 实际上在有两个同步机制，一个是半同步复制，用来 解决主库数据丢失
问题；一个是并行复制，用来 解决主从同步延时问题。 
 
半同步复制，也叫 semi-sync 复制，指的就是主库写入 binlog 日志之后，就会
将强制此时立即将数据同步到从库，从库将日志写入自己本地的 relay log 之后，
接着会返回一个 ack 给主库，主库接收到至少一个从库的 ack 之后才会认为写
操作完成了。 
 
并行复制，指的是从库开启多个线程，并行读取 relay log 中不同库的日志，然
后并行重放不同库的日志，这是库级别的并行。 
什么是主从复制？实现原理是什么？ 
主从复制（Replication）是指数据可以从一个 MySQL 数据库主服务器复制到一
个或多个从服务器，从服务器可以复制主服务器中的所有数据库或者特定的数据
库，或者特定的表。默认采用异步模式。 
实现原理： 
 
主服务器 binary log dump 线程：将主服务器中的数据更改（增删改）日志写入 
Binary log 中； 
 
从服务器 I/O 线程：负责从主服务器读取 binary log，并写入本地的 Relay log； 
 
从服务器 SQL 线程：负责读取 Relay log，解析出主服务器已经执行的数据更
改，并在从服务器中重新执行（Replay），保证主从数据的一致性 
为什么要主从复制？ 
 
展开 
 
读写分离：主服务器负责写，从服务器负责读 
o 缓解了锁的争用，即使主服务器中加了锁，依然可以进行读操作； 
o 从服务器可以使用 MyISAM，提升查询性能以及节约系统开销； 
o 增加冗余，提高可用性 
 
数据实时备份，当系统中某个节点发生故障时，可以方便的故障切换 
 
降低单个服务器磁盘 I/O 访问的频率，提高单个机器的 I/O 性能 
 
mysql 怎么实现主从复制 
Master 开启 bin-log 功能，服务器配置二进制日志（binlog 日志），只保留 update
等的数据。 需要开启三个线程，Master：I/O 线程；Slave：I/O 线程，SQL 线程。 
从数据库会请求主数据库的 binlog 日志，将 bin-log 日志内容写入到 relay-log 中
继日志，创建一个 master.info 文件，然后按日志执行 Slave 已经开启了 sql 线程，
由 sql 线程实时监测 relay-log 日志内容是否有更新，如果有更新，则解析文件中
的 sql 语句，并在 Slave 数据库中执行相同的操作语句。 
数据库锁 
为什么要加锁? 
当多个用户并发地存取数据时，在数据库中就会产生多个事务同时存取同一数据
的情况。若对并发操作不加控制就可能会读取和存储不正确的数据，破坏数据库
的一致性。 
保证多用户环境下保证数据库完整性和一致性。 
按照锁的粒度分数据库锁有哪些？ 
在关系型数据库中，可以按照锁的粒度把数据库锁分为行级锁(INNODB 引擎)、
表级锁(MYISAM 引擎)和页级锁(BDB 引擎 )。 
行级锁 
 
行级锁是 MySQL 中锁定粒度最细的一种锁，表示只针对当前操作的行进行加锁。
行级锁能大大减少数据库操作的冲突。其加锁粒度最小，但加锁的开销也最大。
行级锁分为共享锁 和 排他锁。 
 
开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度
也最高。 
表级锁 
 
表级锁是 MySQL 中锁定粒度最大的一种锁，表示对当前操作的整张表加锁，它
实现简单，资源消耗较少，被大部分 MySQL 引擎支持。最常使用的 MYISAM 与
INNODB 都支持表级锁定。表级锁定分为表共享读锁（共享锁）与表独占写锁
（排他锁）。 
 
开销小，加锁快；不会出现死锁；锁定粒度大，发出锁冲突的概率最高，并发度
最低。 
页级锁 
 
页级锁是 MySQL 中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，
但冲突多，行级冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组
记录。BDB 支持页级锁 
 
开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之
间，并发度一般 
MyISAM 和 InnoDB 存储引擎使用的锁： 
 
MyISAM 采用表级锁(table-level locking)。 
 
InnoDB 支持行级锁(row-level locking)和表级锁，默认为行级锁 
从锁的类别上分 MySQL 都有哪些锁呢？ 
从锁的类别上来讲，有共享锁和排他锁。 
 
共享锁: 又叫做读锁。 当用户要进行数据的读取时，对数据加上共享锁。共享锁
可以同时加上多个。 
 
排他锁: 又叫做写锁。 当用户要进行数据的写入时，对数据加上排他锁。排他锁
只可以加一个，他和其他的排他锁，共享锁都相斥。 
用上面的例子来说就是用户的行为有两种，一种是来看房，多个用户一起看房是
可以接受的。 一种是真正的入住一晚，在这期间，无论是想入住的还是想看房
的都不可以。 
锁的粒度取决于具体的存储引擎，InnoDB 实现了行级锁，页级锁，表级锁。 
他们的加锁开销从大到小，并发能力也是从大到小。 
数据库的乐观锁和悲观锁是什么？怎么实现的？ 
数据库管理系统（DBMS）中的并发控制的任务是确保在多个事务同时存取数据
库中同一数据时不破坏事务的隔离性和统一性以及数据库的统一性。乐观并发控
制（乐观锁）和悲观并发控制（悲观锁）是并发控制主要采用的技术手段。 
 
悲观锁：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。在查询完
数据的时候就把事务锁起来，直到提交事务。实现方式：使用数据库中的锁机制；
应用于数据更新比较频繁的场景 
使用 select ... for update 锁定行数据，更新完提交数据后自动释放行数据，此期
间其它事务无法更新行数据； 
 
乐观锁：假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。在
修改数据的时候把事务锁起来，通过 version 的方式来进行锁定。适用于读多写
少的场景。实现方式：乐观锁一般会使用版本号机制或 CAS 算法实现。乐观锁
的实现方式有：1. 加一个版本号或者时间戳字段，每次数据更新时同时更新这个
字段；2. 先读取想要更新的字段或者所有字段，更新的时候比较一下，只有字段
没有变化才进行更新。 
update set data=?,v=v+1 where id=1 and v=2; 
两种锁的使用场景 
从上面对两种锁的介绍，我们知道两种锁各有优缺点，不可认为一种好于另一种，
像乐观锁适用于写比较少的情况下（多读场景），即冲突真的很少发生的时候，
这样可以省去了锁的开销，加大了系统的整个吞吐量。 
但如果是多写的情况，一般会经常产生冲突，这就会导致上层应用会不断的进行
retry，这样反倒是降低了性能，所以一般多写的场景下用悲观锁就比较合适。 
InnoDB 引擎的行锁是怎么实现的？ 
InnoDB 是基于索引来完成行锁 
例: select * from tab_with_index where id = 1 for update; 
for update 可以根据条件来完成行锁锁定，并且 id 是有索引键的列，如果 id 不
是索引键那么 InnoDB 将完成表锁，并发将无从谈起 
什么是死锁？怎么解决？ 
死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方的资源，从而
导致恶性循环的现象。 
常见的解决死锁的方法 
1、如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可以大大
降低死锁机会。 
2、在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概
率； 
3、对于非常容易产生死锁的业务部分，可以尝试使用升级锁定颗粒度，通过表
级锁定来减少死锁产生的概率； 
如果业务处理不好可以用分布式事务锁或者使用乐观锁 
隔离级别与锁的关系 
在 Read Uncommitted 级别下，读取数据不需要加共享锁，这样就不会跟被修改
的数据上的排他锁冲突 
在 Read Committed 级别下，读操作需要加共享锁，但是在语句执行完以后释放
共享锁； 
在 Repeatable Read 级别下，读操作需要加共享锁，但是在事务提交之前并不释
放共享锁，也就是必须等待事务执行完毕以后才释放共享锁。 
SERIALIZABLE 是限制性最强的隔离级别，因为该级别锁定整个范围的键，并
一直持有锁，直到事务完成。 
优化锁方面的意见？ 
 
使用较低的隔离级别 
 
设计索引，尽量使用索引去访问数据，加锁更加精确，从而减少锁冲突 
 
选择合理的事务大小，给记录显示加锁时，最好一次性请求足够级别的锁。列如，
修改数据的话，最好申请排他锁，而不是先申请共享锁，修改时在申请排他锁，
这样会导致死锁 
 
不同的程序访问一组表的时候，应尽量约定一个相同的顺序访问各表，对于一个
表而言，尽可能的固定顺序的获取表中的行。这样大大的减少死锁的机会。 
 
尽量使用相等条件访问数据，这样可以避免间隙锁对并发插入的影响 
 
不要申请超过实际需要的锁级别 
 
数据查询的时候不是必要，不要使用加锁。MySQL 的 MVCC 可以实现事务中的
查询不用加锁，优化事务性能：MVCC 只在 committed read（读提交）和 repeatable 
read （可重复读）两种隔离级别 
 
对于特定的事务，可以使用表锁来提高处理速度活着减少死锁的可能。 
mysql 中的锁 
根据加锁的范围，MySQL 里面的锁大致可以分成全局锁、表级锁和行锁三类 
全局锁 
MySQL 提供了一个加全局读锁的方法，命令是 Flush tables with read lock 
(FTWRL)。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其
他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包
括建表、修改表结构等）和更新类事务的提交语句。 
全局锁的典型使用场景是，做全库逻辑备份。也就是把整库每个表都 select 出来
存成文本。 
mysqldump 使用参数–single-transaction 的时候，导数据之前就会启动一个事务，
来确保拿到一致性视图。而由于 MVCC 的支持，这个过程中数据是可以正常更
新的。single-transaction 方法只适用于所有的表使用事务引擎的库。 
既然要全库只读，为什么不使用 set global readonly=true 的方式呢？ 
 
一是，在有些系统中，readonly 的值会被用来做其他逻辑，比如用来判断一个库
是主库还是备库。因此，修改 global 变量的方式影响面更大，我不建议你使用。 
 
二是，在异常处理机制上有差异。如果执行 FTWRL 命令之后由于客户端发生
异常断开，那么 MySQL 会自动释放这个全局锁，整个库回到可以正常更新的状
态。而将整个库设置为 readonly 之后，如果客户端发生异常，则数据库就会一
直保持 readonly 状态，这样会导致整个库长时间处于不可写状态，风险较高。 
表级锁 
MySQL 里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，
MDL)。 
表锁的语法是 lock tables … read/write。与 FTWRL 类似，可以用 unlock tables 
主动释放锁，也可以在客户端断开的时候自动释放。需要注意，lock tables 语法
除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。 
举个例子, 如果在某个线程 A 中执行 lock tables t1 read, t2 write; 这个语句，则
其他线程写 t1、读写 t2 的语句都会被阻塞。同时，线程 A 在执行 unlock tables 
之前，也只能执行读 t1、读写 t2 的操作。连写 t1 都不允许，自然也不能访问
其他表。 
在还没有出现更细粒度的锁的时候，表锁是最常用的处理并发的方式。而对于 
InnoDB 这种支持行锁的引擎，一般不使用 lock tables 命令来控制并发，毕竟锁
住整个表的影响面还是太大。 
另一类表级的锁是 MDL（metadata lock)。MDL 不需要显式使用，在访问一个
表的时候会被自动加上。MDL 的作用是，保证读写的正确性。你可以想象一下，
如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做
变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。 
因此，在 MySQL 5.5 版本中引入了 MDL，当对一个表做增删改查操作的时候，
加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁。 
 
读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。 
 
读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如
果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。 
事务中的 MDL 锁，在语句执行开始时申请，但是语句结束后并不会马上释放，
而会等到整个事务提交后再释放。 
行锁 
MySQL 的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持
行锁，比如 MyISAM 引擎就不支持行锁。 
InnoDB 是支持行锁的。 
行锁就是针对数据表中行记录的锁。这很好理解，比如事务 A 更新了一行，而
这时候事务 B 也要更新同一行，则必须等事务 A 的操作完成后才能进行更新。 
在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻
释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。 
如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁
尽量往后放。我给你举个例子。 
假设你负责实现一个电影票在线交易业务，顾客 A 要在影院 B 购买电影票。
我们简化一点，这个业务需要涉及到以下操作： 
1. 从顾客 A 账户余额中扣除电影票价； 
2. 给影院 B 的账户余额增加这张电影票价； 
3. 记录一条交易日志。 
也就是说，要完成这个交易，我们需要 update 两条记录，并 insert 一条记录。
当然，为了保证交易的原子性，我们要把这三个操作放在一个事务中。那么，你
会怎样安排这三个语句在事务中的顺序呢？ 
试想如果同时有另外一个顾客 C 要在影院 B 买票，那么这两个事务冲突的部
分就是语句 2 了。因为它们要更新同一个影院账户的余额，需要修改同一行数
据。 
根据两阶段锁协议，不论你怎样安排语句顺序，所有的操作需要的行锁都是在事
务提交的时候才释放的。所以，如果你把语句 2 安排在最后，比如按照 3、1、
2 这样的顺序，那么影院账户余额这一行的锁时间就最少。这就最大程度地减少
了事务之间的锁等待，提升了并发度。 
好了，现在由于你的正确设计，影院余额这一行的行锁在一个事务中不会停留很
长时间。但是，这并没有完全解决你的困扰。 
死锁和死锁检测 
当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资
源时，就会导致这几个线程都进入无限等待的状态，称为死锁。 
当出现死锁以后，有两种策略： 
 
一 种 策 略 是 ， 直 接 进 入 等 待 ， 直 到 超 时 。 这 个 超 时 时 间 可 以 通 过 参 数 
innodb_lock_wait_timeout 来设置。 
 
另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，
让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启
这个逻辑。 
在 InnoDB 中，innodb_lock_wait_timeout 的默认值是 50s，意味着如果采用第一
个策略，当出现死锁以后，第一个被锁住的线程要过 50s 才会超时退出，然后
其他线程才有可能继续执行。对于在线服务来说，这个等待时间往往是无法接受
的。 
但是，我们又不可能直接把这个时间设置成一个很小的值，比如 1s。这样当出
现死锁的时候，确实很快就可以解开，但如果不是死锁，而是简单的锁等待呢？
所以，超时时间设置太短的话，会出现很多误伤。 
所以，正常情况下我们还是要采用第二种策略，即：主动死锁检测，而且 
innodb_deadlock_detect 的默认值本身就是 on。主动死锁检测在发生死锁的时候，
是能够快速发现并进行处理的，但是它也是有额外负担的。 
你可以想象一下这个过程：每当一个事务被锁的时候，就要看看它所依赖的线程
有没有被别人锁住，如此循环，最后判断是否出现了循环等待，也就是死锁。 
那如果是我们上面说到的所有事务都要更新同一行的场景呢？ 
每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一
个时间复杂度是 O(n) 的操作。假设有 1000 个并发线程要同时更新同一行，那
么死锁检测操作就是 100 万这个量级的。虽然最终检测的结果是没有死锁，但
是这期间要消耗大量的 CPU 资源。因此，你就会看到 CPU 利用率很高，但是
每秒却执行不了几个事务。 
说说什么是锁升级？  
MySQL 行锁只能加在索引上，如果操作不走索引，就会升级为表锁。因为 
InnoDB 的行锁是加在索引上的，如果不走索引，自然就没法使用行锁了，原因
是 InnoDB 是将 primary key index 和相关的行数据共同放在 B+ 树的叶节点。
InnoDB 一定会有一个 primary key，secondary index 查找的时候，也是通过找到
对应的 primary，再找对应的数据行。  
当非唯一索引上记录数超过一定数量时，行锁也会升级为表锁。测试发现当非唯
一索引相同的 内容不少于整个表记录的二分之一时会升级为表锁。因为当非唯
一索引相同的内容达到整个记 录的二分之一时，索引需要的性能比全文检索还
要大，查询语句优化时会选择不走索引，造成 索引失效，行锁自然就会升级为
表锁。 
常见的封锁类型？ 
意向锁是 InnoDB 自动加的， 不需用户干预。 对于 UPDATE、 DELETE 和 
INSERT 语句， InnoDB 会自动给涉及数据集加排他锁（X)； 对于普通 SELECT 
语句，InnoDB 不会加任何锁； 事务可以通过以下语句显式给记录集加共享锁或
排他锁： 共享锁（S）：SELECT * FROM table_name WHERE ... LOCK IN SHARE 
MODE。 其他 session 仍然可以查询记录，并也可以对该记录加 share mode 的
共享锁。但是如果当前事务需要对该记录进行更新操作，则很有可能造成死锁。 
排他锁（X)：SELECT * FROM table_name WHERE ... FOR UPDATE。其他 session 
可以查询该记录，但是不能对该记录加共享锁或排他锁，而是等待获得锁 
 
排它锁（Exclusive Lock）/ X 锁：事务对数据加上 X 锁时，只允许此事务读取和
修改此数据，并且其它事务不能对该数据加任何锁； 
 
共享锁（Shared Lock）/ S 锁：加了 S 锁后，该事务只能对数据进行读取而不能
修改，并且其它事务只能加 S 锁，不能加 X 锁 
 
意向锁 
（Intention Locks）： 
o 一个事务在获得某个数据行对象的 S 锁之前，必须先获得整个表的 IS 锁或更
强的锁； 
o 一个事务在获得某个数据行对象的 X 锁之前，必须先获得整个表的 IX 锁； 
o IS/IX 锁之间都是兼容的； 
o 好处：如果一个事务想要对整个表加 X 锁，就需要先检测是否有其它事务对该
表或者该表中的某一行加了锁，这种检测非常耗时。有了意向锁之后，只需要检
测整个表是否存在 IX/IS/X/S 锁就行了 
锁的作用：用于管理对共享资源的并发访问，保证数据库的完整性和一致性 
 
封锁粒度的概念 
MySQL 中提供了两种封锁粒度：行级锁以及表级锁。 
封锁粒度小： 
 
好处：锁定的数据量越少，发生锁争用的可能就越小，系统的并发程度就越高； 
 
坏处：系统开销大（加锁、释放锁、检查锁的状态都需要消耗资源） 
MySQL 加锁 
SELECT ... LOCK In SHARE MODE; 
SELECT ... FOR UPDATE; 
 
什么是三级封锁协议？ 
 
一级封锁协议：事务在修改数据之前必须先对其加 X 锁，直到事务结束才释放。
可以解决丢失修改问题（两个事务不能同时对一个数据加 X 锁，避免了修改被
覆盖）； 
 
二级封锁协议：在一级的基础上，事务在读取数据之前必须先加 S 锁，读完后释
放。可以解决脏读问题（如果已经有事务在修改数据，就意味着已经加了 X 锁，
此时想要读取数据的事务并不能加 S 锁，也就无法进行读取，避免了读取脏数
据）； 
 
三级封锁协议：在二级的基础上，事务在读取数据之前必须先加 S 锁，直到事务
结束才能释放。可以解决不可重复读问题（避免了在事务结束前其它事务对数据
加 X 锁进行修改，保证了事务期间数据不会被其它事务更新） 
什么是两段锁协议？ 
事务必须严格分为两个阶段对数据进行加锁和解锁的操作，第一阶段加锁，第二
阶段解锁。也就是说一个事务中一旦释放了锁，就不能再申请新锁了。 
可串行化调度是指，通过并发控制，使得并发执行的事务结果与某个串行执行的
事务结果相同。事务遵循两段锁协议是保证可串行化调度的充分条件。 
InnoDB 存储引擎的锁的算法有三种 
Record lock：单个行记录上的锁； 
Gap lock：间隙锁，锁定一个范围，不包括记录本身； 
Next-key lock：record+gap 锁定一个范围，包含记录本身 
MVCC(Multi-Version Concurrency Control) 
多版本并发控制（Multi-Version Concurrency Control, MVCC），MVCC 在每行记
录后面都保存有两个隐藏的列，用来存储创建版本号和删除版本号。 
MVCC 的实现，是通过保存数据在某个时间点的快照来实现的。根据事务开始
的时间不同，每个事务对同一张表，同一时刻看到的数据可能是不一样的。 
同一条记录在系统中可以存在多个版本，这就是数据库的多版本并发控制
（MVCC）。 
 
创建版本号：创建一个数据行时的事务版本号（事务版本号：事务开始时的系统
版本号；系统版本号：每开始一个新的事务，系统版本号就会自动递增）； 
 
删除版本号：删除操作时的事务版本号； 
 
各种操作： 
o 插入操作时，记录创建版本号； 
o 删除操作时，记录删除版本号； 
o 更新操作时，先记录删除版本号，再新增一行记录创建版本号； 
o 查询操作时，要符合以下条件才能被查询出来：删除版本号未定义或大于当前事
务版本号（删除操作是在当前事务启动之后做的）；创建版本号小于或等于当前
事务版本号（创建操作是事务完成或者在事务启动之前完成） 
通过版本号减少了锁的争用，提高了系统性能；可以实现提交读和可重复读两种
隔离级别，未提交读无需使用 MVCC 
 
快照读与当前读 
使用 MVCC 读取的是快照中的数据，这样可以减少加锁所带来的开销： 
select * from table ...; 
当前读读取的是最新的数据，需要加锁。以下第一个语句需要加 S 锁，其它都
需要加 X 锁： 
select * from table where ? lock in share mode; 
select * from table where ? for update; 
insert; 
update; 
delete; 
 
MVCC 可以为数据库解决什么问题？  
在并发读写数据库时，可以做到在读操作时不用阻塞写操作，写操作也不用阻塞
读操作，提高了数 据库并发读写的性能。同时还可以解决脏读、幻读、不可重
复读等事务隔离问题，但不能解决更新丢失问题。 
MVCC 的实现原理 
对于 InnoDB ，聚簇索引记录中包含 3 个隐藏的列： 
 
ROW ID：隐藏的自增 ID，如果表没有主键，InnoDB 会自动按 ROW ID 产生一
个聚集索引树。 
 
事务 ID：记录最后一次修改该记录的事务 ID。 
 
回滚指针：指向这条记录的上一个版本。 
我们拿上面的例子，对应解释下 MVCC 的实现原理，如下图： 
 
如图，首先 insert 语句向表 t1 中插入了一条数据，a 字段为 1，b 字段为 1， 
ROW ID 也为 1 ，事务 ID 假设为 1，回滚指针假设为 null。当执行 update t1 
set b=666 where a=1 时，大致步骤如下： 
 
数据库会先对满足 a=1 的行加排他锁； 
 
然后将原记录复制到 undo 表空间中； 
 
修改 b 字段的值为 666，修改事务 ID 为 2； 
 
并通过隐藏的回滚指针指向 undo log 中的历史记录； 
 
事务提交，释放前面对满足 a=1 的行所加的排他锁。 
在前面实验的第 6 步中，session2 查询的结果是 session1 修改之前的记录，这
个记录就是来自 undolog 中。 
因此可以总结出 MVCC 实现的原理大致是： 
InnoDB 每一行数据都有一个隐藏的回滚指针，用于指向该行修改前的最后一个
历史版本，这个历史版本存放在 undo log 中。如果要执行更新操作，会将原记
录放入 undo log 中，并通过隐藏的回滚指针指向 undo log 中的原记录。其它事
务此时需要查询时，就是查询 undo log 中这行数据的最后一个历史版本。 
MVCC 最大的好处是读不加锁，读写不冲突，极大地增加了 MySQL 的并发性。
通过 MVCC，保证了事务 ACID 中的 I（隔离性）特性。 
 
视图 
视图：view，是一种结构（有行有列），但没有结果（结构中不真实存放数据）
的虚拟表，虚拟表的结构来源不是自己定义的，而是从对应的基表（视图的数据
来源）中产生的。 
视图：从数据库的基本表中通过查询选取出来的数据组成的 
CREATE VIEW <视图名> AS <SELECT 语句> 
# 在 tb_students_info 表上创建一个名为 view_students_info 的视图 
CREATE VIEW view_students_info 
-> AS SELECT * FROM tb_students_info; 
# 修改视图 
ALTER VIEW view_students_info AS SELECT id,name,age FROM tb_students_info; 
用户可以通过视图来插入、更新、删除表中的数据，因为视图是一个虚拟的表，
没有数据。通过视图更新时转到基本表上进行更新，如果对视图增加或删除记录，
实际上是对基本表增加或删除记录。 
DROP VIEW IF EXISTS v_students_info;  # 删除视图 
 
虚拟表（数据库中存放视图的定义）。可以对其进行增/删/改/查等操作。视图是
对若干张基本表的引用，一张虚表，查询语句执行的结果，不存储具体的数据（基
本表数据发生了改变，视图也会跟着改变）；可以跟基本表一样，进行增删改查
操作(ps:增删改操作有条件限制)；如连表查询产生的视图无法进行，对视图的增
删改会影响原表的数据。好处： 
通过只给用户访问视图的权限，保证数据的安全性； 
简化复杂的 SQL 操作，隐藏数据的复杂性（比如复杂的连接）； 
游标（Cursor）：用于定位在查询返回的结果集的特定行，以对特定行进行操作。
使用游标可以方便地对结果集进行移动遍历，根据需要滚动或对浏览/修改任意
行中的数据。主要用于交互式应用。 
在 MySQL 里，有两个“视图”的概念： 
 
一个是 view。它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句
并生成结果。创建视图的语法是 create view … ，而它的查询方法与表一样。 
 
另一个是 InnoDB 在实现 MVCC 时用到的一致性读视图，即 consistent read 
view，用于支持 RC（Read Committed，读提交）和 RR（Repeatable Read，可重
复读）隔离级别的实现。 
视图的作用，视图可以更改么？ 
视图是虚拟的表，与包含数据的表不一样，视图只包含使用时动态检索数据的查
询;不包含任何列或数据。使用视图可以简化复杂的 sql 操作，隐藏具体的细节，
保护数据;视图创建后，可以使用与表相同的方式利用它们。 
视图不能被索引，也不能有关联的触发器或默认值，如果视图本身内有 order by
则对视图再次 order by 将被覆盖。 
创建视图： create view xxx as xxxxxx 
对于某些视图比如未使用联结子查询分组聚集函数 Distinct Union 等，是可以对
其更新的，对视图的更新将对基表进行更新;但是视图主要用于简化检索，保护
数据，并不用于更新，而且大部分视图都不可以更新。 
 
 
 
binlog(归档日志) 
MySQL 的 binlog 是记录所有数据库表结构变更（例如 CREATE、ALTER 
TABLE）以及表数据修改（INSERT、UPDATE、DELETE）的二进制日志。binlog 
不会记录 SELECT 和 SHOW 这类操作，因为这类操作对数据本身并没有修改，
但你可以通过查询通用日志来查看 MySQL 执行过的所有语句。 
MySQL binlog 以事件形式记录，还包含语句所执行的消耗的时间，MySQL 的
二进制日志是事务安全型的。binlog 的主要目的是复制和恢复。 
binlog 有三种格式，各有优缺点： 
 
statement： 基于 SQL 语句的模式，某些语句和函数如 UUID, LOAD DATA 
INFILE 等在复制过程可能导致数据不一致甚至出错。 
 
row： 基于行的模式，记录的是行的变化，很安全。但是 binlog 会比其他两种
模式大很多，在一些大表中清除大量数据时在 binlog 中会生成很多条语句，可
能导致从库延迟变大。 
 
mixed： 混合模式，根据语句来选用是 statement 还是 row 模式。 
1. redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有
引擎都可以使用。 
2. redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑
日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。 
3. redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是
指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。 
mysql> update T set c=c+1 where ID=2; 
update 语句的执行流程图，图中浅色框表示是在 InnoDB 内部执行的，深色框
表示是在执行器中执行的。 
 
1. 执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。
如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，
需要先从磁盘读入内存，然后再返回。 
2. 执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，
得到新的一行数据，再调用引擎接口写入这行新数据。 
3. 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，
此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交
事务。 
4. 执行器生成这个操作的 binlog，并把 binlog 写入磁盘。 
5. 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）
状态，更新完成。 
两阶段提交 
数据库表的空间回收 
一个 InnoDB 表包含两部分，即：表结构定义和数据。在 MySQL 8.0 版本以前，
表结构是存在以.frm 为后缀的文件里。而 MySQL 8.0 版本，则已经允许把表结
构定义放在系统数据表中了。因为表结构定义占用的空间很小，所以我们今天主
要讨论的是表数据。 
参数 innodb_file_per_table 
表数据既可以存在共享表空间里，也可以是单独的文件。这个行为是由参数 
innodb_file_per_table 控制的： 
1. 这个参数设置为 OFF 表示的是，表的数据放在系统共享表空间，也就是跟数据
字典放在一起； 
2. 这个参数设置为 ON 表示的是，每个 InnoDB 表数据存储在一个以 .ibd 为后
缀的文件中。 
我建议你不论使用 MySQL 的哪个版本，都将这个值设置为 ON。因为，一个表
单独存储为一个文件更容易管理，而且在你不需要这个表的时候，通过 drop table 
命令，系统就会直接删除这个文件。而如果是放在共享表空间中，即使表删掉了，
空间也是不会回收的。 
数据删除流程 
记录的复用：只限于符合范围条件的数据。指的是一条数据；这条数据（在 B+
树的某两个记录中间时）删除后，再插入的数据还是在某两个记录中间，即可以
复用此记录位置； 
数据页的复用：当整个页从 B+ 树里面摘掉以后，可以复用到任何位置。 
如果相邻的两个数据页利用率都很小，系统就会把这两个页上的数据合到其中一
个页上，另外一个数据页就被标记为可复用。 
进一步地，如果我们用 delete 命令把整个表的数据删除呢？结果就是，所有的
数据页都会被标记为可复用。但是磁盘上，文件不会变小。也就是说，通过 delete 
命令是不能回收表空间的。这些可以复用，而没有被使用的空间，看起来就像是
“空洞”。 
不止是删除数据会造成空洞，插入数据也会。 
经过大量增删改的表，都是可能是存在空洞的。所以，如果能够把这些空洞去掉，
就能达到收缩表空间的目的。 
而重建表，就可以达到这样的目的。 
重建表 
你可以新建一个与表 A 结构相同的表 B，然后按照主键 ID 递增的顺序，把数
据一行一行地从表 A 里读出来再插入到表 B 中。 
由于表 B 是新建的表，所以表 A 主键索引上的空洞，在表 B 中就都不存在了。
显然地，表 B 的主键索引更紧凑，数据页的利用率也更高。如果我们把表 B 作
为临时表，数据从表 A 导入表 B 的操作完成后，用表 B 替换 A，从效果上看，
就起到了收缩表 A 空间的作用。 
这里，你可以使用 alter table A engine=InnoDB 命令来重建表。在 MySQL 5.5 版
本之前，这个命令的执行流程跟我们前面描述的差不多，区别只是这个临时表 B 
不需要你自己创建，MySQL 会自动完成转存数据、交换表名、删除旧表的操作。 
MySQL 5.6 版本开始引入的 Online DDL，对这个操作流程做了优化。 
简单描述一下引入了 Online DDL 之后，重建表的流程： 
1. 建立一个临时文件，扫描表 A 主键的所有数据页； 
2. 用数据页中表 A 的记录生成 B+ 树，存储到临时文件中； 
3. 生成临时文件的过程中，将所有对 A 的操作记录在一个日志文件（row log）中，
对应的是图中 state2 的状态； 
4. 临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与
表 A 相同的数据文件，对应的就是图中 state3 的状态； 
5. 用临时文件替换表 A 的数据文件。 
 
由于日志文件记录和重放操作这个功能的存在，这个方案在重建表的过程中，允
许对表 A 做增删改操作。 
MySQL 如何做到高可用方案？  
MySQL 高可用，意味着不能一台 MySQL 出了问题，就不能访问了。  
1. MySQL 高可用：分库分表，通过 MyCat 连接多个 MySQL  
2. MyCat 也得高可用：Haproxy，连接多个 MyCat  
3. Haproxy 也得高可用：通过 keepalived 辅助 Haproxy 
mysql tips 
#  
CREATE TABLE `t` ( 
  `id` int(11) NOT NULL, 
  `c` int(11) DEFAULT NULL, 
  `d` int(11) DEFAULT NULL, 
  PRIMARY KEY (`id`), 
  KEY `c` (`c`) 
) ENGINE=InnoDB; 
  
insert into t values(0,0,0),(5,5,5), 
(10,10,10),(15,15,15),(20,20,20),(25,25,25); 
 
# 语句 
begin; 
select * from t where d=5 for update; 
commit; 
# 这个语句会命中 d=5 的这一行，对应的主键 id=5，因此在 select 语句执行完成后，
id=5 这一行会加一个写锁，而且由于两阶段锁协议，这个写锁会在执行 commit 语句的
时候释放。 
 
 
 
8. Redis 
NoSQL---一类新出现的数据库（Not only Sql） 
# 不支持 SQL 语法； 
# 存储结构跟传统的关系型数据库中的那种关系表完全不同，nosql 中存储的数据都是
Key-Value 形式; 
# NoSQL 的世界没有一种通用的语言，每种 NoSQL 数据库都有自己的 api 和语法，以
及擅长的业务领域； 
# NoSQL 基本不支持事务； 事务---一组 sql 操作，要么都成功，要么都失败； 
种类： 
Mongodb 
Redis 
Hbase hadoop 
Cassandra hadoop   
 
Redis 基础 
特性： 
1. Redis 支持数据的持久化，可以将内存中的数据保存到磁盘中，重启的时候可以再次
加载进行使用； 
2. Redis 不仅支持简单的 key-value 类型的数据，同时还提供 list,set,zset,hash 等数据结构
的存储； 
3. Redis 支持数据的备份，即 master-slave 模式的数据备份； 
 
# redis 配置 
/etc/redis/redis.conf 
 
# 核心配置选项 
1. 绑定 ip;如果需要远程访问，可将此行注释掉，或绑定一个真实的 ip；bind 127.0.0.1 
2. 端口，默认为 6379 
3. 是否以守护进程运行； 
   如果以守护进程运行，则不会在命令行阻塞，类似于服务； 
   如果不以守护进程运行，则当前终端被阻塞； 
   daemonize yes 
4. 数据文件；dbfilename dump.rdb 
5. 数据文件存储路径；dir /var/lib/redis 
6. 日志文件；logfile /var/log/redis/redis-server.log 
7. 数据库，默认有 16 个；database 16; 
8. 主从复制，类似于双机备份；slaveof 
 
 
# 服务端 
服务端命令为 redis-server  
使用服务的方式管理 redis 服务： 
启动：service redis start  
停止：service redis stop 
重启：service redis restart  
redis-server /etc/redis/redis.conf 指定加载的配置文件； 
 
# 客户端 
客户端命令为 redis-cli 
连接 redis---redis-cli 
运行测试  ping-->回应 PONG 
数据库没有名称，默认有 16 个，通过 0-15 标识，连接 redis 默认选择第一个数据库； 
select n 
 
 
# Redis 中默认有多少个哈希槽? 
2^14 个 
Redis 集群没有使用一致性 hash, 而是引入了哈希槽的概念。 
请写一段 Python 连接 Redis 数据库的代码 
from redis import StrictRedis, ConnectionPool 
redis_url="redis://:xxxx@112.27.10.168:6379/15" 
pool = ConnectionPool.from_url(redis_url, decode_responses=True) 
r= StrictRedis(connection_pool=pool) 
 
redis 的数据结构（5 种） 
String hash set zset list 
string 
# 保存 
set key value  
 
 
    # 设置键值 
setex key seconds value      # 设置键值以及保存时间，以秒为单位； 
mset key1 value1 key2 value2 # 设置多个键值 
append key value             # 追加值 
 
# 获取 
get key                      # 根据键获取值，如果不存在此键返回 nil 
mget key1 key2...            # 根据多个键获取多个值； 
 
 
 
# 键命令 
keys pattern                 # 查找键，参数支持正则表达式 
keys *                       # 查看所有键 
keys 'a*'                    # 查看名称重包含 a 的键 
exists a1                    # 判断键 a1 是否存在 
type key                     # 查看键对应的 value 值的类型 
del key1 key2...             # 删除键及对应的值 
expire 'a1' 3                # 设置过期时间，设置键 a1 的过期时间为 3 秒 
ttl key                      # 查看有效时间 
 
hash 
hash 用于存储对象，对象的结构为属性、值 
值的类型为 string 
 
 
# 增加，修改 
hset key field value         # 设置键 key 的属性 field 为 value 
hset key field1 value1 field2 value2  # 设置多个属性 
 
 
# 获取 
hkey key                     # 获取指定键的所有属性 
hget key field               # 获取一个属性的值 
hmget key field1 field2...   # 获取多个属性的值 
hvals key                    # 获取所有属性的值 
 
# 删除 
删除整个 hash 键与值            # 使用 del 命令 
hdel key field1 field2       # 删除属性，属性对应的值会相应删除 
 
 
####  21.2. <a name='hash'></a>hash 的底层数据结构 
ziplist（压缩列表）和 hashtable 
list 
# 列表中的元素类型为 string 
# 按照插入顺序排序 
 
# 增加 
lpush key value1 value2...       # 在左侧插入数据 
rpush key value1 value2...       # 在右侧插入数据 
linsert key before 或 after 现有元素 新元素   # 在指定元素的前或后插入新元素 
 
# 获取 
lrange key start stop            # start 和 stop 为元素的下标索引，第一个元素索引为
0，索引可以为负数，表示从尾部开始计数； 
 
# 设置指定索引位置的元素值 
lset key index value  
 
# 删除 
lrem key count value              # 将列表中钱 count 次出现的值为 value 的元素移
除，count>0:从头到尾移除，count<0:从尾到头移除，count=0:移除所有； 
 
 
 
####  21.3. <a name='list'></a>list 的底层数据实现结构 
ziplist 或 linkedlist 
set 
# 无序集合 
# 元素为 string 类型 
# 元素具有唯一性，不重复 
# 集合没有修改操作 
 
# 增加 
sadd key member1 member2...      # 添加元素 
 
# 获取 
smembers key                     # 返回所有元素 
 
# 删除 
srem key member1                 # 删除指定元素 
 
 
 
zset 
sorted set，有序集合 
元素为 string 类型 
元素具有唯一性，不重复 
每个元素都会关联一个 double 类型的 score，表示权重，通过权重将元素从小到大排序 
说明：没有修改操作 
 
 
# 添加 
zadd key score1 member1 score2 member2...                  
 
# 获取 
zrange key start stop            # 返回指定范围内的元素,索引可以为负数，表示从尾
部开始计数；start，stop 为元素的下标索引,索引从左侧开始，第一个元素为 0 
zrangebyscore key min max        # 返回 score 值在 min 和 max 之间的成员 
zscore key member                # 返回成员 member 的 score 
 
# 删除 
zrem key member1 member2...      # 删除指定元素 
zremrangebyscore key min max     # 删除 score 值在 min 和 max 之间的成员 
 
 
####  21.4. <a name='zset'></a>zset 的底层数据实现结构 
zset 底层的存储结构包括 ziplist 或 skiplist，在同时满足以下两个条件的时候使用 ziplist，
其他时候使用 skiplist，两个条件如下： 
有序集合保存的元素数量小于 128 个 
有序集合保存的所有元素的长度小于 64 字节 
 
Redis 的数据类型有哪些？ 
有五种常用数据类型：String、Hash、Set、List、SortedSet。以及三种特殊的数据
类型：Bitmap、HyperLogLog、Geospatial ，其中 HyperLogLog、Bitmap 的底层
都是 String 数据类型，Geospatial 的底层是 Sorted Set 数据类型。 
五种常用的数据类型： 
1、String：String 是最常用的一种数据类型，普通的 key- value 存储都可以归为
此类。其中 Value 既可以是数字也可以是字符串。使用场景：常规 key-value 缓
存应用。常规计数: 微博数， 粉丝数。 
2、Hash：Hash 是一个键值(key => value)对集合。Redishash 是一个 string 类型
的 field 和 value 的映射表，hash 特别适合用于存储对象，并且可以像数据库
中 update 一个属性一样只修改某一项属性值。 
3、Set：Set 是一个无序的天然去重的集合，即 Key-Set。此外还提供了交集、并
集等一系列直接操作集合的方法，对于求共同好友、共同关注什么的功能实现特
别方便。 
4、List：List 是一个有序可重复的集合，其遵循 FIFO 的原则，底层是依赖双向
链表实现的，因此支持正向、反向双重查找。通过 List，我们可以很方面的获得
类似于最新回复这类的功能实现。 
5、SortedSet：类似于 java 中的 TreeSet，是 Set 的可排序版。此外还支持优先级
排序，维护了一个 score 的参数来实现。适用于排行榜和带权重的消息队列等场
景。 
三种特殊的数据类型： 
1、Bitmap：位图，Bitmap 想象成一个以位为单位数组，数组中的每个单元只能
存 0 或者 1，数组的下标在 Bitmap 中叫做偏移量。使用 Bitmap 实现统计功能，
更省空间。如果只需要统计数据的二值状态，例如商品有没有、用户在不在等，
就可以使用 Bitmap，因为它只用一个 bit 位就能表示 0 或 1。 
2 、 Hyperloglog 。 HyperLogLog 是 一 种 用 于 统 计 基 数 的 数 据 集 合 类 型 ，
HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大 
时，计算基数所需的空间总是固定 的、并且是很小的。每个 HyperLogLog 键只
需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基 数。场景：统计
网页的 UV（即 Unique Visitor，不重复访客，一个人访问某个网站多次，但是还
是只计算为一次）。 
要注意，HyperLogLog 的统计规则是基于概率完成的，所以它给出的统计结果是
有一定误差的，标准误算率是 0.81%。 
3、Geospatial ：主要用于存储地理位置信息，并对存储的信息进行操作，适用场
景如朋友的定位、附近的人、打车距离计算等。 
redis 中的跳跃表 
跳跃表是一种有序的数据结构，它通过在每个节点维持多个指向其他节点的指针，
从而达到快速访问节点的目的。 
 
跳跃表基于单链表加索引的方式实现 
 
跳跃表以空间换时间的方式提升了查找速度 
 
Redis 有序集合在节点元素较大或者元素数量较多时使用跳跃表实现 
 
Redis 的跳跃表实现由 zskiplist 和 zskiplistnode 两个结构组成,其中 zskiplist 用
于保存跳跃表信息(比如表头节点、表尾节点、长度),而 zskiplistnode 则用于表示
跳跃表节点 
 
Redis 每个跳跃表节点的层高都是 1 至 32 之间的随机数 
 
在同一个跳跃表中,多个节点可以包含相同的分值,但每个节点的成员对象必须是
唯一的，跳跃表中的节点按照分值大小进行排序,当分值相同时,节点按照成员对
象的大小进行排序。 
redis 缓存 
缓存穿透 
# 举例说明缓存穿透 
我现在有一个博客详情页，然后博客详情页中的内容假设是存储在 Redis 中的，然后通
过博客的 Uid 进行获取，正常的情况是：用户进入博客详情页，然后通过 uid 获取 redis
中缓存的文章详情，如果有内容就直接访问，如果不存在内容，那么需要访问数据库，
然后从数据库中查询我们的博客详情后，然后在存储到 redis 中，最后在把数据返回给
我们的页面。 
但是可能存在一些非法用户，他可能会模拟出很多不存在的 key，然后通过该 key 去请
求后台，首先 redis 的缓存没有命中，那么就去请求数据库，最后数据库没有查询出该
内容，这样很多个非法的请求直接打在数据库中，可能会导致数据库直接宕机，无法对
外提供服务。这就是我们所说的缓存穿透问题。 
 
# 简单的解决方法 
针对这个情况，我们有一种简单的解决方法就是，在数据库没有查询该条数据的时候，
我们让该 key 缓存一个 空数据，这样用户再次以该 key 请求后台的时候，会直接返回
null，避免了再次请求数据库。 
 
 
# 什么是布隆过滤器？ 
布隆过滤器的巨大作用 ，就是能够迅速判断一个元素是否存在一个集合中。因此次他
有如下几个使用场景： 
网站爬虫对 URL 的去重，避免爬取相同的 URL 
反垃圾邮件，从数十亿个垃圾邮件列表中判断某邮箱是否是垃圾邮件（同理，垃圾短信） 
缓存穿透，将所有可能的数据缓存放到布隆过滤器中，当黑客访问不存在的缓存时，迅
速返回避免缓存以及 DB 挂掉。 
 
 
布隆过滤器原理 
布隆过滤器其内部维护了一个全为 0 的 bit 数组，需要说明的是，布隆过滤器有
一个误判的概念，误判率越低，则数组越长，所占空间越大。误判率越高则数组
越小，所占的空间越小。 
假设，根据误判率，我们生成一个 10 位的 bit 数组，以及 2 个 hash 函数 f1 和 
f2，如下图所示：生成的数组的位数 和 hash 函数的数量，我们不用去关心如何
生成的，这是有数学论文进行验证。 
 
然后我们输入一个集合，集合中包含 N1 和 N2，我们通过计算 f1(N1) = 2，f2(N1) 
= 5，则将数组下标为 2 和下标为 5 的位置设置成 1，就得到了下图 
 
同理，我们再次进行计算 N2 的值， f1(N2) = 3，f2(N2) = 6。得到如下所示的图 
 
这个时候，假设我们有第三个数 N3 过来了，我们需要判断 N3 是否在集合 [N1,N2]
中，我们需要做的操作就是，使用 f1 和 f2 计算出数组中的地址 
 
若值恰巧都位于上图的红色位置，我们认为 N3 在集合 [N1,N2] 中 
 
若值有一个不位于上图的红色部分，我们认为 N3 不在集合[N1,N2] 中 
这就是布隆过滤器的计算原理。 
要是分布式缓存发生雪崩了怎么办，要怎么防止发生 
当缓存服务器重启或者大量缓存集中在某一个时间段失效，这样在失效的时候，
也会给后端系统(比如 DB)带来很大压力。通俗讲就是：缓存雪崩可能是因为数
据未加载到缓存中，或者缓存同一时间大面积的失效，从而导致所有请求都去查
数据库，导致数据库 CPU 和内存负载过高，甚至宕机。 
如何防止： 
缓存失效或，通过加锁或队列来控制读取数据库的访问的线程数量，比如对某个
key 值运行一个线程访问数据库，其他线程等待不同的 key，设置不同的过期时
间，让环创失效的时间点尽量均匀做二级缓存，a1 失效时候，访问 a2，a1 失效
的时间设置为短期，a2 为长期 
缓存调度算法 
有哪几种实现方法 
先进先出 FIFO 最近最少使用 LRU 最不经常使用算法 LFU，根据在一段时间里
页面被使用的次数选择出最少使用的页 最优替换（不能实现） LRU 的实现方
案 
用一个数组来存储数据，给每一个数据项标记一个访问时间戳，每次插入新数据
项的时候，先把数组中存在的数据项的时间戳自增，并将新数据项的时间戳置为
0 并插入到数组中。每次访问数组中的数据项的时候，将被访问的数据项的时间
戳置为 0。当数组空间已满时，将时间戳最大的数据项淘汰。 利用一个链表来实
现，每次新插入数据的时候将新数据插到链表的头部；每次缓存命中（即数据被
访问），则将数据移到链表头部；那么当链表满的时候，就将链表尾部的数据丢
弃。 利用链表和 hashmap。当需要插入新的数据项的时候，如果新数据项在链
表中存在（一般称为命中），则把该节点移到链表头部，如果不存在，则新建一
个节点，放到链表头部，若缓存满了，则把链表最后一个节点删除即可。在访问
数据的时候，如果数据项在链表中存在，则把该节点移到链表头部，否则返回-1。
这样一来在链表尾部的节点就是最近最久未访问的数据项。 
主从配置 
####  21.5. <a name='-1'></a>主从概念 
一个 master 可以有多个 slave，一个 slave 又可以拥有多个 slave，如此下去，形成强大
的多级服务器集群架构； 
master 用来写数据，slave 用来读数据，经统计：网站的读写比例为 10:1； 
通过主从配置可以实现读写分离； 
master 和 slave 都是一个 redis 实例（服务）； 
 
 
1. 配置主 
# 修改/etc/redis/redis.conf 文件； 
bind masterip    
# 重启 redis-server;   
service redis stop   
redis-server /etc/redis/redis.conf 
 
2. 配置从 
# 复制/etc/redis/redis.conf，重命名 slave.conf，之后修改  
bind slaveip 
slaveof masterip masterport 
port slaveport 
# 启动 redis 服务 
redis-server /etc/redis/slave.conf 
 
3. 查看主从关系 
redis-cli -h masterip -p masterport info Replication    #主服务的主从关系 
redis-cli -h masterip -p masterport info Replication    #从服务的主从关系 
 
 
 
 
搭建集群 
# 集群是一组相互独立的、通过高速网络互联的计算机，它们构成了一个组，并以单一
系统的模式加以管理。一个客户与集群相互作用时，集群就像是一个独立的服务器。集
群配置是用于提高可用性和可缩放性。 
 
 
# redis 集群 
1. 软件层面； 
只有一台电脑，在这台电脑上启动多个 redis 服务； 
2. 硬件层面； 
存在多台实体的电脑，每台电脑都启动一个 redis 或者多个 redis 服务； 
 
分布式锁 
共享资源+并发请求的时候才会需要加锁。 
锁----是一种参照（也可以是目录/对象）,具有排他性； 
自旋----while True； 
抢锁失败，进入阻塞队列； 
分布式锁是控制分布式系统之间的同步访问共享资源的一种方式。 
分布式锁的实现有三种方式 
 
数据库乐观锁 
 
基于 Redis 的分布式锁 
 
基于 Zookeeper 的分布式锁 
分布式锁满足的条件 
为了确保分布式锁可用，我们至少要保证锁的实现同时满足以下几个条件 
 
互斥性：在任意时刻只有一个客户端能持有锁； 
 
不会死锁：即使有一个客户端在持有锁的期间发生崩溃而没有主动解锁，也能保
证后续其它客户端能加锁； 
 
容错性：只要大部分的 Redis 节点正常运行，客户端就可以加锁和解锁； 
 
解铃还须系铃人：加锁和解锁必须是同一个客户端，客户端自己不能把别人加的
锁给解除； 
 
锁超时：支持超时释放锁，防止死锁 高效，高可用：加锁和解锁需要高效，同
时也需要保证高可用防止分布式锁失效，可以增加降级； 
 
支持阻塞和非阻塞：可以实现超时获取失败，tryLock(long timeOut) 支持公平锁
和非公平锁。 
加锁代码 
public class RedisTool { 
 
    private static final String LOCK_SUCCESS = "OK"; 
    private static final String SET_IF_NOT_EXIST = "NX"; 
    private static final String SET_WITH_EXPIRE_TIME = "PX"; 
 
    /** 
     * 尝试获取分布式锁 
     * @param jedis Redis 客户端 
     * @param lockKey 锁 
     * @param requestId 请求标识 
     * @param expireTime 超期时间 
     * @return 是否获取成功 
     */ 
    public static boolean tryGetDistributedLock(Jedis jedis, String lockKey, String requestId, 
int expireTime) { 
         
        String 
result 
= 
jedis.set(lockKey, 
requestId, 
SET_IF_NOT_EXIST, 
SET_WITH_EXPIRE_TIME, expireTime); 
 
        if (LOCK_SUCCESS.equals(result)) { 
            return true; 
        } 
        return false; 
    } 
} 
可以看到，我们加锁就一行代码：jedis.set(String key, String value, String nxxx, String expx, 
int time)，这个 set()方法一共有五个形参 
 
第一个为 key，我们使用 key 来当锁，因为 key 是唯一的。 
第二个为 value，我们传的是 requestId，很多童鞋可能不明白，有 key 作为锁不就够了
吗，为什么还要用到 value？原因就是我们在上面讲到可靠性时，分布式锁要满足第四
个条件解铃还须系铃人，通过给 value 赋值为 requestId，我们就知道这把锁是哪个请求
加的了，在解锁的时候就可以有依据。requestId 可以使用 UUID.randomUUID().toString()
方法生成。 
第三个为 nxxx，这个参数我们填的是 NX，意思是 SET IF NOT EXIST，即当 key 不存
在时，我们进行 set 操作；若 key 已经存在，则不做任何操作； 
第四个为 expx，这个参数我们传的是 PX，意思是我们要给这个 key 加一个过期的设置，
具体时间由第五个参数决定。 
第五个为 time，与第四个参数相呼应，代表 key 的过期时间。 
总的来说，执行上面的 set()方法就只会导致两种结果：1. 当前没有锁（key 不存在），
那么就进行加锁操作，并对锁设置个有效期，同时 value 表示加锁的客户端。2. 已有锁
存在，不做任何操作 
 
加锁代码满足我们可靠性里描述的三个条件。首先，set()加入了 NX 参数，可以保证如
果已有 key 存在，则函数不会调用成功，也就是只有一个客户端能持有锁，满足互斥性。
其次，由于我们对锁设置了过期时间，即使锁的持有者后续发生崩溃而没有解锁，锁也
会因为到了过期时间而自动解锁（即 key 被删除），不会发生死锁。最后，因为我们将
value 赋值为 requestId，代表加锁的客户端请求标识，那么在客户端在解锁的时候就可
以进行校验是否是同一个客户端。由于我们只考虑 Redis 单机部署的场景，所以容错性
我们暂不考虑。 
面试题 
1. Redis 是什么？简述它的优缺点？ 
Redis 本质上是一个 Key-Value 类型的内存数据库，很像 Memcached，整个数据
库加载在内存当中操作，定期通过异步操作把数据库中的数据 flush 到硬盘上进
行保存。 
因为是纯内存操作，Redis 的性能非常出色，每秒可以处理超过 10 万次读写操
作，是已知性能最快的 Key-Value 数据库。 
优点： 
读写性能极高， Redis 能读的速度是 110000 次/s，写的速度是 81000 次/s。 支
持数据持久化，支持 AOF 和 RDB 两种持久化方式。 支持事务， Redis 的所有
操作都是原子性的，意思就是要么成功执行要么失败完全不执行。单个操作是原
子性的。多个操作也支持事务，即原子性，通过 MULTI 和 EXEC 指令包起来。 
数据结构丰富，除了支持 string 类型的 value 外，还支持 hash、set、zset、list 等
数据结构。 支持主从复制，主机会自动将数据同步到从机，可以进行读写分离。 
丰富的特性 – Redis 还支持 publish/subscribe， 通知， key 过期等特性。 缺点： 
数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此 Redis
适合的场景主要局限在较小数据量的高性能操作和运算上。 主机宕机，宕机前
有部分数据未能及时同步到从机，切换 IP 后还会引入数据不一致的问题，降低
了系统的可用性。 
2. Redis 为什么这么快？ 
内存存储：Redis 是使用内存(in-memeroy)存储，没有磁盘 IO 上的开销。数据存
在内存中，类似于 HashMap，HashMap 的优势就是查找和操作的时间复杂度都
是 O(1)。 
单线程实现（ Redis 6.0 以前）：Redis 使用单个线程处理请求，避免了多个线程
之间线程切换和锁资源争用的开销。注意：单线程是指的是在核心网络模型中，
网络请求模块使用一个线程来处理，即一个线程处理所有网络请求。 
非阻塞 IO：Redis 使用多路复用 IO 技术，将 epoll 作为 I/O 多路复用技术的实现，
再加上 Redis 自身的事件处理模型将 epoll 中的连接、读写、关闭都转换为事件，
不在网络 I/O 上浪费过多的时间。 
优化的数据结构：Redis 有诸多可以直接应用的优化数据结构的实现，应用层可
以直接使用原生的数据结构提升性能。 
使用底层模型不同：Redis 直接自己构建了 VM (虚拟内存)机制 ，因为一般的系
统调用系统函数的话，会浪费一定的时间去移动和请求。 
Redis 的 VM(虚拟内存)机制就是暂时把不经常访问的数据(冷数据)从内存交换到
磁盘中，从而腾出宝贵的内存空间用于其它需要访问的数据(热数据)。通过 VM
功能可以实现冷热数据分离，使热数据仍在内存中、冷数据保存到磁盘。这样就
可以避免因为内存不足而造成访问速度下降的问题。 
Redis 提高数据库容量的办法有两种：一种是可以将数据分割到多个 RedisServer
上；另一种是使用虚拟内存把那些不经常访问的数据交换到磁盘上。需要特别注
意的是 Redis 并没有使用 OS 提供的 Swap，而是自己实现。 
3. Redis 相比 Memcached 有哪些优势？ 
数据类型：Memcached 所有的值均是简单的字符串，Redis 支持更为丰富的数据
类型，支持 string(字符串)，list(列表)，Set(集合)、Sorted Set(有序集合)、Hash(哈
希)等。 
持久化：Redis 支持数据落地持久化存储，可以将内存中的数据保持在磁盘中，
重启的时候可以再次加载进行使用。 memcache 不支持数据持久存储 。 
集群模式：Redis 提供主从同步机制，以及 Cluster 集群部署能力，能够提供高可
用服务。Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片
写入数据 
性能对比：Redis 的速度比 Memcached 快很多。 
网络 IO 模型：Redis 使用单线程的多路 IO 复用模型，Memcached 使用多线程
的非阻塞 IO 模式。 
Redis 支持服务器端的数据操作：Redis 相比 Memcached 来说，拥有更多的数据
结构和并支持更丰富的数据操作，通常在 Memcached 里，你需要将数据拿到客
户端来进行类似的修改再 set 回去。 
这大大增加了网络 IO 的次数和数据体积。在 Redis 中，这些复杂的操作通常和
一般的 GET/SET 一样高效。所以，如果需要缓存能够支持更复杂的结构和操作，
那么 Redis 会是不错的选择。 
4. 为什么要用 Redis 做缓存？ 
从高并发上来说： 
直接操作缓存能够承受的请求是远远大于直接访问数据库的，所以我们可以考虑
把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这
里而不用经过数据库。 从高性能上来说： 
用户第一次访问数据库中的某些数据。 因为是从硬盘上读取的所以这个过程会
比较慢。将该用户访问的数据存在缓存中，下一次再访问这些数据的时候就可以
直接从缓存中获取了。操作缓存就是直接操作内存，所以速度相当快。如果数据
库中的对应数据改变的之后，同步改变缓存中相应的数据。 
5. 为什么要用 Redis 而不用 map/guava 做缓存? 
缓存分为本地缓存和分布式缓存。以 java 为例，使用自带的 map 或者 guava 实
现的是本地缓存，最主要的特点是轻量以及快速，生命周期随着 jvm 的销毁而结
束，并且在多实例的情况下，每个实例都需要各自保存一份缓存，缓存不具有一
致性。 
使用 Redis 或 memcached 之类的称为分布式缓存，在多实例的情况下，各实例共
用一份缓存数据，缓存具有一致性。缺点是需要保持 Redis 或 memcached 服务的
高可用，整个程序架构上较为复杂。 
对比: 
Redis 可以用几十 G 内存来做缓存，Map 不行，一般 JVM 也就分几个 G 数
据就够大了； Redis 的缓存可以持久化，Map 是内存对象，程序一重启数据就
没了； Redis 可以实现分布式的缓存，Map 只能存在创建它的程序里； Redis 
可以处理每秒百万级的并发，是专业的缓存服务，Map 只是一个普通的对象； 
Redis 缓存有过期机制，Map 本身无此功能；Redis 有丰富的 API，Map 就简单
太多了； Redis 可单独部署，多个项目之间可以空想，本地内存无法共享； Redis
有专门的管理工具可以查看缓存数据。 
6. Redis 的常用场景有哪些? 
1、缓存 
缓存现在几乎是所有中大型网站都在用的必杀技，合理的利用缓存不仅能够提升
网站访问速度，还能大大降低数据库的压力。Redis 提供了键过期功能，也提供
了灵活的键淘汰策略，所以，现在 Redis 用在缓存的场合非常多。 
2、排行榜 
很多网站都有排行榜应用的，如京东的月度销量榜单、商品按时间的上新排行榜
等。Redis 提供的有序集合数据类构能实现各种复杂的排行榜应用。 
3、计数器 
什么是计数器，如电商网站商品的浏览量、视频网站视频的播放数等。为了保证
数据实时效，每次浏览都得给+1，并发量高时如果每次都请求数据库操作无疑是
种挑战和压力。Redis 提供的 incr 命令来实现计数器功能，内存操作，性能非常
好，非常适用于这些计数场景。 
4、分布式会话 
集群模式下，在应用不多的情况下一般使用容器自带的 session 复制功能就能满
足，当应用增多相对复杂的系统中，一般都会搭建以 Redis 等内存数据库为中心
的 session 服务，session 不再由容器管理，而是由 session 服务及内存数据库管
理。 
5、分布式锁 
在很多互联网公司中都使用了分布式技术，分布式技术带来的技术挑战是对同一
个资源的并发访问，如全局 ID、减库存、秒杀等场景，并发量不大的场景可以使
用数据库的悲观锁、乐观锁来实现，但在并发量高的场合中，利用数据库锁来控
制资源的并发访问是不太理想的，大大影响了数据库的性能。可以利用 Redis 的
setnx 功能来编写分布式的锁，如果设置返回 1 说明获取锁成功，否则获取锁失
败，实际应用中要考虑的细节要更多。 
6、 社交网络 
点赞、踩、关注/被关注、共同好友等是社交网站的基本功能，社交网站的访问量
通常来说比较大，而且传统的关系数据库类型不适合存储这种类型的数据，Redis
提供的哈希、集合等数据结构能很方便的的实现这些功能。如在微博中的共同好
友，通过 Redis 的 set 能够很方便得出。 
7、最新列表 
Redis 列表结构，LPUSH 可以在列表头部插入一个内容 ID 作为关键字，LTRIM
可用来限制列表的数量，这样列表永远为 N 个 ID，无需查询最新的列表，直接
根据 ID 去到对应的内容页即可。 
8、消息系统 
消息队列是大型网站必用中间件，如 ActiveMQ、RabbitMQ、Kafka 等流行的消
息队列中间件，主要用于业务解耦、流量削峰及异步处理实时性低的业务。Redis
提供了发布/订阅及阻塞队列功能，能实现一个简单的消息队列系统。另外，这个
不能和专业的消息中间件相比。 
7. Redis 持久化机制？ 
为了能够重用 Redis 数据，或者防止系统故障，我们需要将 Redis 中的数据写入
到磁盘空间中，即持久化。 
Redis提供了两种不同的持久化方法可以将数据存储在磁盘中，一种叫快照RDB，
另一种叫只追加文件 AOF。 
RDB 
在指定的时间间隔内将内存中的数据集快照写入磁盘(Snapshot)，它恢复时是将
快照文件直接读到内存里。 
优势：适合大规模的数据恢复；对数据完整性和一致性要求不高 
劣势：在一定间隔时间做一次备份，所以如果 Redis 意外 down 掉的话，就会丢
失最后一次快照后的所有修改。 
AOF 
以日志的形式来记录每个写操作，将 Redis 执行过的所有写指令记录下来(读操
作不记录)，只许追加文件但不可以改写文件，Redis 启动之初会读取该文件重新
构建数据，换言之，Redis 重启的话就根据日志文件的内容将写指令从前到后执
行一次以完成数据的恢复工作。 
AOF 采用文件追加方式，文件会越来越大，为避免出现此种情况，新增了重写机
制，当 AOF 文件的大小超过所设定的阈值时， Redis 就会启动 AOF 文件的内容
压缩，只保留可以恢复数据的最小指令集.。 
优势 
每修改同步：appendfsync always 同步持久化，每次发生数据变更会被立即记录
到磁盘，性能较差但数据完整性比较好 每秒同步：appendfsync everysec 异步操
作，每秒记录，如果一秒内宕机，有数据丢失 不同步：appendfsync no 从不同步 
劣势 
相同数据集的数据而言 aof 文件要远大于 rdb 文件，恢复速度慢于 rdb aof 运行效
率要慢于 rdb，每秒同步策略效率较好，不同步效率和 rdb 相同 
9. 如何选择合适的持久化方式 如果是数据不那么敏感，且可以从其他地方重新生
成补回的，那么可以关闭持久化。 如果是数据比较重要，不想再从其他地方获
取，且可以承受数分钟的数据丢失，比如缓存等，那么可以只使用 RDB。 如果
是用做内存数据库，要使用 Redis 的持久化，建议是 RDB 和 AOF 都开启，或者
定期执行 bgsave 做快照备份，RDB 方式更适合做数据的备份，AOF 可以保证数
据的不丢失。 补充：Redis4.0 对于持久化机制的优化 
Redis4.0 相对与 3.X 版本其中一个比较大的变化是 4.0 添加了新的混合持久化方
式。 
简单的说：新的 AOF 文件前半段是 RDB 格式的全量数据后半段是 AOF 格式的
增量数据，如下图： 
优势：混合持久化结合了 RDB 持久化 和 AOF 持久化的优点， 由于绝大部分
都是 RDB 格式，加载速度快，同时结合 AOF，增量的数据以 AOF 方式保存了，
数据更少的丢失。 
劣势：兼容性差，一旦开启了混合持久化，在 4.0 之前版本都不识别该 aof 文件，
同时由于前部分是 RDB 格式，阅读性较差。 
10. Redis 持久化数据和缓存怎么做扩容？ 如果 Redis 被当做缓存使用，使用一致性
哈希实现动态扩容缩容。 
如果 Redis 被当做一个持久化存储使用，必须使用固定的 keys-to-nodes 映射关
系，节点的数量一旦确定不能变化。否则的话(即 Redis 节点需要动态变化的情
况），必须使用可以在运行时进行数据再平衡的一套系统，而当前只有 Redis 集
群可以做到这样。 
过期键的删除策略、淘汰策略 
11. Redis 过期键的删除策略 Redis 的过期删除策略就是：惰性删除和定期删除两种
策略配合使用。 
惰性删除：惰性删除不会去主动删除数据，而是在访问数据的时候，再检查当前
键值是否过期，如果过期则执行删除并返回 null 给客户端，如果没有过期则返
回正常信息给客户端。它的优点是简单，不需要对过期的数据做额外的处理，只
有在每次访问的时候才会检查键值是否过期，缺点是删除过期键不及时，造成了
一定的空间浪费。 
定期删除：Redis 会周期性的随机测试一批设置了过期时间的 key 并进行处理。
测试到的已过期的 key 将被删除。 
附：删除 key 常见的三种处理方式。 
1、定时删除 
在设置某个 key 的过期时间同时，我们创建一个定时器，让定时器在该过期时间
到来时，立即执行对其进行删除的操作。 
优点：定时删除对内存是最友好的，能够保存内存的 key 一旦过期就能立即从内
存中删除。 
缺点：对 CPU 最不友好，在过期键比较多的时候，删除过期键会占用一部分 CPU 
时间，对服务器的响应时间和吞吐量造成影响。 
2、惰性删除 
设置该 key 过期时间后，我们不去管它，当需要该 key 时，我们在检查其是否过
期，如果过期，我们就删掉它，反之返回该 key。 
优点：对 CPU 友好，我们只会在使用该键时才会进行过期检查，对于很多用不
到的 key 不用浪费时间进行过期检查。 
缺点：对内存不友好，如果一个键已经过期，但是一直没有使用，那么该键就会
一直存在内存中，如果数据库中有很多这种使用不到的过期键，这些键便永远不
会被删除，内存永远不会释放。从而造成内存泄漏。 
3、定期删除 
每隔一段时间，我们就对一些 key 进行检查，删除里面过期的 key。 
优点：可以通过限制删除操作执行的时长和频率来减少删除操作对 CPU 的影响。
另外定期删除，也能有效释放过期键占用的内存。 
缺点：难以确定删除操作执行的时长和频率。如果执行的太频繁，定期删除策略
变得和定时删除策略一样，对 CPU 不友好。如果执行的太少，那又和惰性删除
一样了，过期键占用的内存不会及时得到释放。另外最重要的是，在获取某个键
时，如果某个键的过期时间已经到了，但是还没执行定期删除，那么就会返回这
个键的值，这是业务不能忍受的错误。 
12. Redis key 的过期时间和永久有效分别怎么设置？ 通过 expire 或 pexpire 命令，
客户端可以以秒或毫秒的精度为数据库中的某个键设置生存时间。 
与 expire 和 pexpire 命令类似，客户端可以通过 expireat 和 pexpireat 命令，以秒
或毫秒精度给数据库中的某个键设置过期时间，可以理解为：让某个键在某个时
间点过期。 
13. Redis 内存淘汰策略 Redis 是不断的删除一些过期数据，但是很多没有设置过期
时间的数据也会越来越多，那么 Redis 内存不够用的时候是怎么处理的呢？答案
就是淘汰策略。此类的 
当 Redis 的内存超过最大允许的内存之后，Redis 会触发内存淘汰策略，删除一
些不常用的数据，以保证 Redis 服务器的正常运行。 
Redisv4.0 前提供 6 种数据淘汰策略： 
volatile-lru：利用 LRU 算法移除设置过过期时间的 key (LRU:最近使用 Least 
Recently Used ) allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除
最近最少使用的 key（这个是最常用的） volatile-ttl：从已设置过期时间的数据
集（server.db[i].expires）中挑选将要过期的数据淘汰 volatile-random：从已设置
过期时间的数据集（server.db[i].expires）中任意选择数据淘汰 allkeys-random：
从数据集（server.db[i].dict）中任意选择数据淘汰 no-eviction：禁止驱逐数据，也
就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用
吧！ Redisv4.0 后增加以下两种： 
volatile-lfu：从已设置过期时间的数据集(server.db[i].expires)中挑选最不经常使用
的数据淘汰(LFU(Least Frequently Used)算法，也就是最频繁被访问的数据将来最
有可能被访问到) allkeys-lfu：当内存不足以容纳新写入数据时，在键空间中，移
除最不经常使用的 key。 内存淘汰策略可以通过配置文件来修改，Redis.conf 对
应的配置项是 maxmemory-policy 修改对应的值就行，默认是 noeviction。 
缓存异常 缓存异常有四种类型，分别是缓存和数据库的数据不一致、缓存雪崩、
缓存击穿和缓存穿透。 
14. 如何保证缓存与数据库双写时的数据一致性？ 背景：使用到缓存，无论是本地
内存做缓存还是使用 Redis 做缓存，那么就会存在数据同步的问题，因为配置信
息缓存在内存中，而内存时无法感知到数据在数据库的修改。这样就会造成数据
库中的数据与缓存中数据不一致的问题。 
共有四种方案： 
先更新数据库，后更新缓存 先更新缓存，后更新数据库 先删除缓存，后更新数
据库 先更新数据库，后删除缓存 第一种和第二种方案，没有人使用的，因为第
一种方案存在问题是：并发更新数据库场景下，会将脏数据刷到缓存。 
第二种方案存在的问题是：如果先更新缓存成功，但是数据库更新失败，则肯定
会造成数据不一致。 
目前主要用第三和第四种方案。 
15. 先删除缓存，后更新数据库 该方案也会出问题，此时来了两个请求，请求 A（更
新操作） 和请求 B（查询操作） 
请求 A 进行写操作，删除缓存 请求 B 查询发现缓存不存在 请求 B 去数据库查
询得到旧值 请求 B 将旧值写入缓存 请求 A 将新值写入数据库 上述情况就会
导致不一致的情形出现。而且，如果不采用给缓存设置过期时间策略，该数据永
远都是脏数据。 
答案一：延时双删 最简单的解决办法延时双删 
使用伪代码如下： 
public void write(String key,Object data){   
Redis.delKey(key); 
 
db.updateData(data);  
Thread.sleep(1000);  Redis.delKey(key);  } 转 化 为
中文描述就是 （1）先淘汰缓存 （2）再写数据库（这两步和原来一样） （3）
休眠 1 秒，再次淘汰缓存，这么做，可以将 1 秒内所造成的缓存脏数据，再次删
除。确保读请求结束，写请求可以删除读请求造成的缓存脏数据。自行评估自己
的项目的读数据业务逻辑的耗时，写数据的休眠时间则在读数据业务逻辑的耗时
基础上，加几百 ms 即可。 
如果使用的是 Mysql 的读写分离的架构的话，那么其实主从同步之间也会有时
间差。 
此时来了两个请求，请求 A（更新操作） 和请求 B（查询操作） 
请求 A 更新操作，删除了 Redis 请求主库进行更新操作，主库与从库进行同步
数据的操作 请 B 查询操作，发现 Redis 中没有数据 去从库中拿去数据 此时
同步数据还未完成，拿到的数据是旧数据 此时的解决办法就是如果是对 Redis 
进行填充数据的查询数据库操作，那么就强制将其指向主库进行查询。 
答案二： 更新与读取操作进行异步串行化 采用更新与读取操作进行异步串行化 
异步串行化 
我在系统内部维护 n 个内存队列，更新数据的时候，根据数据的唯一标识，将该
操作路由之后，发送到其中一个 jvm 内部的内存队列中（对同一数据的请求发送
到同一个队列）。读取数据的时候，如果发现数据不在缓存中，并且此时队列里
有更新库存的操作，那么将重新读取数据+更新缓存的操作，根据唯一标识路由
之后，也将发送到同一个 jvm 内部的内存队列中。然后每个队列对应一个工作线
程，每个工作线程串行地拿到对应的操作，然后一条一条的执行。 
这样的话，一个数据变更的操作，先执行删除缓存，然后再去更新数据库，但是
还没完成更新的时候，如果此时一个读请求过来，读到了空的缓存，那么可以先
将缓存更新的请求发送到队列中，此时会在队列中积压，排在刚才更新库的操作
之后，然后同步等待缓存更新完成，再读库。 
读操作去重 
多个读库更新缓存的请求串在同一个队列中是没意义的，因此可以做过滤，如果
发现队列中已经有了该数据的更新缓存的请求了，那么就不用再放进去了，直接
等待前面的更新操作请求完成即可，待那个队列对应的工作线程完成了上一个操
作（数据库的修改）之后，才会去执行下一个操作（读库更新缓存），此时会从
数据库中读取最新的值，然后写入缓存中。 
如果请求还在等待时间范围内，不断轮询发现可以取到值了，那么就直接返回；
如果请求等待的时间超过一定时长，那么这一次直接从数据库中读取当前的旧值。
（返回旧值不是又导致缓存和数据库不一致了么？那至少可以减少这个情况发
生，因为等待超时也不是每次都是，几率很小吧。这里我想的是，如果超时了就
直接读旧值，这时候仅仅是读库后返回而不放缓存） 
16. 先更新数据库，后删除缓存 这一种情况也会出现问题，比如更新数据库成功了，
但是在删除缓存的阶段出错了没有删除成功，那么此时再读取缓存的时候每次都
是错误的数据了。 
此时解决方案就是利用消息队列进行删除的补偿。具体的业务逻辑用语言描述如
下： 
请求 A 先对数据库进行更新操作 在对 Redis 进行删除操作的时候发现报错，
删除失败 此时将 Redis 的 key 作为消息体发送到消息队列中 系统接收到消息
队列发送的消息后再次对 Redis 进行删除操作 但是这个方案会有一个缺点就
是会对业务代码造成大量的侵入，深深的耦合在一起，所以这时会有一个优化的
方案，我们知道对 Mysql 数据库更新操作后再 binlog 日志中我们都能够找到
相应的操作，那么我们可以订阅 Mysql 数据库的 binlog 日志对缓存进行操作。 
17. 什么是缓存击穿? 缓存击穿跟缓存雪崩有点类似，缓存雪崩是大规模的 key 失效，
而缓存击穿是某个热点的 key 失效，大并发集中对其进行请求，就会造成大量请
求读缓存没读到数据，从而导致高并发访问数据库，引起数据库压力剧增。这种
现象就叫做缓存击穿。 
从两个方面解决，第一是否可以考虑热点 key 不设置过期时间，第二是否可以考
虑降低打在数据库上的请求数量。 
解决方案： 
在缓存失效后，通过互斥锁或者队列来控制读数据写缓存的线程数量，比如某个
key 只允许一个线程查询数据和写缓存，其他线程等待。这种方式会阻塞其他的
线程，此时系统的吞吐量会下降 
热点数据缓存永远不过期。永不过期实际包含两层意思： 
物理不过期，针对热点 key 不设置过期时间 逻辑过期，把过期时间存在 key 对
应的 value 里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建 
18. 什么是缓存穿透? 缓存穿透是指用户请求的数据在缓存中不存在即没有命中，同
时在数据库中也不存在，导致用户每次请求该数据都要去数据库中查询一遍。如
果有恶意攻击者不断请求系统中不存在的数据，会导致短时间大量请求落在数据
库上，造成数据库压力过大，甚至导致数据库承受不住而宕机崩溃。 
缓存穿透的关键在于在 Redis 中查不到 key 值，它和缓存击穿的根本区别在于传
进来的 key 在 Redis 中是不存在的。假如有黑客传进大量的不存在的 key，那么
大量的请求打在数据库上是很致命的问题，所以在日常开发中要对参数做好校验，
一些非法的参数，不可能存在的 key 就直接返回错误提示。 
解决方法： 
将无效的 key 存放进 Redis 中： 当出现 Redis 查不到数据，数据库也查不到数据
的情况，我们就把这个 key 保存到 Redis 中，设置 value="null"，并设置其过期时
间极短，后面再出现查询这个 key 的请求的时候，直接返回 null，就不需要再查
询数据库了。但这种处理方式是有问题的，假如传进来的这个不存在的 Key 值每
次都是随机的，那存进 Redis 也没有意义。 
使用布隆过滤器： 如果布隆过滤器判定某个 key 不存在布隆过滤器中，那么就
一定不存在，如果判定某个 key 存在，那么很大可能是存在(存在一定的误判率)。
于是我们可以在缓存之前再加一个布隆过滤器，将数据库中的所有 key 都存储在
布隆过滤器中，在查询 Redis 前先去布隆过滤器查询 key 是否存在，如果不存
在就直接返回，不让其访问数据库，从而避免了对底层存储系统的查询压力。 
如何选择：针对一些恶意攻击，攻击带过来的大量 key 是随机，那么我们采用第
一种方案就会缓存大量不存在 key 的数据。那么这种方案就不合适了，我们可以
先对使用布隆过滤器方案进行过滤掉这些 key。所以，针对这种 key 异常多、请
求重复率比较低的数据，优先使用第二种方案直接过滤掉。而对于空数据的 key
有限的，重复率比较高的，则可优先采用第一种方式进行缓存。 
19. 什么是缓存雪崩? 如果缓在某一个时刻出现大规模的 key 失效，那么就会导致大
量的请求打在了数据库上面，导致数据库压力巨大，如果在高并发的情况下，可
能瞬间就会导致数据库宕机。这时候如果运维马上又重启数据库，马上又会有新
的流量把数据库打死。这就是缓存雪崩。 
造成缓存雪崩的关键在于同一时间的大规模的 key 失效，主要有两种可能：第一
种是 Redis 宕机，第二种可能就是采用了相同的过期时间。 
解决方案： 
1、事前： 
均匀过期：设置不同的过期时间，让缓存失效的时间尽量均匀，避免相同的过期
时间导致缓存雪崩，造成大量数据库的访问。如把每个 Key 的失效时间都加个随
机值，setRedis（Key，value，time + Math.random() * 10000）；，保证数据不会
在同一时间大面积失效。 
分级缓存：第一级缓存失效的基础上，访问二级缓存，每一级缓存的失效时间都
不同。 
热点数据缓存永远不过期。永不过期实际包含两层意思： 
物理不过期，针对热点 key 不设置过期时间 逻辑过期，把过期时间存在 key 对
应的 value 里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建 保
证 Redis 缓存的高可用，防止 Redis 宕机导致缓存雪崩的问题。可以使用 主从+ 
哨兵，Redis 集群来避免 Redis 全盘崩溃的情况。 
2、事中： 
互斥锁：在缓存失效后，通过互斥锁或者队列来控制读数据写缓存的线程数量，
比如某个 key 只允许一个线程查询数据和写缓存，其他线程等待。这种方式会阻
塞其他的线程，此时系统的吞吐量会下降 
使用熔断机制，限流降级。当流量达到一定的阈值，直接返回“系统拥挤”之类的
提示，防止过多的请求打在数据库上将数据库击垮，至少能保证一部分用户是可
以正常使用，其他用户多刷新几次也能得到结果。 
3、事后： 
开启 Redis 持久化机制，尽快恢复缓存数据，一旦重启，就能从磁盘上自动加载
数据恢复内存中的数据。 
20. 什么是缓存预热? 缓存预热是指系统上线后，提前将相关的缓存数据加载到缓存
系统。避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题，用户
直接查询事先被预热的缓存数据。 
如果不进行预热，那么 Redis 初始状态数据为空，系统上线初期，对于高并发的
流量，都会访问到数据库中， 对数据库造成流量的压力。 
缓存预热解决方案： 
数据量不大的时候，工程启动的时候进行加载缓存动作； 
数据量大的时候，设置一个定时任务脚本，进行缓存的刷新； 
数据量太大的时候，优先保证热点数据进行提前加载到缓存。 
21. 什么是缓存降级？ 缓存降级是指缓存失效或缓存服务器挂掉的情况下，不去访
问数据库，直接返回默认数据或访问服务的内存数据。降级一般是有损的操作，
所以尽量减少降级对于业务的影响程度。 
在进行降级之前要对系统进行梳理，看看系统是不是可以丢卒保帅；从而梳理出
哪些必须誓死保护，哪些可降级；比如可以参考日志级别设置预案： 
一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级； 
警告：有些服务在一段时间内成功率有波动（如在 95~100%之间），可以自动降
级或人工降级，并发送告警； 
错误：比如可用率低于 90%，或者数据库连接池被打爆了，或者访问量突然猛增
到系统能承受的最大阀值，此时可以根据情况自动降级或者人工降级； 
严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级。 
线程模型 
22. Redis 为何选择单线程？ 在 Redis 6.0 以前，Redis 的核心网络模型选择用单线程
来实现。先来看下官方的回答： 
It's not very frequent that CPU becomes your bottleneck with Redis， as usually Redisis 
either memory or network bound. For instance， using pipelining Redisrunning on an 
average Linux system can deliver even 1 million requests per second， so if your 
application mainly uses O(N) or O(log(N)) commands， it is hardly going to use too 
much CPU. 
核心意思就是，对于一个 DB 来说，CPU 通常不会是瓶颈，因为大多数请求不
会是 CPU 密集型的，而是 I/O 密集型。具体到 Redis 的话，如果不考虑 
RDB/AOF 等持久化方案，Redis 是完全的纯内存操作，执行速度是非常快的，
因此这部分操作通常不会是性能瓶颈，Redis 真正的性能瓶颈在于网络 I/O，也
就是客户端和服务端之间的网络传输延迟，因此 Redis 选择了单线程的 I/O 多
路复用来实现它的核心网络模型。 
实际上更加具体的选择单线程的原因如下： 
避免过多的上下文切换开销：如果是单线程则可以规避进程内频繁的线程切换开
销，因为程序始终运行在进程中单个线程内，没有多线程切换的场景。 避免同
步机制的开销：如果 Redis 选择多线程模型，又因为 Redis 是一个数据库，那么
势必涉及到底层数据同步的问题，则必然会引入某些同步机制，比如锁，而我们
知道 Redis 不仅仅提供了简单的 key-value 数据结构，还有 list、set 和 hash 等
等其他丰富的数据结构，而不同的数据结构对同步访问的加锁粒度又不尽相同，
可能会导致在操作数据过程中带来很多加锁解锁的开销，增加程序复杂度的同时
还会降低性能。 简单可维护：如果 Redis 使用多线程模式，那么所有的底层数
据结构都必须实现成线程安全的，这无疑又使得 Redis 的实现变得更加复杂。 
总而言之，Redis 选择单线程可以说是多方博弈之后的一种权衡：在保证足够的
性能表现之下，使用单线程保持代码的简单和可维护性。 
23. Redis 真的是单线程？ 讨论 这个问题前，先看下 Redis 的版本中两个重要的节
点： 
Redisv4.0（引入多线程处理异步任务） Redis 6.0（在网络模型中实现多线程 I/O ） 
所以，网络上说的 Redis 是单线程，通常是指在 Redis 6.0 之前，其核心网络模型
使用的是单线程。 
且 Redis6.0 引入多线程 I/O，只是用来处理网络数据的读写和协议的解析，而执
行命令依旧是单线程。 
Redis 在 v4.0 版本的时候就已经引入了的多线程来做一些异步操作，此举主要
针对的是那些非常耗时的命令，通过将这些命令的执行进行异步化，避免阻塞单
线程的事件循环。 
在 Redisv4.0 之后增加了一些的非阻塞命令如 UNLINK、FLUSHALL ASYNC、
FLUSHDB ASYNC。 
24. Redis 6.0 为何引入多线程？ 很简单，就是 Redis 的网络 I/O 瓶颈已经越来越明
显了。 
随着互联网的飞速发展，互联网业务系统所要处理的线上流量越来越大，Redis
的单线程模式会导致系统消耗很多 CPU 时间在网络 I/O 上从而降低吞吐量，
要提升 Redis 的性能有两个方向： 
优化网络 I/O 模块 提高机器内存读写的速度 后者依赖于硬件的发展，暂时无
解。所以只能从前者下手，网络 I/O 的优化又可以分为两个方向： 
零拷贝技术或者 DPDK 技术 利用多核优势 零拷贝技术有其局限性，无法完全
适配 Redis 这一类复杂的网络 I/O 场景，更多网络 I/O 对 CPU 时间的消耗和 
Linux 零拷贝技术。而 DPDK 技术通过旁路网卡 I/O 绕过内核协议栈的方式又
太过于复杂以及需要内核甚至是硬件的支持。 
总结起来，Redis 支持多线程主要就是两个原因： 
可以充分利用服务器 CPU 资源，目前主线程只能利用一个核 
多线程任务可以分摊 Redis 同步 IO 读写负荷 
25. Redis 6.0 采用多线程后，性能的提升效果如何？ Redis 作者 antirez 在 
RedisConf 2019 分享时曾提到：Redis 6 引入的多线程 IO 特性对性能提升至少
是一倍以上。 
国内也有大牛曾使用 unstable 版本在阿里云 esc 进行过测试，GET/SET 命令
在 4 线程 IO 时性能相比单线程是几乎是翻倍了。 
26. 介绍下 Redis 的线程模型 Redis 的线程模型包括 Redis 6.0 之前和 Redis 6.0。 
下面介绍的是 Redis 6.0 之前。 
Redis 是基于 reactor 模式开发了网络事件处理器，这个处理器叫做文件事件处
理器（file event handler）。由于这个文件事件处理器是单线程的，所以 Redis 才
叫做单线程的模型。采用 IO 多路复用机制同时监听多个 Socket，根据 socket 
上的事件来选择对应的事件处理器来处理这个事件。 
IO 多路复用是 IO 模型的一种，有时也称为异步阻塞 IO，是基于经典的 Reactor 
设计模式设计的。多路指的是多个 Socket 连接，复用指的是复用一个线程。多
路复用主要有三种技术：Select，Poll，Epoll。 
Epoll 是最新的也是目前最好的多路复用技术。 
模型如下图： 
文件事件处理器的结构包含了四个部分： 
多个 Socket。Socket 会产生 AE_READABLE 和 AE_WRITABLE 事件： 当 
socket 变得可读时或者有新的可以应答的 socket 出现时，socket 就会产生一个 
AE_READABLE 事 件  当  socket 变 得 可 写 时 ， socket 就 会 产 生 一 个 
AE_WRITABLE 事件。 IO 多路复用程序 文件事件分派器 事件处理器。事件
处理器包括：连接应答处理器、命令请求处理器、命令回复处理器，每个处理器
对应不同的 socket 事件： 如果是客户端要连接 Redis，那么会为 socket 关联
连接应答处理器 如果是客户端要写数据到 Redis（读、写请求命令），那么会为 
socket 关联命令请求处理器 如果是客户端要从 Redis 读数据，那么会为 socket 
关联命令回复处理器 多个 socket 会产生不同的事件，不同的事件对应着不同的
操作，IO 多路复用程序监听着这些 Socket，当这些 Socket 产生了事件，IO 多
路复用程序会将这些事件放到一个队列中，通过这个队列，以有序、同步、每次
一个事件的方式向文件时间分派器中传送。当事件处理器处理完一个事件后，IO 
多路复用程序才会继续向文件分派器传送下一个事件。 
下图是客户端与 Redis 通信的一次完整的流程： 
Redis 启动初始化的时候，Redis 会将连接应答处理器与 AE_READABLE 事件
关联起来。 如果一个客户端跟 Redis 发起连接，此时 Redis 会产生一个 
AE_READABLE 事件，由于开始之初 AE_READABLE 是与连接应答处理器关
联，所以由连接应答处理器来处理该事件，这时连接应答处理器会与客户端建立
连接，创建客户端响应的 socket，同时将这个 socket 的 AE_READABLE 事件
与命令请求处理器关联起来。 如果这个时间客户端向 Redis 发送一个命令（set 
k1 v1），这时 socket 会产生一个 AE_READABLE 事件，IO 多路复用程序会
将该事件压入队列中，此时事件分派器从队列中取得该事件，由于该 socket 的 
AE_READABLE 事件已经和命令请求处理器关联了，因此事件分派器会将该事
件交给命令请求处理器处理，命令请求处理器读取事件中的命令并完成。操作完
成后，Redis 会将该 socket 的 AE_WRITABLE 事件与命令回复处理器关联。 
如 果 客 户 端 已 经 准 备 好 接 受 数 据 后 ， Redis 中 的 该  socket 会 产 生 一 个 
AE_WRITABLE 事件，同样会压入队列然后被事件派发器取出交给相对应的命
令回复处理器，由该命令回复处理器将准备好的响应数据写入 socket 中，供客
户端读取。 命令回复处理器写完后，就会删除该 socket 的 AE_WRITABLE 事
件与命令回复处理器的关联关系。 
27. Redis 6.0 多线程的实现机制？ 流程简述如下： 
主线程负责接收建立连接请求，获取 Socket 放入全局等待读处理队列。 主线程
处理完读事件之后，通过 RR（Round Robin）将这些连接分配给这些 IO 线程。 
主线程阻塞等待 IO 线程读取 Socket 完毕。 主线程通过单线程的方式执行请
求命令，请求数据读取并解析完成，但并不执行。 主线程阻塞等待 IO 线程将
数据回写 Socket 完毕。 
该设计有如下特点： 
IO 线程要么同时在读 Socket，要么同时在写，不会同时读或写。 IO 线程只负
责读写 Socket 解析命令，不负责命令处理。 
28. Redis 6.0 开启多线程后，是否会存在线程并发安全问题？ 从实现机制可以看出，
Redis 的多线程部分只是用来处理网络数据的读写和协议解析，执行命令仍然是
单线程顺序执行。 
所以我们不需要去考虑控制 Key、Lua、事务，LPUSH/LPOP 等等的并发及线程
安全问题。 
29. Redis 6.0 与 Memcached 多线程模型的对比 相同点：都采用了 Master 线程 -
Worker 线程的模型。 
不同点：Memcached 执行主逻辑也是在 Worker 线程里，模型更加简单，实现
了真正的线程隔离，符合我们对线程隔离的常规理解。 
而 Redis 把处理逻辑交还给 Master 线程，虽然一定程度上增加了模型复杂度，
但也解决了线程并发安全等问题。 
事务 
30. Redis 事务的概念 Redis 的事务并不是我们传统意义上理解的事务，我们都知道 
单个 Redis 命令的执行是原子性的，但 Redis 没有在事务上增加任何维持原子
性的机制，所以 Redis 事务的执行并不是原子性的。 
事务可以理解为一个打包的批量执行脚本，但批量指令并非原子化的操作，中间
某条指令的失败不会导致前面已做指令的回滚，也不会造成后续的指令不做。 
总结： 
1. Redis 事务中如果有某一条命令执行失败，之前的命令不会回滚，其后的命令仍
然会被继续执行。鉴于这个原因，所以说 Redis 的事务严格意义上来说是不具备
原子性的。 
2. Redis 事务中所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会
被其他客户端发送来的命令请求所打断。 
3. 在事务开启之前，如果客户端与服务器之间出现通讯故障并导致网络断开，其后
所有待执行的语句都将不会被服务器执行。然而如果网络中断事件是发生在客户
端执行 EXEC 命令之后，那么该事务中的所有命令都会被服务器执行。 
当使用 Append-Only 模式时，Redis 会通过调用系统函数 write 将该事务内的所
有写操作在本次调用中全部写入磁盘。然而如果在写入的过程中出现系统崩溃，
如电源故障导致的宕机，那么此时也许只有部分数据被写入到磁盘，而另外一部
分数据却已经丢失。Redis 服务器会在重新启动时执行一系列必要的一致性检测，
一旦发现类似问题，就会立即退出并给出相应的错误提示。此时，我们就要充分
利用 Redis 工具包中提供的 Redis-check-aof 工具，该工具可以帮助我们定位到数
据不一致的错误，并将已经写入的部分数据进行回滚。修复之后我们就可以再次
重新启动 Redis 服务器了。 
31. Redis 事务的三个阶段 multi 开启事务 大量指令入队 exec 执行事务块内命令，
截止此处一个事务已经结束。 discard 取消事务 watch 监视一个或多个 key，如
果事务执行前 key 被改动，事务将打断。unwatch 取消监视。 事务执行过程中，
如果服务端收到有 EXEC、DISCARD、WATCH、MULTI 之外的请求，将会把请
求放入队列中排队. 
32. Redis事务相关命令 Redis事务功能是通过MULTI、EXEC、DISCARD 和WATCH 
四个原语实现的 
WATCH 命令是一个乐观锁，可以为 Redis 事务提供 check-and-set （CAS）行
为。 可以监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事
务就不会执行，监控一直持续到 EXEC 命令。 MULTI 命令用于开启一个事务，
它总是返回 OK。 MULTI 执行之后，客户端可以继续向服务器发送任意多条命
令，这些命令不会立即被执行，而是被放到一个队列中，当 EXEC 命令被调用
时，所有队列中的命令才会被执行。 EXEC：执行所有事务块内的命令。返回事
务块内所有命令的返回值，按命令执行的先后顺序排列。 当操作被打断时，返
回空值 nil 。 通过调用 DISCARD，客户端可以清空事务队列，并放弃执行事务， 
并且客户端会从事务状态中退出。 UNWATCH 命令可以取消 watch 对所有 key
的监控。 
33. Redis 事务支持隔离性吗? Redis 是单进程程序，并且它保证在执行事务时，不会
对事务进行中断，事务可以运行直到执行完所有事务队列中的命令为止。因此，
Redis 的事务是总是带有隔离性的。 
34. Redis 为什么不支持事务回滚？ Redis 命令只会因为错误的语法而失败，或是命
令用在了错误类型的键上面，这些问题不能在入队时发现，这也就是说，从实用
性的角度来说，失败的命令是由编程错误造成的，而这些错误应该在开发的过程
中被发现，而不应该出现在生产环境中. 因为不需要对回滚进行支持，所以 Redis 
的内部可以保持简单且快速。 
35. Redis 事务其他实现 基于 Lua 脚本，Redis 可以保证脚本内的命令一次性、按顺
序地执行， 其同时也不提供事务运行错误的回滚，执行过程中如果部分命令运
行错误，剩下的命令还是会继续运行完。 基于中间标记变量，通过另外的标记
变量来标识事务是否执行完成，读取数据时先读取该标记变量判断是否事务执行
完成。但这样会需要额外写代码实现，比较繁琐。 主从、哨兵、集群 
36. Redis 常见使用方式有哪些？ Redis 的几种常见使用方式包括： 
Redis 单副本； Redis 多副本（主从）； Redis Sentinel（哨兵）； Redis Cluster； 
Redis 自研。 使用场景： 
如果数据量很少，主要是承载高并发高性能的场景，比如缓存一般就几个 G 的
话，单机足够了。 
主从模式：master 节点挂掉后，需要手动指定新的 master，可用性不高，基本不
用。 
哨兵模式：master 节点挂掉后，哨兵进程会主动选举新的 master，可用性高，但
是每个节点存储的数据是一样的，浪费内存空间。数据量不是很多，集群规模不
是很大，需要自动容错容灾的时候使用。 
Redis cluster 主要是针对海量数据+高并发+高可用的场景，如果是海量数据，如
果你的数据量很大，那么建议就用 Redis cluster，所有 master 的容量总和就是
Redis cluster 可缓存的数据容量。 
37. 介绍下 Redis 单副本 Redis 单副本，采用单个 Redis 节点部署架构，没有备用节
点实时同步数据，不提供数据持久化和备份策略，适用于数据可靠性要求不高的
纯缓存业务场景。 
优点： 
架构简单，部署方便； 高性价比：缓存使用时无需备用节点（单实例可用性可
以用 supervisor 或 crontab 保证），当然为了满足业务的高可用性，也可以牺牲一
个备用节点，但同时刻只有一个实例对外提供服务； 高性能。 缺点： 
不保证数据的可靠性； 在缓存使用，进程重启后，数据丢失，即使有备用的节
点解决高可用性，但是仍然不能解决缓存预热问题，因此不适用于数据可靠性要
求高的业务； 高性能受限于单核 CPU 的处理能力（Redis 是单线程机制），CPU
为主要瓶颈，所以适合操作命令简单，排序、计算较少的场景。也可以考虑用
Memcached 替代。 
38. 介绍下 Redis 多副本（主从） Redis 多副本，采用主从（replication）部署结构，
相较于单副本而言最大的特点就是主从实例间数据实时同步，并且提供数据持久
化和备份策略。主从实例部署在不同的物理服务器上，根据公司的基础环境配置，
可以实现同时对外提供服务和读写分离策略。 
优点： 
高可靠性：一方面，采用双机主备架构，能够在主库出现故障时自动进行主备切
换，从库提升为主库提供服务，保证服务平稳运行；另一方面，开启数据持久化
功能和配置合理的备份策略，能有效的解决数据误操作和数据异常丢失的问题； 
读写分离策略：从节点可以扩展主库节点的读能力，有效应对大并发量的读操作。 
缺点： 
故障恢复复杂，如果没有 RedisHA 系统（需要开发），当主库节点出现故障时，
需要手动将一个从节点晋升为主节点，同时需要通知业务方变更配置，并且需要
让其它从库节点去复制新主库节点，整个过程需要人为干预，比较繁琐； 
主库的写能力受到单机的限制，可以考虑分片； 
主库的存储能力受到单机的限制，可以考虑 Pika； 
原生复制的弊端在早期的版本中也会比较突出，如：Redis 复制中断后，Slave 会
发起 psync，此时如果同步不成功，则会进行全量同步，主库执行全量备份的同
时可能会造成毫秒或秒级的卡顿；又由于 COW 机制，导致极端情况下的主库内
存溢出，程序异常退出或宕机；主库节点生成备份文件导致服务器磁盘 IO 和 CPU
（压缩）资源消耗；发送数 GB 大小的备份文件导致服务器出口带宽暴增，阻塞
请求，建议升级到最新版本。 
39. 介绍下 Redis Sentinel（哨兵） 主从模式下，当主服务器宕机后，需要手动把一
台从服务器切换为主服务器，这就需要人工干预，费事费力，还会造成一段时间
内服务不可用。这种方式并不推荐，实际生产中，我们优先考虑哨兵模式。这种
模式下，master 宕机，哨兵会自动选举 master 并将其他的 slave 指向新的 
master。 
Redis Sentinel 是社区版本推出的原生高可用解决方案，其部署架构主要包括两部
分：Redis Sentinel 集群和 Redis 数据集群。 
其中 Redis Sentinel 集群是由若干 Sentinel 节点组成的分布式集群，可以实现故
障发现、故障自动转移、配置中心和客户端通知。Redis Sentinel 的节点数量要满
足 2n+1（n>=1）的奇数个。 
优点： 
Redis Sentinel 集群部署简单； 能够解决 Redis 主从模式下的高可用切换问题； 
很方便实现 Redis 数据节点的线形扩展，轻松突破 Redis 自身单线程瓶颈，可极
大满足 Redis 大容量或高性能的业务需求； 可以实现一套 Sentinel 监控一组 Redis
数据节点或多组数据节点。 缺点： 
部署相对 Redis 主从模式要复杂一些，原理理解更繁琐； 资源浪费，Redis 数据
节点中 slave 节点作为备份节点不提供服务； Redis Sentinel 主要是针对 Redis 数
据节点中的主节点的高可用切换，对 Redis 的数据节点做失败判定分为主观下线
和客观下线两种，对于 Redis 的从节点有对节点做主观下线操作，并不执行故障
转移。 不能解决读写分离问题，实现起来相对复杂。 
40. 介绍下 Redis Cluster Redis 的哨兵模式基本已经可以实现高可用，读写分离 ，但
是在这种模式下每台 Redis 服务器都存储相同的数据，很浪费内存，所以在 
Redis3.0 上加入了 Cluster 集群模式，实现了 Redis 的分布式存储，对数据进行
分片，也就是说每台 Redis 节点上存储不同的内容。 
Redis Cluster 是社区版推出的 Redis 分布式集群解决方案，主要解决 Redis 分布
式方面的需求，比如，当遇到单机内存，并发和流量等瓶颈的时候，Redis Cluster
能起到很好的负载均衡的目的。 
Redis Cluster 集群节点最小配置 6 个节点以上（3 主 3 从），其中主节点提供读
写操作，从节点作为备用节点，不提供请求，只作为故障转移使用。 
Redis Cluster 采用虚拟槽分区，所有的键根据哈希函数映射到 0～16383 个整数
槽内，每个节点负责维护一部分槽以及槽所印映射的键值数据。 
优点： 
无中心架构； 数据按照 slot 存储分布在多个节点，节点间数据共享，可动态调
整数据分布； 可扩展性：可线性扩展到 1000 多个节点，节点可动态添加或删除； 
高可用性：部分节点不可用时，集群仍可用。通过增加 Slave 做 standby 数据副
本，能够实现故障自动 failover，节点之间通过 gossip 协议交换状态信息，用投
票机制完成 Slave 到 Master 的角色提升； 降低运维成本，提高系统的扩展性和
可用性。 缺点： 
Client 实现复杂，驱动要求实现 Smart Client，缓存 slots mapping 信息并及时更
新，提高了开发难度，客户端的不成熟影响业务的稳定性。目前仅 JedisCluster 相
对成熟，异常处理部分还不完善，比如常见的“max redirect exception”。 节点会
因为某些原因发生阻塞（阻塞时间大于 clutser-node-timeout），被判断下线，这
种 failover 是没有必要的。 数据通过异步复制，不保证数据的强一致性。 多个
业务使用同一套集群时，无法根据统计区分冷热数据，资源隔离性较差，容易出
现相互影响的情况。 Slave 在集群中充当“冷备”，不能缓解读压力，当然可以通
过 SDK 的合理设计来提高 Slave 资源的利用率。 Key 批量操作限制，如使用
mset、mget 目前只支持具有相同 slot 值的 Key 执行批量操作。对于映射为不同
slot 值的 Key 由于 Keys 不支持跨 slot 查询，所以执行 mset、mget、sunion 等操
作支持不友好。 Key 事务操作支持有限，只支持多 key 在同一节点上的事务操
作，当多个 Key 分布于不同的节点上时无法使用事务功能。 Key 作为数据分区
的最小粒度，不能将一个很大的键值对象如 hash、list 等映射到不同的节点。 不
支持多数据库空间，单机下的 Redis 可以支持到 16 个数据库，集群模式下只能
使用 1 个数据库空间，即 db 0。 复制结构只支持一层，从节点只能复制主节点，
不支持嵌套树状复制结构。 避免产生 hot-key，导致主库节点成为系统的短板。 
避免产生 big-key，导致网卡撑爆、慢查询等。 重试时间应该大于 cluster-node-
time 时间。 Redis Cluster 不建议使用 pipeline 和 multi-keys 操作，减少 max redirect
产生的场景。 
41. 介绍下 Redis 自研 Redis 自研的高可用解决方案，主要体现在配置中心、故障探
测和 failover 的处理机制上，通常需要根据企业业务的实际线上环境来定制化。 
优点： 
高可靠性、高可用性； 自主可控性高； 贴切业务实际需求，可缩性好，兼容性
好。 缺点： 
实现复杂，开发成本高； 需要建立配套的周边设施，如监控，域名服务，存储
元数据信息的数据库等； 维护成本高。 
42. Redis 高可用方案具体怎么实施？ 使用官方推荐的哨兵(sentinel)机制就能实现，
当主节点出现故障时，由 Sentinel 自动完成故障发现和转移，并通知应用方，实
现高可用性。它有四个主要功能： 
集群监控，负责监控 Redis master 和 slave 进程是否正常工作。 消息通知，如果
某个 Redis 实例有故障，那么哨兵负责发送消息作为报警通知给管理员。 故障
转移，如果 master node 挂掉了，会自动转移到 slave node 上。 配置中心，如果
故障转移发生了，通知 client 客户端新的 master 地址。 
43. 了解主从复制的原理吗？ 1、主从架构的核心原理 
当启动一个 slave node 的时候，它会发送一个 PSYNC 命令给 master node 
如果这是 slave node 重新连接 master node，那么 master node 仅仅会复制给 slave
部分缺少的数据; 否则如果是 slave node 第一次连接 master node，那么会触发一
次 full resynchronization 
开始 full resynchronization 的时候，master 会启动一个后台线程，开始生成一份
RDB 快照文件，同时还会将从客户端收到的所有写命令缓存在内存中。RDB 文
件生成完毕之后，master 会将这个 RDB 发送给 slave，slave 会先写入本地磁盘，
然后再从本地磁盘加载到内存中。然后 master 会将内存中缓存的写命令发送给
slave，slave 也会同步这些数据。 
slave node 如果跟 master node 有网络故障，断开了连接，会自动重连。master 如
果发现有多个 slave node 都来重新连接，仅仅会启动一个 rdb save 操作，用一份
数据服务所有 slave node。 
2、主从复制的断点续传 
从 Redis 2.8 开始，就支持主从复制的断点续传，如果主从复制过程中，网络连
接断掉了，那么可以接着上次复制的地方，继续复制下去，而不是从头开始复制
一份 
master node 会在内存中常见一个 backlog，master 和 slave 都会保存一个 replica 
offset 还有一个 master id，offset 就是保存在 backlog 中的。如果 master 和 slave
网络连接断掉了，slave 会让 master 从上次的 replica offset 开始继续复制 
但是如果没有找到对应的 offset，那么就会执行一次 resynchronization 
3、无磁盘化复制 
master 在内存中直接创建 rdb，然后发送给 slave，不会在自己本地落地磁盘了 
repl-diskless-sync repl-diskless-sync-delay，等待一定时长再开始复制，因为要等更
多 slave 重新连接过来 
4、过期 key 处理 
slave 不会过期 key，只会等待 master 过期 key。如果 master 过期了一个 key，或
者通过 LRU 淘汰了一个 key，那么会模拟一条 del 命令发送给 slave。 
44. 由于主从延迟导致读取到过期数据怎么处理？ 通过 scan 命令扫库：当 Redis 中
的 key 被 scan 的时候，相当于访问了该 key，同样也会做过期检测，充分发挥
Redis 惰性删除的策略。这个方法能大大降低了脏数据读取的概率，但缺点也比
较明显，会造成一定的数据库压力，否则影响线上业务的效率。 Redis 加入了一
个新特性来解决主从不一致导致读取到过期数据问题，增加了 key 是否过期以及
对主从库的判断，如果 key 已过期，当前访问的 master 则返回 null；当前访问的
是从库，且执行的是只读命令也返回 null。 
45. 主从复制的过程中如果因为网络原因停止复制了会怎么样？ 如果出现网络故障
断开连接了，会自动重连的，从 Redis 2.8 开始，就支持主从复制的断点续传，可
以接着上次复制的地方，继续复制下去，而不是从头开始复制一份。 
master 如果发现有多个 slave node 都来重新连接，仅仅会启动一个 rdb save 操作，
用一份数据服务所有 slave node。 
master node 会在内存中创建一个 backlog，master 和 slave 都会保存一个 replica 
offset，还有一个 master id，offset 就是保存在 backlog 中的。如果 master 和 slave
网络连接断掉了，slave 会让 master 从上次的 replica offset 开始继续复制。 
但是如果没有找到对应的 offset，那么就会执行一次 resynchronization 全量复制。 
46. Redis 主从架构数据会丢失吗，为什么？ 有两种数据丢失的情况： 
异步复制导致的数据丢失：因为 master -> slave 的复制是异步的，所以可能有部
分数据还没复制到 slave，master 就宕机了，此时这些部分数据就丢失了。 脑裂
导致的数据丢失：某个 master 所在机器突然脱离了正常的网络，跟其他 slave 机
器不能连接，但是实际上 master 还运行着，此时哨兵可能就会认为 master 宕机
了，然后开启选举，将其他 slave 切换成了 master。这个时候，集群里就会有两
个 master，也就是所谓的脑裂。此时虽然某个 slave 被切换成了 master，但是可
能 client 还没来得及切换到新的 master，还继续写向旧 master 的数据可能也丢失
了。因此旧 master 再次恢复的时候，会被作为一个 slave 挂到新的 master 上去，
自己的数据会清空，重新从新的 master 复制数据。 
47. 如何解决主从架构数据丢失的问题？ 数据丢失的问题是不可避免的，但是我们
可以尽量减少。 
在 Redis 的配置文件里设置参数 
min-slaves-to-write 1 min-slaves-max-lag 10 min-slaves-to-write 默认情况下是 0，
min-slaves-max-lag 默认情况下是 10。 
上面的配置的意思是要求至少有 1 个 slave，数据复制和同步的延迟不能超过 10
秒。如果说一旦所有的 slave，数据复制和同步的延迟都超过了 10 秒钟，那么这
个时候，master 就不会再接收任何请求了。 
减小 min-slaves-max-lag 参数的值，这样就可以避免在发生故障时大量的数据丢
失，一旦发现延迟超过了该值就不会往 master 中写入数据。 
那么对于 client，我们可以采取降级措施，将数据暂时写入本地缓存和磁盘中，
在一段时间后重新写入 master 来保证数据不丢失；也可以将数据写入 kafka 消息
队列，隔一段时间去消费 kafka 中的数据。 
48. Redis 哨兵是怎么工作的？ 每个 Sentinel 以每秒钟一次的频率向它所知的 Master，
Slave 以及其他 Sentinel 实例发送一个 PING 命令。 
如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-
after-milliseconds 选项所指定的值， 则这个实例会被当前 Sentinel 标记为主观
下线。 
如果一个 Master 被标记为主观下线，则正在监视这个 Master 的所有 Sentinel 要
以每秒一次的频率确认 Master 的确进入了主观下线状态。 
当有足够数量的 Sentinel（大于等于配置文件指定的值）在指定的时间范围内确
认 Master 的确进入了主观下线状态， 则 Master 会被标记为客观下线 。 
当 Master 被 Sentinel 标记为客观下线时，Sentinel 向下线的 Master 的所有 
Slave 发送 INFO 命令的频率会从 10 秒一次改为每秒一次 （在一般情况下， 
每个 Sentinel 会以每 10 秒一次的频率向它已知的所有 Master，Slave 发送 
INFO 命令 ）。 
若没有足够数量的 Sentinel 同意 Master 已经下线， Master 的客观下线状态就
会变成主观下线。若 Master 重新向 Sentinel 的 PING 命令返回有效回复， 
Master 的主观下线状态就会被移除。 
sentinel 节点会与其他 sentinel 节点进行“沟通”，投票选举一个 sentinel 节点进行
故障处理，在从节点中选取一个主节点，其他从节点挂载到新的主节点上自动复
制新主节点的数据。 
49. 故障转移时会从剩下的 slave 选举一个新的 master，被选举为 master 的标准是什
么？ 如果一个 master 被认为 odown 了，而且 majority 哨兵都允许了主备切换，
那么某个哨兵就会执行主备切换操作，此时首先要选举一个 slave 来，会考虑 slave
的一些信息。 
跟 master 断开连接的时长。 如果一个 slave 跟 master 断开连接已经超过了 down-
after-milliseconds 的 10 倍，外加 master 宕机的时长，那么 slave 就被认为不适合
选举为 master. 
( down-after-milliseconds * 10) + milliseconds_since_master_is_in_SDOWN_state 
slave 优先级。 按照 slave 优先级进行排序，slave priority 越低，优先级就越高 
复制 offset。 如果 slave priority 相同，那么看 replica offset，哪个 slave 复制了越
多的数据，offset 越靠后，优先级就越高 
run id 如果上面两个条件都相同，那么选择一个 run id 比较小的那个 slave。 
50. 同步配置的时候其他哨兵根据什么更新自己的配置呢？ 执行切换的那个哨兵，
会从要切换到的新 master（salve->master）那里得到一个 configuration epoch，这
就是一个 version 号，每次切换的 version 号都必须是唯一的。 
如果第一个选举出的哨兵切换失败了，那么其他哨兵，会等待 failover-timeout 时
间，然后接替继续执行切换，此时会重新获取一个新的 configuration epoch 作为
新的 version 号。 
这个 version 号就很重要了，因为各种消息都是通过一个 channel 去发布和监听
的，所以一个哨兵完成一次新的切换之后，新的 master 配置是跟着新的 version
号的，其他的哨兵都是根据版本号的大小来更新自己的 master 配置的。 
51. 为什么 Redis 哨兵集群只有 2 个节点无法正常工作？ 哨兵集群必须部署 2 个以
上节点。 
如果两个哨兵实例，即两个 Redis 实例，一主一从的模式。 
则 Redis 的配置 quorum=1，表示一个哨兵认为 master 宕机即可认为 master 已宕
机。 
但是如果是机器 1 宕机了，那哨兵 1 和 master 都宕机了，虽然哨兵 2 知道 master
宕机了，但是这个时候，需要 majority，也就是大多数哨兵都是运行的，2 个哨
兵的 majority 就是 2（2 的 majority=2，3 的 majority=2，5 的 majority=3，4 的
majority=2），2 个哨兵都运行着，就可以允许执行故障转移。 
但此时哨兵 1 没了就只有 1 个哨兵了了，此时就没有 majority 来允许执行故障转
移，所以故障转移不会执行。 
52. Redis cluster 中是如何实现数据分布的？这种方式有什么优点？ Redis cluster 有
固定的 16384 个 hash slot（哈希槽），对每个 key 计算 CRC16 值，然后对 16384
取模，可以获取 key 对应的 hash slot。 
Redis cluster 中每个 master 都会持有部分 slot（槽），比如有 3 个 master，那么
可能每个 master 持有 5000 多个 hash slot。 
hash slot 让 node 的增加和移除很简单，增加一个 master，就将其他 master 的 hash 
slot 移动部分过去，减少一个 master，就将它的 hash slot 移动到其他 master 上
去。每次增加或减少 master 节点都是对 16384 取模，而不是根据 master 数量，
这样原本在老的 master 上的数据不会因 master 的新增或减少而找不到。并且增
加或减少 master 时 Redis cluster 移动 hash slot 的成本是非常低的。 
53. Redis cluster 节点间通信是什么机制？ Redis cluster 节点间采取 gossip 协议进行
通信，所有节点都持有一份元数据，不同的节点如果出现了元数据的变更之后 U
不断地 i 将元数据发送给其他节点让其他节点进行数据变更。 
节点互相之间不断通信，保持整个集群所有节点的数据是完整的。 主要交换故
障信息、节点的增加和移除、hash slot 信息等。 
这种机制的好处在于，元数据的更新比较分散，不是集中在一个地方，更新请求
会陆陆续续，打到所有节点上去更新，有一定的延时，降低了压力; 
缺点，元数据更新有延时，可能导致集群的一些操作会有一些滞后。 
分布式问题 
54. 什么是分布式锁？为什么用分布式锁？ 锁在程序中的作用就是同步工具，保证
共享资源在同一时刻只能被一个线程访问，Java 中的锁我们都很熟悉了，像
synchronized 、Lock 都是我们经常使用的，但是 Java 的锁只能保证单机的时候
有效，分布式集群环境就无能为力了，这个时候我们就需要用到分布式锁。 
分布式锁，顾名思义，就是分布式项目开发中用到的锁，可以用来控制分布式系
统之间同步访问共享资源。 
思路是：在整个系统提供一个全局、唯一的获取锁的“东西”，然后每个系统在需
要加锁时，都去问这个“东西”拿到一把锁，这样不同的系统拿到的就可以认为是
同一把锁。至于这个“东西”，可以是 Redis、Zookeeper，也可以是数据库。 
一般来说，分布式锁需要满足的特性有这么几点： 
1、互斥性：在任何时刻，对于同一条数据，只有一台应用可以获取到分布式锁； 
2、高可用性：在分布式场景下，一小部分服务器宕机不影响正常使用，这种情
况就需要将提供分布式锁的服务以集群的方式部署； 
3、防止锁超时：如果客户端没有主动释放锁，服务器会在一段时间之后自动释
放锁，防止客户端宕机或者网络不可达时产生死锁； 
4、独占性：加锁解锁必须由同一台服务器进行，也就是锁的持有者才可以释放
锁，不能出现你加的锁，别人给你解锁了。 
55. 常见的分布式锁有哪些解决方案？ 实现分布式锁目前有三种流行方案，即基于
关系型数据库、Redis、ZooKeeper 的方案 
1、基于关系型数据库，如 MySQL 基于关系型数据库实现分布式锁，是依赖数
据库的唯一性来实现资源锁定，比如主键和唯一索引等。 
缺点： 
这把锁强依赖数据库的可用性，数据库是一个单点，一旦数据库挂掉，会导致业
务系统不可用。 这把锁没有失效时间，一旦解锁操作失败，就会导致锁记录一
直在数据库中，其他线程无法再获得到锁。 这把锁只能是非阻塞的，因为数据
的 insert 操作，一旦插入失败就会直接报错。没有获得锁的线程并不会进入排队
队列，要想再次获得锁就要再次触发获得锁操作。 这把锁是非重入的，同一个
线程在没有释放锁之前无法再次获得该锁。因为数据中数据已经存在了。 2、基
于 Redis 实现 
优点： 
Redis 锁实现简单，理解逻辑简单，性能好，可以支撑高并发的获取、释放锁操
作。 
缺点： 
Redis 容易单点故障，集群部署，并不是强一致性的，锁的不够健壮； key 的过
期时间设置多少不明确，只能根据实际情况调整； 需要自己不断去尝试获取锁，
比较消耗性能。 3、基于 zookeeper 
优点： 
zookeeper 天生设计定位就是分布式协调，强一致性，锁很健壮。如果获取不到
锁，只需要添加一个监听器就可以了，不用一直轮询，性能消耗较小。 
缺点： 
在高请求高并发下，系统疯狂的加锁释放锁，最后 zk 承受不住这么大的压力可
能会存在宕机的风险。 
56. Redis 实现分布式锁 分布式锁的三个核心要素 1、加锁 
使用 setnx 来加锁。key 是锁的唯一标识，按业务来决定命名，value 这里设置为
test。 
setx key test 当一个线程执行 setnx 返回 1，说明 key 原本不存在，该线程成功得
到了锁；当一个线程执行 setnx 返回 0，说明 key 已经存在，该线程抢锁失败； 
2、解锁 
有加锁就得有解锁。当得到的锁的线程执行完任务，需要释放锁，以便其他线程
可以进入。释放锁的最简单方式就是执行 del 指令。 
del key 释放锁之后，其他线程就可以继续执行 setnx 命令来获得锁。 
3、锁超时 
锁超时知道的是：如果一个得到锁的线程在执行任务的过程中挂掉，来不及显式
地释放锁，这块资源将会永远被锁住，别的线程北向进来。 
所以，setnx 的 key 必须设置一个超时时间，以保证即使没有被显式释放，这把
锁也要在一段时间后自动释放。setnx 不支持超时参数，所以需要额外指令， 
expire key 30 上述分布式锁存在的问题 通过上述 setnx 、del 和 expire 实现的分
布式锁还是存在着一些问题。 
1、SETNX 和 EXPIRE 非原子性 
假设一个场景中，某一个线程刚执行 setnx，成功得到了锁。此时 setnx 刚执行成
功，还未来得及执行 expire 命令，节点就挂掉了。此时这把锁就没有设置过期时
间，别的线程就再也无法获得该锁。 
解决措施: 
由于 setnx 指令本身是不支持传入超时时间的，而在 Redis2.6.12 版本上为 set 指
令增加了可选参数, 用法如下： 
SET key value EX seconds [NX|XX] EX second: 设置键的过期时间为 second 秒； 
PX millisecond：设置键的过期时间为 millisecond 毫秒； NX：只在键不存在时，
才对键进行设置操作； XX：只在键已经存在时，才对键进行设置操作； SET 操
作完成时，返回 OK，否则返回 nil。 2、锁误解除 
如果线程 A 成功获取到了锁，并且设置了过期时间 30 秒，但线程 A 执行时
间超过了 30 秒，锁过期自动释放，此时线程 B 获取到了锁；随后 A 执行完
成，线程 A 使用 DEL 命令来释放锁，但此时线程 B 加的锁还没有执行完成，
线程 A 实际释放的线程 B 加的锁。 
解决办法： 
在 del 释放锁之前加一个判断，验证当前的锁是不是自己加的锁。 
具体在加锁的时候把当前线程的 id 当做 value，可生成一个 UUID 标识当前线
程，在删除之前验证 key 对应的 value 是不是自己线程的 id。 
还可以使用 lua 脚本做验证标识和解锁操作。 
3、超时解锁导致并发 
如果线程 A 成功获取锁并设置过期时间 30 秒，但线程 A 执行时间超过了 30 
秒，锁过期自动释放，此时线程 B 获取到了锁，线程 A 和线程 B 并发执行。 
A、B 两个线程发生并发显然是不被允许的，一般有两种方式解决该问题： 
将过期时间设置足够长，确保代码逻辑在锁释放之前能够执行完成。 为获取锁
的线程增加守护线程，为将要过期但未释放的锁增加有效时间。 4、不可重入 
当线程在持有锁的情况下再次请求加锁，如果一个锁支持一个线程多次加锁，那
么这个锁就是可重入的。如果一个不可重入锁被再次加锁，由于该锁已经被持有，
再次加锁会失败。Redis 可通过对锁进行重入计数，加锁时加 1，解锁时减 1，
当计数归 0 时释放锁。 
5、无法等待锁释放 
上述命令执行都是立即返回的，如果客户端可以等待锁释放就无法使用。 
可以通过客户端轮询的方式解决该问题，当未获取到锁时，等待一段时间重新获
取锁，直到成功获取锁或等待超时。这种方式比较消耗服务器资源，当并发量比
较大时，会影响服务器的效率。 另一种方式是使用 Redis 的发布订阅功能，当
获取锁失败时，订阅锁释放消息，获取锁成功后释放时，发送锁释放消息。 具
体实现参考：https://xiaomi-info.github.io/2019/12/17/Redis-distributed-lock/ 
57. 了解RedLock吗？ Redlock是一种算法，Redlock也就是 Redis Distributed Lock，
可用实现多节点 Redis 的分布式锁。 
RedLock 官方推荐，Redisson 完成了对 Redlock 算法封装。 
此种方式具有以下特性： 
互斥访问：即永远只有一个 client 能拿到锁 避免死锁：最终 client 都可能拿到
锁，不会出现死锁的情况，即使锁定资源的服务崩溃或者分区，仍然能释放锁。 
容错性：只要大部分 Redis 节点存活（一半以上），就可以正常提供服务 
58. RedLock 的原理 假设有 5 个完全独立的 Redis 主服务器 
获取当前时间戳 
client 尝试按照顺序使用相同的 key,value 获取所有 Redis 服务的锁，在获取锁的
过程中的获取时间比锁过期时间短很多，这是为了不要过长时间等待已经关闭的
Redis 服务。并且试着获取下一个 Redis 实例。 
比如：TTL 为 5s,设置获取锁最多用 1s，所以如果一秒内无法获取锁，就放弃获
取这个锁，从而尝试获取下个锁 
client 通过获取所有能获取的锁后的时间减去第一步的时间，这个时间差要小于
TTL 时间并且至少有 3 个 Redis 实例成功获取锁，才算真正的获取锁成功 
如果成功获取锁，则锁的真正有效时间是 TTL 减去第三步的时间差 的时间；比
如：TTL 是 5s,获取所有锁用了 2s,则真正锁有效时间为 3s(其实应该再减去时钟
漂移); 
如果客户端由于某些原因获取锁失败，便会开始解锁所有 Redis 实例；因为可能
已经获取了小于 3 个锁，必须释放，否则影响其他 client 获取锁 
算法示意图如下： 
其他 
59. Redis 如何做内存优化？ 控制 key 的数量。当使用 Redis 存储大量数据时，通常
会存在大量键，过多的键同样会消耗大量内存。Redis 本质是一个数据结构服务
器，它为我们提供多种数据结构，如 hash，list，set，zset 等结构。使用 Redis 时
不要进入一个误区，大量使用 get/set 这样的 API，把 Redis 当成 Memcached 使
用。对于存储相同的数据内容利用 Redis 的数据结构降低外层键的数量，也可以
节省大量内存。 
缩减键值对象，降低 Redis 内存使用最直接的方式就是缩减键（key）和值（value）
的长度。 
key 长度：如在设计键时，在完整描述业务情况下，键值越短越好。 value 长度：
值对象缩减比较复杂，常见需求是把业务对象序列化成二进制数组放入 Redis。
首先应该在业务上精简业务对象，去掉不必要的属性避免存储无效数据。其次在
序列化工具选择上，应该选择更高效的序列化工具来降低字节数组大小。 编码
优化。Redis 对外提供了 string,list,hash,set,zet 等类型，但是 Redis 内部针对不同
类型存在编码的概念，所谓编码就是具体使用哪种底层数据结构来实现。编码不
同 将 直 接 影 响 数 据 的 内 存 占 用 和 读 写 效 率 。 可 参 考 文 章 ：
https://cloud.tencent.com/developer/article/1162213 
60. 如果现在有个读超高并发的系统，用 Redis 来抗住大部分读请求，你会怎么设计？ 
如果是读高并发的话，先看读并发的数量级是多少，因为 Redis 单机的读 QPS 在
万级，每秒几万没问题，使用一主多从+哨兵集群的缓存架构来承载每秒 10W+
的读并发，主从复制，读写分离。 
使用哨兵集群主要是提高缓存架构的可用性，解决单点故障问题。主库负责写，
多个从库负责读，支持水平扩容，根据读请求的 QPS 来决定加多少个 Redis 从实
例。如果读并发继续增加的话，只需要增加 Redis 从实例就行了。 
如果需要缓存 1T+的数据，选择 Redis cluster 模式，每个主节点存一部分数据，
假设一个 master 存 32G，那只需要 n*32G>=1T，n 个这样的 master 节点就可以
支持 1T+的海量数据的存储了。 
Redis 单主的瓶颈不在于读写的并发，而在于内存容量，即使是一主多从也是不
能解决该问题，因为一主多从架构下，多个 slave 的数据和 master 的完全一样。
假如 master 是 10G 那 slave 也只能存 10G 数据。所以数据量受单主的影响。 而
这个时候又需要缓存海量数据，那就必须得有多主了，并且多个主保存的数据还
不能一样。Redis 官方给出的 Redis cluster 模式完美的解决了这个问题。 
9. MQ 
为什么使用 MQ？ 
使用 MQ 的场景很多，主要有三个：解耦、异步、削峰。 
 
解耦：假设现在，日志不光要插入到数据库里，还要在硬盘中增加文件类型的日
志，同时，一些关键日志还要通过邮件的方式发送给指定的人。那么，如果按照
原来的逻辑，A 可能就需要在原来的代码上做扩展，除了 B 服务，还要加上日志
文件的存储和日志邮件的发送。但是，如果你使用了 MQ，那么，A 服务是不需
要做更改的，它还是将消息放到 MQ 中即可，其它的服务，无论是原来的 B 服
务还是新增的日志文件存储服务或日志邮件发送服务，都直接从 MQ 中获取消
息并处理即可。这就是解耦，它的好处是提高系统灵活性，扩展性。 
 
异步：可以将一些非核心流程，如日志，短信，邮件等，通过 MQ 的方式异步去
处理。这样做的好处是缩短主流程的响应时间，提升用户体验。互联网类企业对
用户的直接操作，一般要求每个请求在 200ms 以内完成。对于一个系统调用多
个系统，不使用 MQ 的情况下，它执行完返回的耗时是调用完所有系统所需时
间的总和；使用 MQ 进行优化后，执行的耗时则是执行主系统的耗时加上发送
数据到消息队列的耗时，大幅度提升系统性能和用户体验。 
 
削峰：MQ 的本质就是业务的排队。所以，面对突然到来的高并发，MQ 也可以
不用慌忙，先排好队，不要着急，一个一个来。削峰的好处就是避免高并发压垮
系统的关键组件，如某个核心服务或数据库等。MySQL 每秒最高并发请求在 
2000 左右，用户访问量高峰期的时候涌入的大量请求，会将 MySQL 打死，然
后系统就挂掉，但过了高峰期，请求量可能远低于 2000，这种情况去增加服务
器就不值得，如果使用 MQ 的情况，将用户的请求全部放到 MQ 中，让系统去
消费用户的请求，不要超过系统所能承受的最大请求数量，保证系统不会再高峰
期挂掉，高峰期过后系统还是按照最大请求数量处理完请求。 
下面附场景解释： 
解耦 
场景：A 系统发送数据到 BCD 三个系统，通过接口调用发送。如果 E 系统也
要这个数据呢？那如果 C 系统现在不需要了呢？A 系统负责人几乎崩溃...... 
在这个场景中，A 系统跟其它各种乱七八糟的系统严重耦合，A 系统产生一条
比较关键的数据，很多系统都需要 A 系统将这个数据发送过来。A 系统要时时
刻刻考虑 BCDE 四个系统如果挂了该咋办？要不要重发，要不要把消息存起来？
头发都白了啊！ 
如果使用 MQ，A 系统产生一条数据，发送到 MQ 里面去，哪个系统需要数据
自己去 MQ 里面消费。如果新系统需要数据，直接从 MQ 里消费即可；如果某
个系统不需要这条数据了，就取消对 MQ 消息的消费即可。这样下来，A 系统
压根儿不需要去考虑要给谁发送数据，不需要维护这个代码，也不需要考虑人家
是否调用成功、失败超时等情况。 
总结：通过一个 MQ，Pub/Sub 发布订阅消息这么一个模型，A 系统就跟其它系
统彻底解耦了。 
异步 
场景：A 系统接收一个请求，需要在自己本地写库，还需要在 BCD 三个系统写
库，自己本地写库要 3ms，BCD 三个系统分别写库要 300ms、450ms、200ms。
最终请求总延时是 3 + 300 + 450 + 200 = 953ms，接近 1s，用户感觉搞个什么东
西，慢死了慢死了。用户通过浏览器发起请求，等待个 1s，这几乎是不可接受
的。 
一般互联网类的企业，对于用户直接的操作，一般要求是每个请求都必须在 200 
ms 以内完成，对用户几乎是无感知的。 
如果使用 MQ，那么 A 系统连续发送 3 条消息到 MQ 队列中，假如耗时 5ms，
A 系统从接受一个请求到返回响应给用户，总时长是 3 + 5 = 8ms，对于用户而
言，其实感觉上就是点个按钮，8ms 以后就直接返回了。 
削峰 
场景：每天 0:00 到 12:00，A 系统风平浪静，每秒并发请求数量就 50 个。结
果每次一到 12:00 ~ 13:00 ，每秒并发请求数量突然会暴增到 5k+ 条。但是系统
是直接基于 MySQL 的，大量的请求涌入 MySQL，每秒钟对 MySQL 执行约 
5k 条 SQL。 
使用 MQ，每秒 5k 个请求写入 MQ，A 系统每秒钟最多处理 2k 个请求，因
为 MySQL 每秒钟最多处理 2k 个。A 系统从 MQ 中慢慢拉取请求，每秒钟就
拉取 2k 个请求，不要超过自己每秒能处理的最大请求数量就 ok，这样下来，
哪怕是高峰期的时候，A 系统也绝对不会挂掉。而 MQ 每秒钟 5k 个请求进来，
就 2k 个请求出去，结果就导致在中午高峰期（1 个小时），可能有几十万甚至
几百万的请求积压在 MQ 中。 
这个短暂的高峰期积压是 ok 的，因为高峰期过了之后，每秒钟就 50 个请求进 
MQ，但是 A 系统依然会按照每秒 2k 个请求的速度在处理。所以说，只要高峰
期一过，A 系统就会快速将积压的消息给解决掉。 
消息队列的缺点 
1、 系统可用性降低 
系统引入的外部依赖越多，越容易挂掉。MQ 挂掉，所关联的系统 都会无法提
供服务。 
2、 系统复杂度提高 
加入了消息队列，要多考虑很多方面的问题，比如：一致性问题、如何保证消息
不被重复消费、如何保证消息可靠性传输等。因此，需要考虑的东西更多，复杂
性增大。 
3、 一致性问题 
A 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，
要是 BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了，
这就数据不一致了。 
Kafka、ActiveMQ、RabbitMQ、RocketMQ 有什么优缺点？ 
特性 
ActiveMQ 
RabbitMQ 
RocketMQ 
Kafka 
开发语
言 
java 
erlang 
java 
scala 
单机吞
吐量 
万
级
，
比 
RocketMQ
、
Kafka 低一个数
量级 
同 ActiveMQ 
10 万级，支撑高吞吐 
10 万级，高吞
数据类的系统
据计算、日志
topic 
数量对
吞吐量
的影响 
 
 
topic 可以达到几百/几千
的级别，吞吐量会有较小
幅 度 的 下 降 ， 这 是 
RocketMQ 的一大优势，在
同等机器下，可以支撑大
量的 topic 
topic 从几十到
吞吐量会大幅
机 器 下 ， K
topic 数量不要
支撑大规模的
加更多的机器
时效性 
ms 级 
微 秒 级 ， 这 是 
RabbitMQ 的 一
大特点，延迟最
低 
ms 级 
延迟在 ms 级
可用性 
高，基于主从架
构实现高可用 
同 ActiveMQ 
非常高，分布式架构 
非常高，分布
个副本，少数
丢失数据，不
特性 
ActiveMQ 
RabbitMQ 
RocketMQ 
Kafka 
消息可
靠性 
有较低的概率丢
失数据 
基本不丢 
经过参数优化配置，可以
做到 0 丢失 
同 RocketMQ
功能支
持 
MQ 领域的功能
极其完备 
基 于  erlang 开
发，并发能力很
强，性能极好，延
时很低 
MQ 功能较为完善，还是
分布式的，扩展性好 
功能较为简单
的 MQ 功能
的实时计算以
大规模使用 
社区活
跃度 
低 
很高 
一般 
很高 
 
中小型公司，技术实力较为一般，技术挑战不是特别高，用 RabbitMQ 是不错的
选择； 
 
大型公司，基础架构研发实力较强，用 RocketMQ 是很好的选择。 
 
大数据领域的实时计算、日志采集等场景，用 是业内标准的，几乎是全世界这
个领域的事实性规范。 
RabbitMQ 
RabbitMQ 是什么？ 
RabbitMQ 是实现了高级消息队列协议（AMQP）的开源消息代理软件（亦称面
向消息的中间件）。RabbitMQ 服务器是用 Erlang 语言编写的，而群集和故障转
移是构建在开放电信平台框架上的。所有主要的编程语言均有与代理接口通讯的
客户端库。 
RabbitMQ 特点? 
可靠性: RabbitMQ 使用一些机制来保证可靠性， 如持久化、传输确认及发布确
认等。 
灵活的路由 : 在消息进入队列之前，通过交换器来路由消息。对于典型的路由
功能， RabbitMQ 己经提供了一些内置的交换器来实现。针对更复杂的路由功
能，可以将多个 交换器绑定在一起， 也可以通过插件机制来实现自己的交换器。 
扩展性: 多个 RabbitMQ 节点可以组成一个集群，也可以根据实际业务情况动态
地扩展集群中节点。 
高可用性: 队列可以在集群中的机器上设置镜像，使得在部分节点出现问题的情
况下队 列仍然可用。 
多种协议: RabbitMQ 除了原生支持 AMQP 协议，还支持 STOMP， MQTT 等多
种消息 中间件协议。 
多语言客户端: RabbitMQ 几乎支持所有常用语言，比如 Java、 Python、 Ruby、 
PHP、C#、JavaScript 等。 
管理界面 : RabbitMQ 提供了一个易用的用户界面，使得用户可以监控和管理消
息、集 群中的节点等。 
令插件机制: RabbitMQ 提供了许多插件 ， 以实现从多方面进行扩展，当然也
可以编写自 己的插件。 
AMQP 是什么? 
RabbitMQ 就 是  AMQP 协 议 的  Erlang 的 实 现 ( 当 然  RabbitMQ 还 支 持 
STOMP2、 MQTT3 等协议 ) AMQP 的模型架构 和 RabbitMQ 的模型架构是一
样的，生产者将消息发送给交换器，交换器和队列绑定 。 
RabbitMQ 中的交换器、交换器类型、队列、绑定、路由键等都是遵循的 AMQP 
协议中相 应的概念。目前 RabbitMQ 最新版本默认支持的是 AMQP 0-9-1。 
AMQP 的 3 层协议？ 
Module Layer:协议最高层，主要定义了一些客户端调用的命令，客户端可以用这
些命令实现自己的业务逻辑。 
Session Layer:中间层，主要负责客户端命令发送给服务器，再将服务端应答返回
客户端，提供可靠性同步机制和错误处理。 
TransportLayer:最底层，主要传输二进制数据流，提供帧的处理、信道服用、错
误检测和数据表示等。 
说说 Broker 服务节点、Queue 队列、Exchange 交换器？ 
 
Broker 可以看做 RabbitMQ 的服务节点。一般请下一个 Broker 可以看做一个
RabbitMQ 服务器。 
 
Queue:RabbitMQ 的内部对象，用于存储消息。多个消费者可以订阅同一队列，
这时队列中的消息会被平摊（轮询）给多个消费者进行处理。 
 
Exchange:生产者将消息发送到交换器，由交换器将消息路由到一个或者多个队
列中。当路由不到时，或返回给生产者或直接丢弃。 
如何保证消息的可靠性？ 
分三点： 
 
生产者到 RabbitMQ：事务机制和 Confirm 机制，注意：事务机制和 Confirm 机
制是互斥的，两者不能共存，会导致 RabbitMQ 报错。 
 
RabbitMQ 自身：持久化、集群、普通模式、镜像模式。 
 
RabbitMQ 到消费者：basicAck 机制、死信队列、消息补偿机制。 
生产者消息运转的流程？ 
1. Producer 先连接到 Broker,建立连接 Connection,开启一个信道(Channel)。 
2. Producer 声明一个交换器并设置好相关属性。 
3. Producer 声明一个队列并设置好相关属性。 
4. Producer 通过路由键将交换器和队列绑定起来。 
5. Producer 发送消息到 Broker,其中包含路由键、交换器等信息。 
6. 相应的交换器根据接收到的路由键查找匹配的队列。 
7. 如果找到，将消息存入对应的队列，如果没有找到，会根据生产者的配置丢弃或
者退回给生产者。 
8. 关闭信道。 
9. 管理连接。 
import pika 
 
###  21.1. <a name='rabbitMQ'></a>rabbitMQ 
connection=pika.BlockingConnection(pika.ConnectionParameters('localhost')) 
channel=connection.channel()       #生成管道，在管道里跑不同的队列 
 
###  21.2. <a name='queue'></a>queue 
channel.queue_declare(queue='hello1') 
##  22. <a name='RabbitMQamessagecanneverbesentdirectlytothequeueitalwaysneedstogothrough'></a>RabbitMQ a message can never be sent directly to the queue,it always needs to go through 
an exchange. 
 
#向队列里发数据 
channel.basic_publish(exchange='',      #先把数据发给 exchange 交换器,exchage
再发给相应队列 
                      routing_key='hello1', #向"hello'队列发数据 
                      body='HelloWorld!!')  #发的消息 
 
print("[x]Sent'HelloWorld!'") 
connection.close() 
消费者接收消息过程？ 
1. Producer 先连接到 Broker,建立连接 Connection,开启一个信道(Channel)。 
2. 向 Broker 请求消费响应的队列中消息，可能会设置响应的回调函数。 
3. 等待 Broker 回应并投递相应队列中的消息，接收消息。 
4. 消费者确认收到的消息,ack。 
5. RabbitMq 从队列中删除已经确定的消息。 
6. 关闭信道。 
7. 关闭连接。 
import pika 
 
connection=pika.BlockingConnection(pika.ConnectionParameters('localhost')) 
channel=connection.channel() 
# You may ask why we declare the queue again ‒ we have already declared it in our previous 
code. 
# We could avoid that if we were sure that the queue already exists. For example if send.py 
program 
# was run before. But we're not yet sure which program to run first. In such cases it's a good 
# practice to repeat declaring the queue in both programs. 
channel.queue_declare(queue='hello1')#声明队列，保证程序不出错 
 
def callback(ch,method,properties,body): 
    print("-->ch",ch) 
    print("-->method",method) 
    print("-->properties",properties) 
    print("[x] Received %r" % body)         #一条消息被一个消费者接收后，该消息
就从队列删除 
 
channel.basic_consume(callback,              #回调函数，一接收到消息就调用回调函
数 
                      queue='hello1', 
                      no_ack=False)    #消费完毕后向服务端发送一个确认，默认
为 False 
 
print('[*] Waiting for messages.To exit press CTRL+C') 
channel.start_consuming() 
生产者如何将消息可靠投递到 RabbitMQ？ 
1. Client 发送消息给 MQ 
2. MQ 将消息持久化后，发送 Ack 消息给 Client，此处有可能因为网络问题导致 Ack
消息无法发送到 Client，那么 Client 在等待超时后，会重传消息； 
3. Client 收到 Ack 消息后，认为消息已经投递成功。 
RabbitMQ 如何将消息可靠投递到消费者？ 
1. MQ 将消息 push 给 Client（或 Client 来 pull 消息） 
2. Client 得到消息并做完业务逻辑 
3. Client 发送 Ack 消息给 MQ，通知 MQ 删除该消息，此处有可能因为网络问题导
致 Ack 失败，那么 Client 会重复消息，这里就引出消费幂等的问题； 
4. MQ 将已消费的消息删除。 
如何保证 RabbitMQ 消息队列的高可用? 
RabbitMQ 有三种模式：单机模式，普通集群模式，镜像集群模式。 
单机模式：就是 demo 级别的，一般就是你本地启动了玩玩儿的，没人生产用单
机模式 
普通集群模式：意思就是在多台机器上启动多个 RabbitMQ 实例，每个机器启动
一个。 
镜像集群模式：这种模式，才是所谓的 RabbitMQ 的高可用模式，跟普通集群模
式不一样的是，你创建的 queue，无论元数据(元数据指 RabbitMQ 的配置数据)还
是 queue 里的消息都会存在于多个实例上，然后每次你写消息到 queue 的时候，
都会自动把消息到多个实例的 queue 里进行消息同步。 
AMQP 模型的几大组件？  
交换器 (Exchange)：消息代理服务器中用于把消息路由到队列的组件。  
队列 (Queue)：用来存储消息的数据结构，位于硬盘或内存中。  
绑定 (Binding)：一套规则，告知交换器消息应该将消息投递给哪个队列。  
生产者 Producer?  
消息生产者，就是投递消息的一方。 消息一般包含两个部分：消息体（payload)
和标签(Label)。  
消费者 Consumer?  
消费消息，也就是接收消息的一方。 消费者连接到 RabbitMQ 服务器，并订阅
到队列上。消费消息时只消费消息体，丢弃标签。  
Broker 服务节点？ 
Broker 可以看做 RabbitMQ 的服务节点。一般请下一个 Broker 可以看做一个
RabbitMQ 服务器。  
Queue 队列？ 
Queue:RabbitMQ 的内部对象，用于存储消息。多个消费者可以订阅同一队列，
这时队列中的消息会被 平摊（轮询）给多个消费者进行处理。  
Exchange 交换器？  
Exchange:生产者将消息发送到交换器，有交换器将消息路由到一个或者多个队
列中。当路由不到时， 或返回给生产者或直接丢弃。  
RoutingKey 路由键？  
生产者将消息发送给交换器的时候，会指定一个 RoutingKey,用来指定这个消息
的路由规则，这个 RoutingKey 需要与交换器类型和绑定键(BindingKey)联合使
用才能最终生效。  
Binding 绑定？  
通过绑定将交换器和队列关联起来，一般会指定一个 BindingKey,这样 RabbitMq
就知道如何正确路由消 息到队列了。  
交换器 4 种类型？  
主要有以下 4 种。  
fanout: 把所有发送到该交换器的消息路由到所有与该交换器绑定的队列中。  
direct:把消息路由到 BindingKey 和 RoutingKey 完全匹配的队列中。  
topic: 匹 配 规 则 ：  RoutingKey 为 一 个  点 号 '.': 分 隔 的 字 符 串 。 比 如 : 
java.xiaoka.show BindingKey 和 RoutingKey 一样也是点号“.“分隔的字符串。 
BindingKey 可使用 * 和 # 用于做模糊匹配，*匹配一个单词，#匹配多个或者 0
个  
headers:不依赖路由键匹配规则路由消息。是根据发送消息内容中的 headers 属性
进行匹配。性能差， 基本用不到。  
如何保证消息不被重复消费?  
消息被重复消费，就是消费方多次接受到了同一条消息。根本原因就是，第一次
消费完之后，消费方给 MQ 确认已消费的反馈，MQ 没有成功接受。比如网络
原因、MQ 重启等。 所以 MQ 是无法保证消息不被重复消费的，只能业务系统
层面考虑。 不被重复消费的问题，就被转化为消息消费的幂等性的问题。幂等
性就是指一次和多次请求的结果一 致，多次请求不会产生副作用。 保证消息消
费的幂等性可以考虑下面的方式： 给消息生成全局 id，消费成功过的消息可以
直接丢弃 消息中保存业务数据的主键字段，结合业务系统需求场景进行处理，
避免多次插入、是否可以根据 主键多次更新而并不影响结果等  
如何保证消息不丢失？  
生产者丢失消息：如网络传输中丢失消息、MQ 发生异常未成功接收消息等情况。
解决办法：主流的 MQ 都有确认或事务机制，可以保证生产者将消息送达到 
MQ。如 RabbitMQ 就有事务模式和 confirm 模式。 MQ 丢失消息：MQ 成功
接收消息内部处理出错、宕机等情况。解决办法：开启 MQ 的持久化配置。 消
费者丢失消息：采用消息自动确认模式，消费者取到消息未处理挂掉了。解决办
法：改为手动确认模 式，消费者成功消费消息再确认。  
如何保证消息的顺序性？  
生产者保证消息入队的顺序。 MQ 本身是一种先进先出的数据接口，将同一类
消息，发到同一个 queue 中，保证出队是有序的。 避免多消费者并发消费同一
个 queue 中的消息。  
消息大量积压怎么解决？  
消息的积压来自于两方面：要么发送快了，要么消费变慢了。 单位时间发送的
消息增多，比如赶上大促或者抢购，短时间内不太可能优化消费端的代码来提升
消费性 能，唯一的办法是通过扩容消费端的实例数来提升总体的消费能力。严
重影响 QM 甚至整个系统时，可 以考虑临时启用多个消费者，并发接受消息，
持久化之后再单独处理，或者直接丢弃消息，回头让生产 者重新生产。 如果短
时间内没有服务器资源扩容，没办法的办法是将系统降级，通过关闭某些不重要
的业务，减少发 送的数据量，最低限度让系统还能正常运转，服务重要业务。 
监控发现，产生和消费消息的速度没什么变化，出现消息积压的情况，检查是有
消费失败反复消费的情 况。 监控发现，消费消息的速度变慢，检查消费实例，
日志中是否有大量消费错误、消费线程是否死锁、是 否卡在某些资源上。  
如何保证 MQ 的高可用?  
ActiveMQ： Master-Slave 部署方式主从热备，方式包括通过共享存储目录来实
现(shared filesystem MasterSlave)、通过共享数据库来实现(shared database Master-
Slave)、5.9 版本后新特性使用 ZooKeeper 协 调选择 master(Replicated LevelDB 
Store)。 Broker-Cluster 部署方式进行负载均衡。 RabbitMQ： 单机模式与普通
集群模式无法满足高可用，镜像集群模式指定多个节点复制 queue 中的消息做
到高可 用，但消息之间的同步网络性能开销较大。  
RocketMQ： 有多 master 多 slave 异步复制模式和多 master 多 slave 同步双
写模式支持集群部署模式。 Producer 随机选择 NameServer 集群中的其中一个
节点建立长连接，定期从 NameServer 获取 Topic 路由信息，并向提供 Topic 
服务的 Broker Master 建立长连接，且定时向 Master 发送心跳，只能将消 息发
送到 Broker master。 Consumer 同时与提供 Topic 服务的 Master、Slave 建立
长连接，从 Master、Slave 订阅消息都可以， 订阅规则由 Broker 配置决定。  
Kafka： 由多个 broker 组成，每个 broker 是一个节点；topic 可以划分为多个 
partition，每个 partition 可以 存在于不同的 broker 上，每个 partition 存放一部
分数据，这样每个 topic 的数据就分散存放在多个机 器上的。 replica 副本机制
保证每个 partition 的数据同步到其他节点，形成多 replica 副本；所有 replica 
副本会 选举一个 leader 与 Producer、Consumer 交互，其他 replica 就是 follower；
写入消息 leader 会把数 据同步到所有 follower，从 leader 读取消息。 每个 
partition 的所有 replica 分布在不同的机器上。某个 broker 宕机，它上面的 
partition 在其他节点 有副本，如果有 partition 的leader，会进行重新选举 leader。  
生产者消息运转？  
1、Producer 先连接到 Broker,建立连接 Connection,开启一个信道(Channel)。 2、
Producer 声明一个交换器并设置好相关属性。 3、Producer 声明一个队列并设置
好相关属性。 4、Producer 通过路由键将交换器和队列绑定起来。 5、Producer
发送消息到 Broker,其中包含路由键、交换器等信息。 6、相应的交换器根据接收
到的路由键查找匹配的队列。 7、如果找到，将消息存入对应的队列，如果没有
找到，会根据生产者的配置丢弃或者退回给生产者。 8、关闭信道。 9、管理连
接。  
消费者接收消息过程？  
1、Producer 先连接到 Broker,建立连接 Connection,开启一个信道(Channel)。 2、
向 Broker 请求消费响应的队列中消息，可能会设置响应的回调函数。 3、等待
Broker 回应并投递相应队列中的消息，接收消息。 4、消费者确认收到的消息,ack。 
5、RabbitMq 从队列中删除已经确定的消息。 6、关闭信道。 7、关闭连接。  
交换器无法根据自身类型和路由键找到符合条件队列时，有哪些 处理？ 
mandatory ：true 返回消息给生产者。 mandatory: false 直接丢弃。  
死信队列？  
DLX，全称为 Dead-Letter-Exchange，死信交换器，死信邮箱。当消息在一个队
列中变成死信 (dead message) 之后，它能被重新被发送到另一个交换器中，这个
交换器就是 DLX，绑定 DLX 的队列就称之 为死信队列。  
导致的死信的几种原因？  
消息被拒（Basic.Reject /Basic.Nack) 且 requeue = false。 消息 TTL 过期。 队列
满了，无法再添加。 
延迟队列？  
存储对应的延迟消息，指当消息被发送以后，并不想让消费者立刻拿到消息，而
是等待特定时间后，消 费者才能拿到这个消息进行消费。  
优先级队列？  
优先级高的队列会先被消费。 可以通过 x-max-priority 参数来实现。 当消费速
度大于生产速度且 Broker 没有堆积的情况下，优先级显得没有意义。  
事务机制？  
RabbitMQ 客户端中与事务机制相关的方法有三个: 1、channel.txSelect 用于将当
前的信道设置成事务模式。 2、channel . txCommit 用于提交事务 。 3、channel . 
txRollback 用于事务回滚,如果在事务提交执行之前由于 RabbitMQ 异常崩溃或
者其他原因 抛出异常,通过 txRollback 来回滚。  
发送确认机制？  
生产者把信道设置为 confirm 确认模式,设置后，所有再改信道发布的消息都会被
指定一个唯一的 ID，一 旦消息被投递到所有匹配的队列之后，RabbitMQ 就会
发送一个确认（Basic.Ack)给生产者（包含消息的 唯一 ID)，这样生产者就知道
消息到达对应的目的地了。  
消费者获取消息的方式？  
推  
拉 
消费者某些原因无法处理当前接受的消息如何来拒绝？  
channel .basicNack channel .basicReject  
消息传输保证层级？  
At most once:最多一次。消息可能会丢失，单不会重复传输。 At least once：最
少一次。消息觉不会丢失，但可能会重复传输。 Exactly once: 恰好一次，每条
消息肯定仅传输一次。  
vhost?  
每一个 RabbitMQ 服务器都能创建虚拟的消息服务器，也叫虚拟主机(virtual host)，
简称 vhost。 默认为“/”。 
集群中的节点类型？  
内存节点：ram,将变更写入内存。 磁盘节点：disc,磁盘写入操作。 RabbitMQ 要
求最少有一个磁盘节点。 队列结构？  
通常由以下两部分组成？ rabbit_amqqueue_process :负责协议相关的消息处理，
即接收生产者发布的消息、向消费者交付 消息、处理消息的确认(包括生产端的 
confirm 和消费端的 ack) 等。 backing_queue:是消息存储的具体形式和引擎，并
向 rabbit amqqueue process 提供相关的接口 以供调用。  
RabbitMQ 中消息可能有的几种状态? alpha: 消息内容(包括消息体、属性和 
headers) 和消息索引都存储在内存中 。 beta: 消息内容保存在磁盘中，消息索
引保存在内存中。 gamma: 消息内容保存在磁盘中，消息索引在磁盘和内存中都
有 。 delta: 消息内容和索引都在磁盘中 。 
 
 
 
10. Nginx 
简述一下什么是 Nginx，它有什么优势和功能？  
Nginx 是一个 web 服务器和方向代理服务器，用于 HTTP、HTTPS、SMTP、POP3
和 IMAP 协议。因它的稳定性、丰富的功能集、示例配置文件和低系统资源的消
耗而闻名。  
Nginx---Ngine X，是一款免费的、自由的、开源的、高性能 HTTP 服务器和反向
代理服务器； 也是一个 IMAP、POP3、SMTP 代理服务器；Nginx 以其高性能、
稳定性、丰富的功能、简单的 配置和低资源消耗而闻名。 也就是说 Nginx 本身
就可以托管网站（类似于 Tomcat 一样），进行 Http 服务处理，也可以作为反向
代理服务器 、负载均衡器和 HTTP 缓存。 Nginx 解决了服务器的 C10K（就是
在一秒之内连接客户端的数目为 10k 即 1 万）问题。它的设计不像传统的服务器
那样使用线程处理请求，而是一个更加高级的机制—事件驱动机制，是一 种异
步事件驱动结构。  
优点：  
（1）更快 这表现在两个方面：一方面，在正常情况下，单次请求会得到更快的
响应；另一方面， 在高峰期（如有数以万计的并发请求），Nginx 可以比其他
Web 服务器更快地响应请求。  
（2）高扩展性，跨平台 Nginx 的设计极具扩展性，它完全是由多个不同功能、
不同层次、不同类型 且耦合度极低的模块组成。因此，当对某一个模块修复 Bug
或进行升级时，可以专注于模块自身， 无须在意其他。而且在 HTTP 模块中，
还设计了 HTTP 过滤器模块：一个正常的 HTTP 模块在处理完请 求后，会有一
串 HTTP 过滤器模块对请求的结果进行再处理。这样，当我们开发一个新的 HTTP
模块 时，不但可以使用诸如 HTTP 核心模块、events 模块、log 模块等不同层次
或者不同类型的模块，还 可以原封不动地复用大量已有的 HTTP 过滤器模块。
这种低耦合度的优秀设计，造就了 Nginx 庞大的 第三方模块，当然，公开的第
三方模块也如官方发布的模块一样容易使用。 Nginx 的模块都是嵌入 到二进制
文件中执行的，无论官方发布的模块还是第三方模块都是如此。这使得第三方模
块一样具 备极其优秀的性能，充分利用 Nginx 的高并发特性，因此，许多高流
量的网站都倾向于开发符合自 己业务特性的定制模块。  
（3）高可靠性：用于反向代理，宕机的概率微乎其微 高可靠性是我们选择 Nginx
的最基本条件，因 为 Nginx 的可靠性是大家有目共睹的，很多家高流量网站都
在核心服务器上大规模使用 Nginx。 Nginx 的高可靠性来自于其核心框架代码的
优秀设计、模块设计的简单性；另外，官方提供的常用 模块都非常稳定，每个
worker 进程相对独立，master 进程在 1 个 worker 进程出错时可以快速“拉 起”新
的 worker 子进程提供服务。  
（4）低内存消耗 一般情况下，10000 个非活跃的 HTTP Keep-Alive 连接在 Nginx
中仅消耗 2.5MB 的内存，这是 Nginx 支持高并发连接的基础。  
（5）单机支持 10 万以上的并发连接 这是一个非常重要的特性！随着互联网的
迅猛发展和互联网用 户数量的成倍增长，各大公司、网站都需要应付海量并发
请求，一个能够在峰值期顶住 10 万以上并 发请求的 Server，无疑会得到大家的
青睐。理论上，Nginx 支持的并发连接上限取决于内存，10 万 远未封顶。当然，
能够及时地处理更多的并发请求，是与业务特点紧密相关的。  
（6）热部署 master 管理进程与 worker 工作进程的分离设计，使得 Nginx 能够
提供热部署功能，即 可以在 7×24 小时不间断服务的前提下，升级 Nginx 的可执
行文件。当然，它也支持不停止服务就更 新配置项、更换日志文件等功能。  
（7）最自由的 BSD 许可协议 这是 Nginx 可以快速发展的强大动力。BSD 许可
协议不只是允许用户免 费使用 Nginx，它还允许用户在自己的项目中直接使用
或修改 Nginx 源码，然后发布。这吸引了无数 开发者继续为 Nginx 贡献自己的
智慧。 以上 7 个特点当然不是 Nginx 的全部，拥有无数个官方功能模 块、第三
方功能模块使得 Nginx 能够满足绝大部分应用场景，这些功能模块间可以叠加以
实现更加 强大、复杂的功能，有些模块还支持 Nginx 与 Perl、Lua 等脚本语言集
成工作，大大提高了开发效 率。这些特点促使用户在寻找一个 Web 服务器时更
多考虑 Nginx。 选择 Nginx 的核心理由还是它能 在支持高并发请求的同时保持
高效的服务。 
Nginx 是如何处理一个 HTTP 请求的呢？  
Nginx 是一个高性能的 Web 服务器，能够同时处理大量的并发请求。它结合多
进程机制和异步机制 ，异步机制使用的是异步非阻塞方式 ，接下来就给大家介
绍一下 Nginx 的多线程机制和异步非阻塞机制 。  
1、多进程机制 服务器每当收到一个客户端时，就有服务器主进程（ master 
process ）生成一个子进程（ worker process ）出来和客户端建立连接进行交互，
直到连接断开，该子进程就结束了。 使用进程的好处是各个进程之间相互独立，
不需要加锁，减少了使用锁对性能造成影响，同时降低编程的复杂度，降低开发
成本。其次，采用独立的进程，可以让进程互相之间不会影响 ，如果一个进程
发生异常退出时，其它进程正常工作， master 进程则很快启动新的 worker 进
程，确保服务 不会中断，从而将风险降到最低。 缺点是操作系统生成一个子进
程需要进行 内存复制等操作，在资源和时间上会产生一定的开销。当 有大量请
求时，会导致系统性能下降 。  
2、异步非阻塞机制 每个工作进程 使用 异步非阻塞方式 ，可以处理 多个客户
端请求 。 当某个 工作进程 接收到客户端的请求以后，调用 IO 进行处理，如
果不能立即得到结果，就去 处理 其他请求 （即为 非阻塞 ）；而 客户端 在
此期间也 无需等待响应 ，可以去处理其他事情（即为 异 步 ）。 当 IO 返回
时，就会通知此 工作进程 ；该进程得到通知，暂时 挂起 当前处理的事务去 响
应客户端 请求 。  
列举一些 Nginx 的特性  
1. Nginx 服务器的特性包括： 2. 反向代理/L7 负载均衡器 3. 嵌入式 Perl 解释器 
4. 动态二进制升级 5. 可用于重新编写 URL，具有非常好的 PCRE 支持  
请列举 Nginx 和 Apache 之间的不同点  
 
在 Nginx 中，如何使用未定义的服务器名称来阻止处理请求？  
只需将请求删除的服务器就可以定义为：  
Server{  
 
 
listen 80;  
 
 
server_name "";  
 
 
return 444;  
}  
这里，服务器名被保留为一个空字符串，它将在没有“主机”头字段的情况下匹配
请求，而一个特殊 的 Nginx 的非标准代码 444 被返回，从而终止连接。 一般推
荐 worker 进程数与 CPU 内核数一致，这样一来不存在大量的子进程生成和管
理任务，避免 了进程之间竞争 CPU 资源和进程切换的开销。而且 Nginx 为了
更好的利用 多核特性 ，提供了 CPU 亲缘性的绑定选项，我们可以将某一个进
程绑定在某一个核上，这样就不会因为进程的切换带来 Cache 的失效。 对于每
个请求，有且只有一个工作进程 对其处理。首先，每个 worker 进程都是从 
master 进程 fork 过来。在 master 进程里面，先建立好需要 listen 的 socket
（listenfd） 之后，然后再 fork 出 多个 worker 进程。 所有 worker 进程的 
listenfd 会在新连接到来时变得可读 ，为保证只有一个进程处理该连接，所有 
worker 进程在注册 listenfd 读事件前抢占 accept_mutex ，抢到互斥锁的那个进
程注册 listenfd 读 事件 ，在读事件里调用 accept 接受该连接。 当一个 worker 
进程在 accept 这个连接之后，就开始读取请求、解析请求、处理请求，产生数
据 后，再返回给客户端 ，最后才断开连接。这样一个完整的请求就是这样的了。
我们可以看到，一个 请求，完全由 worker 进程来处理，而且只在一个 worker 
进程中处理。 在 Nginx 服务器的运行过程中， 主进程和工作进程 需要进程交
互。交互依赖于 Socket 实现的管道 来实现。  
请解释 Nginx 服务器上的 Master 和 Worker 进程分别是什么?  
主程序 Master process 启动后，通过一个 for 循环来 接收 和 处理外部信号 ； 
主进程通过 fork() 函数产生 worker 子进程 ，每个子进程执行一个 for 循环来
实现 Nginx 服务器 对事件的接收和处理 。  
请解释代理中的正向代理和反向代理  
首先，代理服务器一般指局域网内部的机器通过代理服务器发送请求到互联网上
的服务器，代理服 务器一般作用在客户端。例如：GoAgent 翻墙软件。我们的
客户端在进行翻墙操作的时候，我们使 用的正是正向代理，通过正向代理的方
式，在我们的客户端运行一个软件，将我们的 HTTP 请求转发 到其他不同的服
务器端，实现请求的分发。 反向代理服务器作用在服务器端，它在服务器端接
收客户端的请求，然后将请求分发给具体的服务 器进行处理，然后再将服务器
的相应结果反馈给客户端。Nginx 就是一个反向代理服务器软件。 从上图可以
看出：客户端必须设置正向代理服务器，当然前提是要知道正向代理服务器的 IP
地址， 还有代理程序的端口。 反向代理正好与正向代理相反，对于客户端而言
代理服务器就像是原始服务 器，并且客户端不需要进行任何特别的设置。客户
端向反向代理的命名空间（name-space）中的 内容发送普通请求，接着反向代理
将判断向何处（原始服务器）转交请求，并将获得的内容返回给 客户端。  
解释 Nginx 用途  
Nginx 服务器的最佳用法是在网络上部署动态 HTTP 内容，使用 SCGI、WSGI 应
用程序服务器、用于 脚本的 FastCGI 处理程序。它还可以作为负载均衡器。 
11. 分布式 
集群和分布式区别 
集群：同一业务部署在多台服务器上，提供可用性和并发度； 
分布式：不同的业务模块部署在不同的服务器上或者同一业务模块拆分多个字业
务，部署在不同的服务器上； 
分布式幂等性如何设计 
在高并发场景的架构里，幂等性是必须得保证的。比如说支付功能，用户发起支
付，如果后台没有做幂等校验，刚好用户手抖多点了几下，于是后台就可能多次
收到同一个订单请求，不做幂等很容易就让用户重复支付了，这样用户是肯定不
能忍的。 
解决方案： 
1，查询和删除不在幂等讨论范围，查询肯定没有幂等的说，删除：第一次删除
成功后，后面来删除直接返回 0，也是返回成功。  
2，建唯一索引：唯一索引或唯一组合索引来防止新增数据存在脏数据 （当表存
在唯一索引，并发时新增异常时，再查询一次就可以了，数据应该已经存在了，
返回结果即可）。  
3，token 机制：由于重复点击或者网络重发，或者 nginx 重发等情况会导致数据
被重复提交。前端在数据提交前要向后端服务的申请 token，token 放到 Redis 
或 JVM 内存，token 有效时间。提交后后台校验 token，同时删除 token，生成
新的 token 返回。redis 要用删除操作来判断 token，删除成功代表 token 校验通
过，如果用 select+delete 来校验 token，存在并发问题，不建议使用。 
4，悲观锁 悲观锁使用时一般伴随事务一起使用，数据锁定时间可能会很长，根
据实际情况选用（另外还要考虑 id 是否为主键，如果 id 不是主键或者不是 
InnoDB 存储引擎，那么就会出现锁全表）。  
select id ,name from table_# where id='##' for update; 
5，乐观锁，给数据库表增加一个 version 字段，可以通过这个字段来判断是否已
经被修改了  
update table_xxx set name=#name#,version=version+1 where version=#version# 
6，分布式锁，比如 Redis 、 Zookeeper 的分布式锁。单号为 key，然后给 Key
设置有效期（防止支付失败后，锁一直不释放），来一个请求使用订单号生成一
把锁，业务代码执行完成后再释放锁。  
7，保底方案，先查询是否存在此单，不存在进行支付，存在就直接返回支付结
果。 
 
负载均衡的理解 
集群化部署的架构，也就是把一个软件应用同事部署在多个服务器上。 
负载均衡机制的核心目的是让客户端的请求合理均匀的分发到多台目标服务器，
由于请求被多个节点分发，使得服务端的性能得到有效提升。 
1. 基于 DNS 实现负载均衡； 
客户端用户请求 www.xxx.com，DNS 服务器进行域名的解析，返回域名对应的
IP 地址，然后请求实际的 IP 地址； 
DNS 服务器上去针对某个域名做多个 IP 映射，可以随机分配个 IP 地址进行访
问，这样就可以实现目标服务器集群的请求分发；DNS 服务器也可以根据不同
的地域分配就近机房的 IP，比如一个来自长沙的客户端请求，可能会得到一个湖
南范围内最近的机房的 IP，在这个模式下可以实现就近原则的一个请求分发，这
样可以缩短通信距离，从而提升网站的访问速率。 
2. 基于硬件的负载均衡 
可以理解为一个网络设备，类似于物理交换机，性能比较好，每秒可以处理百万
级的请求；支持多种负载均衡的算法，可以非常灵活的去配置不同的负载均衡策
略；具备防火墙等安全功能； 
3. 基于软件的负载均衡 
通过一些开源软件或者商业软件来完成负载均衡的功能。常用的有 Nginx、LVS、
Haproxy； 
负载均衡是作用在网络通信上来实现请求的分发；由于网络架构分成 7 层模型，
根据这一特性，负载均衡根据作用范围分为二层负载、三层负载、四层负载、七
层负载； 
二层负载：根据 MAC 地址来实现请求的分发，一般采用虚拟 MAC 的方式实现；
当服务器收到请求后，可以通过动态分配后的服务器的 MAC 地址来进行响应。 
三层负载：基于 IP 层负载，一般通过虚拟 IP 来实现；外部的请求去访问虚拟 IP
时，服务器收到请求，根据后端的实际 IP 地址进行转发； 
四层负载：将用户请求转发给后端，通过修改请求报文中的目标地址和源地址进
行转发。 
七层负载：基于应用层的负载。服务器端可以根据 http 协议中的请求的报文信息
来决定将请求分发到哪个服务器；比如 cookie，消息体以及 Requestheader 等等； 
 
说说你对分布式事务的了解  
分布式事务是企业集成中的一个技术难点，也是每一个分布式系统架构中都会涉
及到的一个东西， 特别是在微服务架构中，几乎可以说是无法避免。  
首先要搞清楚：ACID、CAP、BASE 理论。  
ACID 指数据库事务正确执行的四个基本要素：  
1. 原子性（Atomicity）  
2. 一致性（Consistency）  
3. 隔离性（Isolation）  
4. 持久性（Durability）  
CAP 
CAP 原则又称 CAP 定理，指的是在一个分布式系统中，一致性（Consistency）、
可用性 （Availability）、分区容忍性（Partition tolerance）。CAP 原则指的是，
这三个要素最多只能同时实现两点，不可能三者兼顾。 一致性：在分布式系统
中的所有数据备份，在同一时刻是否同样的值。 可用性：在集群中一部分节点
故障后，集群整体是否还能响应客户端的读写请求。 分区容忍性：以实际效果
而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数 据一致性，
就意味着发生了分区的情况，必须就当前操作在 C 和 A 之间做出选择。 
BASE 理论  
BASE 理论是对 CAP 中的一致性和可用性进行一个权衡的结果，理论的核心思
想就是：我们无法做到 强一致，但每个应用都可以根据自身的业务特点，采用
适当的方式来使系统达到最终一致性。 Basically Available（基本可用） Soft state
（软状态） Eventually consistent（最终一致性） 
你知道哪些分布式事务解决方案？ 
我目前知道的有五种：  
1. 两阶段提交(2PC)  
2. 三阶段提交(3PC)  
3. 补偿事务(TCC=Try-Confirm-Cancel)  
4. 本地消息队列表(MQ)  
5. Sagas 事务模型(最终一致性) 说完上面五种，面试官一般都会继续问下面这几个
问题（可能就问一两个，也可能全部问）。 
什么是二阶段提交？  
两阶段提交 2PC 是分布式事务中最强大的事务类型之一，两段提交就是分两个
阶段提交： 第一阶段询问各个事务数据源是否准备好。 第二阶段才真正将数据
提交给事务数据源。 为了保证该事务可以满足 ACID，就要引入一个协调者
（Cooradinator）。其他的节点被称为参与者 （Participant）。协调者负责调度参
与者的行为，并最终决定这些参与者是否要把事务进行提交。 处理流程如下： 
 
阶段一 a) 协调者向所有参与者发送事务内容，询问是否可以提交事务，并等待
答复。 b) 各参与者执行事务操作，将 undo 和 redo 信息记入事务日志中（但
不提交事务）。 c) 如参与者执行成功，给协调者反馈 yes，否则反馈 no。  
阶段二 如果协调者收到了参与者的失败消息或者超时，直接给每个参与者发送
回滚(rollback)消息；否则， 发送提交(commit)消息。两种情况处理如下： 情况
1：当所有参与者均反馈 yes，提交事务 a) 协调者向所有参与者发出正式提交事
务的请求（即 commit 请求）。 b) 参与者执行 commit 请求，并释放整个事务
期间占用的资源。 c) 各参与者向协调者反馈 ack(应答)完成的消息。 d) 协调者
收到所有参与者反馈的 ack 消息后，即完成事务提交。 情况 2：当有一个参与
者反馈 no，回滚事务 a) 协调者向所有参与者发出回滚请求（即 rollback 请求）。 
b) 参与者使用阶段 1 中的 undo 信息执行回滚操作，并释放整个事务期间占用
的资源。 c) 各参与者向协调者反馈 ack 完成的消息。 d) 协调者收到所有参与
者反馈的 ack 消息后，即完成事务。  
问题 1) 性能问题：所有参与者在事务提交阶段处于同步阻塞状态，占用系统资
源，容易导致性能瓶颈。 2) 可靠性问题：如果协调者存在单点故障问题，或出
现故障，提供者将一直处于锁定状态。 3) 数据一致性问题：在阶段 2 中，如果
出现协调者和参与者都挂了的情况，有可能导致数据不一 致。 优点：尽量保证
了数据的强一致，适合对数据强一致要求很高的关键领域。（其实也不能 100%
保证 强一致）。 缺点：实现复杂，牺牲了可用性，对性能影响较大，不适合高
并发高性能场景。 
什么是补偿事务？  
TCC （Try Confirm Cancel）是服务化的二阶段编程模型，采用的补偿机制： TCC 
其实就是采用的补偿机制，其核心思想是：针对每个操作，都要注册一个与其对
应的确认和补 偿（撤销）操作。 它分为三个步骤： Try 阶段主要是对业务系
统做检测及资源预留。 Confirm 阶段主要是对业务系统做确认提交，Try 阶段执
行成功并开始执行 Confirm 阶段时，默 认 Confirm 阶段是不会出错的。即：只
要 Try 成功，Confirm 一定成功。 Cancel 阶段主要是在业务执行错误，需要回
滚的状态下执行的业务取消，预留资源释放。 举个例子，假入你要向 老田 转
账，思路大概是： 我们有一个本地方法，里面依次调用步骤： 1、 首先在 Try 
阶段，要先调用远程接口把 你 和 老田 的钱给冻结起来。 2、在 Confirm 阶
段，执行远 程调用的转账的操作，转账成功进行解冻。 3、如果第 2 步执行成
功，那么转账成功，如果第二步执 行失败，则调用远程冻结接口对应的解冻方
法 (Cancel)。 优点： 性能提升：具体业务来实现控制资源锁的粒度变小，不会
锁定整个资源。 数据最终一致性：基于 Confirm 和 Cancel 的幂等性，保证事
务最终完成确认或者取消，保证数据 的一致性。 可靠性：解决了 XA 协议的
协调者单点故障问题，由主业务方发起并控制整个业务活动，业务活动 管理器
也变成多点，引入集群。 缺点：TCC 的 Try、Confirm 和 Cancel 操作功能要
按具体业务来实现，业务耦合度较高，提高了开发成本。 
 
 
分布式缓存 
缓存理解：第一次请求时将一些耗时操作的结果暂存，以后遇到相同的请求，直
接返回暂存的数据，缓存不存在时，调用回调函数获取源数据； 
缓存中最简单的莫过于存储在内存中的键值对缓存了。说到键值对，很容易想到
的是字典(dict)类型，Go 语言中称之为 map。那直接创建一个 map，每次有新数
据就往 map 中插入不就好了，这不就是键值对缓存么？这样做有什么问题呢？ 
1）内存不够了怎么办？ 
那就随机删掉几条数据好了。随机删掉好呢？还是按照时间顺序好呢？或者是有
没有其他更好的淘汰策略呢？不同数据的访问频率是不一样的，优先删除访问频
率低的数据是不是更好呢？数据的访问频率可能随着时间变化，那优先删除最近
最少访问的数据可能是一个更好的选择。我们需要实现一个合理的淘汰策略。 
2）并发写入冲突了怎么办？ 
对缓存的访问，一般不可能是串行的。map 是没有并发保护的，应对并发的场景，
修改操作(包括新增，更新和删除)需要加锁。 
3）单机性能不够怎么办？ 
单台计算机的资源是有限的，计算、存储等都是有限的。随着业务量和访问量的
增加，单台机器很容易遇到瓶颈。如果利用多台计算机的资源，并行处理提高性
能就要缓存应用能够支持分布式，这称为水平扩展(scale horizontally)。与水平扩
展相对应的是垂直扩展(scale vertically)，即通过增加单个节点的计算、存储、带
宽等，来提高系统的性能，硬件的成本和性能并非呈线性关系，大部分情况下，
分布式系统是一个更优的选择。 
 
缓存淘汰算法 
1.1 FIFO(First In First Out) 
先进先出，也就是淘汰缓存中最老(最早添加)的记录。FIFO 认为，最早添加的记
录，其不再被使用的可能性比刚添加的可能性大。这种算法的实现也非常简单，
创建一个队列，新增记录添加到队尾，每次内存不够时，淘汰队首。但是很多场
景下，部分记录虽然是最早添加但也最常被访问，而不得不因为呆的时间太长而
被淘汰。这类数据会被频繁地添加进缓存，又被淘汰出去，导致缓存命中率降低。 
1.2 LFU(Least Frequently Used) 
最少使用，也就是淘汰缓存中访问频率最低的记录。LFU 认为，如果数据过去被
访问多次，那么将来被访问的频率也更高。LFU 的实现需要维护一个按照访问次
数排序的队列，每次访问，访问次数加 1，队列重新排序，淘汰时选择访问次数
最少的即可。LFU 算法的命中率是比较高的，但缺点也非常明显，维护每个记录
的访问次数，对内存的消耗是很高的；另外，如果数据的访问模式发生变化，LFU
需要较长的时间去适应，也就是说 LFU 算法受历史数据的影响比较大。例如某
个数据历史上访问次数奇高，但在某个时间点之后几乎不再被访问，但因为历史
访问次数过高，而迟迟不能被淘汰。 
1.3 LRU(Least Recently Used) 
最近最少使用，相对于仅考虑时间因素的 FIFO 和仅考虑访问频率 LFU，LRU 算
法可以认为是相对平衡的一种淘汰算法。LRU 认为，如果数据最近被访问过，
那么将来被访问的概率也会更高。LRU 算法的实现非常简单，维护一个队列，如
果某条记录被访问了，则移动到队尾，那么队首则是最近最少访问的数据，淘汰
该条记录即可。 
LRU 算法最核心的 2 个数据结构 
字典(map)，存储键和值的映射关系。这样根据某个键(key)查找对应的值(value)
的复杂是 O(1)，在字典中插入一条记录的复杂度也是 O(1)。 
双向链表(double linked list)实现的队列。将所有的值放到双向链表中，这样，当
访问到某个值时，将其移动到队尾的复杂度是 O(1)，在队尾新增一条记录以及删
除一条记录的复杂度均为 O(1)。 
 
一致性哈希 
对于分布式缓存来说，当一个节点接收到请求，如果该节点并没有存储缓存值，
那么它面临的难题是，从谁那获取数据？自己，还是节点 1, 2, 3, 4… 。假设包
括自己在内一共有 10 个节点，当一个节点接收到请求时，随机选择一个节点，
由该节点从数据源获取数据。 
假设第一次随机选取了节点 1 ，节点 1 从数据源获取到数据的同时缓存该数据；
那第二次，只有 1/10 的可能性再次选择节点 1, 有 9/10 的概率选择了其他节
点，如果选择了其他节点，就意味着需要再一次从数据源获取数据，一般来说，
这个操作是很耗时的。这样做，一是缓存效率低，二是各个节点上存储着相同的
数据，浪费了大量的存储空间。 
那有什么办法，对于给定的 key，每一次都选择同一个节点呢？使用 hash 算法
也能够做到这一点。那把 key 的每一个字符的 ASCII 码加起来，再除以 10 取
余数可以吗？当然可以，这可以认为是自定义的 hash 算法。 
节点数量变化了怎么办？ 
简单求取 Hash 值解决了缓存性能的问题，但是没有考虑节点数量变化的场
景。假设，移除了其中一台节点，只剩下 9 个，那么之前 hash(key) % 10 变
成了 hash(key) % 9，也就意味着几乎缓存值对应的节点都发生了改变。即几
乎所有的缓存值都失效了。节点在接收到对应的请求时，均需要重新去数据源
获取数据，容易引起 缓存雪崩。 
缓存雪崩：缓存在同一时刻全部失效，造成瞬时 DB 请求量大、压力骤增，引起雪崩。常因
为缓存服务器宕机，或缓存设置了相同的过期时间引起。 
算法原理 
一致性哈希算法将 key 映射到 2^32 的空间中，将这个数字首尾相连，形成
一个环。 
 
计算节点/机器(通常使用节点的名称、编号和 IP 地址)的哈希值，放置在环
上。 
 
计算 key 的哈希值，放置在环上，顺时针寻找到的第一个节点，就是应选取的
节点/机器。 
 
环上有 peer2，peer4，peer6 三个节点，key11，key2，key27 均映射到 peer2，
key23 映射到 peer4。此时，如果新增节点/机器 peer8，假设它新增位置如图所
示，那么只有 key27 从 peer2 调整到 peer8，其余的映射均没有发生改变。 
也就是说，一致性哈希算法，在新增/删除节点时，只需要重新定位该节点附近的
一小部分数据，而不需要重新定位所有的节点，这就解决了上述的问题。 
数据倾斜问题 
如果服务器的节点过少，容易引起 key 的倾斜。例如上面例子中的 peer2，
peer4，peer6 分布在环的上半部分，下半部分是空的。那么映射到环下半部
分的 key 都会被分配给 peer2，key 过度向 peer2 倾斜，缓存节点间负载
不均。 
为了解决这个问题，引入了虚拟节点的概念，一个真实节点对应多个虚拟节
点。 
假设 1 个真实节点对应 3 个虚拟节点，那么 peer1 对应的虚拟节点是 
peer1-1、 peer1-2、 peer1-3（通常以添加编号的方式实现），其余节点也
以相同的方式操作。 
 
第一步，计算虚拟节点的 Hash 值，放置在环上。 
 
第二步，计算 key 的 Hash 值，在环上顺时针寻找到应选取的虚拟节点，例如是 
peer2-1，那么就对应真实节点 peer2。 
虚拟节点扩充了节点的数量，解决了节点较少的情况下数据容易倾斜的问题。
而且代价非常小，只需要增加一个字典(map)维护真实节点与虚拟节点的映射
关系即可。 
缓存雪崩、缓存击穿与缓存穿透 
缓存雪崩：缓存在同一时刻全部失效，造成瞬时 DB 请求量大、压力骤增，引起
雪崩。缓存雪崩通常因为缓存服务器宕机、缓存的 key 设置了相同的过期时间
等引起。 
缓存击穿：一个存在的 key，在缓存过期的一刻，同时有大量的请求，这些请求
都会击穿到 DB ，造成瞬时 DB 请求量大、压力骤增。 
缓存穿透：查询一个不存在的数据，因为不存在则不会写到缓存中，所以每次都
会去请求 DB，如果瞬间流量过大，穿透到 DB，导致宕机。 
 
 
 
protobuf 
protobuf 即 Protocol Buffers，Google 开发的一种数据描述语言，是一种轻便高
效的结构化数据存储格式，与语言、平台无关，可扩展可序列化。protobuf 以二
进制方式存储，占用空间小。 
protobuf 广泛地应用于远程过程调用(RPC) 的二进制传输，使用 protobuf 的目
的非常简单，为了获得更高的性能。传输前使用 protobuf 编码，接收方再进行
解码，可以显著地降低二进制传输的大小。另外一方面，protobuf 可非常适合传
输结构化数据，便于通信字段的扩展。 
使用 protobuf 一般分为以下 2 步： 
1. 按照 protobuf 的语法，在 .proto 文件中定义数据结构，并使用 protoc 生成 
Go 代码（.proto 文件是跨平台的，还可以生成 C、Java 等其他源码文件）。 
2. 在项目代码中引用生成的 Go 代码。 
 
 
10. Django 
Django 的请求生命周期 
1、当用户在浏览器中输入 url 时浏览器会生成请求头和请求体发送给服务端请
求头和请求体中会包含浏览器的动作（action）这个动作通常为 get 或者 post 提
现在 url 之中； 
2、url 经过 Django 中的 wsgi，就是 socket 服务端，用于接收用户请求并将请求
进行初次封装，然后将请求交给 web 框架； 
3、再经过 django 的中间件，中间件处理请求，帮助我们对请求进行校验或在请
求对象中添加其他相关数据，例如：csrf、request.session； 
4、最后 url 到路由的映射表一条一条进行匹配一旦其中的某一条匹配成功就执
行视图函数，后面的路由就不在继续匹配了； 
5、视图函数中进行业务逻辑的处理，可能涉及到：orm、view 视图将数据渲染到
template 模板，视图函数执行完毕之后，会把客户端想要的数据返回给 dispatch
方法，由 dispatch 方法把数据返回给客户端； 
6、中间件处理响应； 
7、wsgi，将响应的内容发送给浏览器； 
8、客户端浏览器接受到返回的数据，经过渲染后显示给用户. 
 
Flask 和 Django 路由映射的区别？ 
在 django 中，路由是浏览器访问服务器时，先访问的项目中的 url，再由项目中
的 url 找到应用中 url，这些 url 是放在一个列表里，遵从从前往后匹配的规则。
在 flask 中，路由是通过装饰器给每个视图函数提供的，而且根据请求方式的不
同可以一个 url 用于不同的作用。 
 
 
 
 
 
django rest framework 规范 
1url 后尽量用名词，因为 rest frame 是面向资源的编程，因此 url 命名时能体现出
资源 2method 的不同，实现增删改查的操作 3 版本号，因为有版本的更替，为
了体现出版本的过度，因此在发请求的时候，要体现出版本号 4 返回值，与以往
只返回 json 不同,rest api 规范要加上状态码。 5 域名，由于前后端分离，因此要
处理跨域问题，解决方法:jsonp,cors 6 过滤，通过 url 传参的形式传递搜索条件
（列如：指定返回的记录数量，指定分页等） 
 
 
 
简述 Django 的 orm 
ORM，全拼 Object-Relation Mapping，意为对象-关系映射 
实现了数据模型与数据库的解耦，通过简单的配置就可以轻松更换数据库，而不
需要修改代码只需要面向对象编程,orm 操作本质上会根据对接的数据库引擎，
翻译成对应的 sql 语句,所有使用 Django 开发的项目无需关心程序底层使用的是
MySQL、Oracle、sqlite....，如果数据库迁移，只需要更换 Django 的数据库引擎
即可。 
 
 
 
 
django 中当一个用户登录 A 应用服务器（进入登录状态），然
后下次请求被 nginx 代理到 B 应用服务器会出现什么影响？ 
如果用户在 A 应用服务器登陆的 session 数据没有共享到 B 应用服务器，纳米之
前的登录状态就没有了。 
 
 
 
跨域请求问题 django 怎么解决的（原理） 
启用中间件 post 请求 验证码 表单中添加{%csrf_token%}标签 
 
 
 
请解释或描述一下 Django 的架构 
对于 Django 框架遵循 MVC 设计，并且有一个专有名词：MVT M 全拼为 Model，
与 MVC 中的 M 功能相同，负责数据处理，内嵌了 ORM 框架 V 全拼为 View，
与 MVC 中的 C 功能相同，接收 HttpRequest，业务处理，返回 HttpResponse T 全
拼为 Template，与 MVC 中的 V 功能相同，负责封装构造要返回的 html，内嵌了
模板引擎 
 
 
 
django 对数据查询结果排序怎么做，降序怎么做，查询大于某个
字段怎么做 
排序使用 order_by() 降序需要在排序字段名前加- 查询字段大于某个值：使用
filter(字段名_gt=值) 
 
 
 
说一下 Django，MIDDLEWARES 中间件的作用？ 
中间件是介于 request 与 response 处理之间的一道处理过程，相对比较轻量级，
并且在全局上改变 django 的输入与输出。 
 
 
 
你对 Django 的认识？ 
Django 是走大而全的方向，它最出名的是其全自动化的管理后台：只需要使用起
ORM，做简单的对象定义，它就能自动生成数据库结构、以及全功能的管理后
台。 Django 内置的 ORM 跟框架内的其他模块耦合程度高。 
应用程序必须使用 Django 内置的 ORM，否则就不能享受到框架内提供的种种基
于其 ORM 的便利；理论上可以切换掉其 ORM 模块，但这就相当于要把装修完
毕的房子拆除重新装修，倒不如一开始就去毛胚房做全新的装修。 
Django 的卖点是超高的开发效率，其性能扩展有限；采用 Django 的项目，在流
量达到一定规模后，都需要对其进行重构，才能满足性能的要求。 
Django 适用的是中小型的网站，或者是作为大型网站快速实现产品雏形的工具。 
Django 模板的设计哲学是彻底的将代码、样式分离； Django 从根本上杜绝在模
板中进行编码、处理数据的可能。 
 
 
Django 重定向你是如何实现的？用的什么状态码？ 
使用 HttpResponseRedirect redirect 和 reverse 状态码：302,301 
 
 
   
 
 
 
ngnix 的正向代理与反向代理 
正向代理 是一个位于客户端和原始服务器(origin server)之间的服务器，为了从
原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然
后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端必须要进行
一些特别的设置才能使用正向代理。 反向代理正好相反，对于客户端而言它就
像是原始服务器，并且客户端不需要进行任何特别的设置。客户端向反向代理的
命名空间中的内容发送普通请求，接着反向代理将判断向何处(原始服务器)转交
请求，并将获得的内容返回给客户端，就像这些内容原本就是它自己的一样。 
 
 
 
Django 本身提供了 runserver，为什么不能用来部署？ 
runserver 方法是调试 Django 时经常用到的运行方式，它使用 Django 自带的 
WSGI Server 运行，主要在测试和开发中使用，并且 runserver 开启的方式也是
单进程 。 uWSGI 是一个 Web 服务器，它实现了 WSGI 协议、uwsgi、http 等
协议。注意 uwsgi 是一种通信协议，而 uWSGI 是实现 uwsgi 协议和 WSGI 协
议的 Web 服务器。uWSGI 具有超快的性能、低内存占用和多 app 管理等优点，
并且搭配着 Nginx 就是一个生产环境了，能够将用户访问请求与应用 app 隔离
开，实现真正的部署。相比来讲，支持的并发量更高，方便管理多进程，发挥多
核的优势，提升性能。 
 
 
 
 
 
11. flask 
1. 第一个 flask 程序 
from flask import Flask 
# 创建 flask 应用对象，flask 以这个模块所在的总目录为总目录，默认这个目录中的 static
为静态目录，templates 为模板目录 
app = Flask(__name__) 
 
@app.route("/") 
def index(): 
    """定义的视图函数""" 
    return "hello flask!" 
 
 
if __name__ == '__main__': 
    app.run() 
2. 配置参数 
# 配置参数使用方式 
1. 使用配置文件 
app.config.from_pyfile('config.cfg') 
 
2. 使用对象配置参数 
class Config(object): 
    DEBUG = True 
    par = 'python' 
app.config.from_obj(Config) 
 
# 读取配置参数 
1. 直接从全局参数 app 的 config 字典中取值 
app.config.get('par') 
2. 从 current_app 中取值(from flask import current_app) 
current_app.config.get('par') 
3. 启动 flask 程序 
app.run()   # 默认 host 为 127.0.0.1    端口号为 5000 
app.run(host="192.168.10.10", port=5001)   # 自定义监控 ip 和端口 
app.run(host="0.0.0。0", port=5001)   # 默认 127.0.0.1 和主机 ip 都可以访问 
app.run(host="0.0.0。0", port=5001， debug=True)   # 打开 debug 
4. 视图函数的路由规则 
app.url_map     # 可以查看整个 flask 中的路由信息 
# methods 参数限定访问方式，默认是 get/options/head 
@app.route('hello', methods=['POST']) 
def hello(): 
    print('hello') 
 
# 使用 url_for 函数，通过视图函数的名字找到视图对应的 url 路径 
@app.route('/login') 
def login(): 
    url = url_for('hello') 
return redirect(url) 
 
 
 
 
 
 
 
route 装饰器，其实就是将 rule 字符串跟视图函数进行了绑定，通过 add_url_rule()实现
了绑定； 
源代码： 
def route(): 
def decorator(f: t.Callable) -> t.Callable: 
        endpoint = options.pop("endpoint", None) 
        self.add_url_rule(rule, endpoint, f, **options) 
        return f 
    return decorator 
 
 
 
5. 请求参数 
上传文件 
abort(400) 
abort 函数可以立即终止视图函数的执行，并可以返回给前端指定的信息； 
6. 设置响应信息 
# 1. 使用元组，返回自定义的响应信息 
响应体、状态码、响应头 
@app.route('/index') 
def index(): 
    return 'index page', '400', [('city': 'shenzhen', 'age': 20)] 
 
# 2. 使用 make_response 构造响应信息 
resp = make_response('index page') 
resp.status = '400' 
resp.headers['age'] = 20 
7. cookie 
# 设置 cookie，默认有效期是临时 cookie，浏览器关闭就失效 
resp = make_response('success') 
resp.set_cookie('age', 20, max-age=3600)   # max-age 设置有效期的参数，单位为 s 
 
# 获取 cookie 
request.cookies.get('age') 
 
# 删除 cookie 
resp = make_response('success') 
resp.delete_cookie('age')    # 不是让浏览器及时删除此 cookie，而是设置有效期过期 
 
 
  
8. session 
# 一般而言：cookie 中保存 session_id，session_id 以及 session 数据维护在数据库中； 
flask 并不是将 session 保存到数据库，而是保存到 cookie 中，通过 SECRET_KEY 将
session 内容混淆；也就是说 cookie 中保存的是混乱后的 session 数据； 
 
app.config['SECRET_KEY'] = 'sdgdfgfgs454' 
 
@app.route('/login') 
def login(): 
    # 设置 session 数据 
    session['name'] = 'python' 
    session['age'] = '20' 
 
@app.route('/index') 
def index(): 
    # 获取 session 数据 
    name = session.get('name') 
    return 'hello %s' % name 
 
 
session 存储 
1. session 保存到程序内容中；也就是 python 模块中的全局变量中；session 跨机器时会
导致问题；也就是当负载均衡到某台机器时，session 修改了此程序的全局变量，但是下
次请求获取 session 时，可能会返回到前端数据还是未修改前的； 
2. session 保存到数据库中（mysql/redis）； 
 
当浏览器禁用 cookie 时，session_id 在页面中传导；类似这种 index?session_id=1 
     
9. flask-sqlalchemy 
flask 数据库设置 
app = create_app() 
1. 配置数据库连接路径 
mysql+pymysql://user:password@host:port/database 
app.config['SQLALCHEMY_DATABASE_URL'] 
= 
'mysql://root:mysql@127.0.0.1:3306/test3' 
class Config(object): 
    SQLALCHEMY_DATABASE_URL = 'mysql://root:mysql@127.0.0.1:3306/test3' 
    SQLALCHEMY_TRACK_MODIFICATIONS = True   # 设置 sqlalchemy 自动跟踪
数据库 
2. 创建包 ext 
在__init__.py 文件中添加 
app.config.from_object(Config) 
db = SQLAlchemy(app)   # 创建数据库 sqlalchemy 工具对象，必须跟 app 关联 
3. 配置 migrate 
migrate = Migrate(app=app, db=db) 
manager = Manager(app=app) 
manager.add_command(‘db’, MigrateCommand) 
 
4. 创建模型类 
其实就是一个类，继承 db.Model 
5. 使用命令 
在 app.py 中导入模型类 
在终端使用命令 python app.py db init，产生文件夹 migrations 
执行命令 python app.py migrate，自动生成 revision 文件； 
执行命令 python app.py upgrade，就是执行 revision 中的 upgrade 函数； 
 
 
 
数据库查询 
and_  # 并且 
or_  # 或者 
not_ # 取反 
User.query.all()  # 所有 
User.query.get(pk) # 一个 
 
User.query.filter(User.username.in_([‘’, ‘’, ‘’])) 
User.query.filter(User.username == ‘zhangsan’).all() 
User.query.filter(or_(User.username.like(‘z%’), User.username.contains(‘i’)))).all() 
User.query.filter(User.username.contains(‘zs’)).order_by(-User.rdatetime).all() 
User.query.order_by(User.id).all() 
User.query.limit(2).all()  # 取前两条记录 
User.query.offset(2).limit(2).all() # 偏移 2 条取两条，也就是取第 3 条和第 4 条记录 
 
 
app 是实例化的 Flask APP 对象，通过 app.route() 来装饰视图函数。 
Flask-基础 Web 框架 
flask_restful- Flask 的扩展，增加了对快速构建 REST API 的支持 
flask_restful 文件中导入 Api、Resource 两个类，使用上面的 app 对象，构
建一个 api 对象， 
from flask_restful import Api,Resource 
 
app = Flask(__name__) 
 
###  22.1. <a name='ApiRESTfulApi'></a>实例化一个 Api 对象，用来创建、管理 RESTful Api 
api = Api(app) 
###  22.2. <a name='Resource'></a>创建一个 Resource 类的子类，用于定义资源路由 
class UserView(Resource): 
   """ 
  通过继承 Resource 来实现调用 GET/POST 等动作方法 
  """ 
   def get(self): 
       """ 
      GET 请求 
      :return: 
      """ 
 
 
   def post(self): 
       """ 
      POST 请求 
      :return: 
      """ 
       # 参数数据 
       json_data = request.get_json() 
###  22.3. <a name='Api'></a>最后，使用 Api 的实例对象，将上面定义的资源，利用路径，完全暴露出去 
 
 
 
 
 
10. flask 使用蓝图 
app.py 中 
app=Flak(__name__)  创建一个应用 
admin.py 引用 app route 直接报错 
这是由于 flask 使用传统的模块化行不通 
flask 内置模块化处理的类 Blueprint 
使用蓝图三个步骤 
a.创建蓝图对象 Blueprint(‘admin’, __name__) 
b.在这个蓝图对象上进行操作，注册路由，指定静态文件夹，注册模板过滤器等： 
c.在应用对象注册这个蓝图对象。 
 
11. sqlalchemy 使用 
connect 是 mysql 和用户、密码、host、端口、数据库名组合的字符串； 
engine = create_engine(connect) 
session_class = sessionmaker(bind=engine) 
session = session_class() 
models 里面定义类继承 declarative_base 对象，类中有表 id 和表中的字段 
增 session.add(table_name(**kwarg)) 
更新 
session.query(table_name).filter_by(id=id).update(param) 
删 
obj = session.query(table_name).filter_by(id=id) 
session.delete(obj) 
 
 
12. openstack 
网络虚拟化主要为计算存储虚拟化提供流量支撑的，通常包括接口虚拟化：虚拟
机的虚拟端口，转发虚拟化：虚拟交换机，网络虚拟化：vlan 或者 vxlan，网络
功能虚拟化：虚拟路由器，虚拟防火墙，虚拟 vpn，虚拟 lb 等。 
 
云计算 
按使用量付费的模式，提供按需便捷的网络访问，进入可配置的计算资源池。 
私有云----私有环境中，比如企业机房中建立的，运营商建立好租给某些企业的； 
公有云----放到互联网上，付费用户都可以使用。 
 
 
openstack 对数据中心的计算、存储和网络资源进行统一管理。 
openstack 创建虚机的流程 
创建虚机的请求流如下: 
1. 首先 Dashboard 或者 CLI 获取用户的登录信息，调用 keystone 的 REST API 去
做用户身份验证，keystone 对用户登录信息进行校验，然后产生 token 并发回，
用于后续的 REST 调用请求； 
2. Dashboard 或者 CLI 将创建虚机的 REST 请求中的‘launch instance’或‘nova-
boot’部分进行转换，然后调用 nova-api 的 REST 接口; 
3. nova-api 接到请求，向 keystone 发送 auth-token 校验和权限认证请求。Keystone 
校验 token，并将 auth headers 发回，它包括了 roles 和 permissions。nova-api 和 
nova-database 进行交互。nova-database 为新实例创建一个数据库条目。 
4. nova-api 向 nova-scheduler 发送 rpc.call 请求，期望它能通过附带的 host ID 
获取到数据库条目。nova-scheduler 从 queue 中获取到请求。 
5. nova-scheduler 和 nova-database 交互，获取集群中计算节点的信息和状态。
nova-scheduler 通过过滤（filtering）和称重（weighting）找到一个合适的计算节
点（host）。nova-scheduler 向找到的那个 host 上的 nova-compute 发送 rpc.cast 
请求去启动虚机。 
6. 目标 host 上的 nova-compute 从 queue 中获取到请求。nova-compute 向 
nova-conductor 发送 rpc.call 请求去获取待创建虚机的信息比如 host ID 和 
flavor 等。nova-conductor 从 queue 中获取到请求。nova-conductor 和 nova-
database 交互，nova-database 向 nova-conductor 返回虚机的信息。 
7. nova-conductor 向 nova-compute 发送 rpc.call，附带所请求的信息。nova-
compute 从 queue 中获取返回的数据。  
8. nova-compute 调用 glance-api 的 REST API，传入 auth-token，去根据镜像 ID 
获取镜像 URI，从镜像存储中下载（原文为 upload）镜像。glance-api 向 keystone 
校验 auth-token。nova-compute 获取 image 的元数据。 
9. nova-compute 调用 Neutron API ，传入 auth-token，去分配和配置网络，比如
虚机的 IP 地址。neutron-server 通过 keystone 校验 auth-token。nova-compute 获
得网络信息。 
10. nova-compute 调用 Cinder API，传入 auth-token，去将 volume 挂接到实例。
cinder-api 通过 keystone 校验 auth-token。nova-compute 获得块存储信息。 
nova-compute 为 hypervisor driver 产生数据，并调用 Hypersior 执行请求（通过 
libvirt 或者 api）。 
 
OpenStack 创建虚拟机的流程通常如下： 
1. 配置网络和存储：在 OpenStack 控制节点上，管理员需要配置网络和存储，以
便虚拟机可以使用这些资源。这些资源包括网络拓扑、IP 地址、存储池等。 
2. 创建虚拟机镜像：管理员需要创建虚拟机镜像，包括操作系统、软件和预装应
用程序等，这是创建虚拟机的基础。 
3. 创建云主机实例：用户可以通过 OpenStack 管理界面或 API 创建虚拟机。用
户需要选择虚拟机镜像、云主机实例类型、网络配置和安全组等。 
4. 启动云主机实例：一旦创建了云主机实例，OpenStack 就会将虚拟机镜像复制
到计算节点，并在计算节点上创建虚拟机实例。虚拟机实例启动后，OpenStack
会将 IP 地址、MAC 地址和其他网络配置信息等发送到虚拟机。 
5. 配置云主机实例：一旦虚拟机启动，用户可以登录虚拟机并配置操作系统和应
用程序。 
6. 关闭和删除云主机实例：当用户不再需要虚拟机实例时，可以将其关闭并从
OpenStack 中删除。 
需要注意的是，OpenStack 创建虚拟机的流程可能会因为不同的 OpenStack 版本
和配置而有所不同。上述流程仅作为参考。 
 
port 创建成功后的 dhcp 相关操作 
创建 VM 时，nova-compute 与 neutron 的 plugin 交互，在 neutron 的数据库中创
建 VM 所需的 port 信息。neutron 数据库中的 port 信息创建完成后，通知 neutron-
dhcp-agent 去将数据库中的 port 中的 ip 和 mac 信息加载到 dnsmasq 所需的配置
文件中(包括 host 和 addn_hosts 文件)。 
在 VM 启动时，广播 dhcp discover 请求，当 dnsmasq 进程的监听接口 ns-xxx 监
听到这种请求时，dnsmasq 进程将根据配置文件(host 和 leases 文件)中的内容去
判定是否有未分配的 ip 和 mac 为请求者进行提供。  
最终 VM 便真实的获取到与保存在数据库中的 ip 和 mac 信息。neutron-dhcp-agent
只是将所创建 VM 的 ip 和 mac 信息从数据库中获取到自己的配置文件中，然后
等到 VM 启动时，为它提供。因此 neutron-dhcp-agent 相当于在 VM 和数据库之
间起了个中间桥梁的作用。  
当 ports 表发生变化时，neutron-server 将通过 HTTP 请求的方式发送 event 事件
给 nova。 
 
每个网络 dhcp agent 会创建一个 dhcp 命名空间，并在其中创建虚拟网卡，每创
建一个子网就会创建一个 dhcp port，将这个 port 配置到这个虚拟网卡上。命名
空间内的 dnsmasq 进程监听 53 端口，当 network 创建一个 IP 会向 dhcp 的 host
文件中添加一条记录，当 port 绑定虚机时，就能通过 dhcp client 自动获取 IP。 
 
 
 
 
ovs 场景下东西南北向流量 
南北向流量：虚拟机连通外网； ovs 架构下，虚拟机网卡 tap 连接 Linux-bridge
网桥(qbr)，Linux- bridge 通过 qvb 和 qvo 连接集成网桥 br-int，每个 vxlan 网络下
会有对应的 dhcp 端口连接到 br-int 上，qvo 和 vxlan 网络是一对一关系，虚拟
router 有端口 qr 连接到 br-int 上，这样流量经过 br-int 到 router，之后到 br-ex 上
的端口 qg，br-ex 连接到宿主机网卡和互联网通信。router 的内部接口就是 br-int
上的 qr 口，外部网关就是 br-ex 上的 qg 口。  
 
东西向流量：虚拟机与虚拟机时间连通； br-int 下连接一样，这时候 br-int 通过
patch-tun 和 patch-int 连接 br-tun，br-tun 连接到宿主机租户网卡，br-tun 上 vxlan
口和对端 vxlan 口经过隧道连通，之后通过 br-tun 和 br-int 连接到对端虚拟机。 
br-tun 使用 Openflow 规则来处理 Van ID 和 Tunnel Id 的转换； 
 
qrouter 命名空间中有两个接口，qg 连接 br-ex，qr 连接 br-int； 
1．同一个 host 上同一个子网内虚机之间的通信过程 
br-int 是个虚拟的二层交换机，所以同一个 host 上的同一个子网内的虚机之间的
通信只是经过 br-int 桥，不需要经过 br-tun 桥； 
2. 不同主机上同一个子网内的虚机之间的通信过程 
1. 从一个 compute 节点的虚机 1 出发的 packet，经过 Linux bridge 到达 br-int，被打上 
VLAN ID Tag； 
2. 到达 br-tun，将 VLAN ID 转化为 Tunnel ID，从 Tunnel 发出，到达另一个 compute 节
点； 
3. 在另一个 compute 节点上经过相反的过程，到达右边的虚机 
3. 虚机访问外网 
1. Packet 离开虚机，经过 Linux bridge， 到达 br-int，打上 VLAN ID Tag； 
2. 达到 br-tun，将 VLAN ID 转化为 Tunnel ID； 
3. 从物理网卡进入 vxlan 通道； 
4. 从 vxlan 通道达到网络节点的网卡； 
5. 达到跟物理网卡相连的 br-tun，将 Tunnel ID 转化为 VLAN ID； 
6. 达到 br-int，再达到 router，router 的 NAT 表将 fixed IP 地址转化为 floatiing 
IP 地址，再被 route 到 br-ex； 
7. 从 br-ex 相连的物理网卡上出去到外网； 
外网 IP 访问虚机是个相反的过程。 
 
4. 虚机发送 DHCP 请求 
1. 虚机的 packet -> br-int -> br-tun -> GRE Tunnel -> eth2 ------>eth2->br-tun->br-
int->qDHCP 
2. qDHCP 返回其 fixed IP 地址，原路返回 
 
5. 不同 tenant 内虚机之间的通信 
Neutron Tenant 网络是为 tenant 中的虚机之间的通信。如果需要不同 tenant 内的
虚机之间通信，需要在两个 subnet 之间增加 Neutron 路由。 
 
 
Vmware 提供了三种网络工作模式 
bridged 桥接模式 
手工为虚机配置 IP 地址掩码并且和宿主机同一网段，使用桥接模式的虚机和宿
主机的关系就像连接到同一 hub 上的两台电脑。 
host- only 主机模式 
在此模式下，虚机的 IP 配置由 vmnet1 虚拟网络的 DHCP 服务器动态分配，但是
虚机和网内其他机器相隔离，虚机和宿主机可以通信。 
NAT 网络地址转化模式 
在虚拟系统中不用通过任何手动配置就直接访问互联网，只需要宿主机能访问互
联网即可。IP 由 vmnet8 虚拟网络的 DHCP 服务器提供，不能手动修改。 
 
vlan 
virtual local area network 
每个 vlan 对应一个广播域，不同 vlan 间的设备不能互通，只能通过路由器等三
层设备而互通。vlan tag 由交换机端口在数据帧进入交换机时添加，数据帧出交
换机时交换机会剥离其 tag。 
vlan id 取值范围是 1-4094 
 
 
vxlan 
virtual extensible local area network  
采用 L2 over L4(Mac in UDP)的报文封装模式，将二层报文用三层协议进行封装
可以实现二层网络在三层网络扩展，同时满足数据中心大二层虚拟迁移和多租户
的需求。 
1.同网段主机通信，报文查询 Mac 地址进行通信。但是虚拟机规模增加，网卡
Mac 地址增加，二层设备 Mac 地址表项 hold 不住。 
2.vlan 数量只有 4000 个左右，无法满足更多虚拟云计算服务租户隔离。 
3.虚机迁移 IP 和 Mac 参数不变，导致虚机只能限制在一个二层域中； 
 
vtep     
vxlan tunnel endpoints  vxlan 隧道端点 
VTEP 会将 VM 发出的原始报文封装成一个新的 UDP 报文，并使用物理网络的
IP 和 MAC 地址作为外层头，对网络中的其他设备只表现为封装后的参数。也就
是说，网络中的其他设备看不到 VM 发送的原始报文。 
如果服务器作为 VTEP，那从服务器发送到接入设备的报文便是经过封装后的报
文，这样，接入设备就不需要学习 VM 的 MAC 地址了，它只需要根据外层封装
的报文头负责基本的三层转发就可以了。因此，虚拟机规模就不会受网络设备表
项规格的限制了。 
如果网络设备作为 VTEP，它还是需要学习 VM 的 MAC 地址。但是，从对报文
进行封装的角度来说，网络设备的性能还是要比服务器强很多。 
 
vni 
vxlan network identifier   vxlan 网络标识 
一个 vni 代表一个租户，属于不同 vni 的虚拟机时间不能进行二层通信。 
VTEP 在对报文进行 VXLAN 封装时，给 VNI 分配了 24 比特的空间，这就意味
着 VXLAN 网络理论上支持多达 1600 万（即：224-1）的租户隔离。 
 
vxlan 隧道 
是用来传输经过 vxlan 封装的报文，它是建立在 vtep 之间的一条虚拟通道。 
在 IP 网络中，“明”里传输的是跨越三层网络的 UDP 报文，“暗”里却已经悄悄将
源 VM 的原始报文送达目的 VM。就好像在三层的网络之上，构建出了一个虚拟
的二层网络，而且只要 IP 网络路由可达，这个虚拟的二层网络想做多大就做多
大。 
 
VXLAN 部署方法 
VXLAN 网络设备主要有三种角色，分别是 VTEP(VXLAN Tunnel End Point)、
VXLAN 网关、VXLAN IP 网关，对于应用系统来说，只与这三种设备相关，而
与底层传统三层 IP 网络无关。 
 
VTEP、VXLAN 网关、VXLAN IP 网关、形态可以是虚拟交换机，也可以是物理
交换机。根据 VTEP、VXLAN 网关、VXLAN IP 网关是虚拟交换机还是物理交
换机，VXLAN 网络的部署方法主要分三种。 
(1) 第一种是 VTEP、VXLAN 网关、VXLAN IP 网关均通过安装在服务器上的软
件实现。 
(2) 第二种是 VTEP、VXLAN 网关、VXLAN IP 网关均由物理交换机承担，物理
服务器支持 SR-IOV 功能，使虚拟机通过 SR-IOV 技术直接与物理交换机相连，
虚拟机的流量在接入交换机上进行 VXLAN 报文的封装和解封装。 
(3)第三种是 VTEP 由安装在服务器上的软件实现，VXLAN 网关、VXLAN IP 网
关由物理交换机承担。 
对于第一种部署方法，由于所有 VXLAN 报文的封装解封装都通过软件实现，会
占用部分服务器资源，特别是 VXLAN IP 网关，当访问量大时，将会成为系统瓶
颈。对于第二种部署方法，由于需要通过一些特殊的要求或技术实现虚拟机与
VTEP 的对接，组网不够灵活。第三种部署方法通过安装在服务器上的软件实现
虚拟机的 VTEP，通过物理交换机实现物理服务器的 VTEP，通过专业的硬件交
换机实现 VXLAN IP 网关，从而可承载超大规模的流量转发，避免成为系统瓶
颈，第三种部署方法结合了第一种和第二种方法的优势，相对而言是目前最优的
部署方法。 
VxLAN 网络中，虚机之间的三种互访形式： 
相同 VXLAN 内 VM 之间互访： 
单播报文在 VTEP 处查找目的 MAC 地址，确定对应的 VTEP 主机 IP 地址 
根据目的和源 VTEP 主机 IP 地址封装 VXLAN 报文头后发送给 IP 核心网 
IP 核心内部根据路由转发该 UDP 报文给目的 VTEP 
目的 VTEP 解封装 VXLAN 报文头后按照目的 MAC 转发报文给目的 VM 
 
不同 VXLAN 内 VM 之间需要互访经过 VXLAN IP GW 完成， 
在 VXLAN IP GW 上匹配 VXLAN Maping 表项进行转发，报文封装模式同同一
VXLAN 内 VM 一致 
 
VXLAN VM 与 VLAN VM 之间互访，通过 VXLAN GW 来完成， 
VXLAN 报文先通过 VXLAN 内部转发模式对报文进行封装，目的 IP 为 VXLAN 
GW， 
在 VXLAN GW 把 VXLAN 报文解封装后，匹配二层转发表项进行转发，VLAN
到 VXLAN 的访问流程正好相反 
 
 
 
云计算 
云计算是一种资源的服务模式，该模式可以实现随时随地、便捷按需地从可配置
计算资源共享池中获取所需的资源（如网络、服务器、存储、应用及服务），资
源可以快速供应并释放，大大减少了资源管理工作开销。 
 
 
虚拟化 
硬件虚拟化主要通过一个叫 Hypervisor 的程序实现，根据 Hypervisor 的实现方式
和所处的位置，虚拟化分为 I 型虚拟化和 II 型虚拟化； 
 
 
TAP/TUN 是 linux 内核实现的一对虚拟网络设备，TAP 工作在二层，TUN 工作
在三层，linux 内核通过 TAP/TUN 设备向绑定该设备的用户空间程序发送数据。 
openstack 开发基础 
setup.cfg 
setup.py 就是调用 setuptools.setup()，setup()函数有大量的参数需要设置，包括项目的名
称，作者，版本等。setup.cfg 文件的出现就是将 setup()函数解脱出来，它使用 pbr 工具
去读取和过滤 setup.cfg 中的数据，并将其解析后的结果作为自己的参数。 
entry points 
entry points 可以简单理解为它通过 setuptools 注册的外部可以直接调用的接口。 
KVM 
Kernel-based Virtual Machine 
KVM 是一个虚拟机管理程序，它是基于虚拟化扩展的 x86 硬件，现己集成到 
linux 内核中，由标准的 linux 调度程序进行调度。它可以具备内存管理、 存储、
设备驱动及可伸缩性等特点。KVM 有一个内核模块 kvm.ko，用于管理虚拟 CPU
和内存。KVM 本身只关注虚拟机调度和内存管理这两个方面，IO 的虚拟化，比
如存储和网络设备交给 Linux 内核和 QUMU 实现。 
除了 KVM 虚拟化外，目前的虚拟化产品还有 Xen VMWare VirtualBox Hyper-V 
等。  
KVM 的管理工具 Libvirt 
Libvirt 是一套对平台虚拟化技术进行管理的管理工具和 Linux API 作为连接底
层多种虚拟机管理器（Hypervisor）与上层应用的中间适配层，它可以支持 KVM 
Xen QEMU VirtualBox 等多种虚拟机管理器。 
Libvirt 包含 3 个东西，后台 daemon 程序 libvirtd、API 库和命令行工具 virsh； 
libvirtd 是服务程序，接受和处理 API 请求； 
API 库使得其他人可以开发基于 Libvirt 的高级工具，比如 virt-manager，这个是
图形化的 KVM 管理工具，可以用来启动虚拟，对虚机进行各种管理操作； 
virsh 是常用的 KVM 命令行工具； 
 
 
RPC 
openstack 各组件之间的主要是通过 rest api 接口进行通信，而同一组件内部都基
于 AMQP 通信模型的 RPC 通信； 
AMQP 
生产者（Publisher）首先将消息（Message）发送到 Exchange 中， Exchange 可
以对接多个消息队列，根据不同的 Routing， 最终可以把消息分别发送到相应的
消息队列中。不同的消费者最终从各自对应的消息队列中获取消息进行消费。 
 
AMQP 中每种 Exchange 类型都实现 某种路由算法 在这些类型的 Exchange 中，
以下类型 Exchange 在 OpenStack 中比较常见： 
( 1) Direct Exchange 。这是一种默认的 Exchange ，它是基于路由键（ Routing 
Key)来路由消息的一种方式在这种类型 Exchange 中，只有消息中的 Routing 
Key 属性与消费者 routing_key 属性一致时，此消息才会被此消费者获取并处理。 
( 2) Fan-out Exchange 。这是类似于广播的消息分发方式，所有的消费者都可以
接收来自这种类型的 Exchange 消息并处理。  
( 3 ) Topic Exchange 。这 类型 Exchange 允许 Routing Key 表达式的形式进行
定义。在 这类 Routing Key 中允许使用 个特殊符号 “．” “＊”和“＃"，“*”表示
匹配任意字符，“＃”表示匹 配零个或多个字符。例如，“**.stock. ＃＂可以匹配
“usd.stock ”和“eur.stock.db ”这样的 Routing Key， 但是不能匹配“ stock. nasdaq 
这样的 Routing Key; 
 
openstack 通用设计思路 
1.每个 openstack 组件包含若干个服务，其中必有一个 API 服务负责接收客户请
求；对外提供统一接口，隐藏实现细节；运行多个 API 服务实例实现 API 的高
可用； 
2.对一个某个操作，如果有多个实体都能够完成任务，通常有个 scheduler 负责从
这些实体中挑选出一个最合适的来执行操作；调度服务只管分配任务，真正执行
任务的是 worker 工作服务； 
3.基于 Driver 的框架； 
4.messaging 服务； 
程序之间的调用通常分为两种：同步调用和异步调用； 
rpc.call----如 nova 中 api 直接调用 scheduler 的接口就是同步调用。api 发送给
scheduler 请求后，一直等待，直至 scheduler 调用 computer 完成任务，将结果返
回 api，api 才进行后面的任务。rpc.call 就是请求响应类型，一个请求发送出去以
后，需要等待响应，调用需要制定目标的服务节点； 
rpc.cast----api 通过 messaging 调用 scheduler 就是异步调用。API 发出请求后不需
要等待，直接返回，继续做后面的工作，scheduler 从 messaging 接收到请求后执
行调用操作，完成后将结果也通过 messaging 发送给 API。rpc.cast 就是请求响应
类型，一个请求发出去后，不需要等待响应。 
 
 
 
 
 
 
 
neutron 
neutron 核心组件提供了云平台中软件定义网络的功能，它负责管理虚拟网络组
件，包括networks，subnets，switchs和routers，同时提供网络服务，如loadbalancer，
Firewall 和 VPN。 
core api：对外提供管理 network/subnet/port 的 restful api； 
extension api：对外提供管理 lbaas，fwaas，router 等的 restful api； 
common service：认证和校验 api 请求； 
neutron core：neutron-server 的核心处理程序，通过调用相应的 plugin 处理请求； 
core plugin api：定义了 core plugin 的抽象功能集合，neutron core 通过该 api 调用
相应的 core plugin； 
extension plugin api：定义了 service plugin 的抽象功能集合，neutron core 通过该
api 调用相应的 service plugin； 
core plugin：实现 core plugin api，在数据库中实现 network/subnet/port 的状态，
负责调用相应的 agent 在 network provider 上执行相关操作，比如创建网络； 
service plugin：实现 extension plugin api，在数据库中实现 sg/router/lb 等资源的状
态，并负责调用相应的agent在network provider上执行相关操作，比如创建router； 
 
neutron- server 服务启动 
创建一个 socket 监听本机的 9696 端口，neutron.conf 中有 host 和 bind_port 参数。 
之后创建 WSGI server 进程用于处理 neutron client 发来的请求。 
neutron/api/v2 
v2 目录下包含了核心资源的实现代码。每个 neutron API 资源都会被封装成一个
Wsgi application。neutron API 服务进程 neutron- server 接收到用户的 http 请求后
会通过 Router 模块将其路由到相应的资源的 controller 中去执行。 
plugin 初始化时调 neutron.api.extensions 的 append_api_extensions_path 方法，传
入 extension 的路径。 
extension 中 get_resources 方法，根据 plugin，plural_mappings，resource_map，
action_map ， path_prefix
进 行
create_resources ， create_resounces
中 迭 代
resource_map 创建 controller，将 controller 传给 Resource Extension 初始化放到
create_resources 的返回值列表中。 
 
bind_port 
bind_port接口定义在class MechanismDriver，目录为neutron_lib/plugins/ml2/api.py。 
所谓 bind_port 就是将 Network 中的 segment 与 port 之间的关系，存入数据库表
ml2_port_binding_levels 中， 
 
 
Ethernet/以太网 
工作在数据链路层，Ethernet 中的主机使用数据帧通信，MAC(Media Access 
Control）地址是每台主机的唯一标识，MAC 地址由设备厂商硬编码在有线网卡
NIC 中。 
  
VLAN/虚拟局域网 
连接在同一交换机上的主机，如果它们具有不同的 VLAN ID，那么它们之间的
数据是相互隔离的。配置了指定的 VLAN ID 的交换机端口叫做 ACCESS 口。交
换机端口支持配置为允许多个 VLAN ID 的数据帧通过，这样的端口叫做 TRUNK
口。 
Subnet/子网 
 
ARP 
Address Resolution Protocol 
 
DHCP 
Dynamic Host Configuration Protocol 
 
 
DHCP agent 还会在 DHPC namespace 中启动一个 dnsmasq 进程，由它提供 dhcp 
server 服务； 
L2 
链路层，一个可靠的点对点的数据对接，常见：网卡，二层交换机，网桥等； 
port 
port 是虚拟交换机上一个端口，port 上定义 mac 和 ip 地址，instance 的虚拟网卡
VIF(virtual interface)绑定到 port 上时，port 会将 mac 和分配给 VIF。 
nova 中的 instance 是通过虚拟交换机连接到虚拟二层网络的。 
L3 
网络层，在网络的各个节点之间进行地址分配、路由和分发报文，常见：路由器，
多层交换机，防火墙等； 
 
静态路由 
 
 
 
NAT 
Network Address Translation 
NAT 是一个在 IP 数据包传输的过程，动态修改其头部的源 IP 地址或者目的 IP
地址的程序。Linux 中实现 NAT 的工具是 iptables。 
SNAT，通常利用 SNAT 来使具有私网 IP 的主机访问 Internat 网络。当具有私网
IP 的主机访问公网服务时，SNAT 将数据包中的源地址从该私网 IP 修改成一个
公网 IP，这样公网服务就知道回包发给谁了。 
DNAT，NAT 路由器修改 IP 数据包中的目的 IP 地址。 
One-to-One NAT，NAT 路由器维护一张私有 IP 地址到公共 IP 地址的一对一映
射表。Openstack 使用 One-to-One NAT 来实现 Floating IP 功能。 
Router 的 NAT 功能通过 iptables 实现： 
 
传统 Router 
 
 
虚拟路由器（virtual router） 
一个 VR 只属于创建它的租户，只用于该租户的子网之间和子网与外网的路由；
同一网络内的若干子网可以挂在一个 VR 上； 
同一租户的不同网络的没有 IP 地址重叠的子网可以挂在一个 VR 上； 
不同租户之间的内网之间是不能使用 VR 的； 
同一租户的不同网络内的有 IP 地址重叠的两个子网不能使用同一个 VR（添加
子网到 VR 时会报错）； 
在网络节点上，一个 VR 运行在一个 Network namespace 内，该 namespace 的
名称包含该 VR 的 UUID； 
 
 
 
常用的网络设备 
(Switch/Router/Firewall/Load Balancer) 
 
Lbaas 
 负载均衡（Load Balancing）是将来访的网络流量在运行相同应用的多个服务器
之间进行分发的一种核心网络服务。 
负载均衡器一般可以分为两类：第 4 层负载均衡器和第 7 层负载均衡器。 
第 4 层负载平衡器：基于网络和传输层协议（IP，TCP，FTP，UDP 等）来均衡
负载。 
 
第 7 层的负载均衡器：基于应用层协议比如 HTTP, SMTP, SNMP, FTP, Telnet 等
均衡负载。比如对 HTTP 来说，第七层的负载均衡器能根据应用的特定数据比
如 HTTP 头，cookies 或者应用消息中的数据来做进一步的请求分发。 
两种类型的负载均衡器都能接收请求，然后根据特定的算法将请求分发到特定的
服务器。一些行业标准的算法是： 
轮询 (Round robin)：轮流分发到各个（活动）服务器 
加权轮循 (Weighted round robin)：每个服务器有一定的加权（weight），轮询时
考虑加权。 
最少连接 (Least connections)：转发到有最少连接数的服务器 
最少响应时间 (Least response time)：转发到响应时间最短的服务器 
 
 
 
 
 
 
 
 
L2 Population 
L2 Population 是用来提高 VXLAN 网络 Scalability 的。 
通常我们说某个系统的 Scalability 好，其意思是： 
当系统的规模变大时，仍然能够高效地工作。 
L2 Population 到底解决了怎样的 Scalability 问题？ 
有一个包含 5 个节点的 VXLAN 网络，每个节点上运行了若干 VM。 
现在假设 Host 1 上的 VM A 想与 Host 4 上的 VM G 通信，VM A 要做的第一步
是获知 VM G 的 MAC 地址。 
于是 VM A 需要在整个 VXLAN 网络中广播 APR 报文：“VM G 的 MAC 地址是
多少？” 
如果 VXLAN 网络的节点很多，广播的成本会很大，这样 Scalability 就成问题了。 
幸好 L2 Population 出现了。 
L2 Population 的作用是在 VTEP 上提供 Porxy ARP 功能，使得 VTEP 能够预先
获知 VXLAN 网络中如下信息： 
1. VM IP – MAC 对应关系 
2. VM – VTEP 的对应关系 
当 VM A 需要与 VM G 通信时： 
1. Host 1 上的 VTEP 直接响应 VM A 的 APR 请求，告之 VM G 的 MAC 地
址。 
2. 因为 Host 1 上的 VTEP 知道 VM G 位于 Host 4，会将封装好的 VXLAN 
数据包直接发送给 Host 4 的 VTEP。 
这样就解决了 MAC 地址学习和 APR 广播的问题，从而保证了 VXLAN 的 
Scalability。 
那么下一个关键问题是： 
VTEP 是如何提前获知 IP – MAC – VTEP 相关信息的呢？ 
答案是： 
1. Neutron 知道每一个 port 的状态和信息；port 保存了 IP，MAC 相关数据。 
2. instance 启动时，其 port 状态变化过程为：down -> build -> active。 
3. 每当 port 状态发生变化时，Neutron 都会通过 RPC 消息通知各节点上的 
Neutron agent，使得 VTEP 能够更新 VM 和 port 的相关信息 
4. VTEP 可以根据这些信息判断出其他 Host 上都有哪些 VM，以及它们的 
MAC 地址，这样就能直接与之通信，从而避免了不必要的隧道连接和广播。 
 
neutron 使用示例 
# 创建网络 
openstack network create net1 
# 在 net1 中创建子网 subnet1 
openstack subnet create subnet1 --subnet-range 10.0.0.0/24 --network net1 
# 在 net1 中创建一个端口 port1 
openstack port create port1 --network net1 
# 启动虚机时指定网卡所在的网络 
openstack server create --image IMAGE --flavor FLAVOR --nic net-id=NET_ID vm1 
# 添加安全组 
openstack security group rule create --protocol icmp default 
# 创建外部网络和子网 
openstack network create public_net --external 
openstack subnet create --network public_net --subnet-range 172.16.1.0/24 public_subnet 
# 创建 router 
openstack router create router1 
# 将 router 连接到子网 
openstack router add subnet router1 subnet1 
# 将 router 添加到外部网络 
openstack router set --external-gateway public_net router1 
# router 添加静态路由 
openstack router set --route destination=172.16.2.0/24,gateway=172.16.2.1 router1 
# 查看 router 上的 port 
openstack port list -router router1 
# 创建 floatingip 
openstack floating ip create public_net 
# 将 floatingip 和 port 关联 
openstack floating ip add port floatingip_id --port-id internal_vm_port_id 
 
 
 
 
nova 
 
nova hypervisor-list  查看计算节点 
nova hypervisor-servers 《》  
nova keypair-list    查看创建虚机的密钥对 
nova availability-zone-list    
nova pause/nova unpause 
nova suspend/resume 
nova resize id/name <规格> 
nova image-image <name/id> <快照> 
nova diagnostics 获取虚机 CPU 内存使用情况 
 
keystone 
 
token 每次访问都会产生，默认有效期为 24 小时，增长速度很快，token 表数据
越来越多。更好的方法是将 token 放到 memcached 中，利用其特性，自动删除不
使用的缓存。 
 
user 
指的任何使用 Openstack 的实体，可以是真正的用户，其它系统或者服务； 
除了 admin、demo 外，openstack 也为 nova，cinder，glance，neutron 服务创建了
相应的 user 
credentials 
是用户用来证明自己身份的信息，可以是用户名/密码，token，API key 等 
authentication 
是 keystone 验证 user 身份的过程。user 访问 openstack 时，向 keystone 提交用户
名和密码形式的 credentials，keystone 验证后会给 user 签发一个 token 作为后续
访问的 credentials。 
token 
是由字母和数字组成的字符串，user 成功 authentication 后，它由 keystone 分配
给 user，token 用做访问 service 的 credentials，service 会通过 keystone 验证 token
的有效性，token 的有效期默认是 24 小时； 
project 
project 用于将 openstack 的资源(计算、存储、网络)进行分组和隔离； 
资源的所有权归于 project，而不是 user; 
每个 user 必须挂在 project 里面才能访问该 project 的资源，一个 user 可以属于多
个 project; 
serivce 
openstack 的服务包括 compute(nova)，block storage(cinder)，object storage(swift)，
image service(glance)，networking service(neutron)； 
每个 service 都会提供若干个 endpoint，user 通过 endpoint 访问资源和执行操作； 
endpoint 
是一个网络上可以访问的地址，通常是一个 URL，service 通过 endpoint 暴露自
己的 API，keystone 负责管理和维护每个 service 的 endpoint。 
openstack catalog list----查看 endpoint； 
role 
 
keystone 借助 role 来进行鉴权，可以为 user 分配一个或多个 role，service 决定每
个 role 能干什么，service 通过各自的 policy.json 文件对 role 进行访问控制。 
 
glance 
Image 是一个模板，里面包含了基本的操作系统和其他软件； 
 
 
 
 
 
 
 
image 的元数据 通过 glance-registry 存放在 db 中； image 的 chunk 数据 通
过 glance-store 存放在各种 backend store 中，并从中获取。 
 
 
 
openstack metadata 
开启的服务/安装的包/添加 ssh 密钥/配置 hostname 等 
nova-api-metadata 服务提供 restful API 接口，用于虚拟机访问此 API 获取 metadata
信息。 
大致流程：请求发送给 neuteon-ns-metadata-proxy，请求中添加 router-id 和
netwoek-id，然后转发给 neutron-metadata-agent，获取 port 信息，最后转发给 nova-
api-metadata 获取虚拟机的 metadata。 
 
 
 
SDN 
背景 
手工配置和维护各种硬件设备，网络业务变复杂，多租户场景不能通过手工来保
证。 
SDN 是新型网络架构，设计理念是将网络的控制平面和数据转发平面进行分离，
从而通过集中的控制器中的软件平台去实现可编程化底层硬件，实现对网络资源
灵活的按需调度。 
通过集中的 SDN 控制器实现网络资源的统一管理整合以及虚拟化后，采用规范
化的北向接口为上层应用提供按需的网络资源和服务，实现网络功能开放。 
控制层，主要负责数据平面资源的编排，维护网络拓扑，状态信息等； 
基础设施层，负责基于流表的数据处理、转发和状态收集； 
 
SDN 层次化绑定 
VxLAN 的处理主要包括 VxLAN 数据的封装和解封装，这些都是由 VTEP
（VxLAN Tunnel EndPoint）完成的。如果硬件交换机来处理 VxLAN，那么就相
当于 VTEP 要在交换机上，VxLAN 报文的封装解封装都在交换机上完成。这样
的交换机一般是直接与服务器相连接的交换机（ToR，Top of Rack 交换机）。因
为 VxLAN 现在放到了硬件交换机处理，对于服务器或者位于服务器上的虚拟机
来说，是感知不到 VxLAN 的存在。大多数的硬件 SDN（或者说 underlay SDN）
都是采用这种方式处理 VxLAN。 
 
VxLAN 的一个最大好处在于，能够提供更多的租户隔离。多租户隔离依靠的是
VxLAN Header 里面的 24bit VNI（Virtual Networking Identity），不同的租户有不
同的 VNI。但是现在 VxLAN 的封装解封装都是在硬件交换机完成，租户拥有的
服务器或者虚拟机又感知不到 VxLAN，硬件交换机怎么知道哪些网络数据属于
哪个租户，进而给网络数据分配 VNI，完成 VxLAN 封装呢？ 
第一种方式是根据交换机端口来区分。例如，交换机端口 A 的网络流量，认为是
租户 A 的流量，封装成 VNI 为 A 的 VxLAN 数据。同理，端口 B 的流量认为是
租户 B 的流量，封装成 VNI B 的 VxLAN 数据。如下图所示： 
 
这种方式要求交换机的一个端口只能连接一个租户，也就是说，交换机端口连接
的服务器上只能部署一个租户的虚拟机。无论对于管理员还是用户来说，这都不
是一个友好的限制。 
反过来说，一个服务器如果同时有多个租户的虚拟机，那么交换机的一个端口就
会同时存在多个租户的网络数据，也就没有办法再通过交换机端口区分租户，分
配 VNI，进而封装 VxLAN 数据。服务器部署多个租户虚拟机，如下图所示： 
 
这种情况下该怎么让位于交换机上的 VTEP 识别多租户，进而封装 VxLAN 呢？
这就需要另外一种标记多租户网络数据的方式。传统网络里面，是通过 VLAN 识
别多租户的网络，这里还可以通过 VLAN 来做同样的事。首先在服务器内部对
不同租户的虚拟机打上不同的 VLAN Tag，同时将服务器连接到交换机的 Trunk
口，这样服务器可以把多个 VLAN Tag 的网络数据送到交换机。交换机根据
VLAN Tag 识别不同的租户，进而封装成相应的 VxLAN 数据。硬件交换机内的
VTEP 构成如下所示： 
 
硬件交换机上的 VTEP 从 Downlink，也就是与服务器连接的 Trunk 口，收到带 
VLAN Tag 的网络数据，之后查找“VLAN To VxLAN ID MAP”，找到对应的
VxLAN ID，进而封装成 VxLAN 数据。VTEP L2 Table 是 VxLAN 控制层要填的
表，与本文要描述的内容没有关联。 
这样，硬件交换机能够完成多个租户的 VxLAN 封装，而租户虚拟机也不需要知
道 VxLAN 的存在。但是同时，问题也来了。首先，服务器该给不同的租户打什
么样的VLAN Tag？其次，交换机里面的 VLAN To VxLAN ID MAP 由谁来填写？
对于 OpenStack，是通过层次化端口绑定这个功能来解决这两个问题。  
层次化端口绑定 
既然在 OpenStack 内实现这么一个功能，那就需要符合 OpenStack 的软件架构。
层次化端口绑定是在 OpenStack Neutron ML2 模块中实现的。Neutron ML2 我曾
在[2]中有过介绍。ML2 由多类 Driver 组成，其中一类是 Mechanism Driver。每
一个 Mechanism Driver 都管理一种二层网络设备。在层次化端口绑定的场景下，
需要两个 Mechanism Driver，其中一个管理硬件交换机，另一个管理 OpenVSwitch
（当然也可以是其他的虚拟交换机，我曾经在 VMware DVS 上也实现过相同的
功能），具体连接图如下所示： 
 
 
原理讲清楚了，具体的连接关系也讲清楚了，接下来的流程就顺利成章了。我们
最后来过一下层次化端口绑定的流程。 
用户创建了一个虚拟机，并且将虚拟机创建在 VxLAN A 网络中。Neutron 需要
创建一个 VxLAN A 的网络接口，请求被发送到了 ML2。Neutron ML2 先调用到
物理交换机对应的 Mechanism driver 进行端口绑定（port binding），将 VxLAN 
A 与网络接口进行绑定。因为底层还有 VLAN，物理交换机的 Mechanism Driver
会再申请一个 VLAN B，并告知 Neutron ML2，当前网络接口还需要绑定到对应
的 VLAN 上。之后物理交换机的 Mechanism Driver 会通过相应的 API，告知物
理交换机 VLAN B 和 VxLAN A 的对应关系，这样物理交换机就有了 VLAN To 
VxLAN ID MAP。ML2 因为知道了网络接口还需要绑定到对应的 VLAN 上，再
调用 OpenVSwitch 的 Mechanism Driver，将 VLAN B 与网络接口进行绑定。 
之后，OVS 的 Mechanism Driver 会通过相应的 API，告知位于计算节点的
OpenVSwitch，对于这个网络接口的网络数据，打上 VLAN B 的 Tag。 
到此为止层次化端口绑定完成了。在这里，对于同一个网络接口，实际上绑定了
两次，一次是在虚拟交换机上的 VLAN 绑定，另一次是在硬件交换机上的
VxLAN 绑定。所以，对于“Hierarchical Port Binding”到层次化端口绑定这个翻译，
我个人觉得还是比较符合“信雅达”的标准的。 
绑定完成之后，网络数据送到 OpenVSwitch，OVS 会打上 VLAN B 的 Tag，带
VLAN B Tag 的网络数据送到物理交换机。物理交换机根据自己的 VLAN To 
VxLAN ID MAP，将 VLAN Tag 去掉，再封装成相应的 VxLAN 数据。经过这样
的处理，VxLAN 的封装解封装被 offload 到了物理交换机。  
那为什么 OpenStack Neutron 里面没有相应的全部代码？因为层次化端口绑定的
逻辑，有一半是在 Neutron ML2 里面，有另一半是在物理交换机对应的 Mechanism 
driver 里面。物理交换机属于各个厂商，相应的 Mechanism Driver 由各个厂商维
护，而 OpenStack Neutron 不包含各个厂商的代码。 
 
 
OVS 
虚机交换机，为虚拟机提供二层交换功能，支持 openflow 协议，支持控制器对
ovs 远程管理控制; 
openvswich 作为网络驱动之后创建 vxlan 网络会生成三个网桥： 
br-int   连接 dnsmasq，流表逻辑处理； 
br-ex   连接网卡，发送外网，在网络节点 
br-tun  隧道端点，vxlan 和 gre 进行通信 
可以进出流量的端口，往往绑定若干 Mac 地址和 IP 地址，以进行寻址。一般为
虚拟交换机上的虚拟接口，通过端口访问网络。port 可以看作虚拟交换机上的一
个端口。port 上定义了 Mac 地址和 IP 地址，当 instance 的虚拟网卡 VIF 绑定到
port 时，port 会将 Mac 地址和 IP 地址分配给 VIF。 
 
 
控制节点一般需要一个网络端口用于通信/管理各个节点； 
网络节点包含三个网络端口， 
eth0 用于与控制节点进行通信； 
eth1 用于与除了控制节点之外的计算节点/存储节点之间的通信； 
eth2 用于外部的虚拟机与相应网络之间的通信； 
 
计算节点包含至少两个网络端口， 
eth0 与控制节点进行通信，受控制节点统一调配； 
eth1 与网络节点存储节点进行通信； 
 
存储节点包含至少两个网络端口， 
eth0 与控制节点进行通信，接受控制节点任务，受控制节点统一调配； 
eth1 与计算节点/网络节点进行通信，完成控制节点下发的各类任务。 
 
 
 
rpm 安装 openstack 
1.安装 python3-openstackclient 
2.安装 mariadb/mariadb-server/python3-PyMysql 
3.安装 socat/erlang，rpm 安装 rabbitmq- server 包 
4.安装 memcached/python3-memcached 
5.安装 etcd 
6.keystone 身份认证部署，数据库相关 
7.glance 镜像服务 
8.placement 放置服务 
9.nova 计算服务 
10.neutron 网络服务 
11.horizon  安装 openstack-dashboard 
12.安装块存储 cinder 
 
 
 
 
 
 
 
kolla-ansible 安装 openstack 
 
ansible 
是一种 agentless，基于 ssh，可实现批量配置、命令执行和控制，基于 python 实
现的自动化运维工具。 
yaml 三板斧 
缩进： 每个缩进由两个空格组成 
冒号： 以冒号结尾的除外，其它所有冒号后面所有必须有空格 
短横线：表示列表项，使用一个短横杠加一个空格，多个项使用同样的缩进级别
作为同一个列表； 
ansible-playbook 
1.关闭 selinux，关闭防火墙，更改 hosts 并免密登陆 
2.安装 docker-ce 
3.安装 ansible，先 pip2.4.0 后 yum 
4.安装 kolla-ansible 
5.生成密码文件，修改 global.xml 文件以及 multinode 文件 
6.拉取镜像 
7.预检查 
8.部署 
9.验证部署 
10.安装 openstack client 
 
 
 
 
13. Kubernetes 
K8s 是一个管理跨主机容器化应用系统，实现了包括应用部署、高可用管理和弹
性伸缩在内的一系列基础功能并封装成为一套完整、简单易用的 RESTful API 对
外提供服务。 
k8s 整体架构 
 
k8s 由两种节点组成，master 节点和工作节点；前者是管理节点，后者是容器运
行的节点； 
master 主要有三个重要的组件，分别是 APIServer、scheduler 和 controller manager； 
 
 
 
 
pod 
k8s 中，能够被创建、调度和管理的最小单元是 pod，而非单个容器，一个 pod 是
由若干个 docker 容器构成的容器组，pod 里的容器共享 network namespace，并
通过 volume 机制共享一部分存储。 
pod 是 IP 等网络资源的分配的基本单元，这个 IP 及其对应的 network namespace
是由 pod 里面的容器共享的； 
pod 内的容器也共享 volume。当一个 volume 被挂载在同属一个 pod 的多个 docker
容器的文件系统上时，该 volume 可以被这些容器共享； 
每个 pod 都有一个属性 labels----一组键值对，形如： 
"labels": { 
    "key1": "value1", 
    "key2": "value2" 
} 
replication controller 
备份控制器；用于保证在同一时刻 pod 能够维持特定的数目。用户可以将备份控
制器理解为整个容器集群全部节点的进程的监督者。 
它决定了一个 pod 有多少同时运行的副本，并保证这些副本的期望状态与当前状
态一致；如果创建了一个 pod，并且在希望该 pod 是持续运行的应用时[即仅适用
于重启策略为 always 的 pod]，一般都推荐同时给 pod 创建一个 replication 
controller，让这个 controller 一直守护 pod，直到 pod 被删除。 
service 
pod 在 k8s 中 IP 地址不是固定的，因此需要一个代理来确保需要使用 pod 的应
用不需要知晓 pod 的真实 IP 地址；当 replication controller 创建了多个 pod 副本
时，需要一个代理来为这些 pod 做负载均衡。 
service 主要由一个 IP 地址和一个 label selector 组成。 
service 提供的是 pod 的入口访问以及访问策略。 
Label 是一组键值对，用来标识创建的对象的属性。选择器用来过滤带有特定标
签的对象。 
k8s 命令 
# 列举所有匹配标签{"name": "nginx"}的 pod 
kubectl get pods -l name=nginx 
kubectl get pod   # 查看创建的 pod 信息 
kubectl get pod_name container   # 查看 pod 中容器输出的 log 信息 
kubectl get replicationController -o wide   # 查看 replication controller 的基本信息 
kubectl get service   # 查看创建的 service 
kubectl get services   # 查看创建的 services 
 
# 创建 pod，其中 obj.json 可以定义 pod、replication controller、service 等 k8s 对象的 json
格式资源配置文件 
kunectl create -f obj.json     
 
 
# 删除 pod 
kubectl delete pod pod_name    
 
14. jenkins 
持续集成----频繁将代码集成到主干； 持续交付----频繁将软件的新版本交付该
质量团队或者用户，以供审批； 持续部署----代码评审或者测试通过后，将其自
动部署到生产环境； 
 
 
 
 
 
# 15. 算法
##  23. <a name='-1'></a>1. 合并两个无序链表
```python
class Solution: 
   def sortList(self, head: ListNode) -> ListNode: 
       def sort_func(head, tail): 
           if not head: 
               return head 
           if head.next == tail: 
               head.next = None 
               return head 
           slow, fast = head, head 
           while fast != tail: 
               slow = slow.next 
               fast = fast.next 
               if fast != tail: 
                   fast = fast.next 
           mid = slow 
           return merge(sort_func(head, mid), sort_func(mid, tail)) 
 
       def merge(node1, node2): 
           dummy = ListNode(0) 
           temp, temp1, temp2 = dummy, node1, node2 
           while temp1 and temp2: 
               if temp1.val <= temp2.val: 
                   temp.next = temp1 
                   temp1 = temp1.next 
               else: 
                   temp.next = temp2 
                   temp2 = temp2.next 
               temp = temp.next 
           temp.next = temp1 if temp1 else temp2 
           return dummy.next 
       return sort_func(head, None)
```

2. 一次遍历获取列表第二大值 ok 
class Solution(object): 
   def get_2th_num(self, nums): 
       max_num = float('-INF') 
       second_num = float('-INF') 
       for num in nums: 
           if num > max_num: 
               second_num = max_num 
               max_num = num 
           else: 
               if num > second_num: 
                   second_num = num 
       return second_num, max_num 
3. 快排 
1. 挑选基准值：从数列中挑出一个元素，称为"基准"（pivot）; 
2. 分割：重新排序数列，所有比基准值小的元素摆放在基准前面，所有比基准值大的
元素摆在基准后面（与基准值相等的数可以到任何一边）。在这个分割结束之后，对
基准值的排序就已经完成; 
3. 递归排序子序列：递归地将小于基准值元素的子序列和大于基准值元素的子序列排
序。 
递归到最底部的判断条件是数列的大小是零或一，此时该数列显然已经有序。 
def quick_sort(lists,i,j): 
   if i >= j: 
       return lists 
   pivot = lists[i] 
   low = i 
   high = j 
   while i < j: 
       while i < j and lists[j] >= pivot:   
           j -= 1  # 如果 i 与 j 未重合，j(右边)指向的元素大于等于基准元素，则 j 向左
移动 
       lists[i]=lists[j]  # 到此位置时 j 指向一个比基准元素小的元素,将 j 指向的元素放到
i 的位置上,此时 j 指向的位置空着,接下来移动 i 找到符合条件的元素放在此处; 
       while i < j and lists[i] <= pivot: 
           i += 1  # 如果 i 与 j 未重合，i 指向的元素比基准元素小，则 i 向右移动 
       lists[j]=lists[i]  # 此时 i 指向一个比基准元素大的元素,将 i 指向的元素放到 j 空着
的位置上,此时 i 指向的位置空着,之后进行下一次循环,将 j 找到符合条件的元素填到此
处 
   lists[j] = pivot  # 退出循环后，i 与 j 重合，此时所指位置为基准元素的正确位置,左
边的元素都比基准元素小,右边的元素都比基准元素大 
   quick_sort(lists,low,i-1) # 对基准元素左边的子序列进行快速排序 
   quick_sort(lists,i+1,high) # 对基准元素右边的子序列进行快速排序 
   return lists 
 
 
 
def quick_sort(lists): 
   if not lists: 
       return lists 
   smaller = [] 
   equal = [] 
   greater = [] 
   pivot = random.choice(lists) 
   for num in lists: 
       if num < pivot: 
           smaller.append(num) 
       elif num == pivot: 
           equal.append(num) 
       else: 
           greater.append(num) 
   return quick_sort(smaller) + equal + quick_sort(greater) 
4. 归并排序 
# 归并排序 
 
# 方法一 
def merge_sort(nums): 
   n = len(nums) 
   if n <= 1: 
       return nums 
   def merge(a, b): 
       na, nb = len(a), len(b) 
       i, j = 0, 0 
       ans = [] 
       while i < na and j < nb: 
           if a[i] < = b[j]: 
               ans.append(a[i]) 
               i += 1 
           else: 
               ans.append(a[j]) 
               j += 1 
       if i < na: 
          ans.extend(a[i:]) 
       else: 
           ans.extend(b[j:]) 
       return ans 
   mid = n // 2 
   left = merge_sort(nums[0:mid]) 
   right = merge_sort(nums[mid:]) 
return merge(left, right) 
 
 
# 方法二 
   def merge(self, nums, left, mid, right): 
       p, q = left, mid + 1 
       temp = [0] * len(nums) 
       for i in range(left, right+1): 
           temp[i] = nums[i] 
       for j in range(left, right+1): 
           if p > mid:  # 当左半边用尽时，取右半边的元素 
               nums[j] = temp[q] 
               q += 1 
           elif q > right: # 当右半边用尽时，取左半边的元素 
               nums[j] = temp[p] 
               p += 1 
           elif temp[p] < temp[q]: # 当左半边小于右半边时，取左半边的元素 
               nums[j] = temp[p] 
               p += 1 
           else: # 当右半边小于左半边时，取右半边的元素 
               nums[j] = temp[q] 
               q += 1 
 
   def merge_sort(self, nums, left, right): 
       if left >= right: 
           return 
       mid = (left + right) >> 1 
       self.merge_sort(nums, left, mid) 
       self.merge_sort(nums, mid+1, right) 
       self.merge(nums, left, mid, right) 
 
   def main(self, nums): 
       left, right = 0, len(nums) - 1 
       self.merge_sort(nums, left, right) 
       return nums 
5. 最大子列表和 ok 
# 贪心算法 
class Solution(object): 
   def max_subarray(nums): 
       ans = float('-inf') 
       cur = 0 
       for num in nums: 
           if cur >= 0: 
               cur += num 
           else: 
               cur = num 
        ans = max(cur, ans) 
       return ans 
 
# 动态规划 
class Solution(object): 
   def max_subarray(nums): 
       n = len(nums) 
     dp = [nums[0]] + [float('-inf')] * (n - 1) 
       for i in range(1, n): 
           dp[i] = max(dp[i - 1], 0) + nums[i] 
       return max(dp) 
6. 数组中重复的数字 ok 
# 在一个长度为 n 的数组 nums 里的所有数字都在 0～n-1 的范围内。数组中某些数
字是重复的，但不知道有几个数字重复了，也不知道每个数字重复了几次。请找出数
组中任意一个重复的数字。 
 
class Test(object): 
   def func(self, nums): 
       for index, num in enumerate(nums): 
           while index != nums[index]: 
               if nums[nums[index]] == nums[index]: 
                   return nums[index] 
               nums[nums[index]], nums[index] = nums[index], nums[nums[index]] 
       return -1 
7. 最小的 k 个数 ok 
class Solution: 
   def getLeastNumbers(self, arr: List[int], k: int) -> List[int]: 
       n = len(arr) 
       if k == 0: 
           return [] 
       res = list() 
       for i in range(k): 
           res.append(arr[i]) 
       for j in range(k, n): 
           temp = max(res) 
           if arr[j] < temp: 
               res[res.index(temp)] = arr[j] 
       return res 
 
# 用 python 中的最小堆 
class Solution: 
   def getLeastNumbers(self, arr: List[int], k: int) -> List[int]: 
       n = len(arr) 
       if k == 0: 
           return [] 
       heap = [-x for x in arr[0:k]] 
       heapq.heapify(heap) 
       for num in arr[k:]: 
           if -num > heap[0]: 
               heapq.heapreplace(heap, -num) 
       return heap 
8. 两个栈实现一个队列 ok 
class MyQueue: 
 
   def __init__(self): 
       self.in_list = [] 
       self.out_list = [] 
 
   def push(self, x: int) -> None: 
       self.in_list.append(x) 
 
   def pop(self) -> int: 
       if self.out_list: 
           return self.out_list.pop() 
       else: 
           for _ in range(len(self.in_list)): 
               self.out_list.append(self.in_list.pop()) 
           return self.out_list.pop() 
 
9. 单链表相交的入口节点 ok 
class Solution: 
 
    def detectCycle1(self, head: ListNode) -> ListNode: 
        seen = set() 
        cur = head 
        while cur: 
            if cur in seen: 
                return cur 
            seen.add(cur) 
            cur = cur.next 
        return None 
 
    # 从头结点出发一个指针，从相遇节点也出发一个指针，这两个指针每次只走一
个节点， 那么当这两个指针相遇的时候就是 环形入口的节点。 
    def detectCycle2(self, head: ListNode) -> ListNode: 
        slow, fast = head, head 
        while fast and fast.next: 
            slow = slow.next 
            fast = fast.next.next 
            # 如果相遇 
            if slow == fast: 
                p = head 
                q = slow 
                while p != q: 
                    p = p.next 
                    q = q.next 
                return p 
        return None 
 
设链表中环外部分的长度为 a。 slow 指针进入环后，又走了 b 的距离与 fast 相遇。此
时， fast 指针已经走完了环的 n 圈，因此它走过的总距离为 
a+n(b+c)+b=a+(n+1)b+nc。 
根据题意，任意时刻，fast 指针走过的距离都为 slow 指针的 2 倍。因此，我们有 
a+(n+1)b+nc=2(a+b)⟹a=c+(n−1)(b+c) 
有了 a=c+(n-1)(b+c)a=c+(n−1)(b+c) 的等量关系，我们会发现：从相遇点到入环点的距
离加上 n-1 圈的环长，恰好等于从链表头部到入环点的距离。 
因此，当发现 slow 与 fast 相遇时，我们再额外使用一个指针 ptr。起始，它指向链表
头部；随后，它和 slow 每次向后移动一个位置。最终，它们会在入环点相遇。 
 
10. 三数之和 97 
# 给你一个包含 n 个整数的数组 nums，判断 nums 中是否存在三个元素 a，b，c ，
使得 a + b + c = 0 ？请你找出所有和为 0 且不重复的三元组。 
# 注意：答案中不可以包含重复的三元组。 
 
# 输入：nums = [-1,0,1,2,-1,-4] 
# 输出：[[-1,-1,2],[-1,0,1]] 
 
 
class Solution: 
# 双指针法 
    def threeSum3(self, nums): 
        n = len(nums) 
        if n < 3: 
            return list() 
        res = [] 
        nums.sort() 
        for index, num in enumerate(nums): 
            left, right = index + 1, n - 1 
            while left < right: 
                if nums[left] + nums[right] == -num: 
                    temp = [num, nums[left], nums[right]] 
                    if temp not in res: 
                        res.append(temp)  
                    left += 1 
                    right -= 1 
                elif nums[left] + nums[right] + num < 0: 
                    left += 1 
                else: 
                    right -= 1 
        return res 
 
    def two_sum(self, start, nums, target): 
        dic = dict() 
        res = [] 
        for index, num in enumerate(nums): 
            if target - num not in dic: 
                dic[num] = index 
            else: 
                res.append([start + dic[target - num], start + index]) 
        return res 
 
    # 获取索引列表 
    def threeSum4(self, nums): 
        res = [] 
        for index, num in enumerate(nums): 
            idx = self.two_sum(index + 1, nums[index+1:], 0 - num) 
            for l in idx: 
                l.append(index) 
            res.extend(idx) 
        return res 
 
 
 
 
11. 搜索二维矩阵 ok 
编写一个高效的算法来搜索 m x n 矩阵 matrix 中的一个目标值 target 。该矩阵具有以
下特性： 
每行的元素从左到右升序排列。 
每列的元素从上到下升序排列。 
 
class Solution: 
    def searchMatrix(self, matrix: List[List[int]], target: int) -> bool: 
        m = len(matrix) 
        n = len(matrix[0]) 
        i, j = 0, n - 1 
        while i < m and j >= 0: 
            if target == matrix[i][j]: 
                return True 
            elif target > matrix[i][j]: 
                i += 1 
            else: 
                j -= 1 
        return False 
 
 
12. 从前序与中序遍历序列构造二叉树 ok 
给定两个整数数组 preorder 和 inorder ，其中 preorder 是二叉树的先序遍历， 
inorder 是同一棵树的中序遍历，请构造二叉树并返回其根节点。 
 
class Solution: 
    def buildTree(self, preorder: List[int], inorder: List[int]) -> Optiona
l[TreeNode]: 
        if not preorder: 
            return None 
        root_val = preorder[0] 
        root_index = inorder.index(root_val) 
        left_pre = preorder[1:1+root_index] 
        right_pre = preorder[1+root_index:] 
        left_inorder = inorder[0:root_index] 
        right_inorder = inorder[root_index+1:] 
        left = self.buildTree(left_pre, left_inorder) 
        right = self.buildTree(right_pre, right_inorder) 
        root = TreeNode(root_val, left, right) 
        return root 
 
 
 
 
13. 旋转图像 
给定一个 n × n 的二维矩阵 matrix 表示一个图像。请你将图像顺时针旋转 90 度。 
你必须在 原地 旋转图像，这意味着你需要直接修改输入的二维矩阵。请不要 使用另
一个矩阵来旋转图像。 
```python
class Solution: 
    def rotate(self, matrix) -> None: 
        n = len(matrix) 
        for i in range(n // 2): 
            for j in range((n + 1) // 2): 
                matrix[i][j], matrix[n - j - 1][i], matrix[n - i - 1][n - j - 1], matrix[j][n - i - 
1] = matrix[n - j - 1][i], matrix[n - i - 1][n - j - 1], matrix[j][n - i - 1], matrix[i][j] 
        print(matrix) 
```

 
14. 反转链表 ok 
给你单链表的头节点 head ，请你反转链表，并返回反转后的链表 
class Solution: 
    def reverseList(self, head: Optional[ListNode]) -> Optional[ListNode]: 
        pre = None 
        cur = head 
        while cur: 
            node = cur.next 
            cur.next = pre 
            pre = cur 
            cur = node 
        return pre 
 
 
15. K 个一组反转链表 
给你链表的头节点 head ，每 k 个节点一组进行翻转，请你返回修改后的链表。 
k 是一个正整数，它的值小于或等于链表的长度。如果节点总数不是 k 的整数倍，那
么请将最后剩余的节点保持原有顺序。 
你不能只是单纯的改变节点内部的值，而是需要实际进行节点交换。 
class Solution: 
    # 翻转一个子链表，并且返回新的头与尾 
    def reverse(self, head: ListNode, tail: ListNode): 
        prev = tail.next 
        p = head 
        while prev != tail: 
            nex = p.next 
            p.next = prev 
            prev = p 
            p = nex 
        return tail, head 
 
    def reverseKGroup(self, head: ListNode, k: int) -> ListNode: 
        hair = ListNode(0) 
        hair.next = head 
        pre = hair 
        while head: 
            tail = pre 
            # 查看剩余部分长度是否大于等于 k 
            for i in range(k): 
                tail = tail.next 
                if not tail: 
                    return hair.next 
            nex = tail.next 
            head, tail = self.reverse(head, tail) 
            # 把子链表重新接回原链表 
            pre.next = head 
            tail.next = nex 
            pre = tail 
            head = tail.next 
        return hair.next 
 
 
16. 相交链表 ok 
给你两个单链表的头节点 headA 和 headB ，请你找出并返回两个单链表相交的起始
节点。如果两个链表不存在相交节点，返回 null 。 
class Solution: 
    def getIntersectionNode(self, headA: ListNode, headB: ListNode) -> 
Optional[ListNode]: 
        curA, curB = headA, headB 
        while curA != curB: 
            curA = curA.next if curA else headB 
            curB = curB.next if curB else headA 
        return curA 
 
 
 
17. 反转链表 II 
给你单链表的头指针 head 和两个整数 left 和 right ，其中 left <= right 。请你反转从
位置 left 到位置 right 的链表节点，返回反转后的链表 。 
class Solution: 
    def reverseBetween(self, head: Optional[ListNode], left: int, right: int) -> 
Optional[ListNode]: 
        dummy = ListNode(-1) 
        cur = temp = head 
        i = 1 
        pre = dummy 
        while i < left: 
            pre.next = cur 
            cur = cur.next 
            temp = temp.next 
            pre = pre.next 
            i += 1 
        while left <= right: 
            temp = temp.next 
            left += 1 
        tail = temp 
        while cur != tail: 
            node = cur.next 
            cur.next = temp 
            temp = cur 
            cur = node 
        pre.next = temp 
        return dummy.next 
 
class Solution: 
    def reverseBetween(self, head: ListNode, left: int, right: int) -> ListNode: 
        # 设置 dummyNode 是这一类问题的一般做法 
        dummy_node = ListNode(-1) 
        dummy_node.next = head 
        pre = dummy_node 
        for _ in range(left - 1): 
            pre = pre.next 
 
        cur = pre.next 
        for _ in range(right - left): 
            next = cur.next 
            cur.next = next.next 
            next.next = pre.next 
            pre.next = next 
        return dummy_node.next 
 
 
 
18. 合并 K 个升序链表 
给你一个链表数组，每个链表都已经按升序排列。 
请你将所有链表合并到一个升序链表中，返回合并后的链表。 
 
class Solution: 
def mergeKLists(self, lists: List[ListNode]) -> ListNode: 
        if not lists:return  
        n = len(lists) 
        return self.merge(lists, 0, n-1) 
    def merge(self,lists, left, right): 
        if left == right: 
            return lists[left] 
        mid = left + (right - left) // 2 
        l1 = self.merge(lists, left, mid) 
        l2 = self.merge(lists, mid+1, right) 
        return self.mergeTwoLists(l1, l2) 
    def mergeTwoLists(self,l1, l2): 
        if not l1:return l2 
        if not l2:return l1 
        if l1.val < l2.val: 
            l1.next = self.mergeTwoLists(l1.next, l2) 
            return l1 
        else: 
            l2.next = self.mergeTwoLists(l1, l2.next) 
            return l2 
 
 
 
 
19. 堆排序 
堆排序（Heapsort）是指利用堆这种数据结构所设计的一种排序算法。堆积是一个近似
完全二叉树的结构，并同时满足堆积的性质：即子结点的键值或索引总是小于（或者
大于）它的父节点。堆排序可以说是一种利用堆的概念来排序的选择排序。分为两种
方法： 
大顶堆：每个节点的值都大于或等于其子节点的值，在堆排序算法中用于升序排列； 
小顶堆：每个节点的值都小于或等于其子节点的值，在堆排序算法中用于降序排列； 
堆排序的平均时间复杂度为 Ο(nlogn)。 
 
堆排序的过程分为两步： 
第一步是建堆，将一个无序的数组建立为一个堆 
第二步是排序，将堆顶元素取出，然后对剩下的元素进行堆化，反复迭代，直到所有
元素被取出为止 
 
1. 算法步骤 
创建一个堆 H[0……n-1]； 
把堆首（最大值）和堆尾互换； 
把堆的尺寸缩小 1，并调用 shift_down(0)，目的是把新的数组顶端数据调整到相应位
置； 
重复步骤 2，直到堆的尺寸为 1。 
 
 
def buildMaxHeap(arr): 
    import math 
    for i in range(math.floor(len(arr)/2),-1,-1): 
        heapify(arr,i) 
 
def heapify(arr, i): 
    left = 2*i+1 
    right = 2*i+2 
    largest = i 
    if left < arrLen and arr[left] > arr[largest]: 
        largest = left 
    if right < arrLen and arr[right] > arr[largest]: 
        largest = right 
 
    if largest != i: 
        swap(arr, i, largest) 
        heapify(arr, largest) 
 
def swap(arr, i, j): 
    arr[i], arr[j] = arr[j], arr[i] 
 
def heapSort(arr): 
    global arrLen 
    arrLen = len(arr) 
    buildMaxHeap(arr) 
    for i in range(len(arr)-1,0,-1): 
        swap(arr,0,i) 
        arrLen -=1 
        heapify(arr, 0) 
    return arr 
 
 
 
 
20. 双向链表 
class Node: 
    def __init__(self, key, value): 
        """ 
        初始化方法 
        :param key: 
        :param value: 
        """ 
        self.key = key 
        self.value = value 
        self.prev = None 
        self.next = None 
 
class DoubleLinkedList: 
  
    def __init__(self, capacity=0xffffffff): 
        """ 
        双向链表 
        :param capacity: 链表容量 初始化为 int 的最大值 2^32-1 
        :return: 
        """ 
        self.capacity = capacity 
        self.size = 0 
        self.head = None 
        self.tail = None 
  
    def __add_head(self, node): 
        """ 
        向链表头部添加节点 
            头部节点不存在 新添加节点为头部和尾部节点 
            头部节点已存在 新添加的节点为新的头部节点 
        :param node: 要添加的节点 
        :return: 已添加的节点 
        """ 
        # 头部节点为空 
        if not self.head: 
            self.head = node 
            self.tail = node 
            self.head.next = None 
            self.tail.prev = None 
        # 头部节点不为空 
        else: 
            node.next = self.head 
            self.head.prev = node 
            self.head = node 
            self.head.prev = None 
        self.size += 1 
  
        return node 
  
    def __add_tail(self, node): 
        """ 
        向链表尾部添加节点 
            尾部节点不存在 新添加的节点为头部和尾部节点 
            尾部节点已存在 新添加的节点为新的尾部节点 
        :param node: 添加的节点 
        :return: 已添加的节点 
        """ 
        # 尾部节点为空 
        if not self.tail: 
            self.tail = node 
            self.head = node 
            self.head.next = None 
            self.tail.prev = None 
        # 尾部节点不为空 
        else: 
            node.prev = self.tail 
            self.tail.next = node 
            self.tail = node 
            self.tail.next = None 
        self.size += 1 
  
        return node 
  
    def __remove_head(self): 
        """ 
        删除头部节点 
            头部节点不存在 返回 None 
            头部节点已存在 判断链表节点数量 删除头部节点 
        :return: 头部节点 
        """ 
        # 头部节点不存在 
        if not self.head: 
            return None 
  
        # 链表至少存在两个节点 
        head = self.head 
        if head.next: 
            head.next.prev = None 
            self.head = head.next 
        # 只存在头部节点 
        else: 
            self.head = self.tail = None 
        self.size -= 1 
  
        return head 
  
    def __remove_tail(self): 
        """ 
        删除尾部节点 
            尾部节点不存在 返回 None 
            尾部节点已存在 判断链表节点数量 删除尾部节点 
        :return: 尾部节点 
        """ 
        # 尾部节点不存在 
        if not self.tail: 
            return None 
  
        # 链表至少存在两个节点 
        tail = self.tail 
        if tail.prev: 
            tail.prev.next = None 
            self.tail = tail.prev 
        # 只存在尾部节点 
        else: 
            self.head = self.tail = None 
        self.size -= 1 
  
        return tail 
  
    def __remove(self, node): 
        """ 
        删除任意节点 
            被删除的节点不存在 默认删除尾部节点 
            删除头部节点 
            删除尾部节点 
            删除其他节点 
        :param node: 被删除的节点 
        :return: 被删除的节点 
        """ 
        # 被删除的节点不存在 
        if not node: 
            node = self.tail 
  
        # 删除的是头部节点 
        if node == self.head: 
            self.__remove_head() 
        # 删除的是尾部节点 
        elif node == self.tail: 
            self.__remove_tail() 
        # 删除的既不是头部也不是尾部节点 
        else: 
            node.next.prev = node.prev 
            node.prev.next = node.next 
            self.size -= 1 
  
        return node 
  
    def pop(self): 
        """ 
        弹出头部节点 
        :return: 头部节点 
        """ 
        return self.__remove_head() 
  
    def append(self, node): 
        """ 
        添加尾部节点 
        :param node: 待追加的节点 
        :return: 尾部节点 
        """ 
        return self.__add_tail(node) 
  
    def append_front(self, node): 
        """ 
        添加头部节点 
        :param node: 待添加的节点 
        :return: 已添加的节点 
        """ 
        return self.__add_head(node) 
  
    def remove(self, node=None): 
        """ 
        删除任意节点 
        :param node: 待删除的节点 
        :return: 已删除的节点 
        """ 
        return self.__remove(node) 
  
 
 
21. LRU 缓存机制 
请你设计并实现一个满足 LRU (最近最少使用) 缓存约束的数据结构。 
实现 LRUCache 类： 
LRUCache(int capacity) 以正整数作为容量 capacity 初始化 LRU 缓存 
int get(int key) 如果关键字 key 存在于缓存中，则返回关键字的值，否则返回 -1 。 
void put(int key, int value) 如果关键字 key 已经存在，则变更其数据值 value ；如果不
存在，则向缓存中插入该组 key-value 。如果插入操作导致关键字数量超
过 capacity ，则应该逐出最久未使用的关键字。 
函数 get 和 put 必须以 O(1) 的平均时间复杂度运行。 
 
class DLinkedNode: 
    def __init__(self, key=0, value=0): 
        self.key = key 
        self.value = value 
        self.prev = None 
        self.next = None 
 
 
class LRUCache: 
 
    def __init__(self, capacity: int): 
        self.cache = dict() 
        # 使用伪头部和伪尾部节点     
        self.head = DLinkedNode() 
        self.tail = DLinkedNode() 
        self.head.next = self.tail 
        self.tail.prev = self.head 
        self.capacity = capacity 
        self.size = 0 
 
    def get(self, key: int) -> int: 
        if key not in self.cache: 
            return -1 
        # 如果 key 存在，先通过哈希表定位，再移到头部 
        node = self.cache[key] 
self.moveToHead(node) 
        return node.value 
 
    def put(self, key: int, value: int) -> None: 
        if key not in self.cache: 
            # 如果 key 不存在，创建一个新的节点 
            node = DLinkedNode(key, value) 
            # 添加进哈希表 
            self.cache[key] = node 
            # 添加至双向链表的头部 
            self.addToHead(node) 
            self.size += 1 
            if self.size > self.capacity: 
                # 如果超出容量，删除双向链表的尾部节点 
                removed = self.removeTail() 
                # 删除哈希表中对应的项 
                self.cache.pop(removed.key) 
                self.size -= 1 
        else: 
            # 如果 key 存在，先通过哈希表定位，再修改 value，并移到头部 
            node = self.cache[key] 
            node.value = value 
            self.moveToHead(node) 
 
    def addToHead(self, node): 
        node.prev = self.head 
        node.next = self.head.next 
        self.head.next.prev = node 
        self.head.next = node 
     
    def removeNode(self, node): 
        node.prev.next = node.next 
        node.next.prev = node.prev 
 
    def moveToHead(self, node): 
        self.removeNode(node) 
        self.addToHead(node) 
 
    def removeTail(self): 
        node = self.tail.prev 
        self.removeNode(node) 
        return node 
22. 缺失的第一个正数 
给你一个未排序的整数数组 nums ，请你找出其中没有出现的最小的正整数。 
请你实现时间复杂度为 O(n) 并且只使用常数级别额外空间的解决方案。 
示例 1： 
 
输入：nums = [1,2,0] 
输出：3 
示例 2： 
 
输入：nums = [3,4,-1,1] 
输出：2 
示例 3： 
 
输入：nums = [7,8,9,11,12] 
输出：1 
 
class Solution: 
    def firstMissingPositive(self, nums: List[int]) -> int: 
        n = len(nums) 
        for i in range(n): 
            while 1 <= nums[i] <= n and nums[nums[i] - 1] != nums[i]: 
                nums[nums[i] - 1], nums[i] = nums[i], nums[nums[i] - 1] 
        for i in range(n): 
            if nums[i] != i + 1: 
                return i + 1 
        return n + 1 
 
 
23. 只出现一次的数字 ok 
给定一个非空整数数组，除了某个元素只出现一次以外，其余每个元素均出现两次。
找出那个只出现了一次的元素。 
说明： 
你的算法应该具有线性时间复杂度。 你可以不使用额外空间来实现吗？ 
 
class Solution: 
    def singleNumber(self, nums: List[int]) -> int: 
        res = 0 
        for num in nums: 
            res ^= num 
        return res 
 
 
24. 全排列 
class Solution: 
    def permute(self, nums: List[int]) -> List[List[int]]: 
        ''' 
        如果 nums = [1, 2, 3] 
        其全排列有: [1, 2, 3], [1, 3, 2], [2, 1, 3], [2, 3, 1], [3, 1, 2], [3, 2, 1] 
       该题适合用 DFS 之回溯法求解从树的根节点[]开始按照深度逐个遍历 
        回溯法算需要时刻关注两大变量： 
            (1) 递归的终止条件(回溯的本质是递归) 
            (1) 回溯过程中某时间点的当前状态 
         
        下面首先对必要变量进行初始化 
        depth: 当前所在位置所处树的深度 
        path: 记录当前遍历过的数字序列, i.e. [1], [1, 2], [1, 2, 3] 
        res: 最后输出的包含所有的全序列的数组 
        ls_used: 由于全排列同一个数字不可出现 2 次, 所以需创建一个额外数组跟踪
每一个数字的使用情况, 其初始为全 False  
        ''' 
        depth, path, res = 0, [], [] 
        ls_used = [False for _ in nums] 
        # 初始化所有必要变量后开始从树的根节点([])进行深度遍历 
        self.dfs(nums, depth, ls_used, path, res) 
        return res 
 
    def dfs(self, nums, depth, ls_used, path, res): 
        # 递归终止条件: 达到树的尾部, 则将 path 中存储的数字加到 res 中 
        if depth == len(nums): 
            # 这里用 path[:]才能取得 path 里面存储的值，否则 path 是空值 
            res.append(path[:]) 
            return 
         
        # 在当前节点挨个尝试所有没有被探索过的数字 
        for (i, used) in enumerate(ls_used): 
            if used: # 跳过已经在 path 中出现的数字 
                continue 
            path.append(nums[i])  # 如果该数字没有被使用, 则添加到 path 中, 并将
数字状态改为 True 表示其已经被遍历 
            ls_used[i] = True 
            self.dfs(nums, depth + 1, ls_used, path, res) # 递归: 往下一层进一步探索 
            path.pop()  # 回溯到原来位置, 把 path 中最后新加入的弹出, 之前使用过
数字现在变成未使用 
            ls_used[i] = False 
 
 
25. 无重复字符的最长子串 100 
给定一个字符串 s ，请你找出其中不含有重复字符的最长子串的长度。 
 
class Solution: 
    def lengthOfLongestSubstring(self, s: str) -> int: 
        # 哈希集合，记录每个字符是否出现过 
        occ = set() 
        n = len(s) 
        # 右指针，初始值为-1，相当于我们在字符串的左边界的左侧，还没有开始
移动 
        rk, ans = -1, 0 
        for i in range(n): 
if i != 0: 
                # 左指针向右移动一格，移除一个字符 
                occ.remove(s[i - 1]) 
            while rk + 1 < n and s[rk + 1] not in occ: 
                occ.add(s[rk + 1])   # 不断地移动右指针 
                rk += 1 
            # 第 i 到 rk 个字符是一个极长的无重复字符子串 
            ans = max(ans, rk - i + 1) 
        return ans 
 
26. 数组中的第 K 个最大元素 99 
给定整数数组 nums 和整数 k，请返回数组中第 k 个最大的元素。 
请注意，你需要找的是数组排序后的第 k 个最大的元素，而不是第 k 个不同的元
素。 
你必须设计并实现时间复杂度为 O(n)的算法解决此问题。 
 
class Solution: 
    def find_kth_largest(self, nums, k): 
        n = len(nums) 
        l = 0 
        r = n - 1 
        while True: 
            idx = self.partition(nums, l, r) 
            if idx == k - 1: 
                return nums[idx] 
            elif idx < k - 1: 
                l = idx + 1 
            else: 
                r = idx - 1 
 
    def partition(self, nums, l, r): 
        pivot = nums[l] 
        begin = l 
        while l < r: 
            while l < r and nums[r] <= pivot: 
                r -= 1 
            while l < r and nums[l] >= pivot: 
                l += 1 
            if l < r: 
                nums[l], nums[r] = nums[r], nums[l] 
        nums[begin], nums[l] = nums[l], nums[begin] 
        return l 
 
 
27. 二叉树的锯齿形层序遍历 98 ok 
给你二叉树的根节点 root，返回其节点值的锯齿形层序遍历。（即先从左往右，再从
右往左进行下一层遍历，以此类推，层与层之间交替进行）。 
 
from collections import deque 
class Solution: 
    def zigzagLevelOrder(self, root: Optional[TreeNode]) -> List[List[int]]: 
        if not root: return [] 
        dq, res, flag = deque(), [], 1 
        dq.append(root) 
        while len(dq) != 0: 
            temp= [] 
            for i in range(len(dq)): 
                node = dq.popleft() 
                temp.append(node.val) 
                if node.left: dq.append(node.left) 
                if node.right: dq.append(node.right) 
            if flag == 1: 
                res.append(temp[:]) 
                flag = 0 
            else: 
                res.append(temp[::-1]) 
                flag = 1 
        return res 
 
 
 
28. 买卖股票的最佳时机 ok 
 
class Solution: 
    ''' 
    给定一个数组 prices ，它的第 i 个元素 prices[i] 表示一支给定股票第 i 天的价
格。 
    你只能选择 某一天 买入这只股票，并选择在 未来的某一个不同的日子 卖出该
股票。设计一个算法来计算你所能获取的最大利润。 
    返回你可以从这笔交易中获取的最大利润。如果你不能获取任何利润，返回 0 。 
    ''' 
    # 暴力法 
    def max_profit1(self, prices) -> int: 
        max_profit = 0 
        for i in range(0, len(prices)): 
            for j in range(i+1, len(prices)): 
                if prices[j] - prices[i] > max_profit: 
                    max_profit = prices[j] - prices[i] 
        return max_profit 
 
    # 一次遍历 
    def max_profit2(self, prices): 
        inf = int(1e9) 
        min_price = inf 
        max_price = 0 
        for price in prices: 
            max_price = max(price - min_price, max_price) 
            min_price = min(min_price, price) 
        return max_price 
 
    # 动态规划 
    def max_profit3(self, prices): 
        n = len(prices) 
        if n == 0: 
            return 0 
        dp = [0] * n 
        min_price = prices[0] 
        for i in range(1, n): 
            min_price = min(min_price, prices[i]) 
            dp[i] = max(dp[i - 1], prices[i] - min_price) 
            print(dp[i]) 
        return dp[-1] 
 
29. 二叉树的最近公共祖先 
# 给定一个二叉搜索树, 找到该树中两个指定节点的最近公共祖先。 
# 百度百科中最近公共祖先的定义为：“对于有根树 T 的两个结点 p、q，最近公共祖
先表示为一个结点 x，满足 x 是 p、q 的祖先且 x 的深度尽可能大（一个节点也可
以是它自己的祖先）。” 
# 
# 例如，给定如下二叉搜索树: root =[6,2,8,0,4,7,9,null,null,3,5] 
 
# 示例 1: 
# 
# 输入: root = [6,2,8,0,4,7,9,null,null,3,5], p = 2, q = 8 
# 输出: 6 
# 解释: 节点 2 和节点 8 的最近公共祖先是 6。 
# 示例 2: 
# 
# 输入: root = [6,2,8,0,4,7,9,null,null,3,5], p = 2, q = 4 
# 输出: 2 
# 解释: 节点 2 和节点 4 的最近公共祖先是 2, 因为根据定义最近公共祖先节点可以
为节点本身。 
 
# Definition for a binary tree node. 
class TreeNode: 
    def __init__(self, x): 
        self.val = x 
        self.left = None 
        self.right = None 
 
 
class Solution: 
    def lowestCommonAncestor(self, root, p, q): 
        while root: 
            if root.val < p.val and root.val < q.val: 
                root = root.right 
            elif root.val > p.val and root.val > q.val: 
                root = root.left 
            else: 
                break 
        return root 
 
    def lowest_common_ancestor(self, root, p, q): 
        if root.val < p.val and root.val < q.val: 
            return self.lowest_common_ancestor(root.right, p, q) 
        elif root.val > p.val and root.val > q.val: 
            return self.lowest_common_ancestor(root.left, p, q) 
        else: 
            return root 
 
30. 字符串相加 
给定两个字符串形式的非负整数 num1 和 num2 ，计算它们的和并同样以字符串形式
返回。 
你不能使用任何內建的用于处理大整数的库（比如 BigInteger）， 也不能直接将输入
的字符串转换为整数形式。 
class Solution: 
    def addStrings(self, num1: str, num2: str) -> str: 
        res = "" 
        i, j, carry = len(num1) - 1, len(num2) - 1, 0 
        while i >= 0 or j >= 0: 
            n1 = int(num1[i]) if i >= 0 else 0 
            n2 = int(num2[j]) if j >= 0 else 0 
            tmp = n1 + n2 + carry 
            carry = tmp // 10 
            res = str(tmp % 10) + res 
            i, j = i - 1, j - 1 
        return "1" + res if carry else res 
 
 
31. 接雨水 
给定 n 个非负整数表示每个宽度为 1 的柱子的高度图，计算按此排列的柱子，下雨
之后能接多少雨水。 
输入：height = [0,1,0,2,1,0,1,3,2,1,2,1] 
输出：6 
解释：上面是由数组 [0,1,0,2,1,0,1,3,2,1,2,1] 表示的高度图，在这种情况下，可以接 6 
个单位的雨水（蓝色部分表示雨水）。  
 
##### Solution 6 --- Monotonic stack 
class Solution: 
    def trap(self, height: List[int]) -> int: 
        n = len(height) 
        if n < 3: return 0 
        water = 0 
        stack = [] 
        current_idx = 0 
         
        while current_idx < n: 
            # If stack is not empty and current height bigger than stack top's height 
            while stack and height[current_idx]>height[stack[-1]]: 
                h = height[stack.pop()] 
                if not stack: 
                    break 
                # Distance between wall 
                distance = current_idx - stack[-1] -1 
                min_height = min(height[stack[-1]], height[current_idx]) 
                water += distance*(min_height-h) 
             
            stack.append(current_idx) 
            current_idx += 1 
         
        return water 
 
# ##### Solution 5 --- DP and Two pointers O(n), O(1) 
# class Solution: 
#     def trap(self, height: List[int]) -> int: 
#         n = len(height) 
#         if n < 3: return 0 
#         max_left = height[0] 
#         max_right = height[-1] 
#         water = 0 
         
#         left, right = 1, n-2 
#         for _ in range(1, n-1): 
#             # Decide which side is shorter, calculate water and use 
#             # max value of that side to update water. 
#             if height[left-1] < height[right+1]: 
#                 max_left = max(height[left-1], max_left) 
#                 if max_left > height[left]: 
#                     water += max_left - height[left] 
#                 left += 1 
#             else: 
#                 max_right = max(height[right+1], max_right) 
#                 if max_right > height[right]: 
#                     water += max_right - height[right] 
#                 right -= 1 
         
#         return water 
 
# ##### Solution 4 --- DP O(n), O(n) 
# class Solution: 
#     def trap(self, height: List[int]) -> int: 
#         n = len(height) 
#         if n < 3: return 0 
#         max_left = height[0] 
#         max_right = [height[-1]]*n 
#         water = 0 
         
#         for i in range(n-2,-1,-1): 
#             max_right[i] = max(max_right[i+1], height[i+1]) 
             
#         for i in range(1, n-1): 
#             max_left = max(max_left, height[i-1]) 
#             h = min(max_left, max_right[i]) 
#             if h > height[i]: 
#                 water += h-height[i] 
         
#         return water 
 
# ##### Solution 3 --- DP O(n), O(n) 
# class Solution: 
#     def trap(self, height: List[int]) -> int: 
#         n = len(height) 
#         if n < 3: return 0 
#         max_left = [height[0]]*n 
#         max_right = [height[-1]]*n 
#         water = 0 
 
#         for i in range(1, n): 
#             max_left[i] = max(max_left[i-1], height[i-1]) 
#         for i in range(n-2,-1,-1): 
#             max_right[i] = max(max_right[i+1], height[i+1]) 
             
#         for i in range(1, n-1): 
#             h = min(max_left[i], max_right[i]) 
#             if h > height[i]: 
#                 water += h-height[i] 
         
#         return water 
 
# ##### Solution 2 --- naive O(n^2), O(1) 
# class Solution: 
#     def trap(self, height: List[int]) -> int: 
#         # Check for i-th column's left highest wall and right one, 
#         # pick the short one and compare it with current height. 
#         # If current is lower, add height difference to water, else, 
#         # else there won't be any water. 
#         n = len(height) 
#         if n < 3: return 0 
 
#         water = 0 
#         h_left, h_right = height[0], height[-1] 
#         # Skip first and last column, cuz there won't be water. 
#         for i in range(1, n-1): 
#             h_right = max(height[i+1:]) 
#             h = min(h_right, h_left) 
#             if h > height[i]: 
#                 water += h - height[i] 
#             h_left = max(height[i], h_left) 
         
#         return water 
 
##### Solution 1  O(n), O(1) 
# class Solution: 
#     def trap(self, height: List[int]) -> int: 
#         ans = 0 
#         h1 = 0 
#         h2 = 0 
#         for i in range(len(height)): 
#             h1 = max(h1,height[i]) 
#             h2 = max(h2,height[-i-1]) 
#             ans += h1 + h2 -height[i] 
#         return  ans - len(height)*h1 
 
32. 二叉树的右视图 ok 
给定一个二叉树的 根节点 root，想象自己站在它的右侧，按照从顶部到底部的顺序，
返回从右侧所能看到的节点值。 
class Solution: 
    def rightSideView(self, root: Optional[TreeNode]) -> List[int]: 
        if not root: 
            return list() 
        from collections import deque 
        queue = deque([root]) 
        ans = list() 
        while queue: 
            ans.append(queue[-1].val) 
            for _ in range(len(queue)): 
                node = queue.popleft() 
                if node.left: 
                    queue.append(node.left) 
                if node.right: 
                    queue.append(node.right) 
        return ans 
 
33. 合并两个有序数组 
给你两个按 非递减顺序 排列的整数数组 nums1 和 nums2，另有两个整数 m 和 
n ，分别表示 nums1 和 nums2 中的元素数目。 
 
请你合并 nums2 到 nums1 中，使合并后的数组同样按非递减顺序排列。 
 
注意：最终，合并后数组不应由函数返回，而是存储在数组 nums1 中。为了应对这种
情况，nums1 的初始长度为 m + n，其中前 m 个元素表示应合并的元素，后 n 个元
素为 0 ，应忽略。nums2 的长度为 n 。 
输入：nums1 = [1,2,3,0,0,0], m = 3, nums2 = [2,5,6], n = 3 
输出：[1,2,2,3,5,6] 
解释：需要合并 [1,2,3] 和 [2,5,6] 。 
合并结果是 [1,2,2,3,5,6] ，其中斜体加粗标注的为 nums1 中的元素。 
class Solution: 
    def merge(self, nums1, m, nums2, n): 
        """ 
        Do not return anything, modify nums1 in-place instead. 
        """ 
        p1, p2 = m - 1, n - 1 
        tail = m + n - 1 
        while p1 >= 0 or p2 >= 0: 
            if p1 == -1: 
                nums1[tail] = nums2[p2] 
                p2 -= 1 
            elif p2 == -1: 
                nums1[tail] = nums1[p1] 
                p1 -= 1 
            elif nums1[p1] > nums2[p2]: 
                nums1[tail] = nums1[p1] 
                p1 -= 1 
            else: 
                nums1[tail] = nums2[p2] 
                p2 -= 1 
            tail -= 1 
 
 
34. 搜索旋转排序数组 
整数数组 nums 按升序排列，数组中的值 互不相同 。 
 
在传递给函数之前，nums 在预先未知的某个下标 k（0 <= k < nums.length）上进行了 
旋转，使数组变为 [nums[k], nums[k+1], ..., nums[n-1], nums[0], nums[1], ..., nums[k-1]]
（下标 从 0 开始 计数）。例如， [0,1,2,4,5,6,7] 在下标 3 处经旋转后可能变
为 [4,5,6,7,0,1,2] 。 
给你 旋转后 的数组 nums 和一个整数 target ，如果 nums 中存在这个目标值 
target ，则返回它的下标，否则返回 -1 。 
你必须设计一个时间复杂度为 O(log n) 的算法解决此问题。 
输入：nums = [4,5,6,7,0,1,2], target = 0 
输出：4 
 
class Solution: 
    def search(self, nums: List[int], target: int) -> int: 
        n = len(nums) 
        left, right = 0, n - 1 
        while left <= right: 
            mid = (left + right) // 2 
            if nums[mid] == target: 
                return mid 
            if nums[0] <= nums[mid]: 
                if nums[0] <= target < nums[mid]: 
                    right = mid - 1 
                else: 
                    left = mid + 1 
            else: 
                if nums[mid] < target <= nums[n-1]: 
                    left = mid + 1 
                else: 
                    right = mid - 1 
        return -1 
 
 
 
35. 螺旋矩阵 
给你一个 m 行 n 列的矩阵 matrix ，请按照 顺时针螺旋顺序 ，返回矩阵中的所有
元素。 
 
 
 
class Solution: 
    def spiralOrder(self, matrix: List[List[int]]) -> List[int]: 
        m = len(matrix) 
        n = len(matrix[0]) 
        res = list() 
        i, j = 0, n - 1 
        x, y = m - 1, 0 
        while i <= x and j >= y: 
            for o in range(y, j + 1): 
                res.append(matrix[i][o]) 
            for p in range(i + 1, x + 1): 
                res.append(matrix[p][j]) 
            if y < j and i < x: 
                for q in range(j - 1, y - 1, -1): 
                    res.append(matrix[x][q]) 
                for r in range(x - 1, i, -1): 
                    res.append(matrix[r][y]) 
            i += 1 
            j -= 1 
            x -= 1 
            y += 1 
        return res 
 
36. 二叉树的层序遍历 ok 
给你二叉树的根节点 root ，返回其节点值的 层序遍历 。 （即逐层地，从左到右访
问所有节点）。 
 
class Solution: 
    def levelOrder(self, root: Optional[TreeNode]) -> List[List[int]]: 
        if not root: 
            return list() 
        from collections import deque 
        queue = deque([root]) 
        ans = list() 
        while queue: 
            temp = list() 
            for _ in range(len(queue)): 
                node = queue.popleft() 
                temp.append(node.val) 
                if node.left: 
                    queue.append(node.left) 
                if node.right: 
                    queue.append(node.right) 
            ans.append(temp) 
        return ans 
 
37. 有效的括号 ok 
给定一个只包括 '('，')'，'{'，'}'，'['，']' 的字符串 s ，判断字符串是否有效。 
有效字符串需满足： 
左括号必须用相同类型的右括号闭合。 
左括号必须以正确的顺序闭合。 
每个右括号都有一个对应的相同类型的左括号。 
class Solution: 
    def isValid(self, s: str) -> bool: 
        stack = list() 
        s_map = {')': '(', '}': '{', ']': '['} 
        for ch in s: 
            if ch in s_map.values(): 
                stack.append(ch) 
            else: 
                if stack and stack[-1] == s_map[ch]: 
                    stack.pop() 
                else: 
                    return False 
        return True if not stack else False 
 
 
38. 数组中的逆序对 
在数组中的两个数字，如果前面一个数字大于后面的数字，则这两个数字组成一个逆
序对。输入一个数组，求出这个数组中的逆序对的总数。 
示例 1: 
输入: [7,5,6,4] 
输出: 5 
 
 
class Solution: 
    def reversePairs(self, nums: List[int]) -> int: 
        def merge_sort(l, r): 
            # 终止条件 
            if l >= r: return 0 
            # 递归划分 
            m = (l + r) // 2 
            res = merge_sort(l, m) + merge_sort(m + 1, r) 
            # 合并阶段 
            i, j = l, m + 1 
            tmp[l:r + 1] = nums[l:r + 1] 
            for k in range(l, r + 1): 
                  # 代表左子数组已合并完 
                if i == m + 1: 
                    nums[k] = tmp[j] 
                    j += 1 
                elif j == r + 1 or tmp[i] <= tmp[j]: 
                    nums[k] = tmp[i] 
                    i += 1 
                else: 
                    nums[k] = tmp[j] 
                    j += 1 
                    res += m - i + 1 # 统计逆序对 
            return res 
         
        tmp = [0] * len(nums) 
        return merge_sort(0, len(nums) - 1) 
 
39. 岛屿数量 
给你一个由 '1'（陆地）和 '0'（水）组成的的二维网格，请你计算网格中岛屿的数量。 
岛屿总是被水包围，并且每座岛屿只能由水平方向和/或竖直方向上相邻的陆地连接形
成。 
此外，你可以假设该网格的四条边均被水包围。 
 
class Solution: 
    def numIslands(self, grid: List[List[str]]) -> int: 
        m, n = len(grid), len(grid[0]) 
        res = 0 
 
        def dfs(i, j, grid): 
            grid[i][j] = '0' 
            for x, y in [(i+1, j), (i-1, j), (i, j-1), (i, j+1)]: 
                if 0 <= x < m and 0 <= y < n and grid[x][y] == '1': 
                    dfs(x, y, grid) 
        for i in range(m): 
            for j in range(n): 
                if grid[i][j] == '1': 
                    res += 1 
                    dfs(i, j, grid) 
        return res 
 
40. 合并区间 
以数组 intervals 表示若干个区间的集合，其中单个区间为 intervals[i] = [starti, 
endi] 。请你合并所有重叠的区间，并返回 一个不重叠的区间数组，该数组需恰好覆
盖输入中的所有区间。 
示例 1： 
输入：intervals = [[1,3],[2,6],[8,10],[15,18]] 
输出：[[1,6],[8,10],[15,18]] 
解释：区间 [1,3] 和 [2,6] 重叠, 将它们合并为 [1,6]. 
 
 
class Solution: 
    def merge(self, intervals): 
        n = len(intervals) 
        if n == 1: 
            return intervals 
        intervals.sort(key=lambda x:x[0]) 
        i, res = 0, [] 
        while i < n: 
            if i == 0 or res[-1][1] < intervals[i][0]: 
                res.append(intervals[i]) 
            else: 
                res[-1][1] = max(res[-1][1], intervals[i][1]) 
            i += 1 
        return res 
 
41. 递增的三元子序列 
给你一个整数数组 nums ，判断这个数组中是否存在长度为 3 的递增子序列。 
 
如果存在这样的三元组下标 (i, j, k) 且满足 i < j < k ，使得 nums[i] < nums[j] < 
nums[k] ，返回 true ；否则，返回 false 。 
 
 
 
class Solution: 
    def increasingTriplet2(self, nums): 
        small, mid = float('inf'), float('inf') 
        for x in nums: 
            if x <= small: 
                small = x 
            elif x <= mid: 
                mid = x 
            elif x > mid: 
                return True 
        return False 
 
42. 最长递增子序列 
给你一个整数数组 nums ，找到其中最长严格递增子序列的长度。 
子序列是由数组派生而来的序列，删除（或不删除）数组中的元素而不改变其余元素 
的顺序。例如，[3,6,2,7]是数组 [0,3,1,6,2,2,7]的子序列。 
 
# Dynamic programming. 
class Solution: 
    def lengthOfLIS(self, nums: List[int]) -> int: 
        if not nums: return 0 
        dp = [1] * len(nums) 
        for i in range(len(nums)): 
            for j in range(i): 
                if nums[j] < nums[i]: # 如果要求非严格递增，将此行 '<' 改为 
'<=' 即可。 
                    dp[i] = max(dp[i], dp[j] + 1) 
        return max(dp) 
 
 
43. x 的平方根 
给你一个非负整数 x ，计算并返回 x 的 算术平方根 。 
由于返回类型是整数，结果只保留 整数部分 ，小数部分将被 舍去 。 
注意：不允许使用任何内置指数函数和算符，例如 pow(x, 0.5) 或者 x ** 0.5 。 
class Solution: 
    def mySqrt(self, x: int) -> int: 
        l, r, ans = 0, x, -1 
        while l <= r: 
            mid = (l + r) // 2 
            if mid * mid <= x: 
                ans = mid 
                l = mid + 1 
            else: 
                r = mid - 1 
        return ans 
 
44. 二叉树中的最大路径和 
路径 被定义为一条从树中任意节点出发，沿父节点-子节点连接，达到任意节点的序
列。同一个节点在一条路径序列中至多出现一次。该路径至少包含一个节点，且不一
定经过根节点。 
 
路径和是路径中各节点值的总和。 
给你一个二叉树的根节点 root ，返回其最大路径和。 
 
 
class Solution: 
    def __init__(self): 
        self.maxSum = float("-inf") 
 
    def maxPathSum(self, root: TreeNode) -> int: 
        def maxGain(node): 
            if not node: 
                return 0 
 
            # 递归计算左右子节点的最大贡献值 
            # 只有在最大贡献值大于 0 时，才会选取对应子节点 
            leftGain = max(maxGain(node.left), 0) 
            rightGain = max(maxGain(node.right), 0) 
             
            # 节点的最大路径和取决于该节点的值与该节点的左右子节点的最大贡献值 
            priceNewpath = node.val + leftGain + rightGain 
             
            # 更新答案 
            self.maxSum = max(self.maxSum, priceNewpath) 
         
            # 返回节点的最大贡献值 
            return node.val + max(leftGain, rightGain) 
    
        maxGain(root) 
        return self.maxSum 
 
45. 最长回文子串 
给你一个字符串 s，找到 s 中最长的回文子串。 
dp[i][j]) 表示字符串 s 的第 i 到 j 个字母组成的串（表示成 s[i:j]）是否为回文串 
class Solution: 
    def longestPalindrome(self, s: str) -> str: 
        if not s: 
            return "" 
        begin, n, max_len = 0, len(s), 1 
        if n < 2: 
            return s 
        dp = [[False]*n for _ in range(n)] 
        for index in range(n): 
            dp[index][index] = True 
        for j in range(1, n): 
            for i in range(0, j): 
                if s[i] != s[j]: 
                    dp[i][j] = False  
                else: 
                    if j - i < 3: 
                        dp[i][j] = True 
                    else: 
                        dp[i][j] = dp[i+1][j-1] 
                if max_len < j - i + 1 and dp[i][j]: 
                    begin = i 
                    max_len = j - i + 1 
        return s[begin:begin+max_len] 
 
46. 二叉树中序遍历 
class Solution: 
    def inorderTraversal(self, root): 
        if not root: 
            return [] 
        res = [] 
        def inner(node): 
            if node.left: 
                inner(node.left) 
            res.append(node.val) 
            if node.right: 
                inner(node.right) 
        inner(root) 
        return res 
 
    def inorder_traversal(self, root): 
        res = [] 
        stack = [] 
        while stack or root: 
            if root: 
                stack.append(root) 
                root = root.left 
            else: 
                tmp = stack.pop() 
                res.append(tmp.val) 
                root = tmp.right 
        return res 
 
47. 最小栈 
设计一个支持 push ，pop ，top 操作，并能在常数时间内检索到最小元素的栈。 
实现 MinStack 类: 
 
MinStack() 初始化堆栈对象。 
void push(int val) 将元素 val 推入堆栈。 
void pop() 删除堆栈顶部的元素。 
int top() 获取堆栈顶部的元素。 
int getMin() 获取堆栈中的最小元素。 
class MinStack: 
 
    def __init__(self): 
        """ 
        initialize your data structure here. 
        """ 
        self.stack = list() 
        self.min_stack = list() 
 
    def push(self, x: int) -> None: 
        self.stack.append(x) 
        if not self.min_stack or x <= self.min_stack[-1]: 
            self.min_stack.append(x) 
 
    def pop(self) -> None: 
        if self.stack.pop() == self.min_stack[-1]: 
            self.min_stack.pop() 
 
    def top(self) -> int: 
        return self.stack[-1] 
 
    def min(self) -> int: 
        return self.min_stack[-1] 
 
 
48. 重排链表 
给定一个单链表 L 的头节点 head ，单链表 L 表示为： 
L0 → L1 → … → Ln - 1 → Ln 
请将其重新排列后变为： 
L0 → Ln → L1 → Ln - 1 → L2 → Ln - 2 → … 
不能只是单纯的改变节点内部的值，而是需要实际的进行节点交换。 
 
class Solution: 
    def reorderList(self, head: ListNode) -> None: 
        if not head: 
            return 
         
        mid = self.middleNode(head) 
        l1 = head 
        l2 = mid.next 
        mid.next = None 
        l2 = self.reverseList(l2) 
        self.mergeList(l1, l2) 
     
    def middleNode(self, head: ListNode) -> ListNode: 
        slow = fast = head 
        while fast.next and fast.next.next: 
            slow = slow.next 
            fast = fast.next.next 
        return slow 
     
    def reverseList(self, head: ListNode) -> ListNode: 
        prev = None 
        curr = head 
        while curr: 
            nextTemp = curr.next 
            curr.next = prev 
            prev = curr 
            curr = nextTemp 
        return prev 
 
    def mergeList(self, l1: ListNode, l2: ListNode): 
        while l1 and l2: 
            l1_tmp = l1.next 
            l2_tmp = l2.next 
 
            l1.next = l2 
            l1 = l1_tmp 
 
            l2.next = l1 
            l2 = l2_tmp 
 
 
49. 对称的二叉树 
请实现一个函数，用来判断一棵二叉树是不是对称的。如果一棵二叉树和它的镜像一
样，那么它是对称的。 
 
 
class Solution: 
    def isSymmetric(self, root: TreeNode) -> bool: 
        if not root: 
            return True 
        queue = [root] 
        while queue: 
            tmp = [] 
            node_list = [] 
            for node in queue: 
                if node.left: 
                    tmp.append(node.left.val) 
                    node_list.append(node.left) 
                else: 
                    tmp.append('null') 
                if node.right: 
                    tmp.append(node.right.val) 
                    node_list.append(node.right) 
                else: 
                    tmp.append('null') 
            if tmp == tmp[::-1]: 
                queue = node_list 
            else: 
                return False 
        return True 
 
    def is_symmetric(self, root: TreeNode) -> bool: 
        def is_sysmmetric_tree(left, right): 
            if left is None and right is None: 
                return True 
            if left is None or right is None: 
                return False 
            if left.val != right.val: 
                return False 
            return is_sysmmetric_tree(left.left, right.right) & \ 
                   is_sysmmetric_tree(right.left, left.right) 
        if not root: 
            return True 
        return is_sysmmetric_tree(root.left, root.right) 
 
50. 路径总和 II 
给你二叉树的根节点 root 和一个整数目标和 targetSum ，找出所有 从根节点到叶子
节点 路径总和等于给定目标和的路径。 
叶子节点是指没有子节点的节点。 
 
 
class Solution: 
    def pathSum(self, root: TreeNode, targetSum: int) -> List[List[int]]: 
        ret = list() 
        path = list() 
         
        def dfs(root: TreeNode, targetSum: int): 
            if not root: 
                return 
            path.append(root.val) 
            targetSum -= root.val 
            if not root.left and not root.right and targetSum == 0: 
                ret.append(path[:]) 
            dfs(root.left, targetSum) 
            dfs(root.right, targetSum) 
            path.pop() 
         
        dfs(root, targetSum) 
        return ret 
 
 
 
51. 二叉树的完全性检验 
给定一个二叉树的 root ，确定它是否是一个 完全二叉树 。 
 
在一个 完全二叉树 中，除了最后一个关卡外，所有关卡都是完全被填满的，并且最
后一个关卡中的所有节点都是尽可能靠左的。它可以包含 1 到 2h 节点之间的最后一
级 h 。 
 
class Solution: 
    def isCompleteTree(self, root: Optional[TreeNode]) -> bool: 
        q = collections.deque([root]) 
        while q: 
            node = q.popleft() 
            if node:  
                q.extend([node.left, node.right]) 
            else: 
                return not any(q) 
 
 
52. 爬楼梯 
假设你正在爬楼梯。需要 n 阶你才能到达楼顶。 
 
每次你可以爬 1 或 2 个台阶。你有多少种不同的方法可以爬到楼顶呢？ 
 
 
class Solution: 
    def climbStairs(self, n: int) -> int: 
        dp = dict() 
        dp[1] = 1 
        dp[2] = 1 
        for i in range(3, n+1): 
            dp[i] = dp[i-1] + dp[i-2] 
        return dp[n] 
 
53. 链表中倒数第 k 个节点 ok 
# 输入一个链表，输出该链表中倒数第 k 个节点。为了符合大多数人的习惯，本题从 1
开始计数，即链表的尾节点是倒数第 1 个节点。 
 
# 例如，一个链表有 6 个节点，从头节点开始，它们的值依次是 1、2、3、4、5、
6。这个链表的倒数第 3 个节点是值为 4 的节点。 
# 示例： 
# 给定一个链表: 1->2->3->4->5, 和 k = 2. 
# 返回链表 4->5. 
class Solution: 
    def getKthFromEnd(self, head, k: int): 
        fast, slow = head, head 
        while fast and k >= 1: 
            fast = fast.next 
            k -= 1 
        while fast: 
            fast = fast.next 
            slow = slow.next 
        return slow 
 
 
54. 验证二叉搜索树 
给你一个二叉树的根节点 root ，判断其是否是一个有效的二叉搜索树。 
 
有效 二叉搜索树定义如下： 
节点的左子树只包含 小于 当前节点的数。 
节点的右子树只包含 大于 当前节点的数。 
所有左子树和右子树自身必须也是二叉搜索树。 
 
class Solution: 
    # 递归 
    def is_valid_BST(self, root): 
        if not root: 
            return True 
 
        def DFS(root, left, right): 
            if not root: 
                return True 
            return left < root.val < right and DFS(root.left, left, 
root.val) and DFS(root.right, root.val, right) 
 
        return DFS(root, float('-inf'), float('inf')) 
 
    # 中序遍历 
    def is_valid_BST2(self, root): 
        stack, inorder = list(), float('-inf') 
        while stack or root: 
            while root: 
                stack.append(root) 
                root = root.left 
            root = stack.pop() 
            if root.val <= inorder: 
                return False 
            inorder = root.val 
            root = root.right 
        return True 
 
 
55. 组合总和 
给你一个 无重复元素 的整数数组 candidates 和一个目标整数 target ，找出 
candidates 中可以使数字和为目标数 target 的 所有 不同组合 ，并以列表形式返回。
你可以按 任意顺序 返回这些组合。 
candidates 中的 同一个 数字可以 无限制重复被选取 。如果至少一个数字的被选数量
不同，则两种组合是不同的。 
对于给定的输入，保证和为 target 的不同组合数少于 150 个。 
输入：candidates = [2,3,6,7], target = 7 
输出：[[2,2,3],[7]] 
解释： 
2 和 3 可以形成一组候选，2 + 2 + 3 = 7 。注意 2 可以使用多次。 
7 也是一个候选， 7 = 7 。 
仅有这两种组合。 
 
 
 
class Solution: 
    def combinationSum(self, candidates, target): 
        def dfs(candidates, begin, size, path, res, target): 
            if target < 0: 
                return 
            if target == 0: 
                res.append(path) 
                return 
 
            for index in range(begin, size): 
                dfs(candidates, index, size, path + [candidates[index]], 
res, target - candidates[index]) 
 
        size = len(candidates) 
        if size == 0: 
            return [] 
        path = [] 
        res = [] 
        dfs(candidates, 0, size, path, res, target) 
        return res 
 
 
56. 奇偶链表 
给定单链表的头节点 head ，将所有索引为奇数的节点和索引为偶数的节点分别组合
在一起，然后返回重新排序的列表。 
第一个节点的索引被认为是 奇数 ， 第二个节点的索引为 偶数 ，以此类推。 
请注意，偶数组和奇数组内部的相对顺序应该与输入时保持一致。 
你必须在 O(1) 的额外空间复杂度和 O(n) 的时间复杂度下解决这个问题。 
 
class Solution: 
    def oddEvenList(self, head: Optional[ListNode]) -> Optional[ListNode]: 
        pre = odd = ListNode(0) 
        event = cur = ListNode(0) 
        while head: 
            odd.next = head 
            odd = odd.next 
            cur.next = head.next 
            if cur.next: 
                cur = cur.next 
            head = head.next 
            if head: 
                head = head.next 
            else: 
                break 
        odd.next = event.next 
        return pre.next 
 
57. 回文链表 
给定单链表的头节点 head ，将所有索引为奇数的节点和索引为偶数的节点分别组合
在一起，然后返回重新排序的列表。 
第一种方式放到节点的值放到列表中； 
class Solution: 
    def isPalindrome(self, head: Optional[ListNode]) -> bool: 
        if not head: 
            return True 
        fast_pointer = head 
        slow_pointer = head 
 
        def get_half_pointer(fast_pointer, slow_pointer): 
            while fast_pointer.next and fast_pointer.next.next: 
                fast_pointer = fast_pointer.next.next 
                slow_pointer = slow_pointer.next 
            return slow_pointer 
 
        def reverse_linkedlist(head): 
            pre = None 
            cur = head 
            while cur: 
                node = cur.next 
                cur.next = pre 
                pre = cur 
                cur = node 
            return pre 
 
        slow_pointer = get_half_pointer(fast_pointer, slow_pointer) 
        slow_pointer = reverse_linkedlist(slow_pointer.next) 
        while slow_pointer: 
            if slow_pointer.val != head.val: 
                return False 
            slow_pointer = slow_pointer.next 
            head = head.next 
        return True 
 
58. 平衡二叉树 
给定一个二叉树，判断它是否是高度平衡的二叉树。 
本题中，一棵高度平衡二叉树定义为： 
 
一个二叉树每个节点 的左右两个子树的高度差的绝对值不超过 1 。 
class Solution: 
    def isBalanced(self, root: Optional[TreeNode]) -> bool: 
        if not root: 
            return True 
        def get_depth(root): 
            if not root: 
                return 0 
            return 1 + max(get_depth(root.left), get_depth(root.right)) 
        if -1 <= get_depth(root.left) - get_depth(root.right) <= 1 and \ 
                self.isBalanced(root.left) and self.isBalanced(root.right): 
            return True 
        return False 
 
 
59. 二叉树的直径 
给定一棵二叉树，你需要计算它的直径长度。一棵二叉树的直径长度是任意两个结点
路径长度中的最大值。这条路径可能穿过也可能不穿过根结点。 
示例 : 
给定二叉树 
          1 
         / \ 
        2   3 
       / \      
      4   5     
返回 3, 它的长度是路径 [4,2,1,3] 或者 [5,2,1,3]。 
class Solution: 
    def diameterOfBinaryTree(self, root: TreeNode) -> int: 
        self.ans = 1 
        def depth(node): 
            # 访问到空节点了，返回 0 
            if not node: 
                return 0 
            # 左儿子为根的子树的深度 
            L = depth(node.left) 
            # 右儿子为根的子树的深度 
            R = depth(node.right) 
            # 计算 d_node 即 L+R+1 并更新 ans 
            self.ans = max(self.ans, L + R + 1) 
            # 返回该节点为根的子树的深度 
            return max(L, R) + 1 
 
        depth(root) 
        return self.ans - 1 
 
60. 最长重复子数组 
给两个整数数组 nums1 和 nums2 ，返回两个数组中公共的、长度最长的子数组的长
度。 
class Solution: 
    def findLength(self, A: List[int], B: List[int]) -> int: 
        # 滑动窗口 
         
        def findmax(A,B): 
            ans_max = 0 
            la = len(A) 
            lb = len(B) 
            # B 进来，从 1 到 la 长度 
            for tlen in range(1,la+1): 
                ans_max = max(ans_max,max_len(A,0,B,lb-tlen,tlen)) 
            # B 出去,长度保持在 la 
            for j in range(lb-la,-1,-1): 
                ans_max = max(ans_max,max_len(A,0,B,j,la)) 
            # B 出去，长度从 la 到 0 -->相当于 A 左移 
            for i in range(1,la): 
                ans_max = max(ans_max,max_len(A,i,B,0,la-i)) 
 
            return ans_max 
 
        def max_len(A,i,B,j,length): 
            count = 0 
            temp_max =0 
            for k in range(length): 
                if A[i+k]==B[j+k]: 
                    count += 1 
                elif count>0: 
                    temp_max = max(temp_max,count) 
                    count = 0 
            temp_max = max(temp_max,count) 
            return temp_max 
         
        if len(A)<=len(B): 
            return findmax(A,B) 
        else: 
            return findmax(B,A) 
 
 
61. 反转字符串中的单词 
给你一个字符串 s ，请你反转字符串中单词的顺序。 
 
单词 是由非空格字符组成的字符串。s 中使用至少一个空格将字符串中的单词分隔
开。 
返回单词顺序颠倒且 单词 之间用单个空格连接的结果字符串。 
注意：输入字符串 s 中可能会存在前导空格、尾随空格或者单词间的多个空格。返回
的结果字符串中，单词间应当仅用单个空格分隔，且不包含任何额外的空格。 
class Solution: 
    def reverseWords(self, s: str) -> str: 
        left, right = 0, len(s) - 1 
        # 去掉字符串开头的空白字符 
        while left <= right and s[left] == ' ': 
            left += 1 
         
        # 去掉字符串末尾的空白字符 
        while left <= right and s[right] == ' ': 
            right -= 1 
             
        d, word = collections.deque(), [] 
        # 将单词 push 到队列的头部 
        while left <= right: 
            if s[left] == ' ' and word: 
                d.appendleft(''.join(word)) 
                word = [] 
            elif s[left] != ' ': 
                word.append(s[left]) 
            left += 1 
        d.appendleft(''.join(word)) 
         
        return ' '.join(d) 
或者： 
class Solution: 
    def reverseWords(self, s: str) -> str: 
        return " ".join(reversed(s.split())) 
或 
class Solution: 
    def reverseWords(self, s: str) -> str: 
        return " ".join(s[::-1].split(" ")[::-1]) 
 
 
62. 最小路径和 
给定一个包含非负整数的 m x n 网格 grid ，请找出一条从左上角到右下角的路径，
使得路径上的数字总和为最小。 
 
说明：每次只能向下或者向右移动一步。 
class Solution: 
    def minPathSum(self, grid: [[int]]) -> int: 
        for i in range(len(grid)): 
            for j in range(len(grid[0])): 
                if i == j == 0:  
                    continue 
                elif i == 0:   
                    grid[i][j] = grid[i][j - 1] + grid[i][j] 
                elif j == 0:   
                    grid[i][j] = grid[i - 1][j] + grid[i][j] 
                else:  
                    grid[i][j] = min(grid[i - 1][j], grid[i][j - 1]) + 
grid[i][j] 
        return grid[-1][-1] 
 
63. 不同路径 ok 
一个机器人位于一个 m x n 网格的左上角 （起始点在下图中标记为 “Start” ）。 
机器人每次只能向下或者向右移动一步。机器人试图达到网格的右下角（在下图中标
记为 “Finish” ）。 
问总共有多少条不同的路径？ 
class Solution: 
    def uniquePaths(self, m: int, n: int) -> int: 
        f = [[1] * n] + [[1] + [0] * (n - 1) for _ in range(m - 1)] 
        print(f) 
        for i in range(1, m): 
            for j in range(1, n): 
                f[i][j] = f[i - 1][j] + f[i][j - 1] 
        return f[m - 1][n - 1] 
 
 
 
64. 删除排序链表中的重复元素 ok 
给定一个已排序的链表的头 head， 删除所有重复的元素，使每个元素只出现一次 。
返回 已排序的链表 。 
 
 
class Solution: 
    def deleteDuplicates(self, head: ListNode) -> ListNode: 
        if not head: 
            return head 
        cur = head 
        while cur.next: 
            if cur.val == cur.next.val: 
                cur.next = cur.next.next 
            else: 
                cur = cur.next 
        return head 
 
65. 寻找峰值 ok 
峰值元素是指其值严格大于左右相邻值的元素 
给你一个整数数组 nums，找到峰值元素并返回其索引。数组可能包含多个峰值，在这
种情况下，返回 任何一个峰值 所在位置即可。 
你可以假设 nums[-1] = nums[n] = -∞ 。 
你必须实现时间复杂度为 O(log n) 的算法来解决此问题。 
class Solution: 
    def findPeakElement(self, nums: List[int]) -> int: 
        n = len(nums) 
 
        # 辅助函数，输入下标 i，返回 nums[i] 的值 
        # 方便处理 nums[-1] 以及 nums[n] 的边界情况 
        def get(i: int) -> int: 
            if i == -1 or i == n: 
                return float('-inf') 
            return nums[i] 
         
        left, right, ans = 0, n - 1, -1 
        while left <= right: 
            mid = (left + right) // 2 
            if get(mid - 1) < get(mid) > get(mid + 1): 
                ans = mid 
                break 
            if get(mid) < get(mid + 1): 
                left = mid + 1 
            else: 
                right = mid - 1 
         
        return ans 
 
66. 长度最小的子数组 ok 
给定一个含有 n 个正整数的数组和一个正整数 target 。 
找出该数组中满足其和 ≥ target 的长度最小的 连续子数组 [numsl, numsl+1, ..., numsr-
1, numsr] ，并返回其长度。如果不存在符合条件的子数组，返回 0 。 
 
 
class Solution: 
    def minSubArrayLen(self, s: int, nums: List[int]) -> int: 
        if not nums: 
            return 00 
         
        n = len(nums) 
        ans = n + 1 
        start, end = 0, 0 
        total = 0 
        while end < n: 
            total += nums[end] 
            while total >= s: 
                ans = min(ans, end - start + 1) 
                total -= nums[start] 
                start += 1 
            end += 1 
         
        return 0 if ans == n + 1 else ans 
 
67. 零钱兑换 II  
给你一个整数数组 coins 表示不同面额的硬币，另给一个整数 amount 表示总金额。 
请你计算并返回可以凑成总金额的硬币组合数。如果任何硬币组合都无法凑出总金
额，返回 0 。 
假设每一种面额的硬币有无限个。  
题目数据保证结果符合 32 位带符号整数。 
 
 
用 dp[x] 表示金额之和等于 x 的硬币组合数，目标是求 dp[amount] 
动态规划的边界是 dp[0]=。只有当不选取任何硬币时，金额之和才为 000，因此只有 111 种
硬币组合。 
对于面额为 coin 的硬币，当 coin≤i≤amount 时，如果存在一种硬币组合的金额之和等于 
i−coin，则在该硬币组合中增加一个面额为 coin 的硬币，即可得到一种金额之和等于 iii 的
硬币组合。因此需要遍历 coins，对于其中的每一种面额的硬币，更新数组 dp 中的每个大
于或等于该面额的元素的值。 
 
class Solution: 
    def change(self, amount: int, coins: List[int]) -> int: 
        dp = [0] * (amount+1)  
        dp[0] = 1 
        for coin in coins: 
            i = coin 
            while i <= amount: 
                dp[i] += dp[i - coin] 
                i += 1 
        return dp[amount] 
 
68. 最小覆盖子串  
给你一个字符串 s 、一个字符串 t 。返回 s 中涵盖 t 所有字符的最小子串。如果 s 
中不存在涵盖 t 所有字符的子串，则返回空字符串 "" 。 
输入：s = "ADOBECODEBANC", t = "ABC" 
输出："BANC" 
class Solution: 
    def minWindow(self, s: str, t: str) -> str: 
         
        if len(t) > len(s): 
            return ''         
         
        cnt = collections.Counter(t)    # 哈希表：记录需要匹配到的各个元素的数
目 
        need = len(t)                   # 记录需要匹配到的字符总数【need=0 表示
匹配到了】 
         
        n = len(s) 
        start, end = 0, -1          # 记录目标子串 s[start, end]的起始和结尾 
        min_len = n + 1             # 符合题意的最短子串长度【初始化为一个不可能
的较大值】 
        left = right = 0            # 滑动窗口的左右边界 
         
        for right in range(n): 
             
            # 窗口右边界右移一位 
            ch = s[right]               # 窗口中新加入的字符 
            if ch in cnt:               # 新加入的字符位于 t 中 
                if cnt[ch] > 0:         # 对当前字符 ch 还有需求 
                    need -= 1           # 此时新加入窗口中的 ch 对 need 有影响 
                cnt[ch] -= 1 
             
            # 窗口左边界持续右移 
            while need == 0:            # need=0，当前窗口完全覆盖了 t 
                if right - left + 1 < min_len:      # 出现了更短的子串 
                    min_len = right - left + 1 
                    start, end = left, right 
                 
                ch = s[left]            # 窗口中要滑出的字符 
                if ch in cnt:           # 刚滑出的字符位于 t 中 
                    if cnt[ch] >= 0:    # 对当前字符 ch 还有需求，或刚好无需求
(其实此时只有=0 的情况) 
                        need += 1       # 此时滑出窗口的 ch 会对 need 有影响 
                    cnt[ch] += 1 
                left += 1               # 窗口左边界+1 
         
        return s[start: end+1] 
 
69. 最长有效括号  
给你一个只包含 '(' 和 ')' 的字符串，找出最长有效（格式正确且连续）括号子串的长
度。 
 
class Solution: 
    def longestValidParentheses(self, s: str) -> int: 
        if len(s) < 1: return 0 
        stack, res = [-1], 0 
        for i in range(len(s)): 
            if s[i] == "(": 
                stack.append(i) 
            else: 
                # Stack either store the index of "(" or the last invalide 
bracket ")" index. 
                stack.pop() 
                if not stack: 
                    stack.append(i) # To store the last one that is not a 
valid bracket. 
                else: 
                    # Current index minus the last invalid bracket index. 
                    res = max(res, i - stack[-1]) 
        return res 
 
 
70. 交替打印奇偶数 ok 
import threading 
 
 
def thread_a(): 
    for i in range(1, 101): 
        if i % 2 != 0: 
            lock_b.acquire() 
            print(i) 
            lock_a.release() 
 
 
def thread_b(): 
    for i in range(1, 101): 
        if i % 2 == 0: 
            lock_a.acquire() 
            print(i)  
            lock_b.release() 
 
 
if __name__ == '__main__': 
    lock_a = threading.Lock() 
    lock_b = threading.Lock() 
 
    t1 = threading.Thread(target=thread_a) 
    t2 = threading.Thread(target=thread_b) 
 
    lock_a.acquire() 
    t1.start() 
    t2.start() 
 
    t1.join() 
 
 
71. 滑动窗口最大值 
给你一个整数数组 nums，有一个大小为 k 的滑动窗口从数组的最左侧移动到数组的最
右侧。你只可以看到在滑动窗口内的 k 个数字。滑动窗口每次只向右移动一位。 
 
返回滑动窗口中的最大值。 
 
class Solution: 
    def maxSlidingWindow(self, nums, k: int): 
        n = len(nums) 
        q = [(-nums[i], i) for i in range(k)] 
        heapq.heapify(q) 
        res = [-q[0][0]] 
        for i in range(k, n): 
            heapq.heappush(q, (-nums[i], i)) 
            while i - k >= q[0][1]: 
                heapq.heappop(q) 
            res.append(-q[0][0]) 
        return res 
     
        def max_sliding_window(self, nums, k): 
        n = len(nums) 
        from collections import deque 
        q = deque() 
        for i in range(0, k): 
            while q and nums[i] >= nums[q[-1]]: 
                q.pop() 
            q.append(i) 
        res = [] 
        res.append(nums[q[0]]) 
        for i in range(k, n): 
            while q and nums[i] >= nums[q[-1]]: 
                q.pop() 
            q.append(i) 
            while q[0] <= i - k: 
                q.popleft() 
            res.append(nums[q[0]]) 
        return res 
 
    def max_sliding_window2(self, nums, k): 
        from collections import deque 
        n = len(nums) 
        d, res = deque(), [] 
        for i, j in zip(range(1-k, n+1-k), range(n)): 
            if i > 0 and d[0] == nums[i - 1]: 
                d.popleft() 
                # 保持 deque 递减 
            while d and d[-1] < nums[j]: 
                d.pop() 
            d.append(nums[j]) 
            # 记录窗口最大值 
            if i >= 0: 
                res.append(d[0]) 
        return res 
 
72. 复原 IP 地址 
有效 IP 地址 正好由四个整数（每个整数位于 0 到 255 之间组成，且不能含有前导 
0），整数之间用 '.' 分隔。 
   
例如："0.1.2.201" 和 "192.168.1.1" 是 有效 IP 地址，但是 "0.011.255.245"、
"192.168.1.312" 和 "192.168@1.1" 是 无效 IP 地址。 
给定一个只包含数字的字符串 s ，用以表示一个 IP 地址，返回所有可能的有效 IP 
地址，这些地址可以通过在 s 中插入 '.' 来形成。你 不能 重新排序或删除 s 中的任
何数字。你可以按 任何 顺序返回答案。 
 
 
class Solution: 
    def restoreIpAddresses(self, s: str) -> List[str]: 
        SEG_COUNT = 4 
        ans = list() 
        segments = [0] * SEG_COUNT 
         
        def dfs(segId: int, segStart: int): 
            # 如果找到了 4 段 IP 地址并且遍历完了字符串，那么就是一种答案 
            if segId == SEG_COUNT: 
                if segStart == len(s): 
                    ipAddr = ".".join(str(seg) for seg in segments) 
                    ans.append(ipAddr) 
                return 
             
            # 如果还没有找到 4 段 IP 地址就已经遍历完了字符串，那么提前回溯 
            if segStart == len(s): 
                return 
 
            # 由于不能有前导零，如果当前数字为 0，那么这一段 IP 地址只能为 0 
            if s[segStart] == "0": 
                segments[segId] = 0 
                dfs(segId + 1, segStart + 1) 
             
            # 一般情况，枚举每一种可能性并递归 
            addr = 0 
            for segEnd in range(segStart, len(s)): 
                addr = addr * 10 + (ord(s[segEnd]) - ord("0")) 
                if 0 < addr <= 0xFF: 
                    segments[segId] = addr 
                    dfs(segId + 1, segEnd + 1) 
                else: 
                    break 
         
 
        dfs(0, 0) 
        return ans 
 
73. 调整数组顺序使奇数位于偶数前面 
输入一个整数数组，实现一个函数来调整该数组中数字的顺序，使得所有奇数在数组
的前半部分，所有偶数在数组的后半部分。 
 
class Solution: 
    def exchange(self, nums: List[int]) -> List[int]: 
        n = len(nums) 
        left, right = 0, n - 1 
        while left < right: 
            while left < right and nums[left] % 2 != 0: 
                left += 1 
            while right > left and nums[right] % 2 == 0: 
                right -= 1 
            if left < right: 
                nums[left], nums[right] = nums[right], nums[left] 
                left += 1 
                right -= 1 
        return nums 
 
 
 
74. 最长公共前缀 
编写一个函数来查找字符串数组中的最长公共前缀。 
如果不存在公共前缀，返回空字符串 ""。 
class Solution: 
    def longestCommonPrefix(self, strs: List[str]) -> str: 
        def lcp(s1, s2): 
            n = min(len(s1), len(s2)) 
            index = 0 
            while index < n and s1[index] == s2[index]: 
                index += 1 
            return s1[0:index] 
        if not strs: 
            return "" 
        prefix = strs[0] 
        for s in strs[1:]: 
            prefix = lcp(prefix, s) 
            if not prefix: 
                return '' 
        return prefix 
 
class Solution: 
    def longestCommonPrefix(self, strs: List[str]) -> str: 
        def lcp(s1, s2): 
            n = min(len(s1), len(s2)) 
            index = 0 
            while index < n and s1[index] == s2[index]: 
                index += 1 
            return s1[0:index] 
        if not strs: 
            return "" 
        strs.sort() 
        return lcp(strs[0], strs[-1]) 
 
class Solution: 
    def longestCommonPrefix(self, strs: List[str]) -> str: 
        ans = '' 
        for l in zip(*strs): 
            seen = set(l) 
            if len(seen) == 1: 
                ans += l[0] 
            else: 
                break 
        return ans 
 
 
 
智力题 
字节一面 
1. 有 64 匹马和 8 条跑道，每次只允许最多 8 匹马同时比赛（假定每匹
马每次比赛速度相同），但是没有秒表不能计时，问最少要比多少次，才
能选出最快的 4 匹马？ 
https://zhuanlan.zhihu.com/p/398143738 
 
 
 
英文自我介绍 
Good morning, Interviewers. It is really my honor to have this opportunity for an 
interview, I hope I can make a good performance today. Now I will introduce myself 
briefly. My name is dongxiangxiang. I received a master’s degree from the University 
of Electronic Science and Technology of China in the year of two thousand and 
nineteen. I passed CET6. During my postgraduate study in the major of eletronic 
science and technology, I published two SCI papers.  
I have three years work experience in ZTE Nanjing Research Institute, engaged in 
network protocol development. I was in charge of the development of extended network 
resources based on openstack and the northbound interface orchestration of the SDN 
controller. I'm a hardworking, responsible person. During my spare time, I like playing 
table tennis and running, I think we should work actively and keep exercising at the 
same time. I'm quite interested in this job, I sincerely hope to get the chance to work 
for your company, so that I can promote myself and make my contributions to the 
company. Thanks. 
 
From the SDN controller's point of view 
 
 
 
项目经历 
 
 
Director  
Director 和 Tecs 安装完毕，迪普防火墙接入成功，通过 Director 配置 ipsec-site-
connection 实例，可以通过 Tecs 正常配置正确落地生效到迪普防火墙上。 
配置包括增删改查以及查列表，还有订购，取消订购，修改订购。 
 
director web 门户—director 订单管理—CloudNetwork 微服务—neutron-server—
driver—迪普防火墙。 
   
vpn driver 开发 
配置 service_provider VPN driver 
在创建 VPN service 时进行 VPN service_id 和 provider 的关系存库   provider 根
据 flavor 来确定，不然是默认值 
 
创建 ipsec 时，根据 ipsec 中的 VPN service_id 取得 provider，再根据 provider 获
得 driver 对象，来进行 driver 的增删改 
 
初始化 driver 时获得 rest 对象、迪普设备账号密码 IP、引流参数配置对象 
创建时创 SA policy—protect net—ipsec connection 
neutron vpn-ikepolicy-create ikepolicy1 
neutron vpn-ipsecpolicy-create ipsecpolicy1 
neutron vpn-service-create --name myvpnA routerA netA 
neutron ipsec-site-connection-create --name vpnconnectionA --vpnservice-id myvpnA 
--ikepolicy-id ikepolicy1 --ipsecpolicy-id ipsecpolicy1 --peer-address 172.24.4.233 --
peer-id 172.24.4.233 --peer-cidr 10.2.0.0/24 --psk secret 
 
 
Director 云安全服务开发 
web 应用防火墙 
漏洞扫描 
数据库安全审计 
日志审计 
堡垒机 
功能：创建 更新 删除 订单支付 订单修改 资源列表 续费 安全服务详情页 
实际服务创建请求都是从订单下来的。 
订单支付后，在服务页面，可以看到安全服务的状态是 building，过一段时间状
态变成 active。 
为安全服务虚机 port 绑定安全组和浮动 IP 整个流程：调用山石云池创建接口，
创建安全服务虚机，云池接口返回创建状态，以及安全服务虚机 id 等信息，将
安全服务虚机相关字段写入数据库包括虚机状态。flask 框架中微服务起进程定
时读取数据库中虚机实例列表，过滤列表中虚机状态不为 error/deleted/active 的
虚机，使用山石云池 get 接口实时查询上一个步骤中取出的正在创建的虚机状态，
如果创建时间在 30 分钟完成，则取出符合条件的虚机 port_id 进行浮动 IP 和安
全组绑定。 
 
单点登录： 
云池接口获取 token，拿着 token 获取跳转到安全服务虚机页面 url，根据用户名
密码单点登录至安全服务页面详情页。 
 
 
 
A10 plugin 创建 lbaas 冲突问题 
resource_lock 表 
user_id 和 lock 和 last_lock_time 
 
handler_lb 初始化时，user_id 赋值 1，初始化 lock 即 init_lock，init_lock 中根据
user_id=1 取库，如果库里没有值，按 user_id=1，lock=false，last_lock_time=now
时间  存库。如果库里有值时将 lock 值置成 false，last_lock_time 更新成 now 时
间。 
 
aquire_lock 时，根据 user_id 获取 db 如果 lock=True 当前时间的上下超时时间比
如 10s 内，不允许获取 lock。 
否则获取锁，将 lock=true，将 last_lock_time=now 时间更新库。 
执行完毕后，在 context.session.begin()上下文中释放锁，lock=false。 
 
with A10context(self, context, lb) as c 
__enter__方法中获取 client 也就是下发设备的 rest API，之后 active partition，hook
钩子进行下发设备前的操作 before_vip_create 返回参数进行 after_vip_create。 
  
创建的 lb 中有参数子网，根据子网通过 ml2 plugin 获取 network_id，如果从数据
库中有此 network_id 关联的数据，则说明是在同一网络下创建 lb，一个网络一个
vlan_id，一个 vrrp，同网络子网已经存在，创建 ve 口以及 floatingip， 
同网络，有 v4 子网，并且要创建的 lb 的子网也是 v4，取之前的 v4 的 ve 口 port_id
以及 vrrp 的 floatingip 下发； 
同网络，有 v6 子网，并且要创建的 lb 的子网也是 v6，取之前的 v6 的 ve 口 port_id
以及 vrrp 的 floatingip 下发； 
现在问题是两个 lb 同一子网几乎同时创建，在 lb 创建流程中，会根据 network_id
查库，然而在两个 lb 都查找为空，所以创建了两个 vlan_id，导致接下来下发设
备时创建了两个 ve 口 ip 地址，设备不支持报错。 
LOCK_TIMEOUT = 10 
 
 
class ResourceLock(model.BASEV2): 
    __tablename__ = 'zte_resource_lock' 
    user_id = sa.Column(sa.Interger, primary_key=True, nullable=False) 
    lock = sa.Column(sa.Boolean(), nullable=False) 
    last_lock_time = sa.Column(sa.DateTime, nullable=True) 
 
 
class DeviceLockDb(object): 
    def init_lock_db(self, context, user_id): 
        db = context.session.query(ResourceLock) 
        db = db.filter(ResourceLock.user_id == user_id).first() 
        if not db: 
            with context.session.begin(subtransactions=True): 
                args = { 
                    'user_id': user_id, 
                    'lock': False, 
                    'last_lock_time': timeutils.utcnow() 
                } 
                db = ResourceLock(**args) 
                context.session.add(db) 
        else: 
            db.lock = False 
            db.last_lock_time = timeutils.utcnow() 
            with context.session.begin(subtransactions=True): 
                db.update(db) 
 
    def acquire_lock(self, context, user_id): 
        db = context.session.query(ResourceLock) 
        db = db.filter(ResourceLock.user_id == 
user_id).with_for_update().first() 
        if db.lock: 
            if not timeutils.is_newer_than(db.last_lock_time, LOCK_TIMEOUT) 
and \ 
                not timeutils.is_older_than(db.last_lock_time, LOCK_TIMEOUT) 
                return False 
        db.lock = True 
        db.last_lock_time = timeutils.utcnow() 
        with context.session.begin(subtransactions=True): 
            db.update(db) 
             
    def release_lock(self, context, user_id): 
        db = context.session.query(ResourceLock) 
        db = db.filter(ResourceLock.user_id == user_id).first() 
        db.lock = False 
        with context.session.begin(subtransactions=True): 
            db.update(db) 
 
 
class DeviceLock(DeviceLockDb): 
    def init_db(self, context, user_id): 
        self.init_lock_db(context, user_id) 
        LOG.info('init resource lock...') 
     
    def acquire(self, context, user_id): 
        ret = self.acquire_lock(context, user_id) 
        if ret: 
            LOG.info('get resource lock successfullly, user_id: %s', 
user_id) 
            return True 
        else: 
            LOG.info('can not get resource lock, user_id: %s', user_id) 
            return False 
         
    def release(self, context, user_id): 
        self.release_lock(context, user_id) 
        LOG.info('release resource lock, user_id: %s', user_id) 
 
 
插件部署 
bin 包生成 
首先分别用 python2 和 python3 setup.py bdist_rpm 生成 rpm 包 
之后通过 makeself.sh 脚本创建安装文件*.bin； 
 
 
ml2 
l3 
qos 
taas 
trunk 
vpc 
fwaas 
bgp 
 
 
 
项目产品很稳定，以及商用 6 年了了，暂时的需求只是修修补补，对于个人而言
就是增删几行代码的工作，提升机会不多，所以外边看看机会，想找能学到东西
的岗位。 
公司加班文化比较严重，1 2 4 6 加班，而且没有加班费，经常性被叫白嫖厂，考
核时同样完成任务，会将加班时长作为考核项。 
 
