
<!-- vscode-markdown-toc-config
	numbering=false
	autoSave=true
	/vscode-markdown-toc-config -->
<!-- /vscode-markdown-toc -->

## <a name='OSI'></a>OSI 的七层模型
OSI 七层模型一般指开放系统互连参考模型 (Open System Interconnect 简称 OSI)
是国际标准化组织(ISO)和国际电报电话咨询委员会(CCITT)联合制定的开放系
统互连参考模型,为开放式互连信息系 统提供了一种功能结构的框架。  

应用层：为应用程序提供交互服务，各种应用程序协议，比如 HTTP、HTTPS、FTP、SOCKS 安全套接字协议、DNS 域名系统、GDP 网关发现协议等等。  
表示层：主要负责数据格式的转换，如加密解密、转换翻译、压缩解压缩等。比如 LPP 轻量级表示协议。  
会话层：负责在网络中的两节点之间建立、维持和终止通信，如服务器验证用户登录便是由会话层完成的，比如 SSL 安全套接字层协议、TLS 传输层安全协议、RPC 远程过程调用协议等等。 
传输层：接受上一层的数据，在必要的时候对数据进行分割，并将这些数据交给网络层，保证这些数据段有效到达对端，比如 TCP 传输控制协议、UDP 数据报协议。  
网络层：选择合适的路由和交换结点，确保数据及时传送，控制子网的运行：逻辑编址、分组传输、路由选择，比如 IP、IPV6、SLIP 等等。  
数据链路层：将网络层传下来的 IP 数据包组装成帧，并再相邻节点的链路上传送帧。物理寻址，同时将原始比特流转变为逻辑传输路线，
比如 XTP 压缩传输协议、 PPTP 点对点隧道协议等等。  
物理层：现相邻节点间比特流的透明传输，尽可能屏蔽传输介质和通信手段的差异。机械、电子、定时接口通信信道上的原始比特流传输，比如 IEEE802.2 等等。 


## <a name='TCPIP4'></a>TCP/IP 4 层模型 
应用层 
传输层 
网络层 
网络接口层 



## <a name='TCP'></a>TCP 
HTTP 在应用层，TCP 传输层，TSL or SSL 安全层，IP 网络层； 
TCP 会按序、无差错地承载 HTTP 数据，TCP 为 HTTP 提供了一条可靠的比特传输管道。
从 TCP 连接一端填入的字节会从另一端以原有顺序、正确地传送出来。
HTTP 要传送一条报文时，会以流的形式将报文数据的内容通过一条打开的TCP 连接按序传输。
TCP 收到数据流之后，会将数据流砍成被称为段的小数据块，并将段封装在 IP 分组中，通过因特网进行传输。 
每个 TCP 段都是由 IP 分组承载，从一个 IP 地址发送到另一个 IP 地址的。


#### <a name='TCPUDP'></a>TCP 和 UDP 区别 
1. TCP 协议是有连接的，有连接的意思是开始传输实际数据之前 TCP 的客户端和服务器端必须通过三次握手建立连接，会话结束后也要结束连接。
而 UDP 是无连接的；
2. TCP 协议保证数据发送，按序送达，提供超时重传保证数据可靠性。
但是 UDP 不保证按序到达，甚至不能保证到达，即便是按序发送的序列，也不保证按序送到； 
3. TCP 协议所需资源多，TCP 首部需 20 个字节（不算可选项），UDP 首部字段只需 8 个字节;  
4. TCP 有流量控制和拥塞控制，UDP 没有。网络拥堵不会影响发送端的发送速率;  
5. TCP 面向的字节流的服务，UDP 面向的是报文的服务。 
TCP 应用场景： 
效率要求相对低，但对准确性要求相对高的场景。因为传输中需要对数据确认、重发、排序等操作，相比之下效率没有 UDP 高。
举几个例子：文件传输、接受邮件、远程登录。 
UDP 应用场景：
效率要求相对高，对准确性要求相对低的场景。举几个例子：QQ 聊天、在线视频、网络语音电话、广播通信（广播、多播）。 


#### <a name='TCP-1'></a>TCP 协议如何保证可靠性 
TCP 主要提供了检验和、序列号/确认应答、超时重传、滑动窗口、拥塞控制和流量控制等方法实现了可靠性传输。 
1. 检验和：通过检验和的方式，接收端可以检测出来数据是否有差错和异常，假如有差错就会直接丢弃 TCP 段，重新发送。 
2. 序列号/确认应答：序列号的作用不仅仅是应答的作用，有了序列号能够将接收到的数据根据序列号排序，并且去掉重复序列号的数据。 
TCP 传输的过程中，每次接收方收到数据后，都会对传输方进行确认应答。
也就是发送 ACK 报文，这个 ACK 报文当中带有对应的确认序列号，告诉发送方，接收到了哪些数据，下一次的数据从哪里发。 
3. 滑动窗口：滑动窗口既提高了报文传输的效率，也避免了发送方发送过多的数据而导致接收方无法正常处理的异常。 
4. 超时重传：超时重传是指发送出去的数据包到接收到确认包之间的时间，如果超过了这个时间会被认为是丢包了，需要重传。
最大超时时间是动态计算的。 
5. 拥塞控制：在数据传输过程中，可能由于网络状态的问题，造成网络拥堵，此时引入拥塞控制机制，在保证 TCP 可靠性的同时，提高性能。 
6. 流量控制：如果主机 A 一直向主机 B 发送数据，不考虑主机 B 的接受能力，则
可能导致主机 B 的接受缓冲区满了而无法再接受数据，从而会导致大量的数据丢包，引发重传机制。
而在重传的过程中，若主机 B 的接收缓冲区情况仍未好转，则会将大量的时间浪费在重传数据上，降低传送数据的效率。
所以引入流量控制机制，主机 B 通过告诉主机 A 自己接收缓冲区的大小，来使主机 A 控制发送的数据量。
流量控制与 TCP 协议报头中的窗口大小有关。


#### <a name='TCP-1'></a>详细讲一下 TCP 的滑动窗口 
在进行数据传输时，如果传输的数据比较大，就需要拆分为多个数据包进行发送。
TCP 协议需要对数据进行确认后，才可以发送下一个数据包。这样一来，就会在等待确认应答包环节浪费时间。 
为了避免这种情况，TCP 引入了窗口概念。窗口大小指的是不需要等待确认应答包而可以继续发送数据包的最大值。 
滑动窗口左边的是已发送并且被确认的分组，滑动窗口右边是还没有轮到的分组。 
滑动窗口里面也分为两块，一块是已经发送但是未被确认的分组，另一块是窗口内等待发送的分组。
随着已发送的分组不断被确认，窗口内等待发送的分组也会不断被发送。整个窗口就会往右移动，让还没轮到的分组进入窗口内。
可以看到滑动窗口起到了一个限流的作用，也就是说当前滑动窗口的大小决定了当前 TCP 发送包的速率，
而滑动窗口的大小取决于拥塞控制窗口和流量控制窗口的两者间的最小值。


#### <a name='tcp'></a>tcp拥塞控制介绍一下
在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，
但是一重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放大....

所以，TCP 不能忽略网络上发生的事，它被设计成一个无私的协议，当网络发送拥塞时，TCP 会自我牺牲，降低发送的数据量。

于是，就有了拥塞控制，控制的目的就是避免「发送方」的数据填满整个网络。

为了在「发送方」调节所要发送数据的量，定义了一个叫做「拥塞窗口」的概念。



#### <a name=''></a>三次握手
首先 Client 端发送连接请求报文，Server 端接收连接后回复 ACK 报文，并为这次连接分配资源。
Client 端接收到 ACK 报文后也向 Server 段发送 ACK 报文，并分配资源，这样 TCP 连接就建立了。 
详细过程： 
第一次握手：起初两端都处于 CLOSED 关闭状态，Client 将标志位 SYN 置为 1，随机产生一个值 seq=x，
并将该数据包发送给 Server，Client 进入 SYN-SENT 状态，等待 Server 确认；  
第二次握手：Server 收到数据包后由标志位 SYN=1 得知 Client 请求建立连接，
Server 将标志位 SYN 和 ACK 都置为 1，ack=x+1，随机产生一个值 seq=y，并将
该数据包发送给 Client 以确认连接请求，Server 进入 SYN-RCVD 状态，此时操作系统为该 TCP 连接分配 TCP 缓存和变量；  
第三次握手：Client 收到确认后，检查 ack 是否为 x+1，ACK 是否为 1，如果正
确则将标志位 ACK 置为 1，ack=y+1，并且此时操作系统为该 TCP 连接分配 TCP
缓存和变量，并将该数据包发送给 Server，Server 检查 ack 是否为 y+1，ACK 是
否为 1，如果正确则连接建立成功，Client 和 Server 进入 ESTABLISHED 状态，
完成三次握手，随后 Client 和 Server 就可以开始传输数据。  
TCB 传输控制块 Transmission Control Block，存储每一个连接中的重要信息，如
TCP 连接表，到发送和接收缓存的指针，到重传队列的指针，当前的发送和接收序号。 


#### <a name='-1'></a>四次挥手过程
1）A 的应用进程先向其 TCP 发出连接释放报文段（FIN=1，序号 seq=u），并停
止再发送数据，主动关闭 TCP 连接，进入 FIN-WAIT-1（终止等待 1）状态，等待 B 的确认。  
2）B 收到连接释放报文段后即发出确认报文段，（ACK=1，确认号 ack=u+1，序号 seq=v），
B 进入 CLOSE-WAIT（关闭等待）状态，此时的 TCP 处于半关闭状态，A 到 B 的连接释放。  
3）A 收到 B 的确认后，进入 FIN-WAIT-2（终止等待 2）状态，等待 B 发出的连接释放报文段。  
4）B 没有要向 A 发出的数据，B 发出连接释放报文段（FIN=1，ACK=1，序号seq=w，确认号 ack=u+1），
B 进入 LAST-ACK（最后确认）状态，等待 A 的确认。 
5）A 收到 B 的连接释放报文段后，对此发出确认报文段（ACK=1，seq=u+1，ack=w+1），
A 进入 TIME-WAIT（时间等待）状态。此时 TCP 未释放掉，需要经过时间等待计时器设置的时间 2MSL 后，A 才进入 CLOSED 状态。 


#### <a name='TCP-1'></a>TCP 协议为什么需要三次握手 
1. 通信双方都必须要维护一个序列号，去标记已经发送出去的数据包，哪些是已经被对方签收的； 
2. TCP 协议就要在一个不可靠的网络环境下，也要实现可靠的数据传输。
通信双方须要通过某种手段来实现一个可靠的数据传输通道，而三次通信是建立这样通道的最小值；
3. 防止历史的重复连接初始化造成的混乱问题，两次握手端只能选择接受或者拒绝这个连接请求。 


#### <a name='2MSL'></a>四次挥手释放连接时，等待 2MSL 的意义
MSL---Maximum Segment Lifetime，报文最大生存时间；
2MSL时长 这其实是相当于至少允许报文丢失一次。
比如，若 ACK 在一个 MSL 内丢失，这样被动方重发的 FIN 会在第 2 个 MSL 内到达，TIME_WAIT 状态的连接可以应对。

第一，为了保证 A 发送的最后一个 ACK 报文段能够到达 B。
这个 ACK 报文段有可能丢失，因而使处在 LAST-ACK 状态的 B 收不到对已发送的 FIN 和 ACK 报文段的确认。
B 会超时重传这个 FIN 和 ACK 报文段，而 A 就能在 2MSL 时间内收到这个重传的 ACK+FIN 报文段。接着 A 重传一次确认。  
第二，就是防止上面提到的已失效的连接请求报文段出现在本连接中，A 在发送
完最有一个 ACK 报文段后，再经过 2MSL，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。 


#### <a name='Time_Wait'></a>为什么要 Time_Wait 
谁先关闭谁先进入 time_wait 状态可靠的终止 TCP 连接。
保证让迟来的 TCP 报文有足够的时间被识别并丢弃，让网络上的数据包自动消亡，防止旧连接初始了新的连接。


#### <a name='-1'></a>要是没有三次握手会怎么样 
三次握手的首要原因是为了防止旧的重复连接初始化造成混乱。（防止历史连接初始化了连接）同步双方初始序列号 避免资源浪费 
三次握手的目的是建立可靠的通信信道，三次握手最主要的目的就是双方确认自己与对方的发送与接收是正常的。 
第三次握手是为了防止失效的连接请求到达服务器，让服务器错误打开连接。 


#### <a name='-1'></a>为什么要四次挥手？ 
TCP 是全双工通信，可以双向传输数据。任何一方都可以在数据传送结束后发出连接释放的通知，待对方确认后进入半关闭状态。
当另一方也没有数据再发送的时候，则发出连接释放通知，对方确认后就完全关闭了 TCP 连接。 
举个例子：A 和 B 打电话，通话即将结束后。 
第一次挥手 ： A 说“我没啥要说的了” 
第二次挥手 ：B 回答“我知道了”，但是 B 可能还会有要说的话，A 不能要求B 跟着自己的节奏结束通话 
第三次挥手 ：于是 B 可能又巴拉巴拉说了一通，最后 B 说“我说完了” 
第四次挥手 ：A 回答“知道了”，这样通话才算结束。


#### <a name='-1'></a>为什么需要三次握手，而不是两次？ 
主要有三个原因： 
1. 防止已过期的连接请求报文突然又传送到服务器，因而产生错误和资源浪费。 
在双方两次握手即可建立连接的情况下，假设客户端发送 A 报文段请求建立连接，
由于网络原因造成 A 暂时无法到达服务器，服务器接收不到请求报文段就不会返回确认报文段。 
客户端在长时间得不到应答的情况下重新发送请求报文段 B，这次 B 顺利到达服务器，服务器随即返回确认报文并进入 ESTABLISHED 状态，
客户端在收到确认报文后也进入 ESTABLISHED 状态，双方建立连接并传输数据，之后正常断开连接。 
此时姗姗来迟的 A 报文段才到达服务器，服务器随即返回确认报文并进入ESTABLISHED 状态，
但是已经进入 CLOSED 状态的客户端无法再接受确认报文段，更无法进入 ESTABLISHED 状态，这将导致服务器长时间单方面等待，造成资源浪费。 
2. 三次握手才能让双方均确认自己和对方的发送和接收能力都正常。 
第一次握手：客户端只是发送处请求报文段，什么都无法确认，而服务器可以确认自己的接收能力和对方的发送能力正常； 
第二次握手：客户端可以确认自己发送能力和接收能力正常，对方发送能力和接收能力正常； 
第三次握手：服务器可以确认自己发送能力和接收能力正常，对方发送能力和接收能力正常； 
可见三次握手才能让双方都确认自己和对方的发送和接收能力全部正常，这样就可以愉快地进行通信了。 
3. 告知对方自己的初始序号值，并确认收到对方的初始序号值。
TCP 实现了可靠的数据传输，原因之一就是 TCP 报文段中维护了序号字段和确认序号字段，
通过这两个字段双方都可以知道在自己发出的数据中，哪些是已经被对方确认接收的。
这两个字段的值会在初始序号值的基础递增，如果是两次握手，只有发起方的初始序号可以得到确认，而另一方的初始序号则得不到确认。 


#### <a name='-1'></a>为什么要三次握手，而不是四次？ 
因为三次握手已经可以确认双方的发送接收能力正常，双方都知道彼此已经准备好，
而且也可以完成对双方初始序号值得确认，也就无需再第四次握手了。 
第一次握手：服务端确认“自己收、客户端发”报文功能正常。 
第二次握手：客户端确认“自己发、自己收、服务端收、客户端发”报文功能正常，客户端认为连接已建立。 
第三次握手：服务端确认“自己发、客户端收”报文功能正常，此时双方均建立连接，可以正常通信。 

三次握手建立连接时，发送方再次发送确认的必要性？ 
主要是为了防止已失效的连接请求报文段突然又传到了 B,因而产生错误。假定
出现一种异常情况，即 A 发出的第一个连接请求报文段并没有丢失，而是在某
些网络结点长时间滞留了，一直延迟到连接释放以后的某个时间才到达 B，本来
这是一个早已失效的报文段。但 B 收到此失效的连接请求报文段后，就误认为是
A 又发出一次 新的连接请求，于是就向 A 发出确认报文段，同意建立连接。假
定不采用三次握手，那么只要 B 发出确认，新的连接就建立了，这样一直等待 A
发来数据，B 的许多 资源就这样白白浪费了。 


#### <a name='ACK'></a>三次握手连接阶段，最后一次 ACK 包丢失，会发生什么？ 
服务端：
第三次的 ACK 在网络中丢失，那么服务端该 TCP 连接的状态为 SYN_RECV,并且会根据 TCP 的超时重传机制，
会等待 3 秒、6 秒、12 秒后重新发送 SYN+ACK包，以便客户端重新发送 ACK 包。 
如果重发指定次数之后，仍然未收到 客户端的 ACK 应答，那么一段时间后，服务端自动关闭这个连接。 
客户端：
客户端认为这个连接已经建立，如果客户端向服务端发送数据，服务端将以 RS 包（Reset，标示复位，用于异常的关闭连接）响应。
此时，客户端知道第三次握手失败。 


#### <a name='-1'></a>为什么连接的时候是三次握手，关闭的时候却是四次握手？ 
服务器在收到客户端的 FIN 报文段后，可能还有一些数据要传输，所以不能马上关闭连接，但是会做出应答，返回 ACK 报文段. 
接下来可能会继续发送数据，在数据发送完后，服务器会向客户单发送 FIN 报文，表示数据已经发送完毕，请求关闭连接。
服务器的 ACK 和 FIN 一般都会分开发送，从而导致多了一次，因此一共需要四次挥手。 


#### <a name='CLOSE-WAIT'></a>CLOSE-WAIT 状态问题
客户端发送了 FIN 连接释放报文之后，服务器收到了这个报文，就进入了CLOSE-WAIT 状态。
这个状态是为了让服务器端发送还未传送完毕的数据，传送完毕之后，服务器会发送 FIN 连接释放报文。 


#### <a name='TIME-WAIT'></a>TIME-WAIT 状态问题
客户端接收到服务器端的 FIN 报文后进入此状态，此时并不是直接进入CLOSED 状态，还需要等待一个时间计时器设置的时间 2MSL。
这么做有两个理由：
1. 确保最后一个确认报文能够到达。如果 B 没收到 A 发送来的确认报文，那么就会重新发送连接释放请求报文，A 等待一段时间就是为了处理这种情况的发生。 
2. 等待一段时间是为了让本连接持续时间内所产生的所有报文都从网络中消失，使得下一个新的连接不会出现旧的连接请求报文。 
通信双方建立 TCP 连接后，主动关闭连接的一方就会进入 TIME_WAIT 状态。 


#### <a name='-1'></a>如果已经建立了连接，但是客户端出现故障了怎么办？或者说，如果三次握手阶段、四次挥手阶段的包丢失了怎么办？
如“服务端重发FIN 丢失”的问题。 
简而言之，通过定时器 + 超时重试机制，尝试获取确认，直到最后会自动断开连接。 
具体而言，TCP 设有一个保活计时器。服务器每收到一次客户端的数据，都会重新复位这个计时器，时间通常是设置为 2 小时。
若 2 小时还没有收到客户端的任何数据，服务器就开始重试：每隔 75 分钟发送一个探测报文段，
若一连发送10 个探测报文后客户端依然没有回应，那么服务器就认为连接已经断开了。 

握手报文丢失
1. 如果第一次握手丢失了，客户端会触发超时重传SYN包；
2. 如果第二次握手丢失了，客户端会触发超时重传SYN包，服务端会触发超时重传SYN+ACK包；
3. 如果第三次握手丢失了，服务端会触发超时重传SYN+ACK包；

挥手报文丢失
1. 第一次挥手丢失了。客户端迟迟收不到服务端的ACK报文，触发超时重传机制；重传 FIN 报文，重发次数由 tcp_orphan_retries 参数控制。
当客户端重传 FIN 报文的次数超过 tcp_orphan_retries 后，就不再发送 FIN 报文，则会在等待一段时间（时间为上一次超时时间的 2 倍），
如果还是没能收到第二次挥手，那么直接进入到 close 状态。
2. 第二次挥手丢失了
ACK 报文是不会重传的，所以如果服务端的第二次挥手丢失了，客户端就会触发超时重传机制，重传 FIN 报文，直到收到服务端的第二次挥手，或者达到最大的重传次数。
3. 第三次挥手丢失了
服务端处于 CLOSE_WAIT 状态时，调用了 close 函数，内核就会发出 FIN 报文，同时连接进入 LAST_ACK 状态，等待客户端返回 ACK 来确认连接关闭。
如果迟迟收不到这个 ACK，服务端就会重发 FIN 报文，重发次数仍然由 tcp_orphan_retries 参数控制，这与客户端重发 FIN 报文的重传次数控制方式是一样的。
客户端和服务端都会断开连接；
4. 第四次挥手丢失了
客户端进入了TIME_WAIT状态，持续2MSL后才会进入关闭状态；
服务端会重发FIN报文；超过了tcp_orphan_retries次数，等待一段事件服务端即关闭；


#### <a name='TIME-WAIT-1'></a>TIME-WAIT 状态过多会产生什么后果？怎样处理？ 
从服务器来讲，短时间内关闭了大量的 Client 连接，就会造成服务器上出现大量的 TIME_WAIT 连接，严重消耗着服务器的资源，此时部分客户端就会显示连接不上。 
从客户端来讲，客户端 TIME_WAIT 过多，就会导致端口资源被占用，因为端口就 65536 个，被占满就会导致无法创建新的连接。 
解决办法：
服务器可以设置 SO_REUSEADDR 套接字选项来避免 TIME_WAIT 状态，此套
接字选项告诉内核，即使此端口正忙（处于 TIME_WAIT 状态），也请继续并重用它。 
调整系统内核参数，修改/etc/sysctl.conf 文件，
即修改 net.ipv4.tcp_tw_reuse 和 tcp_timestamps net.ipv4.tcp_tw_reuse = 1 表示开启重用。允许将 TIME-WAIT sockets 重新用于新的 TCP 连接，默认为 0，表示关闭； 
net.ipv4.tcp_tw_recycle = 1 表示开启 TCP 连接中 TIME-WAIT sockets 的快速回收，默认为 0，表示关闭。 
强制关闭，发送 RST 包越过 TIME_WAIT 状态，直接进入 CLOSED 状态。 


#### <a name='TIME_WAIT'></a>TIME_WAIT 是服务器端的状态?还是客户端的状态?
TIME_WAIT 是主动断开连接的一方会进入的状态，一般情况下，都是客户端所处的状态；服务器端一般设置不主动关闭连接。 
TIME_WAIT 需要等待 2MSL，在大量短连接的情况下，TIME_WAIT 会太多，这也会消耗很多系统资源。
对于服务器来说，在 HTTP 协议里指定 KeepAlive（浏览器重用一个 TCP 连接来处理多个 HTTP 请求），
由浏览器来主动断开连接，可以一定程度上减少服务器的这个问题。 


#### <a name='2ACKSYN'></a>第 2 次握手传回了 ACK，为什么还要传回 SYN？ 
服务端传回发送端所发送的 ACK 是为了告诉客户端：“我接收到的信息确实就是你所发送的信号了”，这表明从客户端到服务端的通信是正常的。
回传 SYN 则是为了建立并确认从服务端到客户端的通信。 
SYN 同步序列编号(Synchronize Sequence Numbers) 是 TCP/IP 建立连接时使用的握手信号。
在客户机和服务器之间建立正常的 TCP 网络连接时，客户机首先发出一个 SYN 消息，服务器使用 SYN-ACK 应答表示接收到了这个消息，
最后客户机再以 ACK(Acknowledgement）消息响应。
这样在客户机和服务器之间才能建立起可靠的 TCP 连接，数据才可以在客户机和服务器之间传递。 



###### TCP快速重传
快速重传的工作方式是当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。
第一份 Seq1 先送到了，于是就 Ack 回 2；
结果 Seq2 因为某些原因没收到，Seq3 到达了，于是还是 Ack 回 2；
后面的 Seq4 和 Seq5 都到了，但还是 Ack 回 2，因为 Seq2 还是没有收到；
发送端收到了三个 Ack = 2 的确认，知道了 Seq2 还没有收到，就会在定时器过期之前，重传丢失的 Seq2。
最后，收到了 Seq2，此时因为 Seq3，Seq4，Seq5 都收到了，于是 Ack 回 6 。

###### TCP SACK方法
selective acknowledgment,选择性确认
TCP 头部「选项」字段里加一个 SACK 的东西，它可以将已收到的数据的信息发送给「发送方」，
这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以只重传丢失的数据。

###### TCP duplicate SACK
主要使用了 SACK 来告诉「发送方」有哪些数据被重复接收了。
「接收方」发给「发送方」的两个 ACK 确认应答都丢失了，所以发送方超时后，重传第一个数据包（3000 ~ 3499）
于是「接收方」发现数据是重复收到的，于是回了一个 SACK = 3000~3500，告诉「发送方」 3000~3500 的数据早已被接收了，因为 ACK 都到了 4000 了，已经意味着 4000 之前的所有数据都已收到，所以这个 SACK 就代表着 D-SACK。
这样「发送方」就知道了，数据没有丢，是「接收方」的 ACK 确认报文丢了。


#### <a name='-1'></a>滑动窗口
窗口大小就是指无需等待确认应答，而可以继续发送数据的最大值。
TCP 头里有一个字段叫 Window，也就是窗口大小。
这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。
所以，通常窗口的大小是由接收方的窗口大小来决定的。
发送方窗口：
已发送但未收到ACK确认的数据+未发送但总大小在接收方处理范围内；
窗口左边是已发送且已收到ACK确认的数据；
窗口右边是未发送但查过接收方处理方位的数据；



#### <a name='TCP-1'></a>TCP拆包沾包原因
TCP 拆包指的是发送方将大块数据分成多个小的数据包进行发送，而接收方可能一次性接收到多个小的数据包。
这可能会导致接收方无法正确解析每个数据包的边界，从而导致数据解析错误。

TCP 粘包则相反，发送方将多个小的数据包连续地发送，接收方可能会一次性接收到多个小的数据包合并成一个大的数据包。
这会导致接收方解析时无法准确判断每个数据包的边界，也会导致数据解析错误。

TCP拆包和沾包现象是由于TCP协议的特性以及网络传输过程中的各种因素所导致的：
TCP协议是基于字节流的传输层协议，没有固定的分包边界。
发送方将数据分成多个小的数据包进行传输，接收方再将这些数据包组合成完整的数据。在这个过程中，可能会出现拆包和沾包现象。

网络传输中的延迟和拥塞会影响数据包发送的速度和到达接收方的顺序。这可能导致数据包的拆分和组合不规律，从而出现拆包和沾包现象。
接收方的缓冲区大小限制。当接收方的缓冲区不足以容纳一个完整的数据包时，可能会将数据包拆分成多个部分，导致拆包现象。
为了解决TCP拆包和沾包的问题，可以采用以下方法：
在应用层实现数据包的边界识别，例如通过添加包头，包头中包含数据包长度等信息，使得接收方能够准确地将数据包进行拼接。
使用固定长度的数据包或者特殊的分隔符，以便于接收方识别数据包的边界。
使用更高级的传输层协议，如WebSocket，它在TCP基础上增加了数据帧的概念，可以更好地解决拆包和沾包问题。


#### <a name='TCP-1'></a>一台机器理论上能创建多少条TCP连接？
如果在不考虑服务器的内存和文件句柄资源的情况下，理论上一个服务端进程最多能支持约为 2 的 48 次方（2^32 (ip数) * 2^16 (端口数），约等于两百多万亿！

但是在实际中是支持不了这个数值的，每个 TCP 连接都是一个文件，会占用文件句柄资源，也会占用一定的内存空间。

一台服务器是可以有多个服务端进程的，每个服务端进程监听不同的端口，当然所有65535个端口你都可以用来监听一遍，这样理论上线就到了2的32次方（ip数）×2的16次方（port数）×2的16次方（服务器port数）个，这个基本相当于无穷个了。

但是 Linux每维护一条TCP连接都要花费内存资源的，每一条静止状态（不发送数据和不接收数据）的 TCP 连接大约需要吃 3.44K 的内存，那么 8 GB 物理内存的服务器，最大能支持的 TCP 连接数=8GB/3.44KB=2,438,956（约240万）。

实际过程中的 TCP 连接，还会进行发送数据和接收数据了，那么这些过程还是会额外消耗更多的内存资源的，并发很难达到百万级别。



## <a name='HTTPS'></a>HTTPS 原理详解 
HTTPS 是对 HTTP 的扩展，保证了通信安全，二者关系如下：HTTPS = HTTP + SSL / TLS。
HTTPS 加密、解密、验证及数据传输过程:
HTTPS 的整个通信过程可以分为两大阶段：证书验证和数据传输阶段，数据传输阶段又可以分为非对称加密和对称加密两个阶段。 
1. 客户端请求 HTTPS 网址，然后连接到 server 的 443 端口 (HTTPS 默认端口，类似于 HTTP 的 80 端口)。 
2. 采用 HTTPS 协议的服务器必须要有一套数字 CA (Certification Authority)证书，
证书是需要申请的，并由专门的数字证书认证机构(CA)通过非常严格的审核之后颁发的电子证书。
颁发证书的同时会产生一个私钥和公钥。私钥由服务端自己保存，不可泄漏。公钥则是附带在证书的信息中，可以公开的。
证书本身也附带一个证书电子签名，这个签名用来验证证书的完整性和真实性，可以防止证书被篡改。 
3. 服务器响应客户端请求，将证书传递给客户端，证书包含公钥和大量其他信息，比如证书颁发机构信息，公司信息和证书有效期等。
Chrome 浏览器点击地址栏的锁标志再点击证书就可以看到证书详细信息。
4. 客户端解析证书并对其进行验证。如果证书不是可信机构颁布，或者证书中的
域名与实际域名不一致，或者证书已经过期，就会向访问者显示一个警告，由其选择是否还要继续通信。
如果证书没有问题，客户端就会从服务器证书中取出服务器的公钥 A。然后客户端还会生成一个随机码 KEY，并使用公钥 A 将其加密。 
5. 客户端把加密后的随机码 KEY 发送给服务器，作为后面对称加密的密钥。 
6. 服务器在收到随机码 KEY 之后会使用私钥 B 将其解密。经过以上这些步骤，
客户端和服务器终于建立了安全连接，完美解决了对称加密的密钥泄露问题，接下来就可以用对称加密愉快地进行通信了。 
7. 服务器使用密钥 (随机码 KEY)对数据进行对称加密并发送给客户端，客户端使用相同的密钥 (随机码 KEY)解密数据。 
8. 双方使用对称加密愉快地传输所有数据。 


#### <a name='-1'></a>对称加密和非对称加密
对称加密
是指加密和解密都使用的同一个密钥，一方通过密钥将信息加密后，把密文传给另一个方，另一方通过这个相同的密钥
将密文解密，转换成可以理解的明文。
他们之间的关系如下:明文 -> 密钥 -> 密文 
这种方式存在的最大的问题就是密钥发送问题，即如何安全的将密钥发送给对方。 

非对称加密 
非对称加密是通过两个密钥（公钥-私钥）来实现对数据的加密和解密的，公钥用于加密，私钥用于解密。

###### 对称加密和非对称加密的区别？
对称加密只使用一个密钥进行加解密，优点是运算速度快，缺点是密钥必须保密，无法做到安全的密钥交换。
非对称加密使用两个密钥：公钥和私钥。公钥可以任意分发而私钥保密，解决了密钥交换问题但速度慢。
公钥和私钥都可以用来加密和解密，流程的不同，意味着目的也不相同：
公钥加密，私钥解密。这个目的是为了保证内容传输的安全，因为被公钥加密的内容，其他人是无法解密的，
只有持有私钥的人，才能解密出实际的内容；
私钥加密，公钥解密。这个目的是为了保证消息不会被冒充，因为私钥是不可泄露的，
如果公钥能正常解密出私钥加密的内容，就能证明这个消息是来源于持有私钥身份的人发送的。
一般我们不会用非对称加密来加密实际的传输内容，因为非对称加密的计算比较耗费性能的。

###### 你分别了解哪些对称加密和非对称加密的算法？
对称加密算法包括：
AES：对称加密算法中最流行和广泛使用的算法之一，支持不同的密钥长度（如AES-128、AES-256）。
非对称加密算法包括：
RSA：最常见的非对称加密算法，用于数据加密和数字签名。
ECC：基于椭圆曲线的非对称加密算法，具有较高的安全性和效率，适用于移动设备等资源受限的环境。
在信息传输过程中，Https用的是对称加密还是非对称加密？
混合加密
HTTPS 采用的是对称加密和非对称加密结合的「混合加密」方式：
在通信建立前采用非对称加密的方式交换「会话秘钥」，后续就不再使用非对称加密。
在通信过程中全部使用对称加密的「会话秘钥」的方式加密明文数据。

###### HTTPS 四次握手过程说一下
SSL/TLS 协议基本流程：
1. 客户端向服务器索要并验证服务器的公钥。
2. 双方协商生产「会话秘钥」。
3. 双方采用「会话秘钥」进行加密通信。
前两步也就是 SSL/TLS 的建立过程，也就是 TLS 握手阶段。

TLS 协议建立的详细流程：

1. ClientHello
首先，由客户端向服务器发起加密通信请求，也就是 ClientHello 请求。
在这一步，客户端主要向服务器发送以下信息：
（1）客户端支持的 TLS 协议版本，如 TLS 1.2 版本。
（2）客户端生产的随机数（Client Random），后面用于生成「会话秘钥」条件之一。
（3）客户端支持的密码套件列表，如 RSA 加密算法。

2. SeverHello
服务器收到客户端请求后，向客户端发出响应，也就是 SeverHello。服务器回应的内容有如下内容：
（1）确认 TLS 协议版本，如果浏览器不支持，则关闭加密通信。
（2）服务器生产的随机数（Server Random），也是后面用于生产「会话秘钥」条件之一。
（3）确认的密码套件列表，如 RSA 加密算法。
（4）服务器的数字证书。

3. 客户端回应
客户端收到服务器的回应之后，首先通过浏览器或者操作系统中的 CA 公钥，确认服务器的数字证书的真实性。
如果证书没有问题，客户端会从数字证书中取出服务器的公钥，然后使用它加密报文，向服务器发送如下信息：
（1）一个随机数（pre-master key）。该随机数会被服务器公钥加密。
（2）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。
（3）客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供服务端校验。
上面第一项的随机数是整个握手阶段的第三个随机数，会发给服务端，所以这个随机数客户端和服务端都是一样的。
服务器和客户端有了这三个随机数（Client Random、Server Random、pre-master key），接着就用双方协商的加密算法，各自生成本次通信的「会话秘钥」。

4. 服务器的最后回应
服务器收到客户端的第三个随机数（pre-master key）之后，通过协商的加密算法，计算出本次通信的「会话秘钥」。
然后，向客户端发送最后的信息：
（1）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。
（2）服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供客户端校验。
至此，整个 TLS 的握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的 HTTP 协议，只不过用「会话秘钥」加密内容。



## <a name='ARP'></a>ARP 
Address Resolution Protocol

ARP 协议是属于网络层的协议，主要作用是实现从 IP 地址转换为 MAC 地址，
在每个主机或者路由器中都建有一个 ARP 缓存表，表中有 IP 地址及 IP 地址对应的 MAC 地址。 
ARP 的工作流程
1. 局域网内，主机 A 要向主机 B 发送 IP 数据报时，首先会在主机 A 的 ARP 缓
存表中查找是否有 IP 地址及其对应的 MAC 地址，如果有，则将 MAC 地址写入
到 MAC 帧的首部，并通过局域网将 MAC 帧发送到 MAC 地址所在的主机 B; 
2. 主机 A 的 ARP 缓存表中没有主机 B 的 IP 地址及所对应的 MAC 地址，主机
A 会在局域网内广播发送一个 ARP 请求分组，局域网内的所有主机都会受到这个 ARP 请求分组； 
3. 在看到主机 A 发送的 ARP 请求分组中有自己的 IP 地址，会向主机 A 以单播
的方式发送一个带有自己 MAC 地址的响应分组； 
4. 收到主机 B 的响应分组后，会在 ARP 缓存表中写入主机 B 的 IP 地址及其 IP地址对应的 MAC 地址； 
5. 主机 A 和主机 B 不在同一个局域网内，即使知道主机 B 的 MAC 地址也是不
能直接通信的，必须通过路由器转发到主机 B 的局域网才能通过 B 的 MAC 地
址找到主机 B。并且主机 A 和主机 B 已经可以通信的情况下，主机 A 的 ARP 缓
存表中存的并不是主机 B 的 IP 地址及其对应的 MAC，而是主机 B 的 IP 地址及
该通信链路上的下一跳路由器的 MAC 地址。 
6. 主机 A 和主机 B 不在同一局域网，这时主机 A 需要先广播找到路由器的 MAC
地址，再由此路由器找到主机 B 所在的下一跳路由器的 MAC 地址，最后这个路
由器再广播到主机 B 的 MAC 地址，建立起通信链路。 



## <a name='http'></a>http
HyperText Transfer Protocol。超文本传输协议。
HTTP 是一个在计算机世界里专门在「两点」之间「传输」文字、图片、音频、视频等「超文本」数据的「约定和规范」。
HTTP 是一个属于应用层的面向对象的协议，由于其简捷、快速的方式，适用于分布式超媒体信息系统。 
HTTP 协议的主要特点可概括如下：
1.支持客户/服务器模式。
2.简单快速：客户向服务器请求服务时，只需传送请求方法和路径。请求方法常用的有 GET、HEAD、POST。
每种方法规定了客户与服务器联系的类型不同。
由于 HTTP 协议简单，使得 HTTP 服务器的程序规模小，因而通信速度很快。 
3.灵活：HTTP 允许传输任意类型的数据对象。正在传输的类型由 Content-Type 加以标记。 
4.无连接：无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。
采用这种方式可以节省传输时间。 
5.无状态：HTTP 协议是无状态协议。无状态是指协议对于事务处理没有记忆能力。
缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。
另一方面，在服务器不需要先前信息时它的应答就较快。

#### <a name='http-1'></a>http为什么是无状态
HTTP被称为无状态协议是因为每个HTTP请求之间是相互独立的，服务器不会在不同请求之间保留客户端的状态信息。
这意味着每个HTTP请求都是独立的，服务器不会记住先前的请求或会话状态。

HTTP无状态的原因：
简单性：无状态使得HTTP协议设计更加简单和灵活，每个请求都可以独立处理，不需要维护复杂的状态信息。
可伸缩性：由于服务器不需要保留客户端状态信息，可以更容易地进行水平扩展，处理更多的并发请求。
易于缓存：无状态使得缓存更加有效，可以缓存响应并在多个请求之间共享，提高性能和减少网络流量。
尽管HTTP是无状态的，但为了处理用户会话和状态管理，通常会使用一些机制来维护状态信息，比如使用Cookies、Session等技术来跟踪用户状态。


#### <a name='HTTPHTTPS'></a>HTTP 和 HTTPS 有什么区别？ 
1. 端口号：HTTP 默认是 80，HTTPS 默认是 443。 
2. URL 前缀：HTTP 的 URL 前缀是 http://，HTTPS 的 URL 前缀是 https://。
3. 安全性和资源消耗 ： HTTP 协议运行在 TCP 之上，所有传输的内容都是明文，客户端和服务器端都无法验证对方的身份。
HTTPS 是运行在 SSL/TLS 之上的 HTTP 协议，SSL/TLS 运行在 TCP 之上。
所有传输的内容都经过加密，加密采用对称加密，但对称加密的密钥用服务器方的证书进行了非对称加密。
所以说，HTTP 安全性没有 HTTPS 高，但是 HTTPS 比 HTTP 耗费更多服务器资源。 


#### <a name='http-1'></a>http 请求方法 
HTTP 请求 8 种方法介绍 HTTP/1.1 协议中共定义了 8 种 HTTP 请求方法，HTTP
请求方法也被叫做“请求动作”，不同的方法规定了不同的操作指定的资源方式。
服务端也会根据不同的请求方法做不同的响应。 
###### GET 
GET 请求会显示请求指定的资源。一般来说 GET 方法应该只用于数据的读取，
而不应当用于会产生副作用的非幂等的操作中。 
GET 方法请求指定的页面信息，并返回响应主体，GET 被认为是不安全的方法，因为 GET 方法会被网络蜘蛛等任意的访问。 

###### HEAD
HEAD 方法与 GET 方法一样，都是向服务器发出指定资源的请求。但是，服务
器在响应 HEAD 请求时不会回传资源的内容部分，即：响应主体。这样，我们可
以不传输全部内容的情况下，就可以获取服务器的响应头信息。HEAD 方法常被用于客户端查看服务器的性能。 

###### POST
POST 请求会 向指定资源提交数据，请求服务器进行处理，如：表单数据提交、文件上传等，请求数据会被包含在请求体中。
POST 方法是非幂等的方法，因为这个请求可能会创建新的资源或/和修改现有资源。 

###### PUT
PUT 请求会身向指定资源位置上传其最新内容，PUT 方法是幂等的方法。通过
该方法客户端可以将指定资源的最新数据传送给服务器取代指定的资源的内容。 

###### DELETE 
DELETE 请求用于请求服务器删除所请求 URI（统一资源标识符，Uniform 
Resource Identifier）所标识的资源。DELETE 请求后指定资源会被删除，DELETE方法也是幂等的。 

###### CONNECT
CONNECT 方法是 HTTP/1.1 协议预留的，能够将连接改为管道方式的代理服务器。
通常用于 SSL 加密服务器的链接与非加密的 HTTP 代理服务器的通信。

###### OPTIONS
OPTIONS 请求与 HEAD 类似，一般也是用于客户端查看服务器的性能。 这个
方法会请求服务器返回该资源所支持的所有 HTTP 请求方法，该方法会用’*’来
代替资源名称，向服务器发送 OPTIONS 请求，可以测试服务器功能是否正常。
JavaScript 的 XMLHttpRequest 对象进行 CORS 跨域资源共享时，就是使用
OPTIONS 方法发送嗅探请求，以判断是否有对指定资源的访问权限。 允许 

###### TRACE 
TRACE 请求服务器回显其收到的请求信息，该方法主要用于 HTTP 请求的测试或诊断。 

HTTP/1.1 之后增加的方法
在 HTTP/1.1 标准制定之后，又陆续扩展了一些方法。其中使用中较多的是PATCH 方法： 
###### PATCH
PATCH 方法出现的较晚，它在 2010 年的 RFC 5789 标准中被定义。PATCH 请
求与 PUT 请求类似，同样用于资源的更新。二者有以下两点不同： 
但 PATCH 一般用于资源的部分更新，而 PUT 一般用于资源的整体更新。 当资
源不存在时，PATCH 会创建一个新的资源，而 PUT 只会对已在资源进行更新。 


#### <a name='httpgetpost'></a>http 请求中 get post 区别 
1. get 请求只能提交 1kb 以下的数据，post 请求可以提交大数据； GET 提交有
数据大小的限制，一般是不超过 1024 个字节，而这种说法也不完全准确，HTTP
协议并没有设定 URL 字节长度的上限，而是浏览器做了些处理，所以长度依据浏览器的不同有所不同；
POST 请求在 HTTP 协议中也没有做说明，一般来说是没有设置限制的，但是实际上浏览器也有默认值。
总体来说，少量的数据使用 GET，大量的数据使用 POST。 
2. get 请求，请求的参数会在浏览器上显示，post 请求它的数据不会再浏览器上显示（安全）； 
3. get 请求用来从服务器上获得资源，而 post 是用来向服务器提交数据；  
4. get 将表单中数据按照 name=value 的形式，添加到 action 所指向的 URL 后
面，并且两者使用"?"连接，而各个变量之间使用"&"连接；post 是将表单中的
数据放在 HTTP 协议的请求头或消息体中，传递到 action 所指向 URL； 
5. 对于 GET 方式，服务器端用 Request.QueryString 获取变量的值，对于 POST方式，服务器端用 Request.Form 获取提交的数据； 
6. GET 是幂等的，即读取同一个资源，总是得到相同的数据，POST 不是幂等的； 


 
#### <a name='http-1'></a>列出常见的 http 状态码和意义 
状态代码有三位数字组成，第一个数字定义响应的类别，共分 5 种类型 
1xx:提示信息--表示请求接受，继续处理 
2xx:成功表示请求成功接收，理解，接受 
3xx:重定向要完成请求必须更进一步操作 
4xx:客户端错误，请求有语法错误或请求无法实现 
5xx:服务器端错误--服务器没有实现合法请求 
 
200 OK-----请求正常处理完毕 
204 No Content-----请求成功处理，没有实体的主体返回 
206 Partial Content-----GET 范围请求已成功处理 
301 Moved Permanently-----永久重定向，比如建设一个网站后，将网站的 url 变换了，重新申请一个域名， 
但是希望之前的用户访问之前 url 仍然可以访问到，就可以做一个重定向新的 url 下面。 
302 Found-----临时重定向，比如用户在未登录时访问个人中心页面，这时可以临时重定向到登录的 url 
303 See Other-----临时重定向，期望使用 GET 定向获取 
304 Not Modified-----发送的附带条件请求未满足,当客户端拥有可能过期的缓存时，会携
带缓存的标识 etag、时间等信息询问服务器缓存是否仍可复用，而 304 是告诉客户端可以复用缓存 
307 Temporary Redirect-----临时重定向，POST 不会变成 GET 
400 Bad Request-----请求报文语法错误或参数错误，服务器无法理解此请求。不作修改，客户程序就无法重复此请求 
401 Unauthorized-----需要通过 HTTP 认证，或认证失败 
403 Forbidden-----请求资源被拒绝,系统中某些页面只有在某些权限下才能访问，当用户
去访问了一个本身没有访问权限的 url，回报 403 错误 
404 Not Found-----无法找到请求资源（服务器无理由拒绝）,一般是自己输入了一个 url，
这个 url 并不合法。404 找不到，Web 服务器找不到您所请求的文件或脚本。请检查URL 以确保路径正确; 
500 Internal Server Error-----服务器故障或 Web 应用故障,比如服务器某一个函数代码出
错了，有没有捕获异常，这时候会报 500 错误。500 服务器的内部错误，Web 服务器不能执行此请求。请稍后重试此请求 
502 Bad Gateway 
通常指代网关或代理服务器从上游服务器接收到无效的响应。这意味着代理服务器无法从上游服务器获取有效的响应。
503 Service Unavailable-----服务器超负载或停机维护,系统正在维护或者服务器暂停的时候，回报 500 错误 
504 Gateway Timeout-----表示在网关或代理服务器尝试访问上游服务器时，等待服务器响应超时。这通常发生在代理服务器等候上游服务器响应的时间超过了限制。


#### <a name='Idempotence'></a>幂等 Idempotence 
HTTP 方法的幂等性是指一次和多次请求某一个资源应该具有同样的副作用。(注意是副作用)；
一个方法被多次重复执行的时候所期望的结果要和第一次执行所期望的结果保持一致；
简单来说就是一个逻辑即使被执行多次，也不影响最终结果的一致性。 
以下两种行为都有可能导致接口被重复执行： 
a. 重复提交或者恶意攻击； 
b. 超时重试机制； 

幂等性的核心思想，其实就是保证这个接口的执行结果只影响一次，后续即使再次调用，也不能对数据产生影响。 

如何解决幂等性问题
两种思路：接口只允许调用一次，比如唯一约束、基于 redis 的锁机制；对数据的影响只会触发一次，比如乐观锁等。 
1. 使用数据库的唯一约束来实现幂等 
比如说对于数据插入的场景而言，假设我们要去创建一个订单，订单号肯定是唯一的，
如果我们多次去触发数据库的唯一约束，它就会产生异常，从而避免一个请求创建多个订单的问题； 
2. 可以使用 redis 提供的 setNX 指令；
比如我们 MQ 消息的场景，我们避免 MQ 重复消费，从而导致数据多次被修改
的问题，可以在接收 MQ 消息的时候，把这个消息通过 setNX 写入到 redis 中，一旦这个消息被消费，我们就不会再次消费； 
3. 使用状态机来实现幂等 
状态机指的是一条数据的完整的运行状态的转化流程，比如说订单的状态，因为
它的状态只会向前变更，所以多次修改同一条数据的时候，一旦状态发生变更，
那么这条数据修改造成的影响也就之后发生一次， 

GET http://www.bank.com/account/123456，不会改变资源的状态，不论调用一次还是
N 次都没有副作用。请注意，这里强调的是一次和 N 次具有相同的副作用，而不是每次 GET 的结果相同。
GET http://www.news.com/latest-news 这个 HTTP 请求可
能会每次得到不同的结果，但它本身并没有产生任何副作用，因而是满足幂等性的。

DELETE 方法用于删除资源，有副作用，但它应该满足幂等性。比如：DELETE 
http://www.forum.com/article/4231，调用一次和 N 次对系统产生的副作用是相同的，
即删掉 id 为 4231 的帖子；因此，调用者可以多次调用或刷新页面而不必担心引起错误。

POST 所对应的 URI 并非创建的资源本身，而是资源的接收者。比如：POST 
http://www.forum.com/articles 的语义是在 http://www.forum.com/articles 下创建一篇帖子，
HTTP 响应中应包含帖子的创建状态以及帖子的 URI。 两次相同的 POST 请求会在服务器端创建两份资源，它们具有不同的 URI；
所以，POST 方法不具备幂等性。 
PUT 所对应的URI是要创建或更新的资源本身。
比如：PUT http://www.forum/articles/4231 的语义是创建或更新 ID 为 4231 的帖子。
对同一URI 进行多次 PUT 的副作用和一次 PUT 是相同的；因此，PUT 方法具有幂等性


#### <a name='HTTP'></a>解释一下 HTTP 长连接和短连接 
在 HTTP/1.0 中，默认使用的是短连接。也就是说，浏览器和服务器每进行一次HTTP 操作，就建立一次连接，但任务结束就中断连接。
如果客户端浏览器访问的某个 HTML 或其他类型的 Web 页中包含有其他的 Web 资源，
如 JavaScript 文件、图像文件、CSS 文件等；当浏览器每遇到这样一个 Web 资源，就会建立一个 HTTP 会话。 
但从 HTTP/1.1 起，默认使用长连接，用以保持连接特性。
使用长连接的 HTTP协议，会在响应头有加入这行代码：Connection:keep-alive 
在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输HTTP 数据的 TCP 连接不会关闭。
如果客户端再次访问这个服务器上的网页，会继续使用这一条已经建立的连接。
Keep-Alive 不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如 Apache）中设定这个时间。
实现长连接要客户端和服务端都支持长连接。 
HTTP 协议的长连接和短连接，实质上是 TCP 协议的长连接和短连接。 

HTTP 的 Keep-Alive 和 TCP 的 Keep-Alive 有些不同，两个意图不一样。
HTTP 的 Keep-Alive 也叫 HTTP 长连接，该功能是由「应用程序」实现的，可以使得用同一个 TCP 连接来发送和接收多个 HTTP 请求/应答， 减少了 HTTP 短连接带来的多次 TCP 连接建立和释放的开销。
TCP 的 Keepalive 也叫 TCP 保活机制，该功能是由「内核」实现的，当客户端和服务端长达一定时间没有进行数据交互时， 内核为了确保该连接是否还有效，就会发送探测报文，来检测对方是否还在线，然后来决定是否要关闭该连接。
sysctl -w net.ipv4.tcp_keepalive_time=120   临时设置tcp超时时间
sysctl -a|grep net.ipv4.tcp_keepalive_time   查看tcp连接超时时间，超过这个时间默认会重试2次，间隔10s


#### <a name='http-1'></a>http常见字段
###### host
客户端发送请求时，用来指定服务器的域名。

###### context-length
服务器在返回数据时，会有 Content-Length 字段，表明本次回应的数据长度。

###### connection
Connection 字段最常用于客户端要求服务器使用「HTTP 长连接」机制，以便其他请求复用。
Connection: Keep-Alive

###### Context-Type
用于服务器回应时，告诉客户端，本次数据是什么格式；
客户端请求的时候，可以使用 Accept 字段声明自己可以接受哪些数据格式。Accept: */*

###### Accept
客户端发送请求时，使用 Accept 字段声明自己可以接受哪些数据格式。
Accept: */*指的是客户端声明自己可以接受任何格式的数据。


###### Context-Encoding
Content-Encoding 字段说明数据的压缩方法。表示服务器返回的数据使用了什么压缩格式


###### 错误码
504 错误码是网关超时错误，通常是nginx将请求代理到后端应用时，后端应用没有在规定的时间返回数据；代理服务器后面的后端服务器已经过载，它要处理的请求报文实在太多，忙不过来了。
502 网关错误
1. 后端服务端设置的超时时间过短,nginx转发后请求还没处理完成，就超时了
2. 看下后端服务端是否宕机或者有崩溃重启过 ps -ef|grep tomcat  如果是的话，可以分析崩溃堆栈日志找出具体原因（如果没有日志，看下是否可能是内存泄露导致进程占用内存越来越多，最后导致超过服务器的最大内存限制，触发OOM，或者是其他原因导致进程主动退出。）
1）通过监控排查服务端应用是否发生过崩溃重启（对服务端的cpu或者内存做过监控，可以看下CPU或内存的监控图是否出现过断崖式的突然下跌。如果有，十有八九百，就是你的服务端应用程序曾经崩溃过）
2）或者ps -o lstart {pid} 看下进程上次的启动时间是什么时候 ，这个时间如果跟你印象中的操作时间有差距，那说明进程可能是崩了之后被重新拉起了。
3. 如果进程没崩溃过，去排查下nginx的日志，看下是否将请求打到了某个不知名IP端口上。（看下nginx配置转发服务端，ip和端口是否请求的是正确地址）
https://juejin.cn/post/7155280646112280613
4. 检查网络连接和防火墙（nginx服务器上telnet后端服务器ip和端口看是否可以访问通）


#### <a name='http-1'></a>http各个版本的特性？
HTTP/1.1 相比 HTTP/1.0 性能上的改进：
1. 使用长连接的方式改善了 HTTP/1.0 短连接造成的性能开销。
2. 支持管道（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。

HTTP/2 相比 HTTP/1.1 性能上的改进：
1. 头部压缩
HTTP/2 会压缩头（Header）如果你同时发出多个请求，他们的头是一样的或是相似的，那么，协议会帮你消除重复的部分。
这就是所谓的 HPACK 算法：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就提高速度了。
2. 二进制格式
HTTP/2 不再像 HTTP/1.1 里的纯文本形式的报文，而是全面采用了二进制格式，头信息和数据体都是二进制，
并且统称为帧（frame）：头信息帧（Headers Frame）和数据帧（Data Frame）。
这样虽然对人不友好，但是对计算机非常友好，因为计算机只懂二进制，那么收到报文后，无需再将明文的报文转成二进制，而是直接解析二进制报文，这增加了数据传输的效率。

3. 并发传输
HTTP/2 引出了 Stream 概念，多个 Stream 复用在一条 TCP 连接。
1 个 TCP 连接包含多个 Stream，Stream 里可以包含 1 个或多个 Message，Message 对应 HTTP/1 中的请求或响应，由 HTTP 头部和包体构成。
Message 里包含一条或者多个 Frame，Frame 是 HTTP/2 最小单位，以二进制压缩格式存放 HTTP/1 中的内容（头部和包体）。
针对不同的 HTTP 请求用独一无二的 Stream ID 来区分，接收端可以通过 Stream ID 有序组装成 HTTP 消息，
不同 Stream 的帧是可以乱序发送的，因此可以并发不同的 Stream ，也就是 HTTP/2 可以并行交错地发送请求和响应。

4. 服务器主动推送资源
HTTP/2 还在一定程度上改善了传统的「请求 - 应答」工作模式，服务端不再是被动地响应，可以主动向客户端发送消息。
客户端和服务器双方都可以建立 Stream， Stream ID 也是有区别的，客户端建立的 Stream 必须是奇数号，而服务器建立的 Stream 必须是偶数号。



## <a name='DNS'></a>DNS 解析的过程
1. 在浏览器中输入 www.qq.com 域名，操作系统会先检查自己本地的 hosts 文件
是否有这个网址映射关系，如果有，就先调用这个 IP 地址映射，完成域名解析。 
2. 如果 hosts 里没有这个域名的映射，则查找本地 DNS 解析器缓存，是否有这
个网址映射关系，如果有，直接返回，完成域名解析。 
3. 如果 hosts 与本地 DNS 解析器缓存都没有相应的网址映射关系，首先会找
TCP/IP 参数中设置的首选 DNS 服务器，在此我们叫它本地 DNS 服务器，此服
务器收到查询时，如果要查询的域名，包含在本地配置区域资源中，则返回解析
结果给客户机，完成域名解析，此解析具有权威性。 
4. 如果要查询的域名，不由本地 DNS 服务器区域解析，但该服务器已缓存了此
网址映射关系，则调用这个 IP 地址映射，完成域名解析，此解析不具有权威性。 
5. 如果本地 DNS 服务器本地区域文件与缓存解析都失效，则根据本地 DNS 服
务器的设置（是否设置转发器）进行查询，如果未用转发模式，本地 DNS 就把
请求发至 “根 DNS 服务器”，“根 DNS 服务器”收到请求后会判断这个域名(.com)
是谁来授权管理，并会返回一个负责该顶级域名服务器的一个 IP。本地 DNS 服
务器收到 IP 信息后，将会联系负责.com 域的这台服务器。这台负责.com 域的服
务器收到请求后，如果自己无法解析，它就会找一个管理.com 域的下一级 DNS
服务器地址(qq.com)给本地 DNS 服务器。当本地 DNS 服务器收到这个地址后，
就会找 qq.com 域服务器，重复上面的动作，进行查询，直至找到 www.qq.com 主机。 
6. 如果用的是转发模式，此 DNS 服务器就会把请求转发至上一级 DNS 服务器，
由上一级服务器进行解析，上一级服务器如果不能解析，或找根 DNS 或把转请
求转至上上级，以此循环。不管本地 DNS 服务器用的是转发，还是根提示，最
后都是把结果返回给本地 DNS 服务器，由此 DNS 服务器再返回给客户机。 

所谓 递归查询过程 就是 “查询的递交者” 更替, 而 迭代查询过程 则是 “查询
的递交者”不变。 

DNS 基于UDP协议实现，DNS使用UDP协议进行域名解析和数据传输。


## <a name='IP'></a>IP
ICMP--用于告知网络包传送过程中产生的错误以及各种控制信息。确认 IP 包是否成功送达目标地址、报告发送过程中 IP 包被废弃的原因和改善网络设置等。
ARP--用于根据 IP 地址查询相应的以太网 MAC 地址。   arp -a查看缓存内容
MTU--一个网络包的最大长度，以太网中的一般为1500字节；
MSS--除了IP和TCP头部后，一个网络包所能容纳的TCP数据的最大长度；

1. 因为路由器是基于 IP 设计的，俗称三层网络设备，路由器的各个端口都具有 MAC 地址和 IP 地址；
而交换机是基于以太网设计的，俗称二层网络设备，交换机的端口不具有 MAC 地址。
2. 


## <a name='IPv6'></a>IPv6
1. 128位,每16位一组，每组用：隔开；
2. 可自动配置，即使没有DHCP服务器也能实现自动分配IP地址；
3. IPv6 包头包首部长度采用固定的值 40 字节，去掉了包头校验和，简化了首部结构，减轻了路由器负荷，大大提高了传输的性能。
4. IPv6 有应对伪造 IP 地址的网络安全功能以及防止线路窃听的功能，大大提升了安全性。


## <a name='DHCP'></a>DHCP
DHCP 客户端进程监听的是 68 端口号，DHCP 服务端进程监听的是 67 端口号。
获取IP的过程：
1. 客户端发送dhcp发现报文，使用UDP广播报文（源地址0.0.0.0，源端口为68，目的地址为255.255.255.255，目的端口为67）；
2. dhcp服务端收到报文后用DHCP提供报文回应，该报文仍然使用 IP 广播地址 255.255.255.255，该报文信息携带服务器提供可租约的 IP 地址、子网掩码、默认网关、DNS 服务器以及 IP 地址租用期。
3. 客户端收到一个或多个服务器的 DHCP 提供报文后，从中选择一个服务器，并向选中的服务器发送 DHCP 请求报文（DHCP REQUEST进行响应，回显配置的参数。
4. 最后，服务端用 DHCP ACK 报文对 DHCP 请求报文进行响应，应答所要求的参数。


## <a name='ICMP'></a>ICMP
Internet Control Message Protocol，也就是互联网控制报文协议。
在 IP 通信中如果某个 IP 包因为某种原因未能达到目标地址，那么这个具体的原因将由 ICMP 负责通知。
1. 网络不可达Network Unreachable，路由表匹配不到接收方IP的网络号；
2. 主机不可达Host Unreachable，路由表没有该主机的信息，或者该主机没有连接到网络；
3. 协议不可达Protocol Unreachable，能找到对端的主机，但是但是对端主机禁止了TCP协议的访问；
4. 端口不可达Port Unreachable,对端主机没有进程监听此端口；
5. 超时消息ICMP Time Exceeded Message，IP 包中有一个字段叫做 TTL （Time To Live，生存周期），它的值随着每经过一次路由器就会减 1，直到减到 0 时该 IP 包会被丢弃。 此时，路由器将会发送一个 ICMP 超时消息给发送端主机，并通知该包已被丢弃。

traceroute <目的地址>    追踪去往目的地时沿途经过的路由；



## <a name='websocket'></a>websocket
http/1.1 101 Switching Protocols\r\n     ## 101状态码，表示协议转换
Connection: Upgrade    ## 浏览器想升级协议
Upgrade: WebSocket     ## 想升级成WebSocket协议
Sec-WebSocket-Key: T2a6wZlAwhgQNqruZ2YUyg==\r\n         ## 随机生成的base64码

websocket只有在建立连接时才用到http,升级完后就和http没有关系了。


## <a name='-1'></a>输入网址后发生了什么？
回答：应用层DNS解析，传输层TCP连接，网络层IP，数据链路MAC，真实物理层，接收到之后再一层层扒皮。

#### <a name='DNS-1'></a>DNS解析的具体过程
DNS 域名解析，简单地说就是把域名翻译成 IP 地址。例如：把 www.baidu.com 这个域名翻译成对应 IP 220.181.38.251。

域名解析流程：
首先，再进行dns服务器解析之前，会查缓存，总共有两次缓存的查询：
浏览器缓存检查：浏览器会首先搜索浏览器自身的 DNS 缓存，缓存时间比较短，大概只有1分钟，且只能容纳 1000 条缓存，看自身的缓存中是否有对应的条目，而且没有过期，如果有且没有过期则解析到此结束。
操作系统缓存检查 + hosts 解析：如果浏览器的缓存里没有找到对应的条目，操作系统也会有一个域名解析的过程，那么浏览器先搜索操作系统的 DNS 缓存中是否有这个域名对应的解析结果，如果找到且没有过期则停止搜索，解析到此结束。在 Linux 中可以通过 /etc/hosts 文件来设置，可以将任何域名解析到任何能够访问的IP 地址。如果在这里指定了一个域名对应的 IP 地址，那么浏览器会首先使用这个 IP地址。当解析到这个配置文件中的某个域名时，操作系统会在缓存中缓存这个解析结果，缓存的时间同样是受这个域名的失效时间和缓存的空间大小控制的。
接着就进行dns解析：
第一步：客户端通过浏览器访问域名为 www.baidu.com (http://www.baidu.com) 的网站，发起查询该域名的 IP 地址的 DNS 请求。该请求发送到了本地 DNS 服务器上。
本地 DNS 服务器会首先查询它的缓存记录，如果缓存中有此条记录，就可以直接返回结果。如果没有，本地 DNS 服务器还要向 DNS 根服务器进行查询。
第二步：本地 DNS 服务器向根服务器发送 DNS 请求，请求域名为 www.baidu.com (http://www.baidu.com) 的 IP 地址。
第三步：根服务器经过查询，没有记录该域名及 IP 地址的对应关系。但是会告诉本地 DNS 服务器，可以到域名服务器上继续查询，并给出域名服务器的地址(.com 服务器)。
第四步：本地 DNS 服务器向 .com 服务器发送 DNS 请求，请求域名 www.baidu.com (http://www.baidu.com) 的 IP 地址。
第五步：com 服务器收到请求后，不会直接返回域名和 IP 地址的对应关系，而是告诉本地DNS 服务器，该域名可以在 baidu.com 域名服务器上进行解析获取 IP 地址，并告诉 baidu.com 域名服务器的地址。
第六步：本地 DNS 服务器向 baidu.com 域名服务器发送 DNS 请求，请求域名 www.baidu.com (http://www.baidu.com) 的 IP 地址。
第七步：baidu.com 服务器收到请求后，在自己的缓存表中发现了该域名和 IP 地址的对应关系，并将 IP 地址返回给本地 DNS 服务器。
第八步：本地 DNS 服务器将获取到与域名对应的 IP 地址返回给客户端，并且将域名和 IP 地址的对应关系保存在缓存中，以备下次别的用户查询时使用。


